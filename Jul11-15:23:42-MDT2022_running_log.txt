rank:0
Namespace(csv='full.csv', dataset='ogbn-products', gpu=0, log_dir='test', lr=0.001, n_epochs=50, n_hidden=128, online=False)
Inited proc group
Max label: tensor(46)
----Data statistics------'
    #Nodes 2449029
    #Edges 126167309
    #Classes/Labels (multi binary labels) 47
    #Train samples 196615
    #Val samples 39323
    #Test samples 2213091
Running on: 0
GCN(
  (layers): ModuleList(
    (0): GraphConv(in=100, out=128, normalization=both, activation=<function relu at 0x14fbed38ec20>)
    (1): GraphConv(in=128, out=47, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0.1, inplace=False)
)
Namespace(csv='full.csv', dataset='ogbn-products', gpu=0, log_dir='test', lr=0.001, n_epochs=50, n_hidden=128, online=False)
epoch:1/50, Iteration 32/32:training loss 3.821605920791626
Train F1-mic 0.0235, Train F1-mac 0.0133
 F1-mic 0.0360,  F1-mac 0.0191
new best val f1: 0.036014786558709065
ogbn-products,dgl,1,0,1.7418,0.0360

 F1-mic 0.0535,  F1-mac 0.0264
new best val f1: 0.05349576678048937
ogbn-products,dgl,1,1,1.9933,0.0535

 F1-mic 0.0742,  F1-mac 0.0342
new best val f1: 0.07421339655712304
ogbn-products,dgl,1,2,2.2463,0.0742

 F1-mic 0.0967,  F1-mac 0.0423
new best val f1: 0.09674929770172126
ogbn-products,dgl,1,3,2.5004,0.0967

 F1-mic 0.1207,  F1-mac 0.0497
new best val f1: 0.12074198485285964
ogbn-products,dgl,1,4,2.7539,0.1207

 F1-mic 0.1446,  F1-mac 0.0567
new best val f1: 0.14462487082546538
ogbn-products,dgl,1,5,3.0076,0.1446

 F1-mic 0.1705,  F1-mac 0.0639
new best val f1: 0.1705185191209941
ogbn-products,dgl,1,6,3.2612,0.1705

 F1-mic 0.1949,  F1-mac 0.0708
new best val f1: 0.19485597293559098
ogbn-products,dgl,1,7,3.5156,0.1949

 F1-mic 0.2191,  F1-mac 0.0773
new best val f1: 0.2190967294160068
ogbn-products,dgl,1,8,3.7696,0.2191

 F1-mic 0.2436,  F1-mac 0.0836
new best val f1: 0.2436284816123693
ogbn-products,dgl,1,9,4.0236,0.2436

epoch:11/50, Iteration 32/32:training loss 3.4852283000946045
Train F1-mic 0.2474, Train F1-mac 0.0840
 F1-mic 0.2682,  F1-mac 0.0895
new best val f1: 0.26818101921701365
ogbn-products,dgl,1,10,4.2777,0.2682

 F1-mic 0.2928,  F1-mac 0.0952
new best val f1: 0.29280404646713576
ogbn-products,dgl,1,11,4.5292,0.2928

 F1-mic 0.3171,  F1-mac 0.1006
new best val f1: 0.31705293636818366
ogbn-products,dgl,1,12,4.7841,0.3171

 F1-mic 0.3410,  F1-mac 0.1061
new best val f1: 0.3410117342666885
ogbn-products,dgl,1,13,5.0378,0.3410

 F1-mic 0.3636,  F1-mac 0.1114
new best val f1: 0.3635648059659544
ogbn-products,dgl,1,14,5.2916,0.3636

 F1-mic 0.3850,  F1-mac 0.1165
new best val f1: 0.3850203177365955
ogbn-products,dgl,1,15,5.5454,0.3850

 F1-mic 0.4052,  F1-mac 0.1215
new best val f1: 0.4052142455958657
ogbn-products,dgl,1,16,5.7990,0.4052

 F1-mic 0.4240,  F1-mac 0.1263
new best val f1: 0.4239780469940007
ogbn-products,dgl,1,17,6.0531,0.4240

 F1-mic 0.4417,  F1-mac 0.1308
new best val f1: 0.44171839296260296
ogbn-products,dgl,1,18,6.3067,0.4417

 F1-mic 0.4579,  F1-mac 0.1349
new best val f1: 0.4578826627553951
ogbn-products,dgl,1,19,6.5609,0.4579

epoch:21/50, Iteration 32/32:training loss 3.1696159839630127
Train F1-mic 0.4649, Train F1-mac 0.1355
 F1-mic 0.4729,  F1-mac 0.1389
new best val f1: 0.4728757199771722
ogbn-products,dgl,1,20,6.8148,0.4729

 F1-mic 0.4870,  F1-mac 0.1428
new best val f1: 0.4870495609986214
ogbn-products,dgl,1,21,7.0662,0.4870

 F1-mic 0.5003,  F1-mac 0.1465
new best val f1: 0.5003165256195972
ogbn-products,dgl,1,22,7.3200,0.5003

 F1-mic 0.5126,  F1-mac 0.1500
new best val f1: 0.5126070279080255
ogbn-products,dgl,1,23,7.5734,0.5126

 F1-mic 0.5237,  F1-mac 0.1534
new best val f1: 0.5237425844667029
ogbn-products,dgl,1,24,7.8272,0.5237

 F1-mic 0.5342,  F1-mac 0.1567
new best val f1: 0.5342247562346059
ogbn-products,dgl,1,25,8.0809,0.5342

 F1-mic 0.5438,  F1-mac 0.1599
new best val f1: 0.5438298741443528
ogbn-products,dgl,1,26,8.3343,0.5438

 F1-mic 0.5529,  F1-mac 0.1630
new best val f1: 0.5528557117624173
ogbn-products,dgl,1,27,8.5880,0.5529

 F1-mic 0.5614,  F1-mac 0.1662
new best val f1: 0.5614206555446658
ogbn-products,dgl,1,28,8.8417,0.5614

 F1-mic 0.5694,  F1-mac 0.1693
new best val f1: 0.5694149043125656
ogbn-products,dgl,1,29,9.0960,0.5694

epoch:31/50, Iteration 32/32:training loss 2.8663017749786377
Train F1-mic 0.5766, Train F1-mac 0.1701
 F1-mic 0.5769,  F1-mac 0.1724
new best val f1: 0.5769116588518051
ogbn-products,dgl,1,30,9.3496,0.5769

 F1-mic 0.5841,  F1-mac 0.1756
new best val f1: 0.5841386549400815
ogbn-products,dgl,1,31,9.6010,0.5841

 F1-mic 0.5907,  F1-mac 0.1786
new best val f1: 0.5906955475396176
ogbn-products,dgl,1,32,9.8546,0.5907

 F1-mic 0.5969,  F1-mac 0.1815
new best val f1: 0.5968981844849579
ogbn-products,dgl,1,33,10.1084,0.5969

 F1-mic 0.6026,  F1-mac 0.1842
new best val f1: 0.6026101050521646
ogbn-products,dgl,1,34,10.3621,0.6026

 F1-mic 0.6081,  F1-mac 0.1870
new best val f1: 0.6081046825458148
ogbn-products,dgl,1,35,10.6161,0.6081

 F1-mic 0.6132,  F1-mac 0.1895
new best val f1: 0.6132264782604963
ogbn-products,dgl,1,36,10.8704,0.6132

 F1-mic 0.6179,  F1-mac 0.1920
new best val f1: 0.6179474770806984
ogbn-products,dgl,1,37,11.1243,0.6179

 F1-mic 0.6223,  F1-mac 0.1943
new best val f1: 0.6222514121651572
ogbn-products,dgl,1,38,11.3780,0.6223

 F1-mic 0.6262,  F1-mac 0.1965
new best val f1: 0.6262291067109306
ogbn-products,dgl,1,39,11.6318,0.6262

epoch:41/50, Iteration 32/32:training loss 2.575362205505371
Train F1-mic 0.6334, Train F1-mac 0.1976
 F1-mic 0.6301,  F1-mac 0.1985
new best val f1: 0.6300649182523448
ogbn-products,dgl,1,40,11.8855,0.6301

 F1-mic 0.6336,  F1-mac 0.2005
new best val f1: 0.6335979858035662
ogbn-products,dgl,1,41,12.1368,0.6336

 F1-mic 0.6368,  F1-mac 0.2022
new best val f1: 0.6367546567222043
ogbn-products,dgl,1,42,12.3906,0.6368

 F1-mic 0.6396,  F1-mac 0.2040
new best val f1: 0.6396257542053173
ogbn-products,dgl,1,43,12.6451,0.6396

 F1-mic 0.6423,  F1-mac 0.2059
new best val f1: 0.6422975828829451
ogbn-products,dgl,1,44,12.8990,0.6423

 F1-mic 0.6447,  F1-mac 0.2078
new best val f1: 0.6447010086797154
ogbn-products,dgl,1,45,13.1525,0.6447

 F1-mic 0.6469,  F1-mac 0.2094
new best val f1: 0.6468513947234885
ogbn-products,dgl,1,46,13.4062,0.6469

 F1-mic 0.6488,  F1-mac 0.2110
new best val f1: 0.6488458902051475
ogbn-products,dgl,1,47,13.6599,0.6488

 F1-mic 0.6507,  F1-mac 0.2126
new best val f1: 0.6506894655484117
ogbn-products,dgl,1,48,13.9142,0.6507

 F1-mic 0.6523,  F1-mac 0.2140
new best val f1: 0.6523446166470335
ogbn-products,dgl,1,49,14.1677,0.6523

epoch:51/50, Iteration 32/32:training loss 2.305936813354492
Train F1-mic 0.6596, Train F1-mac 0.2152
 F1-mic 0.6539,  F1-mac 0.2153
new best val f1: 0.6538818331464906
ogbn-products,dgl,1,50,14.4213,0.6539

 F1-mic 0.6552,  F1-mac 0.2165
new best val f1: 0.6552161659868483
ogbn-products,dgl,1,51,14.6731,0.6552

 F1-mic 0.6565,  F1-mac 0.2177
new best val f1: 0.656461934913657
ogbn-products,dgl,1,52,14.9269,0.6565

 F1-mic 0.6577,  F1-mac 0.2188
new best val f1: 0.6577257781085368
ogbn-products,dgl,1,53,15.1815,0.6577

 F1-mic 0.6589,  F1-mac 0.2200
new best val f1: 0.6589064796702891
ogbn-products,dgl,1,54,15.4356,0.6589

 F1-mic 0.6601,  F1-mac 0.2211
new best val f1: 0.6600641365402508
ogbn-products,dgl,1,55,15.6896,0.6601

 F1-mic 0.6612,  F1-mac 0.2223
new best val f1: 0.6611987487184214
ogbn-products,dgl,1,56,15.9432,0.6612

 F1-mic 0.6624,  F1-mac 0.2235
new best val f1: 0.6623722205729453
ogbn-products,dgl,1,57,16.1971,0.6624

 F1-mic 0.6635,  F1-mac 0.2247
new best val f1: 0.6635113513181338
ogbn-products,dgl,1,58,16.4511,0.6635

 F1-mic 0.6647,  F1-mac 0.2260
new best val f1: 0.6647033492974306
ogbn-products,dgl,1,59,16.7054,0.6647

epoch:61/50, Iteration 32/32:training loss 2.069483757019043
Train F1-mic 0.6719, Train F1-mac 0.2272
 F1-mic 0.6660,  F1-mac 0.2275
new best val f1: 0.6659771333397497
ogbn-products,dgl,1,60,16.9596,0.6660

 F1-mic 0.6673,  F1-mac 0.2289
new best val f1: 0.6672726065037543
ogbn-products,dgl,1,61,17.2111,0.6673

 F1-mic 0.6686,  F1-mac 0.2305
new best val f1: 0.6685947392131638
ogbn-products,dgl,1,62,17.4646,0.6686

 F1-mic 0.6699,  F1-mac 0.2321
new best val f1: 0.6699498574618035
ogbn-products,dgl,1,63,17.7182,0.6699

 F1-mic 0.6713,  F1-mac 0.2336
new best val f1: 0.6713225981218124
ogbn-products,dgl,1,64,17.9720,0.6713

 F1-mic 0.6728,  F1-mac 0.2352
new best val f1: 0.6728295402222503
ogbn-products,dgl,1,65,18.2261,0.6728

 F1-mic 0.6743,  F1-mac 0.2368
new best val f1: 0.6743048523535634
ogbn-products,dgl,1,66,18.4796,0.6743

 F1-mic 0.6759,  F1-mac 0.2384
new best val f1: 0.675884091526286
ogbn-products,dgl,1,67,18.7334,0.6759

 F1-mic 0.6775,  F1-mac 0.2400
new best val f1: 0.6774556491350785
ogbn-products,dgl,1,68,18.9871,0.6775

 F1-mic 0.6790,  F1-mac 0.2415
new best val f1: 0.6789729839396572
ogbn-products,dgl,1,69,19.2416,0.6790

epoch:71/50, Iteration 32/32:training loss 1.870947241783142
Train F1-mic 0.6859, Train F1-mac 0.2428
 F1-mic 0.6805,  F1-mac 0.2430
new best val f1: 0.6805147190061321
ogbn-products,dgl,1,70,19.4952,0.6805

 F1-mic 0.6821,  F1-mac 0.2445
new best val f1: 0.6821432105593489
ogbn-products,dgl,1,71,19.7466,0.6821

 F1-mic 0.6838,  F1-mac 0.2460
new best val f1: 0.6838394806178327
ogbn-products,dgl,1,72,20.0004,0.6838

 F1-mic 0.6855,  F1-mac 0.2474
new best val f1: 0.6854864982958224
ogbn-products,dgl,1,73,20.2539,0.6855

 F1-mic 0.6872,  F1-mac 0.2489
new best val f1: 0.6871985833388686
ogbn-products,dgl,1,74,20.5084,0.6872

 F1-mic 0.6889,  F1-mac 0.2503
new best val f1: 0.688903890531388
ogbn-products,dgl,1,75,20.7624,0.6889

 F1-mic 0.6907,  F1-mac 0.2517
new best val f1: 0.6906706502353496
ogbn-products,dgl,1,76,21.0160,0.6907

 F1-mic 0.6925,  F1-mac 0.2531
new best val f1: 0.6924523212104698
ogbn-products,dgl,1,77,21.2695,0.6925

 F1-mic 0.6942,  F1-mac 0.2545
new best val f1: 0.6942498071701525
ogbn-products,dgl,1,78,21.5233,0.6942

 F1-mic 0.6961,  F1-mac 0.2559
new best val f1: 0.696105130787663
ogbn-products,dgl,1,79,21.7769,0.6961

epoch:81/50, Iteration 32/32:training loss 1.7070529460906982
Train F1-mic 0.7027, Train F1-mac 0.2573
 F1-mic 0.6979,  F1-mac 0.2572
new best val f1: 0.6979496098443309
ogbn-products,dgl,1,80,22.0307,0.6979

 F1-mic 0.6998,  F1-mac 0.2586
new best val f1: 0.699770592352506
ogbn-products,dgl,1,81,22.2821,0.6998

 F1-mic 0.7015,  F1-mac 0.2598
new best val f1: 0.7015201815018
ogbn-products,dgl,1,82,22.5356,0.7015

 F1-mic 0.7033,  F1-mac 0.2611
new best val f1: 0.7033398084398699
ogbn-products,dgl,1,83,22.7902,0.7033

 F1-mic 0.7051,  F1-mac 0.2623
new best val f1: 0.7051259979820079
ogbn-products,dgl,1,84,23.0440,0.7051

 F1-mic 0.7068,  F1-mac 0.2635
new best val f1: 0.706832208887931
ogbn-products,dgl,1,85,23.2979,0.7068

 F1-mic 0.7086,  F1-mac 0.2647
new best val f1: 0.7085790868970142
ogbn-products,dgl,1,86,23.5516,0.7086

 F1-mic 0.7102,  F1-mac 0.2658
new best val f1: 0.7101664594903689
ogbn-products,dgl,1,87,23.8059,0.7102

 F1-mic 0.7118,  F1-mac 0.2669
new best val f1: 0.711833358863237
ogbn-products,dgl,1,88,24.0596,0.7118

 F1-mic 0.7134,  F1-mac 0.2680
new best val f1: 0.7134424205782771
ogbn-products,dgl,1,89,24.3131,0.7134

epoch:91/50, Iteration 32/32:training loss 1.571792721748352
Train F1-mic 0.7197, Train F1-mac 0.2694
 F1-mic 0.7151,  F1-mac 0.2691
new best val f1: 0.71507497884181
ogbn-products,dgl,1,90,24.5669,0.7151

 F1-mic 0.7167,  F1-mac 0.2702
new best val f1: 0.7167301299404317
ogbn-products,dgl,1,91,24.8183,0.7167

 F1-mic 0.7183,  F1-mac 0.2713
new best val f1: 0.7183441620791916
ogbn-products,dgl,1,92,25.0725,0.7183

 F1-mic 0.7199,  F1-mac 0.2723
new best val f1: 0.7199062306972467
ogbn-products,dgl,1,93,25.3260,0.7199

 F1-mic 0.7215,  F1-mac 0.2734
new best val f1: 0.7214601658946694
ogbn-products,dgl,1,94,25.5804,0.7215

 F1-mic 0.7230,  F1-mac 0.2744
new best val f1: 0.7229788562693537
ogbn-products,dgl,1,95,25.8342,0.7230

 F1-mic 0.7245,  F1-mac 0.2755
new best val f1: 0.724501161497652
ogbn-products,dgl,1,96,26.0887,0.7245

 F1-mic 0.7260,  F1-mac 0.2765
new best val f1: 0.7259724069186491
ogbn-products,dgl,1,97,26.3430,0.7260

 F1-mic 0.7274,  F1-mac 0.2776
new best val f1: 0.7274355189190143
ogbn-products,dgl,1,98,26.5965,0.7274

 F1-mic 0.7289,  F1-mac 0.2786
new best val f1: 0.7288904974987473
ogbn-products,dgl,1,99,26.8501,0.7289

epoch:101/50, Iteration 32/32:training loss 1.4600130319595337
Train F1-mic 0.7348, Train F1-mac 0.2800
 F1-mic 0.7303,  F1-mac 0.2797
new best val f1: 0.7302709197226865
ogbn-products,dgl,1,100,27.1037,0.7303

 F1-mic 0.7316,  F1-mac 0.2807
new best val f1: 0.7316427566692919
ogbn-products,dgl,1,101,27.3551,0.7316

 F1-mic 0.7330,  F1-mac 0.2818
new best val f1: 0.7330435124448114
ogbn-products,dgl,1,102,27.6092,0.7330

 F1-mic 0.7343,  F1-mac 0.2827
new best val f1: 0.7343136816335162
ogbn-products,dgl,1,103,27.8631,0.7343

 F1-mic 0.7356,  F1-mac 0.2836
new best val f1: 0.7356064436573101
ogbn-products,dgl,1,104,28.1166,0.7356

 F1-mic 0.7368,  F1-mac 0.2844
new best val f1: 0.7368205826149942
ogbn-products,dgl,1,105,28.3715,0.7368

 F1-mic 0.7380,  F1-mac 0.2853
new best val f1: 0.73803517342938
ogbn-products,dgl,1,106,28.6253,0.7380

 F1-mic 0.7392,  F1-mac 0.2861
new best val f1: 0.7392240084117644
ogbn-products,dgl,1,107,28.8791,0.7392

 F1-mic 0.7403,  F1-mac 0.2869
new best val f1: 0.7403446130321799
ogbn-products,dgl,1,108,29.1327,0.7403

 F1-mic 0.7415,  F1-mac 0.2877
new best val f1: 0.7414954920516147
ogbn-products,dgl,1,109,29.3864,0.7415

epoch:111/50, Iteration 32/32:training loss 1.3673909902572632
Train F1-mic 0.7472, Train F1-mac 0.2889
 F1-mic 0.7426,  F1-mac 0.2885
new best val f1: 0.742600281687468
ogbn-products,dgl,1,110,29.6407,0.7426

 F1-mic 0.7436,  F1-mac 0.2892
new best val f1: 0.743602499852017
ogbn-products,dgl,1,111,29.8929,0.7436

 F1-mic 0.7446,  F1-mac 0.2899
new best val f1: 0.7446182737176194
ogbn-products,dgl,1,112,30.1473,0.7446

 F1-mic 0.7456,  F1-mac 0.2906
new best val f1: 0.745582535919219
ogbn-products,dgl,1,113,30.4009,0.7456

 F1-mic 0.7465,  F1-mac 0.2913
new best val f1: 0.7465377609867827
ogbn-products,dgl,1,114,30.6547,0.7465

 F1-mic 0.7475,  F1-mac 0.2919
new best val f1: 0.7474572893749061
ogbn-products,dgl,1,115,30.9084,0.7475

 F1-mic 0.7483,  F1-mac 0.2925
new best val f1: 0.7483253060990263
ogbn-products,dgl,1,116,31.1622,0.7483

 F1-mic 0.7492,  F1-mac 0.2931
new best val f1: 0.7491996488169714
ogbn-products,dgl,1,117,31.4159,0.7492

 F1-mic 0.7500,  F1-mac 0.2936
new best val f1: 0.7500410059956866
ogbn-products,dgl,1,118,31.6702,0.7500

 F1-mic 0.7509,  F1-mac 0.2942
new best val f1: 0.7508914003084374
ogbn-products,dgl,1,119,31.9247,0.7509

epoch:121/50, Iteration 32/32:training loss 1.2902559041976929
Train F1-mic 0.7564, Train F1-mac 0.2953
 F1-mic 0.7517,  F1-mac 0.2948
new best val f1: 0.7516938978107994
ogbn-products,dgl,1,120,32.1784,0.7517

 F1-mic 0.7525,  F1-mac 0.2953
new best val f1: 0.7525171807214435
ogbn-products,dgl,1,121,32.4305,0.7525

 F1-mic 0.7533,  F1-mac 0.2959
new best val f1: 0.7533237449341216
ogbn-products,dgl,1,122,32.6843,0.7533

 F1-mic 0.7541,  F1-mac 0.2965
new best val f1: 0.7541361832839227
ogbn-products,dgl,1,123,32.9385,0.7541

 F1-mic 0.7549,  F1-mac 0.2971
new best val f1: 0.7548790357016498
ogbn-products,dgl,1,124,33.1919,0.7549

 F1-mic 0.7557,  F1-mac 0.2976
new best val f1: 0.7556521625183962
ogbn-products,dgl,1,125,33.4462,0.7557

 F1-mic 0.7564,  F1-mac 0.2982
new best val f1: 0.7564275486186514
ogbn-products,dgl,1,126,33.7000,0.7564

 F1-mic 0.7572,  F1-mac 0.2988
new best val f1: 0.7571704010363786
ogbn-products,dgl,1,127,33.9542,0.7572

 F1-mic 0.7579,  F1-mac 0.2994
new best val f1: 0.7578978903262451
ogbn-products,dgl,1,128,34.2079,0.7579

 F1-mic 0.7586,  F1-mac 0.3000
new best val f1: 0.7586298981831293
ogbn-products,dgl,1,129,34.4616,0.7586

epoch:131/50, Iteration 32/32:training loss 1.2256836891174316
Train F1-mic 0.7640, Train F1-mac 0.3011
 F1-mic 0.7594,  F1-mac 0.3007
new best val f1: 0.7593578393296978
ogbn-products,dgl,1,130,34.7157,0.7594

 F1-mic 0.7601,  F1-mac 0.3013
new best val f1: 0.7600668024947912
ogbn-products,dgl,1,131,34.9671,0.7601

 F1-mic 0.7608,  F1-mac 0.3020
new best val f1: 0.7607513653979886
ogbn-products,dgl,1,132,35.2206,0.7608

 F1-mic 0.7614,  F1-mac 0.3025
new best val f1: 0.7614178540331148
ogbn-products,dgl,1,133,35.4740,0.7614

 F1-mic 0.7621,  F1-mac 0.3032
new best val f1: 0.7620802759579249
ogbn-products,dgl,1,134,35.7280,0.7621

 F1-mic 0.7628,  F1-mac 0.3039
new best val f1: 0.7627598684374026
ogbn-products,dgl,1,135,35.9817,0.7628

 F1-mic 0.7634,  F1-mac 0.3045
new best val f1: 0.7633942752467024
ogbn-products,dgl,1,136,36.2354,0.7634

 F1-mic 0.7640,  F1-mac 0.3051
new best val f1: 0.7640372673333361
ogbn-products,dgl,1,137,36.4890,0.7640

 F1-mic 0.7647,  F1-mac 0.3058
new best val f1: 0.7646888446973035
ogbn-products,dgl,1,138,36.7425,0.7647

 F1-mic 0.7653,  F1-mac 0.3064
new best val f1: 0.7653449406282886
ogbn-products,dgl,1,139,36.9962,0.7653

epoch:141/50, Iteration 32/32:training loss 1.1712539196014404
Train F1-mic 0.7706, Train F1-mac 0.3075
 F1-mic 0.7659,  F1-mac 0.3070
new best val f1: 0.7659305469137961
ogbn-products,dgl,1,140,37.2499,0.7659

 F1-mic 0.7666,  F1-mac 0.3076
new best val f1: 0.7665617907261835
ogbn-products,dgl,1,141,37.5012,0.7666

 F1-mic 0.7672,  F1-mac 0.3083
new best val f1: 0.7671785751241137
ogbn-products,dgl,1,142,37.7549,0.7672

 F1-mic 0.7678,  F1-mac 0.3089
new best val f1: 0.7678043966560797
ogbn-products,dgl,1,143,38.0089,0.7678

 F1-mic 0.7684,  F1-mac 0.3096
new best val f1: 0.7684320256148527
ogbn-products,dgl,1,144,38.2631,0.7684

 F1-mic 0.7690,  F1-mac 0.3102
new best val f1: 0.7690406765921509
ogbn-products,dgl,1,145,38.5171,0.7690

 F1-mic 0.7696,  F1-mac 0.3108
new best val f1: 0.769645712715835
ogbn-products,dgl,1,146,38.7707,0.7696

 F1-mic 0.7702,  F1-mac 0.3114
new best val f1: 0.7702471339859048
ogbn-products,dgl,1,147,39.0251,0.7702

 F1-mic 0.7708,  F1-mac 0.3119
new best val f1: 0.7708087918662179
ogbn-products,dgl,1,148,39.2787,0.7708

 F1-mic 0.7714,  F1-mac 0.3125
new best val f1: 0.7713980130053396
ogbn-products,dgl,1,149,39.5322,0.7714

epoch:151/50, Iteration 32/32:training loss 1.1250511407852173
Train F1-mic 0.7766, Train F1-mac 0.3136
 F1-mic 0.7720,  F1-mac 0.3130
new best val f1: 0.7719533448918278
ogbn-products,dgl,1,150,39.7857,0.7720

 F1-mic 0.7725,  F1-mac 0.3135
new best val f1: 0.772498284074175
ogbn-products,dgl,1,151,40.0372,0.7725

 F1-mic 0.7730,  F1-mac 0.3140
new best val f1: 0.7730197267080297
ogbn-products,dgl,1,152,40.2907,0.7730

 F1-mic 0.7735,  F1-mac 0.3145
new best val f1: 0.7735443323387967
ogbn-products,dgl,1,153,40.5441,0.7735

 F1-mic 0.7741,  F1-mac 0.3150
new best val f1: 0.7740571896953176
ogbn-products,dgl,1,154,40.7978,0.7741

 F1-mic 0.7746,  F1-mac 0.3155
new best val f1: 0.7746256254261573
ogbn-products,dgl,1,155,41.0521,0.7746

 F1-mic 0.7752,  F1-mac 0.3161
new best val f1: 0.7751561051940477
ogbn-products,dgl,1,156,41.3056,0.7752

 F1-mic 0.7756,  F1-mac 0.3165
new best val f1: 0.7756319103010224
ogbn-products,dgl,1,157,41.5597,0.7756

 F1-mic 0.7761,  F1-mac 0.3170
new best val f1: 0.7761325675265952
ogbn-products,dgl,1,158,41.8139,0.7761

 F1-mic 0.7766,  F1-mac 0.3174
new best val f1: 0.7766296098985537
ogbn-products,dgl,1,159,42.0674,0.7766

epoch:161/50, Iteration 32/32:training loss 1.085546851158142
Train F1-mic 0.7818, Train F1-mac 0.3185
 F1-mic 0.7771,  F1-mac 0.3179
new best val f1: 0.7771031557220196
ogbn-products,dgl,1,160,42.3210,0.7771

 F1-mic 0.7776,  F1-mac 0.3183
new best val f1: 0.777567212554748
ogbn-products,dgl,1,161,42.5725,0.7776

 F1-mic 0.7780,  F1-mac 0.3187
new best val f1: 0.7780213285400376
ogbn-products,dgl,1,162,42.8262,0.7780

 F1-mic 0.7785,  F1-mac 0.3191
new best val f1: 0.7784808668057482
ogbn-products,dgl,1,163,43.0797,0.7785

 F1-mic 0.7789,  F1-mac 0.3195
new best val f1: 0.7789458273518802
ogbn-products,dgl,1,164,43.3335,0.7789

 F1-mic 0.7794,  F1-mac 0.3199
new best val f1: 0.7793728319350628
ogbn-products,dgl,1,165,43.5870,0.7794

 F1-mic 0.7798,  F1-mac 0.3203
new best val f1: 0.779821073783229
ogbn-products,dgl,1,166,43.8406,0.7798

 F1-mic 0.7802,  F1-mac 0.3207
new best val f1: 0.7802485302231132
ogbn-products,dgl,1,167,44.0950,0.7802

 F1-mic 0.7807,  F1-mac 0.3211
new best val f1: 0.7806619791052424
ogbn-products,dgl,1,168,44.3485,0.7807

 F1-mic 0.7811,  F1-mac 0.3215
new best val f1: 0.7810709094203537
ogbn-products,dgl,1,169,44.6030,0.7811

epoch:171/50, Iteration 32/32:training loss 1.051510214805603
Train F1-mic 0.7862, Train F1-mac 0.3226
 F1-mic 0.7815,  F1-mac 0.3218
new best val f1: 0.7814902324396059
ogbn-products,dgl,1,170,44.8568,0.7815

 F1-mic 0.7819,  F1-mac 0.3222
new best val f1: 0.7818928367608924
ogbn-products,dgl,1,171,45.1082,0.7819

 F1-mic 0.7823,  F1-mac 0.3226
new best val f1: 0.7822719445336861
ogbn-products,dgl,1,172,45.3626,0.7823

 F1-mic 0.7827,  F1-mac 0.3230
new best val f1: 0.7826524078765853
ogbn-products,dgl,1,173,45.6163,0.7827

 F1-mic 0.7830,  F1-mac 0.3233
new best val f1: 0.7830310637926773
ogbn-products,dgl,1,174,45.8705,0.7830

 F1-mic 0.7834,  F1-mac 0.3237
new best val f1: 0.7834187568428049
ogbn-products,dgl,1,175,46.1242,0.7834

 F1-mic 0.7838,  F1-mac 0.3240
new best val f1: 0.783791086765072
ogbn-products,dgl,1,176,46.3778,0.7838

 F1-mic 0.7842,  F1-mac 0.3244
new best val f1: 0.7841629648306373
ogbn-products,dgl,1,177,46.6315,0.7842

 F1-mic 0.7845,  F1-mac 0.3247
new best val f1: 0.7845063759239905
ogbn-products,dgl,1,178,46.8853,0.7845

 F1-mic 0.7849,  F1-mac 0.3250
new best val f1: 0.7848768984194504
ogbn-products,dgl,1,179,47.1389,0.7849

epoch:181/50, Iteration 32/32:training loss 1.0219742059707642
Train F1-mic 0.7899, Train F1-mac 0.3262
 F1-mic 0.7852,  F1-mac 0.3253
new best val f1: 0.7852261836499266
ogbn-products,dgl,1,180,47.3926,0.7852

 F1-mic 0.7856,  F1-mac 0.3257
new best val f1: 0.7855813430175261
ogbn-products,dgl,1,181,47.6440,0.7856

 F1-mic 0.7859,  F1-mac 0.3260
new best val f1: 0.7859053242727028
ogbn-products,dgl,1,182,47.8978,0.7859

 F1-mic 0.7863,  F1-mac 0.3263
new best val f1: 0.78626500220732
ogbn-products,dgl,1,183,48.1522,0.7863

 F1-mic 0.7866,  F1-mac 0.3266
new best val f1: 0.7866165467213053
ogbn-products,dgl,1,184,48.4064,0.7866

 F1-mic 0.7869,  F1-mac 0.3269
new best val f1: 0.7869459502569032
ogbn-products,dgl,1,185,48.6601,0.7869

 F1-mic 0.7873,  F1-mac 0.3272
new best val f1: 0.78727761307601
ogbn-products,dgl,1,186,48.9138,0.7873

 F1-mic 0.7876,  F1-mac 0.3276
new best val f1: 0.7876255427363809
ogbn-products,dgl,1,187,49.1681,0.7876

 F1-mic 0.7880,  F1-mac 0.3279
new best val f1: 0.787950427704961
ogbn-products,dgl,1,188,49.4216,0.7880

 F1-mic 0.7883,  F1-mac 0.3282
new best val f1: 0.7882915795148053
ogbn-products,dgl,1,189,49.6753,0.7883

epoch:191/50, Iteration 32/32:training loss 0.9961153864860535
Train F1-mic 0.7934, Train F1-mac 0.3295
 F1-mic 0.7886,  F1-mac 0.3285
new best val f1: 0.7886395091751762
ogbn-products,dgl,1,190,49.9291,0.7886

 F1-mic 0.7890,  F1-mac 0.3288
new best val f1: 0.7889689127107741
ogbn-products,dgl,1,191,50.1811,0.7890

 F1-mic 0.7893,  F1-mac 0.3291
new best val f1: 0.7892775308380903
ogbn-products,dgl,1,192,50.4350,0.7893

 F1-mic 0.7896,  F1-mac 0.3294
new best val f1: 0.7896295272087772
ogbn-products,dgl,1,193,50.6892,0.7896

 F1-mic 0.7899,  F1-mac 0.3297
new best val f1: 0.7899277526319524
ogbn-products,dgl,1,194,50.9430,0.7899

 F1-mic 0.7902,  F1-mac 0.3300
new best val f1: 0.7902422448963915
ogbn-products,dgl,1,195,51.1967,0.7902

 F1-mic 0.7906,  F1-mac 0.3303
new best val f1: 0.7905558334474272
ogbn-products,dgl,1,196,51.4505,0.7906

 F1-mic 0.7909,  F1-mac 0.3305
new best val f1: 0.7908707775685682
ogbn-products,dgl,1,197,51.7041,0.7909

 F1-mic 0.7912,  F1-mac 0.3308
new best val f1: 0.7911635807113219
ogbn-products,dgl,1,198,51.9579,0.7912

 F1-mic 0.7914,  F1-mac 0.3311
new best val f1: 0.7914355984457936
ogbn-products,dgl,1,199,52.2116,0.7914

epoch:201/50, Iteration 32/32:training loss 0.9733246564865112
Train F1-mic 0.7965, Train F1-mac 0.3323
 F1-mic 0.7917,  F1-mac 0.3313
new best val f1: 0.7917284015885474
ogbn-products,dgl,1,200,52.4654,0.7917

 F1-mic 0.7920,  F1-mac 0.3316
new best val f1: 0.7920365678591617
ogbn-products,dgl,1,201,52.7173,0.7920

 F1-mic 0.7923,  F1-mac 0.3318
new best val f1: 0.7922959336059838
ogbn-products,dgl,1,202,52.9713,0.7923

 F1-mic 0.7926,  F1-mac 0.3321
new best val f1: 0.7925711143373679
ogbn-products,dgl,1,203,53.2250,0.7926

 F1-mic 0.7928,  F1-mac 0.3323
new best val f1: 0.7928327393676988
ogbn-products,dgl,1,204,53.4794,0.7928

 F1-mic 0.7931,  F1-mac 0.3325
new best val f1: 0.7930988829650475
ogbn-products,dgl,1,205,53.7336,0.7931

 F1-mic 0.7934,  F1-mac 0.3328
new best val f1: 0.793392137964503
ogbn-products,dgl,1,206,53.9878,0.7934

 F1-mic 0.7937,  F1-mac 0.3330
new best val f1: 0.7936908152443799
ogbn-products,dgl,1,207,54.2421,0.7937

 F1-mic 0.7940,  F1-mac 0.3333
new best val f1: 0.7939614774087465
ogbn-products,dgl,1,208,54.4956,0.7940

 F1-mic 0.7942,  F1-mac 0.3335
new best val f1: 0.7941869539029347
ogbn-products,dgl,1,209,54.7495,0.7942

epoch:211/50, Iteration 32/32:training loss 0.9530619978904724
Train F1-mic 0.7992, Train F1-mac 0.3348
 F1-mic 0.7944,  F1-mac 0.3337
new best val f1: 0.7944187563909483
ogbn-products,dgl,1,210,55.0032,0.7944

 F1-mic 0.7947,  F1-mac 0.3339
new best val f1: 0.7946957445491396
ogbn-products,dgl,1,211,55.2547,0.7947

 F1-mic 0.7949,  F1-mac 0.3341
new best val f1: 0.7949248358969423
ogbn-products,dgl,1,212,55.5085,0.7949

 F1-mic 0.7952,  F1-mac 0.3343
new best val f1: 0.7951842016437644
ogbn-products,dgl,1,213,55.7621,0.7952

 F1-mic 0.7954,  F1-mac 0.3345
new best val f1: 0.7954065151410403
ogbn-products,dgl,1,214,56.0158,0.7954

 F1-mic 0.7956,  F1-mac 0.3347
new best val f1: 0.7956274730682109
ogbn-products,dgl,1,215,56.2694,0.7956

 F1-mic 0.7959,  F1-mac 0.3350
new best val f1: 0.7958610829830314
ogbn-products,dgl,1,216,56.5232,0.7959

 F1-mic 0.7961,  F1-mac 0.3351
new best val f1: 0.79607390748957
ogbn-products,dgl,1,217,56.7770,0.7961

 F1-mic 0.7963,  F1-mac 0.3353
new best val f1: 0.7962966728435478
ogbn-products,dgl,1,218,57.0316,0.7963

 F1-mic 0.7965,  F1-mac 0.3355
new best val f1: 0.7965320901851753
ogbn-products,dgl,1,219,57.2853,0.7965

epoch:221/50, Iteration 32/32:training loss 0.9349333047866821
Train F1-mic 0.8016, Train F1-mac 0.3369
 F1-mic 0.7967,  F1-mac 0.3357
new best val f1: 0.7967336182741694
ogbn-products,dgl,1,220,57.5391,0.7967

 F1-mic 0.7969,  F1-mac 0.3359
new best val f1: 0.7969414723569885
ogbn-products,dgl,1,221,57.7912,0.7969

 F1-mic 0.7972,  F1-mac 0.3361
new best val f1: 0.797171015561493
ogbn-products,dgl,1,222,58.0448,0.7972

 F1-mic 0.7974,  F1-mac 0.3363
new best val f1: 0.7973937809154708
ogbn-products,dgl,1,223,58.2992,0.7974

 F1-mic 0.7976,  F1-mac 0.3365
new best val f1: 0.7976111239890271
ogbn-products,dgl,1,224,58.5538,0.7976

 F1-mic 0.7978,  F1-mac 0.3367
new best val f1: 0.7978456376172511
ogbn-products,dgl,1,225,58.8074,0.7978

 F1-mic 0.7981,  F1-mac 0.3369
new best val f1: 0.7980729215382468
ogbn-products,dgl,1,226,59.0615,0.7981

 F1-mic 0.7983,  F1-mac 0.3371
new best val f1: 0.798294783178821
ogbn-products,dgl,1,227,59.3151,0.7983

 F1-mic 0.7985,  F1-mac 0.3372
new best val f1: 0.7984954075544116
ogbn-products,dgl,1,228,59.5690,0.7985

 F1-mic 0.7987,  F1-mac 0.3374
new best val f1: 0.7987064246341429
ogbn-products,dgl,1,229,59.8225,0.7987

epoch:231/50, Iteration 32/32:training loss 0.9185890555381775
Train F1-mic 0.8037, Train F1-mac 0.3387
 F1-mic 0.7989,  F1-mac 0.3376
new best val f1: 0.7989106638633476
ogbn-products,dgl,1,230,60.0767,0.7989

 F1-mic 0.7991,  F1-mac 0.3378
new best val f1: 0.7991203253729738
ogbn-products,dgl,1,231,60.3282,0.7991

 F1-mic 0.7993,  F1-mac 0.3379
new best val f1: 0.7993272757423894
ogbn-products,dgl,1,232,60.5821,0.7993

 F1-mic 0.7995,  F1-mac 0.3381
new best val f1: 0.799531514971594
ogbn-products,dgl,1,233,60.8359,0.7995

 F1-mic 0.7997,  F1-mac 0.3383
new best val f1: 0.7997398209111148
ogbn-products,dgl,1,234,61.0896,0.7997

 F1-mic 0.8000,  F1-mac 0.3385
new best val f1: 0.7999517417042499
ogbn-products,dgl,1,235,61.3438,0.8000

 F1-mic 0.8001,  F1-mac 0.3386
new best val f1: 0.8001351955251729
ogbn-products,dgl,1,236,61.5974,0.8001

 F1-mic 0.8003,  F1-mac 0.3387
new best val f1: 0.8003213604863063
ogbn-products,dgl,1,237,61.8511,0.8003

 F1-mic 0.8005,  F1-mac 0.3389
new best val f1: 0.8005002957402113
ogbn-products,dgl,1,238,62.1046,0.8005

 F1-mic 0.8007,  F1-mac 0.3391
new best val f1: 0.800702727542609
ogbn-products,dgl,1,239,62.3584,0.8007

epoch:241/50, Iteration 32/32:training loss 0.9037575721740723
Train F1-mic 0.8056, Train F1-mac 0.3404
 F1-mic 0.8009,  F1-mac 0.3393
new best val f1: 0.8009114853388315
ogbn-products,dgl,1,240,62.6130,0.8009

 F1-mic 0.8011,  F1-mac 0.3394
new best val f1: 0.801081383458701
ogbn-products,dgl,1,241,62.8645,0.8011

 F1-mic 0.8013,  F1-mac 0.3396
new best val f1: 0.8012797485507825
ogbn-products,dgl,1,242,63.1182,0.8013

 F1-mic 0.8015,  F1-mac 0.3397
new best val f1: 0.8014735950758464
ogbn-products,dgl,1,243,63.3727,0.8015

 F1-mic 0.8016,  F1-mac 0.3399
new best val f1: 0.8016385227719963
ogbn-products,dgl,1,244,63.6264,0.8016

 F1-mic 0.8018,  F1-mac 0.3400
new best val f1: 0.8018409545743939
ogbn-products,dgl,1,245,63.8800,0.8018

 F1-mic 0.8020,  F1-mac 0.3402
new best val f1: 0.8020311862458436
ogbn-products,dgl,1,246,64.1337,0.8020

 F1-mic 0.8022,  F1-mac 0.3404
new best val f1: 0.802213284496661
ogbn-products,dgl,1,247,64.3878,0.8022

 F1-mic 0.8024,  F1-mac 0.3405
new best val f1: 0.8023976420309874
ogbn-products,dgl,1,248,64.6419,0.8024

 F1-mic 0.8026,  F1-mac 0.3407
new best val f1: 0.8025910366993495
ogbn-products,dgl,1,249,64.8957,0.8026

epoch:251/50, Iteration 32/32:training loss 0.890220046043396
Train F1-mic 0.8075, Train F1-mac 0.3419
 F1-mic 0.8028,  F1-mac 0.3408
new best val f1: 0.8027663570996404
ogbn-products,dgl,1,250,65.1493,0.8028

 F1-mic 0.8029,  F1-mac 0.3410
new best val f1: 0.802929477368983
ogbn-products,dgl,1,251,65.4013,0.8029

 F1-mic 0.8031,  F1-mac 0.3411
new best val f1: 0.8031084126228881
ogbn-products,dgl,1,252,65.6559,0.8031

 F1-mic 0.8033,  F1-mac 0.3413
new best val f1: 0.8032801181695646
ogbn-products,dgl,1,253,65.9105,0.8033

 F1-mic 0.8035,  F1-mac 0.3414
new best val f1: 0.8034635719904873
ogbn-products,dgl,1,254,66.1643,0.8035

 F1-mic 0.8036,  F1-mac 0.3416
new best val f1: 0.8036262404031285
ogbn-products,dgl,1,255,66.4179,0.8036

 F1-mic 0.8038,  F1-mac 0.3417
new best val f1: 0.8037807753951374
ogbn-products,dgl,1,256,66.6713,0.8038

 F1-mic 0.8040,  F1-mac 0.3420
new best val f1: 0.8039515772284104
ogbn-products,dgl,1,257,66.9250,0.8040

 F1-mic 0.8041,  F1-mac 0.3422
new best val f1: 0.804131416195719
ogbn-products,dgl,1,258,67.1785,0.8041

 F1-mic 0.8043,  F1-mac 0.3425
new best val f1: 0.8043031217423956
ogbn-products,dgl,1,259,67.4323,0.8043

epoch:261/50, Iteration 32/32:training loss 0.877806544303894
Train F1-mic 0.8092, Train F1-mac 0.3437
 F1-mic 0.8045,  F1-mac 0.3428
new best val f1: 0.8044965164107576
ogbn-products,dgl,1,260,67.6860,0.8045

 F1-mic 0.8047,  F1-mac 0.3430
new best val f1: 0.8046709330976449
ogbn-products,dgl,1,261,67.9376,0.8047

 F1-mic 0.8048,  F1-mac 0.3432
new best val f1: 0.804847609068041
ogbn-products,dgl,1,262,68.1914,0.8048

 F1-mic 0.8050,  F1-mac 0.3434
new best val f1: 0.8050324184590693
ogbn-products,dgl,1,263,68.4457,0.8050

 F1-mic 0.8052,  F1-mac 0.3437
new best val f1: 0.8052014128655351
ogbn-products,dgl,1,264,68.7000,0.8052

 F1-mic 0.8054,  F1-mac 0.3440
new best val f1: 0.8053862222565632
ogbn-products,dgl,1,265,68.9545,0.8054

 F1-mic 0.8056,  F1-mac 0.3442
new best val f1: 0.8055592833733453
ogbn-products,dgl,1,266,69.2080,0.8056

 F1-mic 0.8057,  F1-mac 0.3443
new best val f1: 0.8057468039045842
ogbn-products,dgl,1,267,69.4617,0.8057

 F1-mic 0.8059,  F1-mac 0.3446
new best val f1: 0.8058968203295752
ogbn-products,dgl,1,268,69.7153,0.8059

 F1-mic 0.8061,  F1-mac 0.3447
new best val f1: 0.8060590368855144
ogbn-products,dgl,1,269,69.9690,0.8061

epoch:271/50, Iteration 32/32:training loss 0.8663924336433411
Train F1-mic 0.8109, Train F1-mac 0.3459
 F1-mic 0.8062,  F1-mac 0.3449
new best val f1: 0.8062185423012428
ogbn-products,dgl,1,270,70.2229,0.8062

 F1-mic 0.8064,  F1-mac 0.3451
new best val f1: 0.8063753365767607
ogbn-products,dgl,1,271,70.4745,0.8064

 F1-mic 0.8065,  F1-mac 0.3452
new best val f1: 0.8065294197120678
ogbn-products,dgl,1,272,70.7283,0.8065

 F1-mic 0.8067,  F1-mac 0.3455
new best val f1: 0.8066830509906733
ogbn-products,dgl,1,273,70.9827,0.8067

 F1-mic 0.8068,  F1-mac 0.3456
new best val f1: 0.8068357785558751
ogbn-products,dgl,1,274,71.2363,0.8068

 F1-mic 0.8070,  F1-mac 0.3458
new best val f1: 0.8070011581087266
ogbn-products,dgl,1,275,71.4901,0.8070

 F1-mic 0.8072,  F1-mac 0.3459
new best val f1: 0.807150722677016
ogbn-products,dgl,1,276,71.7439,0.8072

 F1-mic 0.8073,  F1-mac 0.3461
new best val f1: 0.8072989316752
ogbn-products,dgl,1,277,71.9974,0.8073

 F1-mic 0.8074,  F1-mac 0.3462
new best val f1: 0.8074498518135946
ogbn-products,dgl,1,278,72.2510,0.8074

 F1-mic 0.8076,  F1-mac 0.3464
new best val f1: 0.8076089053726214
ogbn-products,dgl,1,279,72.5047,0.8076

epoch:281/50, Iteration 32/32:training loss 0.8558405041694641
Train F1-mic 0.8124, Train F1-mac 0.3476
 F1-mic 0.8078,  F1-mac 0.3466
new best val f1: 0.8077584699409107
ogbn-products,dgl,1,280,72.7583,0.8078

 F1-mic 0.8079,  F1-mac 0.3467
new best val f1: 0.8078989973751645
ogbn-products,dgl,1,281,73.0098,0.8079

 F1-mic 0.8081,  F1-mac 0.3468
new best val f1: 0.8080503693702609
ogbn-products,dgl,1,282,73.2634,0.8081

 F1-mic 0.8082,  F1-mac 0.3470
new best val f1: 0.8082116822127965
ogbn-products,dgl,1,283,73.5171,0.8082

 F1-mic 0.8084,  F1-mac 0.3472
new best val f1: 0.8083964916038247
ogbn-products,dgl,1,284,73.7709,0.8084

 F1-mic 0.8085,  F1-mac 0.3473
new best val f1: 0.8085474117422193
ogbn-products,dgl,1,285,74.0255,0.8085

 F1-mic 0.8087,  F1-mac 0.3474
new best val f1: 0.8086775464723321
ogbn-products,dgl,1,286,74.2792,0.8087

 F1-mic 0.8088,  F1-mac 0.3476
new best val f1: 0.8088140071962698
ogbn-products,dgl,1,287,74.5329,0.8088

 F1-mic 0.8090,  F1-mac 0.3478
new best val f1: 0.8089834534594375
ogbn-products,dgl,1,288,74.7869,0.8090

 F1-mic 0.8091,  F1-mac 0.3480
new best val f1: 0.8091370847380428
ogbn-products,dgl,1,289,75.0414,0.8091

epoch:291/50, Iteration 32/32:training loss 0.8460395336151123
Train F1-mic 0.8139, Train F1-mac 0.3492
 F1-mic 0.8093,  F1-mac 0.3481
new best val f1: 0.8093128569950354
ogbn-products,dgl,1,290,75.2954,0.8093

 F1-mic 0.8095,  F1-mac 0.3483
new best val f1: 0.8094664882736408
ogbn-products,dgl,1,291,75.5468,0.8095

 F1-mic 0.8096,  F1-mac 0.3484
new best val f1: 0.8096160528419302
ogbn-products,dgl,1,292,75.8004,0.8096

 F1-mic 0.8098,  F1-mac 0.3486
new best val f1: 0.8097660692669213
ogbn-products,dgl,1,293,76.0543,0.8098

 F1-mic 0.8099,  F1-mac 0.3488
new best val f1: 0.8099174412620178
ogbn-products,dgl,1,294,76.3081,0.8099

 F1-mic 0.8100,  F1-mac 0.3489
new best val f1: 0.8100439611385162
ogbn-products,dgl,1,295,76.5618,0.8100

 F1-mic 0.8102,  F1-mac 0.3490
new best val f1: 0.8101682217315058
ogbn-products,dgl,1,296,76.8160,0.8102

 F1-mic 0.8103,  F1-mac 0.3492
new best val f1: 0.810315978872988
ogbn-products,dgl,1,297,77.0697,0.8103

 F1-mic 0.8105,  F1-mac 0.3493
new best val f1: 0.8104678027247862
ogbn-products,dgl,1,298,77.3232,0.8105

 F1-mic 0.8106,  F1-mac 0.3495
new best val f1: 0.8106006485951097
ogbn-products,dgl,1,299,77.5769,0.8106

epoch:301/50, Iteration 32/32:training loss 0.8368998765945435
Train F1-mic 0.8154, Train F1-mac 0.3507
 F1-mic 0.8107,  F1-mac 0.3496
new best val f1: 0.8107325907520295
ogbn-products,dgl,1,300,77.8304,0.8107

 F1-mic 0.8109,  F1-mac 0.3498
new best val f1: 0.8108767330398977
ogbn-products,dgl,1,301,78.0817,0.8109

 F1-mic 0.8110,  F1-mac 0.3500
new best val f1: 0.8110348828855208
ogbn-products,dgl,1,302,78.3356,0.8110

 F1-mic 0.8112,  F1-mac 0.3501
new best val f1: 0.8111717954661601
ogbn-products,dgl,1,303,78.5895,0.8112

 F1-mic 0.8113,  F1-mac 0.3502
new best val f1: 0.8113249748880638
ogbn-products,dgl,1,304,78.8435,0.8113

 F1-mic 0.8115,  F1-mac 0.3504
new best val f1: 0.8114510429078605
ogbn-products,dgl,1,305,79.0972,0.8115

 F1-mic 0.8116,  F1-mac 0.3506
new best val f1: 0.8115802739245697
ogbn-products,dgl,1,306,79.3508,0.8116

 F1-mic 0.8117,  F1-mac 0.3506
new best val f1: 0.8116878158195935
ogbn-products,dgl,1,307,79.6047,0.8117

 F1-mic 0.8118,  F1-mac 0.3508
new best val f1: 0.8118301506806543
ogbn-products,dgl,1,308,79.8583,0.8118

 F1-mic 0.8120,  F1-mac 0.3509
new best val f1: 0.8119562187004511
ogbn-products,dgl,1,309,80.1120,0.8120

epoch:311/50, Iteration 32/32:training loss 0.8283382654190063
Train F1-mic 0.8167, Train F1-mac 0.3520
 F1-mic 0.8121,  F1-mac 0.3510
new best val f1: 0.8120813830068443
ogbn-products,dgl,1,310,80.3656,0.8121

 F1-mic 0.8122,  F1-mac 0.3511
new best val f1: 0.8122101621668516
ogbn-products,dgl,1,311,80.6175,0.8122

 F1-mic 0.8123,  F1-mac 0.3513
new best val f1: 0.8123380376134557
ogbn-products,dgl,1,312,80.8717,0.8123

 F1-mic 0.8125,  F1-mac 0.3514
new best val f1: 0.8124699797703755
ogbn-products,dgl,1,313,81.1254,0.8125

 F1-mic 0.8126,  F1-mac 0.3515
new best val f1: 0.8125974033602775
ogbn-products,dgl,1,314,81.3791,0.8126

 F1-mic 0.8127,  F1-mac 0.3517
new best val f1: 0.8127374789378294
ogbn-products,dgl,1,315,81.6328,0.8127

 F1-mic 0.8129,  F1-mac 0.3518
new best val f1: 0.8128630951009245
ogbn-products,dgl,1,316,81.8865,0.8129

 F1-mic 0.8130,  F1-mac 0.3520
new best val f1: 0.8130104003857049
ogbn-products,dgl,1,317,82.1403,0.8130

 F1-mic 0.8131,  F1-mac 0.3521
new best val f1: 0.8131351128353963
ogbn-products,dgl,1,318,82.3942,0.8131

 F1-mic 0.8133,  F1-mac 0.3523
new best val f1: 0.8132553067180699
ogbn-products,dgl,1,319,82.6480,0.8133

epoch:321/50, Iteration 32/32:training loss 0.8203077912330627
Train F1-mic 0.8179, Train F1-mac 0.3534
 F1-mic 0.8134,  F1-mac 0.3524
new best val f1: 0.8133551670491633
ogbn-products,dgl,1,320,82.9015,0.8134

 F1-mic 0.8135,  F1-mac 0.3525
new best val f1: 0.8134577385204675
ogbn-products,dgl,1,321,83.1529,0.8135

 F1-mic 0.8136,  F1-mac 0.3526
new best val f1: 0.813590584390791
ogbn-products,dgl,1,322,83.4067,0.8136

 F1-mic 0.8137,  F1-mac 0.3527
new best val f1: 0.8137184598373949
ogbn-products,dgl,1,323,83.6604,0.8137

 F1-mic 0.8138,  F1-mac 0.3529
new best val f1: 0.8138300684427346
ogbn-products,dgl,1,324,83.9147,0.8138

 F1-mic 0.8140,  F1-mac 0.3530
new best val f1: 0.813957040175935
ogbn-products,dgl,1,325,84.1685,0.8140

 F1-mic 0.8141,  F1-mac 0.3531
new best val f1: 0.814096663896785
ogbn-products,dgl,1,326,84.4223,0.8141

 F1-mic 0.8142,  F1-mac 0.3533
new best val f1: 0.8142078206454231
ogbn-products,dgl,1,327,84.6765,0.8142

 F1-mic 0.8143,  F1-mac 0.3534
new best val f1: 0.8143234959610789
ogbn-products,dgl,1,328,84.9300,0.8143

 F1-mic 0.8144,  F1-mac 0.3535
new best val f1: 0.8144482084107703
ogbn-products,dgl,1,329,85.1839,0.8144

epoch:331/50, Iteration 32/32:training loss 0.8127497434616089
Train F1-mic 0.8191, Train F1-mac 0.3547
 F1-mic 0.8146,  F1-mac 0.3536
new best val f1: 0.814570209720251
ogbn-products,dgl,1,330,85.4382,0.8146

 F1-mic 0.8147,  F1-mac 0.3538
new best val f1: 0.8146890480328193
ogbn-products,dgl,1,331,85.6895,0.8147

 F1-mic 0.8148,  F1-mac 0.3539
new best val f1: 0.8147803230865789
ogbn-products,dgl,1,332,85.9434,0.8148

 F1-mic 0.8149,  F1-mac 0.3540
new best val f1: 0.8148847019846902
ogbn-products,dgl,1,333,86.1968,0.8149

 F1-mic 0.8150,  F1-mac 0.3541
new best val f1: 0.8150008291570477
ogbn-products,dgl,1,334,86.4505,0.8150

 F1-mic 0.8151,  F1-mac 0.3542
new best val f1: 0.8151160526160017
ogbn-products,dgl,1,335,86.7043,0.8151

 F1-mic 0.8152,  F1-mac 0.3543
new best val f1: 0.8152244982244292
ogbn-products,dgl,1,336,86.9582,0.8152

 F1-mic 0.8154,  F1-mac 0.3545
new best val f1: 0.8153550848112436
ogbn-products,dgl,1,337,87.2123,0.8154

 F1-mic 0.8155,  F1-mac 0.3546
new best val f1: 0.8154698564134959
ogbn-products,dgl,1,338,87.4659,0.8155

 F1-mic 0.8156,  F1-mac 0.3547
new best val f1: 0.8155683611744841
ogbn-products,dgl,1,339,87.7199,0.8156

epoch:341/50, Iteration 32/32:training loss 0.8056190609931946
Train F1-mic 0.8202, Train F1-mac 0.3558
 F1-mic 0.8157,  F1-mac 0.3548
new best val f1: 0.8156912661973683
ogbn-products,dgl,1,340,87.9742,0.8157

 F1-mic 0.8158,  F1-mac 0.3549
new best val f1: 0.8157965488088832
ogbn-products,dgl,1,341,88.2257,0.8158

 F1-mic 0.8159,  F1-mac 0.3551
new best val f1: 0.815905898130714
ogbn-products,dgl,1,342,88.4803,0.8159

 F1-mic 0.8160,  F1-mac 0.3552
new best val f1: 0.8160156993092467
ogbn-products,dgl,1,343,88.7344,0.8160

 F1-mic 0.8161,  F1-mac 0.3554
new best val f1: 0.8161363450486221
ogbn-products,dgl,1,344,88.9880,0.8161

 F1-mic 0.8163,  F1-mac 0.3555
new best val f1: 0.8162615093550152
ogbn-products,dgl,1,345,89.2425,0.8163

 F1-mic 0.8164,  F1-mac 0.3556
new best val f1: 0.8163672438232319
ogbn-products,dgl,1,346,89.4968,0.8164

 F1-mic 0.8165,  F1-mac 0.3557
new best val f1: 0.8164856302790984
ogbn-products,dgl,1,347,89.7503,0.8165

 F1-mic 0.8166,  F1-mac 0.3558
new best val f1: 0.816597238884438
ogbn-products,dgl,1,348,90.0044,0.8166

 F1-mic 0.8167,  F1-mac 0.3560
new best val f1: 0.8166848990845835
ogbn-products,dgl,1,349,90.2588,0.8167

epoch:351/50, Iteration 32/32:training loss 0.7988796234130859
Train F1-mic 0.8213, Train F1-mac 0.3570
 F1-mic 0.8168,  F1-mac 0.3561
new best val f1: 0.8167915372662037
ogbn-products,dgl,1,350,90.5124,0.8168

 F1-mic 0.8169,  F1-mac 0.3562
new best val f1: 0.8169035977282453
ogbn-products,dgl,1,351,90.7639,0.8169

 F1-mic 0.8170,  F1-mac 0.3563
new best val f1: 0.8170039099160405
ogbn-products,dgl,1,352,91.0177,0.8170

 F1-mic 0.8171,  F1-mac 0.3564
new best val f1: 0.817115970378082
ogbn-products,dgl,1,353,91.2713,0.8171

 F1-mic 0.8172,  F1-mac 0.3566
new best val f1: 0.8172239641298076
ogbn-products,dgl,1,354,91.5251,0.8172

 F1-mic 0.8173,  F1-mac 0.3567
new best val f1: 0.8173337653083403
ogbn-products,dgl,1,355,91.7792,0.8173

 F1-mic 0.8174,  F1-mac 0.3568
new best val f1: 0.8174250403620998
ogbn-products,dgl,1,356,92.0333,0.8174

 F1-mic 0.8175,  F1-mac 0.3570
new best val f1: 0.817523545123088
ogbn-products,dgl,1,357,92.2868,0.8175

 F1-mic 0.8176,  F1-mac 0.3571
new best val f1: 0.817620242457269
ogbn-products,dgl,1,358,92.5406,0.8176

 F1-mic 0.8177,  F1-mac 0.3572
new best val f1: 0.8177241694986785
ogbn-products,dgl,1,359,92.7943,0.8177

epoch:361/50, Iteration 32/32:training loss 0.7924901843070984
Train F1-mic 0.8223, Train F1-mac 0.3582
 F1-mic 0.8178,  F1-mac 0.3572
new best val f1: 0.8177973702843669
ogbn-products,dgl,1,360,93.0480,0.8178

 F1-mic 0.8179,  F1-mac 0.3573
new best val f1: 0.8178958750453551
ogbn-products,dgl,1,361,93.3001,0.8179

 F1-mic 0.8180,  F1-mac 0.3575
new best val f1: 0.8180029650836771
ogbn-products,dgl,1,362,93.5547,0.8180

 F1-mic 0.8181,  F1-mac 0.3576
new best val f1: 0.8181032772714723
ogbn-products,dgl,1,363,93.8081,0.8181

 F1-mic 0.8182,  F1-mac 0.3577
new best val f1: 0.818209011739689
ogbn-products,dgl,1,364,94.0617,0.8182

 F1-mic 0.8183,  F1-mac 0.3578
new best val f1: 0.8183246870553447
ogbn-products,dgl,1,365,94.3159,0.8183

 F1-mic 0.8184,  F1-mac 0.3580
new best val f1: 0.8184426216545094
ogbn-products,dgl,1,366,94.5696,0.8184

 F1-mic 0.8185,  F1-mac 0.3581
new best val f1: 0.8185483561227261
ogbn-products,dgl,1,367,94.8232,0.8185

 F1-mic 0.8187,  F1-mac 0.3582
new best val f1: 0.8186604165847676
ogbn-products,dgl,1,368,95.0770,0.8187

 F1-mic 0.8188,  F1-mac 0.3583
new best val f1: 0.8187562102055451
ogbn-products,dgl,1,369,95.3308,0.8188

epoch:371/50, Iteration 32/32:training loss 0.7864256501197815
Train F1-mic 0.8233, Train F1-mac 0.3593
 F1-mic 0.8189,  F1-mac 0.3584
new best val f1: 0.8188565223933404
ogbn-products,dgl,1,370,95.5843,0.8189

 F1-mic 0.8189,  F1-mac 0.3585
new best val f1: 0.8189468937336963
ogbn-products,dgl,1,371,95.8366,0.8189

 F1-mic 0.8190,  F1-mac 0.3586
new best val f1: 0.819048561491597
ogbn-products,dgl,1,372,96.0903,0.8190

 F1-mic 0.8191,  F1-mac 0.3587
new best val f1: 0.8191497773927958
ogbn-products,dgl,1,373,96.3443,0.8191

 F1-mic 0.8192,  F1-mac 0.3589
new best val f1: 0.8192433117300644
ogbn-products,dgl,1,374,96.5983,0.8192

 F1-mic 0.8193,  F1-mac 0.3590
new best val f1: 0.8193499499116847
ogbn-products,dgl,1,375,96.8521,0.8193

 F1-mic 0.8194,  F1-mac 0.3591
new best val f1: 0.8194470991025674
ogbn-products,dgl,1,376,97.1059,0.8194

 F1-mic 0.8195,  F1-mac 0.3592
new best val f1: 0.8195266258820809
ogbn-products,dgl,1,377,97.3602,0.8195

 F1-mic 0.8196,  F1-mac 0.3593
new best val f1: 0.8196251306430689
ogbn-products,dgl,1,378,97.6140,0.8196

 F1-mic 0.8197,  F1-mac 0.3595
new best val f1: 0.8197105315597055
ogbn-products,dgl,1,379,97.8674,0.8197

epoch:381/50, Iteration 32/32:training loss 0.7806558012962341
Train F1-mic 0.8242, Train F1-mac 0.3605
 F1-mic 0.8198,  F1-mac 0.3596
new best val f1: 0.8197891546258153
ogbn-products,dgl,1,380,98.1212,0.8198

 F1-mic 0.8199,  F1-mac 0.3597
new best val f1: 0.8198998595177515
ogbn-products,dgl,1,381,98.3728,0.8199

 F1-mic 0.8200,  F1-mac 0.3598
new best val f1: 0.8199929419983182
ogbn-products,dgl,1,382,98.6263,0.8200

 F1-mic 0.8201,  F1-mac 0.3599
new best val f1: 0.8200824096252707
ogbn-products,dgl,1,383,98.8800,0.8201

 F1-mic 0.8202,  F1-mac 0.3600
new best val f1: 0.8201813662429607
ogbn-products,dgl,1,384,99.1339,0.8202

 F1-mic 0.8203,  F1-mac 0.3601
new best val f1: 0.820302011982336
ogbn-products,dgl,1,385,99.3881,0.8203

 F1-mic 0.8204,  F1-mac 0.3602
new best val f1: 0.8204158798711846
ogbn-products,dgl,1,386,99.6423,0.8204

 F1-mic 0.8205,  F1-mac 0.3604
new best val f1: 0.8205121253486638
ogbn-products,dgl,1,387,99.8959,0.8205

 F1-mic 0.8206,  F1-mac 0.3605
new best val f1: 0.8206011411189147
ogbn-products,dgl,1,388,100.1496,0.8206

 F1-mic 0.8207,  F1-mac 0.3606
new best val f1: 0.8206838308953405
ogbn-products,dgl,1,389,100.4035,0.8207

epoch:391/50, Iteration 32/32:training loss 0.7751625776290894
Train F1-mic 0.8252, Train F1-mac 0.3616
 F1-mic 0.8208,  F1-mac 0.3607
new best val f1: 0.820769231811977
ogbn-products,dgl,1,390,100.6572,0.8208

 F1-mic 0.8209,  F1-mac 0.3609
new best val f1: 0.8208686402863687
ogbn-products,dgl,1,391,100.9092,0.8209

 F1-mic 0.8210,  F1-mac 0.3610
new best val f1: 0.8209572041999176
ogbn-products,dgl,1,392,101.1630,0.8210

 F1-mic 0.8210,  F1-mac 0.3611
new best val f1: 0.8210462199701685
ogbn-products,dgl,1,393,101.4170,0.8210

 F1-mic 0.8211,  F1-mac 0.3612
new best val f1: 0.8211429173043494
ogbn-products,dgl,1,394,101.6709,0.8211

 F1-mic 0.8212,  F1-mac 0.3614
new best val f1: 0.8212305775044948
ogbn-products,dgl,1,395,101.9245,0.8212

 F1-mic 0.8213,  F1-mac 0.3614
new best val f1: 0.821318689561342
ogbn-products,dgl,1,396,102.1782,0.8213

 F1-mic 0.8214,  F1-mac 0.3616
new best val f1: 0.8214140313254177
ogbn-products,dgl,1,397,102.4327,0.8214

 F1-mic 0.8215,  F1-mac 0.3617
new best val f1: 0.8214944618183346
ogbn-products,dgl,1,398,102.6865,0.8215

 F1-mic 0.8216,  F1-mac 0.3618
new best val f1: 0.8215888998690067
ogbn-products,dgl,1,399,102.9401,0.8216

epoch:401/50, Iteration 32/32:training loss 0.7699159383773804
Train F1-mic 0.8261, Train F1-mac 0.3628
 F1-mic 0.8217,  F1-mac 0.3619
new best val f1: 0.8216752044990469
ogbn-products,dgl,1,400,103.1940,0.8217

 F1-mic 0.8218,  F1-mac 0.3621
new best val f1: 0.8217556349919637
ogbn-products,dgl,1,401,103.4454,0.8218

 F1-mic 0.8219,  F1-mac 0.3622
new best val f1: 0.8218550434663555
ogbn-products,dgl,1,402,103.6993,0.8219

 F1-mic 0.8220,  F1-mac 0.3624
new best val f1: 0.821963037218081
ogbn-products,dgl,1,403,103.9529,0.8220

 F1-mic 0.8220,  F1-mac 0.3625
new best val f1: 0.8220466307079103
ogbn-products,dgl,1,404,104.2064,0.8220

 F1-mic 0.8221,  F1-mac 0.3626
new best val f1: 0.8221464910390038
ogbn-products,dgl,1,405,104.4612,0.8221

 F1-mic 0.8223,  F1-mac 0.3627
new best val f1: 0.8222504180804133
ogbn-products,dgl,1,406,104.7147,0.8223

 F1-mic 0.8224,  F1-mac 0.3628
new best val f1: 0.8223511821249103
ogbn-products,dgl,1,407,104.9692,0.8224

 F1-mic 0.8224,  F1-mac 0.3630
new best val f1: 0.822448783172495
ogbn-products,dgl,1,408,105.2228,0.8224

 F1-mic 0.8225,  F1-mac 0.3631
new best val f1: 0.8225237913849905
ogbn-products,dgl,1,409,105.4769,0.8225

epoch:411/50, Iteration 32/32:training loss 0.7649014592170715
Train F1-mic 0.8270, Train F1-mac 0.3640
 F1-mic 0.8226,  F1-mac 0.3632
new best val f1: 0.8226060293047145
ogbn-products,dgl,1,410,105.7305,0.8226

 F1-mic 0.8227,  F1-mac 0.3633
new best val f1: 0.8226991117852813
ogbn-products,dgl,1,411,105.9834,0.8227

 F1-mic 0.8228,  F1-mac 0.3634
new best val f1: 0.8227926461225499
ogbn-products,dgl,1,412,106.2380,0.8228

 F1-mic 0.8229,  F1-mac 0.3635
new best val f1: 0.8228690099051508
ogbn-products,dgl,1,413,106.4924,0.8229

 F1-mic 0.8230,  F1-mac 0.3636
new best val f1: 0.8229697739496478
ogbn-products,dgl,1,414,106.7460,0.8230

 F1-mic 0.8231,  F1-mac 0.3637
new best val f1: 0.8230592415766004
ogbn-products,dgl,1,415,106.9997,0.8231

 F1-mic 0.8231,  F1-mac 0.3639
new best val f1: 0.8231491610602546
ogbn-products,dgl,1,416,107.2533,0.8231

 F1-mic 0.8232,  F1-mac 0.3640
new best val f1: 0.8232196507057324
ogbn-products,dgl,1,417,107.5068,0.8232

 F1-mic 0.8233,  F1-mac 0.3641
new best val f1: 0.8233073109058779
ogbn-products,dgl,1,418,107.7607,0.8233

 F1-mic 0.8234,  F1-mac 0.3642
new best val f1: 0.8233814154049698
ogbn-products,dgl,1,419,108.0145,0.8234

epoch:421/50, Iteration 32/32:training loss 0.7601024508476257
Train F1-mic 0.8278, Train F1-mac 0.3651
 F1-mic 0.8235,  F1-mac 0.3643
new best val f1: 0.8234659126082028
ogbn-products,dgl,1,420,108.2689,0.8235

 F1-mic 0.8236,  F1-mac 0.3644
new best val f1: 0.8235522172382428
ogbn-products,dgl,1,421,108.5202,0.8236

 F1-mic 0.8236,  F1-mac 0.3646
new best val f1: 0.8236439441487042
ogbn-products,dgl,1,422,108.7747,0.8236

 F1-mic 0.8237,  F1-mac 0.3647
new best val f1: 0.8237230190715158
ogbn-products,dgl,1,423,109.0283,0.8237

 F1-mic 0.8238,  F1-mac 0.3647
new best val f1: 0.8238102274149595
ogbn-products,dgl,1,424,109.2819,0.8238

 F1-mic 0.8239,  F1-mac 0.3648
new best val f1: 0.8238874949109639
ogbn-products,dgl,1,425,109.5365,0.8239

 F1-mic 0.8240,  F1-mac 0.3650
new best val f1: 0.8239891626688645
ogbn-products,dgl,1,426,109.7902,0.8240

 F1-mic 0.8241,  F1-mac 0.3651
new best val f1: 0.8240854081463437
ogbn-products,dgl,1,427,110.0441,0.8241

 F1-mic 0.8242,  F1-mac 0.3652
new best val f1: 0.8241757794866998
ogbn-products,dgl,1,428,110.2980,0.8242

 F1-mic 0.8243,  F1-mac 0.3653
new best val f1: 0.8242544025528097
ogbn-products,dgl,1,429,110.5514,0.8243

epoch:431/50, Iteration 32/32:training loss 0.7554988265037537
Train F1-mic 0.8287, Train F1-mac 0.3661
 F1-mic 0.8243,  F1-mac 0.3654
new best val f1: 0.8243456776065693
ogbn-products,dgl,1,430,110.8053,0.8243

 F1-mic 0.8244,  F1-mac 0.3655
new best val f1: 0.8244319822366093
ogbn-products,dgl,1,431,111.0566,0.8244

 F1-mic 0.8245,  F1-mac 0.3656
new best val f1: 0.8245286795707903
ogbn-products,dgl,1,432,111.3113,0.8245

 F1-mic 0.8246,  F1-mac 0.3657
new best val f1: 0.8246045914966895
ogbn-products,dgl,1,433,111.5647,0.8246

 F1-mic 0.8247,  F1-mac 0.3658
new best val f1: 0.8246805034225886
ogbn-products,dgl,1,434,111.8182,0.8247

 F1-mic 0.8248,  F1-mac 0.3659
new best val f1: 0.8247555116350842
ogbn-products,dgl,1,435,112.0718,0.8248

 F1-mic 0.8248,  F1-mac 0.3660
new best val f1: 0.8248332309877904
ogbn-products,dgl,1,436,112.3255,0.8248

 F1-mic 0.8249,  F1-mac 0.3661
new best val f1: 0.8249177281910234
ogbn-products,dgl,1,437,112.5794,0.8249

 F1-mic 0.8250,  F1-mac 0.3662
new best val f1: 0.8250022253942563
ogbn-products,dgl,1,438,112.8332,0.8250

 F1-mic 0.8251,  F1-mac 0.3663
new best val f1: 0.8250740706098394
ogbn-products,dgl,1,439,113.0870,0.8251

epoch:441/50, Iteration 32/32:training loss 0.7510786652565002
Train F1-mic 0.8295, Train F1-mac 0.3671
 F1-mic 0.8252,  F1-mac 0.3664
new best val f1: 0.8251517899625457
ogbn-products,dgl,1,440,113.3415,0.8252

 F1-mic 0.8252,  F1-mac 0.3665
new best val f1: 0.8252453242998141
ogbn-products,dgl,1,441,113.5929,0.8252

 F1-mic 0.8253,  F1-mac 0.3666
new best val f1: 0.8253334363566613
ogbn-products,dgl,1,442,113.8470,0.8253

 F1-mic 0.8254,  F1-mac 0.3667
new best val f1: 0.8254156742763855
ogbn-products,dgl,1,443,114.1008,0.8254

 F1-mic 0.8255,  F1-mac 0.3668
new best val f1: 0.8254920380589863
ogbn-products,dgl,1,444,114.3544,0.8255

 F1-mic 0.8256,  F1-mac 0.3669
new best val f1: 0.8255697574116925
ogbn-products,dgl,1,445,114.6087,0.8256

 F1-mic 0.8256,  F1-mac 0.3670
new best val f1: 0.8256348247767489
ogbn-products,dgl,1,446,114.8629,0.8256

 F1-mic 0.8257,  F1-mac 0.3671
new best val f1: 0.8257215812634907
ogbn-products,dgl,1,447,115.1166,0.8257

 F1-mic 0.8258,  F1-mac 0.3672
new best val f1: 0.8258146637440575
ogbn-products,dgl,1,448,115.3704,0.8258

 F1-mic 0.8259,  F1-mac 0.3674
new best val f1: 0.8259068425112207
ogbn-products,dgl,1,449,115.6239,0.8259

epoch:451/50, Iteration 32/32:training loss 0.7468290328979492
Train F1-mic 0.8303, Train F1-mac 0.3682
 F1-mic 0.8260,  F1-mac 0.3675
new best val f1: 0.8260067028423143
ogbn-products,dgl,1,450,115.8784,0.8260

 F1-mic 0.8261,  F1-mac 0.3676
new best val f1: 0.8260948148991614
ogbn-products,dgl,1,451,116.1302,0.8261

 F1-mic 0.8262,  F1-mac 0.3678
new best val f1: 0.8261702749683587
ogbn-products,dgl,1,452,116.3840,0.8262

 F1-mic 0.8263,  F1-mac 0.3679
new best val f1: 0.8262516091746792
ogbn-products,dgl,1,453,116.6381,0.8263

 F1-mic 0.8263,  F1-mac 0.3680
new best val f1: 0.826326165530473
ogbn-products,dgl,1,454,116.8920,0.8263

 F1-mic 0.8264,  F1-mac 0.3682
new best val f1: 0.8264097590203023
ogbn-products,dgl,1,455,117.1456,0.8264

 F1-mic 0.8265,  F1-mac 0.3683
new best val f1: 0.8264969673637461
ogbn-products,dgl,1,456,117.3991,0.8265

 F1-mic 0.8266,  F1-mac 0.3684
new best val f1: 0.8265837238504878
ogbn-products,dgl,1,457,117.6526,0.8266

 F1-mic 0.8267,  F1-mac 0.3685
new best val f1: 0.826659635776387
ogbn-products,dgl,1,458,117.9062,0.8267

 F1-mic 0.8267,  F1-mac 0.3686
new best val f1: 0.8267427774095145
ogbn-products,dgl,1,459,118.1600,0.8267

epoch:461/50, Iteration 32/32:training loss 0.7427353858947754
Train F1-mic 0.8311, Train F1-mac 0.3694
 F1-mic 0.8268,  F1-mac 0.3687
new best val f1: 0.8268331487498706
ogbn-products,dgl,1,460,118.4145,0.8268

 F1-mic 0.8269,  F1-mac 0.3688
new best val f1: 0.8269212608067178
ogbn-products,dgl,1,461,118.6664,0.8269

 F1-mic 0.8270,  F1-mac 0.3689
new best val f1: 0.8270071135800561
ogbn-products,dgl,1,462,118.9199,0.8270

 F1-mic 0.8271,  F1-mac 0.3691
new best val f1: 0.8270934182100962
ogbn-products,dgl,1,463,119.1739,0.8271

 F1-mic 0.8272,  F1-mac 0.3692
new best val f1: 0.8271688782792935
ogbn-products,dgl,1,464,119.4278,0.8272

 F1-mic 0.8272,  F1-mac 0.3693
new best val f1: 0.8272425309216838
ogbn-products,dgl,1,465,119.6814,0.8272

 F1-mic 0.8273,  F1-mac 0.3695
new best val f1: 0.8273202502743898
ogbn-products,dgl,1,466,119.9359,0.8273

 F1-mic 0.8274,  F1-mac 0.3696
new best val f1: 0.8274015844807104
ogbn-products,dgl,1,467,120.1899,0.8274

 F1-mic 0.8275,  F1-mac 0.3698
new best val f1: 0.8274779482633113
ogbn-products,dgl,1,468,120.4437,0.8275

 F1-mic 0.8276,  F1-mac 0.3699
new best val f1: 0.8275619936098424
ogbn-products,dgl,1,469,120.6972,0.8276

epoch:471/50, Iteration 32/32:training loss 0.7387877702713013
Train F1-mic 0.8319, Train F1-mac 0.3707
 F1-mic 0.8277,  F1-mac 0.3700
new best val f1: 0.8276546242337075
ogbn-products,dgl,1,470,120.9509,0.8277

 F1-mic 0.8277,  F1-mac 0.3701
new best val f1: 0.8277251138791852
ogbn-products,dgl,1,471,121.2025,0.8277

 F1-mic 0.8278,  F1-mac 0.3702
new best val f1: 0.827795603524663
ogbn-products,dgl,1,472,121.4566,0.8278

 F1-mic 0.8279,  F1-mac 0.3703
new best val f1: 0.8278706117371586
ogbn-products,dgl,1,473,121.7102,0.8279

 F1-mic 0.8279,  F1-mac 0.3704
new best val f1: 0.8279365828156187
ogbn-products,dgl,1,474,121.9638,0.8279

 F1-mic 0.8280,  F1-mac 0.3706
new best val f1: 0.8280165614518337
ogbn-products,dgl,1,475,122.2178,0.8280

 F1-mic 0.8281,  F1-mac 0.3707
new best val f1: 0.8280834362436972
ogbn-products,dgl,1,476,122.4722,0.8281

 F1-mic 0.8282,  F1-mac 0.3708
new best val f1: 0.8281670297335265
ogbn-products,dgl,1,477,122.7261,0.8282

 F1-mic 0.8282,  F1-mac 0.3709
new best val f1: 0.8282320970985829
ogbn-products,dgl,1,478,122.9799,0.8282

 F1-mic 0.8283,  F1-mac 0.3710
new best val f1: 0.8283116238780963
ogbn-products,dgl,1,479,123.2344,0.8283

epoch:481/50, Iteration 32/32:training loss 0.7349753379821777
Train F1-mic 0.8326, Train F1-mac 0.3718
 F1-mic 0.8284,  F1-mac 0.3711
new best val f1: 0.8283780468132579
ogbn-products,dgl,1,480,123.4885,0.8284

 F1-mic 0.8284,  F1-mac 0.3712
new best val f1: 0.8284458253185251
ogbn-products,dgl,1,481,123.7398,0.8284

 F1-mic 0.8285,  F1-mac 0.3713
new best val f1: 0.828522189101126
ogbn-products,dgl,1,482,123.9943,0.8285

 F1-mic 0.8286,  F1-mac 0.3714
new best val f1: 0.8285872564661824
ogbn-products,dgl,1,483,124.2478,0.8286

 F1-mic 0.8287,  F1-mac 0.3715
new best val f1: 0.8286572942549584
ogbn-products,dgl,1,484,124.5015,0.8287

 F1-mic 0.8287,  F1-mac 0.3716
new best val f1: 0.8287300431839449
ogbn-products,dgl,1,485,124.7565,0.8287

 F1-mic 0.8288,  F1-mac 0.3717
new best val f1: 0.8288050513964406
ogbn-products,dgl,1,486,125.0103,0.8288

 F1-mic 0.8289,  F1-mac 0.3718
new best val f1: 0.8288814151790416
ogbn-products,dgl,1,487,125.2638,0.8289

 F1-mic 0.8290,  F1-mac 0.3719
new best val f1: 0.8289699790925904
ogbn-products,dgl,1,488,125.5174,0.8290

 F1-mic 0.8290,  F1-mac 0.3720
new best val f1: 0.8290404687380681
ogbn-products,dgl,1,489,125.7712,0.8290

epoch:491/50, Iteration 32/32:training loss 0.7312894463539124
Train F1-mic 0.8333, Train F1-mac 0.3727
 F1-mic 0.8291,  F1-mac 0.3721
new best val f1: 0.829133551218635
ogbn-products,dgl,1,490,126.0255,0.8291

 F1-mic 0.8292,  F1-mac 0.3722
new best val f1: 0.8292085594311305
ogbn-products,dgl,1,491,126.2769,0.8292

 F1-mic 0.8293,  F1-mac 0.3723
new best val f1: 0.8292781453632047
ogbn-products,dgl,1,492,126.5307,0.8293

 F1-mic 0.8293,  F1-mac 0.3724
new best val f1: 0.8293486350086824
ogbn-products,dgl,1,493,126.7843,0.8293

 F1-mic 0.8294,  F1-mac 0.3725
new best val f1: 0.829417317227353
ogbn-products,dgl,1,494,127.0384,0.8294

 F1-mic 0.8295,  F1-mac 0.3726
new best val f1: 0.8294909698697434
ogbn-products,dgl,1,495,127.2924,0.8295

 F1-mic 0.8296,  F1-mac 0.3728
new best val f1: 0.8295659780822389
ogbn-products,dgl,1,496,127.5465,0.8296

 F1-mic 0.8296,  F1-mac 0.3729
new best val f1: 0.829629238020488
ogbn-products,dgl,1,497,127.8002,0.8296

 F1-mic 0.8297,  F1-mac 0.3730
new best val f1: 0.8296771348308769
ogbn-products,dgl,1,498,128.0540,0.8297

 F1-mic 0.8298,  F1-mac 0.3732
new best val f1: 0.8297598246073027
ogbn-products,dgl,1,499,128.3076,0.8298

epoch:501/50, Iteration 32/32:training loss 0.727715790271759
Train F1-mic 0.8340, Train F1-mac 0.3739
 F1-mic 0.8298,  F1-mac 0.3734
new best val f1: 0.8298375439600089
ogbn-products,dgl,1,500,128.5615,0.8298

 F1-mic 0.8299,  F1-mac 0.3735
new best val f1: 0.829907129892083
ogbn-products,dgl,1,501,128.8130,0.8299

 F1-mic 0.8300,  F1-mac 0.3736
new best val f1: 0.8299961456623338
ogbn-products,dgl,1,502,129.0670,0.8300

 F1-mic 0.8301,  F1-mac 0.3737
new best val f1: 0.8300630204541973
ogbn-products,dgl,1,503,129.3212,0.8301

 F1-mic 0.8301,  F1-mac 0.3739
new best val f1: 0.8301339619563769
ogbn-products,dgl,1,504,129.5756,0.8301

 F1-mic 0.8302,  F1-mac 0.3740
new best val f1: 0.8302085183121706
ogbn-products,dgl,1,505,129.8293,0.8302

 F1-mic 0.8303,  F1-mac 0.3741
new best val f1: 0.8302749412473324
ogbn-products,dgl,1,506,130.0830,0.8303

 F1-mic 0.8303,  F1-mac 0.3743
new best val f1: 0.8303418160391959
ogbn-products,dgl,1,507,130.3365,0.8303

 F1-mic 0.8304,  F1-mac 0.3744
new best val f1: 0.8304086908310594
ogbn-products,dgl,1,508,130.5902,0.8304

 F1-mic 0.8305,  F1-mac 0.3745
new best val f1: 0.830485506470362
ogbn-products,dgl,1,509,130.8436,0.8305

epoch:511/50, Iteration 32/32:training loss 0.7242526412010193
Train F1-mic 0.8347, Train F1-mac 0.3752
 F1-mic 0.8306,  F1-mac 0.3746
new best val f1: 0.830551477548822
ogbn-products,dgl,1,510,131.0975,0.8306

 F1-mic 0.8306,  F1-mac 0.3747
new best val f1: 0.8306282931881247
ogbn-products,dgl,1,511,131.3489,0.8306

 F1-mic 0.8307,  F1-mac 0.3748
new best val f1: 0.8306983309769006
ogbn-products,dgl,1,512,131.6029,0.8307

 F1-mic 0.8308,  F1-mac 0.3749
new best val f1: 0.8307751466162033
ogbn-products,dgl,1,513,131.8569,0.8308

 F1-mic 0.8309,  F1-mac 0.3751
new best val f1: 0.8308528659689096
ogbn-products,dgl,1,514,132.1108,0.8309

 F1-mic 0.8309,  F1-mac 0.3753
new best val f1: 0.830926066754598
ogbn-products,dgl,1,515,132.3646,0.8309

 F1-mic 0.8310,  F1-mac 0.3753
new best val f1: 0.8309970082567775
ogbn-products,dgl,1,516,132.6184,0.8310

 F1-mic 0.8311,  F1-mac 0.3755
new best val f1: 0.8310647867620445
ogbn-products,dgl,1,517,132.8720,0.8311

 F1-mic 0.8311,  F1-mac 0.3756
new best val f1: 0.8311334689807152
ogbn-products,dgl,1,518,133.1259,0.8311

 F1-mic 0.8312,  F1-mac 0.3758
new best val f1: 0.8311890473550342
ogbn-products,dgl,1,519,133.3797,0.8312

epoch:521/50, Iteration 32/32:training loss 0.7208898663520813
Train F1-mic 0.8354, Train F1-mac 0.3765
 F1-mic 0.8313,  F1-mac 0.3759
new best val f1: 0.8312622481407226
ogbn-products,dgl,1,520,133.6335,0.8313

 F1-mic 0.8313,  F1-mac 0.3760
new best val f1: 0.8313340933563058
ogbn-products,dgl,1,521,133.8850,0.8313

 F1-mic 0.8314,  F1-mac 0.3762
new best val f1: 0.8313946421543443
ogbn-products,dgl,1,522,134.1387,0.8314

 F1-mic 0.8315,  F1-mac 0.3763
new best val f1: 0.83146965036684
ogbn-products,dgl,1,523,134.3924,0.8315

 F1-mic 0.8315,  F1-mac 0.3764
new best val f1: 0.8315238731710535
ogbn-products,dgl,1,524,134.6467,0.8315

 F1-mic 0.8316,  F1-mac 0.3766
new best val f1: 0.8315984295268473
ogbn-products,dgl,1,525,134.9007,0.8316

 F1-mic 0.8317,  F1-mac 0.3768
new best val f1: 0.8316580746114823
ogbn-products,dgl,1,526,135.1546,0.8317

 F1-mic 0.8317,  F1-mac 0.3769
new best val f1: 0.8317249494033458
ogbn-products,dgl,1,527,135.4081,0.8317

 F1-mic 0.8318,  F1-mac 0.3771
new best val f1: 0.8317791722075595
ogbn-products,dgl,1,528,135.6616,0.8318

 F1-mic 0.8318,  F1-mac 0.3772
new best val f1: 0.8318474025695283
ogbn-products,dgl,1,529,135.9153,0.8318

epoch:531/50, Iteration 32/32:training loss 0.7176252007484436
Train F1-mic 0.8361, Train F1-mac 0.3778
 F1-mic 0.8319,  F1-mac 0.3773
new best val f1: 0.831912018077883
ogbn-products,dgl,1,530,136.1689,0.8319

 F1-mic 0.8320,  F1-mac 0.3775
new best val f1: 0.8319748261594304
ogbn-products,dgl,1,531,136.4208,0.8320

 F1-mic 0.8320,  F1-mac 0.3776
new best val f1: 0.8320335675306618
ogbn-products,dgl,1,532,136.6748,0.8320

 F1-mic 0.8321,  F1-mac 0.3777
new best val f1: 0.8320954718988058
ogbn-products,dgl,1,533,136.9296,0.8321

 F1-mic 0.8322,  F1-mac 0.3778
new best val f1: 0.8321515021298266
ogbn-products,dgl,1,534,137.1833,0.8322

 F1-mic 0.8322,  F1-mac 0.3779
new best val f1: 0.8322111472144617
ogbn-products,dgl,1,535,137.4372,0.8322

 F1-mic 0.8323,  F1-mac 0.3780
new best val f1: 0.8322712441557983
ogbn-products,dgl,1,536,137.6907,0.8323

 F1-mic 0.8323,  F1-mac 0.3782
new best val f1: 0.8323394745177672
ogbn-products,dgl,1,537,137.9444,0.8323

 F1-mic 0.8324,  F1-mac 0.3783
new best val f1: 0.8324040900261218
ogbn-products,dgl,1,538,138.1981,0.8324

 F1-mic 0.8325,  F1-mac 0.3784
new best val f1: 0.8324899427994601
ogbn-products,dgl,1,539,138.4526,0.8325

epoch:541/50, Iteration 32/32:training loss 0.7144472599029541
Train F1-mic 0.8367, Train F1-mac 0.3790
 F1-mic 0.8326,  F1-mac 0.3785
new best val f1: 0.832558173161429
ogbn-products,dgl,1,540,138.7065,0.8326

 F1-mic 0.8326,  F1-mac 0.3787
new best val f1: 0.8326069736852213
ogbn-products,dgl,1,541,138.9579,0.8326

 F1-mic 0.8327,  F1-mac 0.3788
new best val f1: 0.8326616483461367
ogbn-products,dgl,1,542,139.2117,0.8327

 F1-mic 0.8327,  F1-mac 0.3789
new best val f1: 0.832726715711193
ogbn-products,dgl,1,543,139.4655,0.8327

 F1-mic 0.8328,  F1-mac 0.3790
new best val f1: 0.8327999164968815
ogbn-products,dgl,1,544,139.7192,0.8328

 F1-mic 0.8329,  F1-mac 0.3791
new best val f1: 0.8328545911577969
ogbn-products,dgl,1,545,139.9728,0.8329

 F1-mic 0.8329,  F1-mac 0.3793
new best val f1: 0.8329164955259408
ogbn-products,dgl,1,546,140.2264,0.8329

 F1-mic 0.8330,  F1-mac 0.3794
new best val f1: 0.8329946667353488
ogbn-products,dgl,1,547,140.4807,0.8330

 F1-mic 0.8330,  F1-mac 0.3795
new best val f1: 0.8330470821127555
ogbn-products,dgl,1,548,140.7342,0.8330

 F1-mic 0.8331,  F1-mac 0.3796
new best val f1: 0.8331062753406887
ogbn-products,dgl,1,549,140.9878,0.8331

epoch:551/50, Iteration 32/32:training loss 0.7113561630249023
Train F1-mic 0.8373, Train F1-mac 0.3802
 F1-mic 0.8332,  F1-mac 0.3797
new best val f1: 0.8331568832912881
ogbn-products,dgl,1,550,141.2418,0.8332

 F1-mic 0.8332,  F1-mac 0.3798
new best val f1: 0.8332214987996427
ogbn-products,dgl,1,551,141.4934,0.8332

 F1-mic 0.8333,  F1-mac 0.3799
new best val f1: 0.8332838550244884
ogbn-products,dgl,1,552,141.7468,0.8333

 F1-mic 0.8333,  F1-mac 0.3800
new best val f1: 0.8333435001091235
ogbn-products,dgl,1,553,142.0009,0.8333

 F1-mic 0.8334,  F1-mac 0.3801
new best val f1: 0.83338326349888
ogbn-products,dgl,1,554,142.2546,0.8334

 F1-mic 0.8334,  F1-mac 0.3802
new best val f1: 0.8334379381597955
ogbn-products,dgl,1,555,142.5081,0.8334

 F1-mic 0.8335,  F1-mac 0.3804
new best val f1: 0.8335025536681501
ogbn-products,dgl,1,556,142.7623,0.8335

 F1-mic 0.8336,  F1-mac 0.3805
new best val f1: 0.8335581320424691
ogbn-products,dgl,1,557,143.0164,0.8336

 F1-mic 0.8336,  F1-mac 0.3806
new best val f1: 0.8336155178435952
ogbn-products,dgl,1,558,143.2701,0.8336

 F1-mic 0.8337,  F1-mac 0.3807
new best val f1: 0.8336710962179142
ogbn-products,dgl,1,559,143.5240,0.8337

epoch:561/50, Iteration 32/32:training loss 0.7083423137664795
Train F1-mic 0.8379, Train F1-mac 0.3814
 F1-mic 0.8337,  F1-mac 0.3809
new best val f1: 0.8337424895767955
ogbn-products,dgl,1,560,143.7777,0.8337

 F1-mic 0.8338,  F1-mac 0.3810
new best val f1: 0.8337998753779217
ogbn-products,dgl,1,561,144.0290,0.8338

 F1-mic 0.8339,  F1-mac 0.3812
new best val f1: 0.8338662983130835
ogbn-products,dgl,1,562,144.2829,0.8339

 F1-mic 0.8339,  F1-mac 0.3813
new best val f1: 0.8339295582513326
ogbn-products,dgl,1,563,144.5367,0.8339

 F1-mic 0.8340,  F1-mac 0.3814
new best val f1: 0.833992818189582
ogbn-products,dgl,1,564,144.7905,0.8340

 F1-mic 0.8341,  F1-mac 0.3816
new best val f1: 0.8340538188443223
ogbn-products,dgl,1,565,145.0445,0.8341

 F1-mic 0.8341,  F1-mac 0.3817
new best val f1: 0.8341080416485359
ogbn-products,dgl,1,566,145.2987,0.8341

 F1-mic 0.8342,  F1-mac 0.3819
new best val f1: 0.8341694941599781
ogbn-products,dgl,1,567,145.5521,0.8342

 F1-mic 0.8342,  F1-mac 0.3821
new best val f1: 0.8342237169641917
ogbn-products,dgl,1,568,145.8061,0.8342

 F1-mic 0.8343,  F1-mac 0.3823
new best val f1: 0.834286976902441
ogbn-products,dgl,1,569,146.0600,0.8343

epoch:571/50, Iteration 32/32:training loss 0.7054057717323303
Train F1-mic 0.8385, Train F1-mac 0.3828
 F1-mic 0.8343,  F1-mac 0.3824
new best val f1: 0.8343470738437778
ogbn-products,dgl,1,570,146.3138,0.8343

 F1-mic 0.8344,  F1-mac 0.3826
new best val f1: 0.8344180153459573
ogbn-products,dgl,1,571,146.5652,0.8344

 F1-mic 0.8345,  F1-mac 0.3827
new best val f1: 0.8344830827110137
ogbn-products,dgl,1,572,146.8190,0.8345

 F1-mic 0.8345,  F1-mac 0.3827
new best val f1: 0.8345373055152273
ogbn-products,dgl,1,573,147.0728,0.8345

 F1-mic 0.8346,  F1-mac 0.3828
new best val f1: 0.8345847504689143
ogbn-products,dgl,1,574,147.3263,0.8346

 F1-mic 0.8346,  F1-mac 0.3830
new best val f1: 0.8346380695597245
ogbn-products,dgl,1,575,147.5799,0.8346

 F1-mic 0.8347,  F1-mac 0.3831
new best val f1: 0.8347072036350968
ogbn-products,dgl,1,576,147.8349,0.8347

 F1-mic 0.8348,  F1-mac 0.3832
new best val f1: 0.8347605227259067
ogbn-products,dgl,1,577,148.0888,0.8348

 F1-mic 0.8348,  F1-mac 0.3833
new best val f1: 0.8348233308074544
ogbn-products,dgl,1,578,148.3425,0.8348

 F1-mic 0.8349,  F1-mac 0.3835
new best val f1: 0.83489833901995
ogbn-products,dgl,1,579,148.5963,0.8349

epoch:581/50, Iteration 32/32:training loss 0.702539324760437
Train F1-mic 0.8391, Train F1-mac 0.3841
 F1-mic 0.8350,  F1-mac 0.3836
new best val f1: 0.8349584359612867
ogbn-products,dgl,1,580,148.8500,0.8350

 F1-mic 0.8350,  F1-mac 0.3838
new best val f1: 0.8350122069087986
ogbn-products,dgl,1,581,149.1014,0.8350

 F1-mic 0.8351,  F1-mac 0.3840
new best val f1: 0.8350781779872586
ogbn-products,dgl,1,582,149.3551,0.8351

 F1-mic 0.8351,  F1-mac 0.3842
new best val f1: 0.8351337563615775
ogbn-products,dgl,1,583,149.6093,0.8351

 F1-mic 0.8352,  F1-mac 0.3843
new best val f1: 0.8351843643121769
ogbn-products,dgl,1,584,149.8629,0.8352

 F1-mic 0.8353,  F1-mac 0.3845
new best val f1: 0.8352589206679707
ogbn-products,dgl,1,585,150.1166,0.8353

 F1-mic 0.8353,  F1-mac 0.3847
new best val f1: 0.835314047185588
ogbn-products,dgl,1,586,150.3703,0.8353

 F1-mic 0.8354,  F1-mac 0.3849
new best val f1: 0.8353678181330998
ogbn-products,dgl,1,587,150.6241,0.8354

 F1-mic 0.8354,  F1-mac 0.3851
new best val f1: 0.8354455374858061
ogbn-products,dgl,1,588,150.8780,0.8354

 F1-mic 0.8355,  F1-mac 0.3853
new best val f1: 0.8354988565766162
ogbn-products,dgl,1,589,151.1318,0.8355

epoch:591/50, Iteration 32/32:training loss 0.6997403502464294
Train F1-mic 0.8396, Train F1-mac 0.3859
 F1-mic 0.8355,  F1-mac 0.3855
new best val f1: 0.8355481089571102
ogbn-products,dgl,1,590,151.3855,0.8355

 F1-mic 0.8356,  F1-mac 0.3856
new best val f1: 0.83560639847164
ogbn-products,dgl,1,591,151.6368,0.8356

 F1-mic 0.8357,  F1-mac 0.3858
new best val f1: 0.8356655916995731
ogbn-products,dgl,1,592,151.8910,0.8357

 F1-mic 0.8357,  F1-mac 0.3860
new best val f1: 0.8357225256439975
ogbn-products,dgl,1,593,152.1445,0.8357

 F1-mic 0.8358,  F1-mac 0.3862
new best val f1: 0.8357839781554396
ogbn-products,dgl,1,594,152.3983,0.8358

 F1-mic 0.8358,  F1-mac 0.3864
new best val f1: 0.8358368453895479
ogbn-products,dgl,1,595,152.6527,0.8358

 F1-mic 0.8359,  F1-mac 0.3906
new best val f1: 0.8358942311906741
ogbn-products,dgl,1,596,152.9063,0.8359

 F1-mic 0.8360,  F1-mac 0.3907
new best val f1: 0.8359615578392393
ogbn-products,dgl,1,597,153.1600,0.8360

 F1-mic 0.8360,  F1-mac 0.3925
new best val f1: 0.8360270770609974
ogbn-products,dgl,1,598,153.4134,0.8360

 F1-mic 0.8361,  F1-mac 0.3928
new best val f1: 0.8360894332858432
ogbn-products,dgl,1,599,153.6672,0.8361

epoch:601/50, Iteration 32/32:training loss 0.6970128417015076
Train F1-mic 0.8402, Train F1-mac 0.3925
 F1-mic 0.8361,  F1-mac 0.3930
new best val f1: 0.8361395893797409
ogbn-products,dgl,1,600,153.9208,0.8361

 F1-mic 0.8362,  F1-mac 0.3933
new best val f1: 0.8361956196107616
ogbn-products,dgl,1,601,154.1721,0.8362

 F1-mic 0.8363,  F1-mac 0.3936
new best val f1: 0.836256620265502
ogbn-products,dgl,1,602,154.4256,0.8363

 F1-mic 0.8363,  F1-mac 0.3938
new best val f1: 0.8363081319295049
ogbn-products,dgl,1,603,154.6792,0.8363

 F1-mic 0.8364,  F1-mac 0.3939
new best val f1: 0.8363569324532973
ogbn-products,dgl,1,604,154.9328,0.8364

 F1-mic 0.8364,  F1-mac 0.3940
new best val f1: 0.8364201923915465
ogbn-products,dgl,1,605,155.1864,0.8364

 F1-mic 0.8365,  F1-mac 0.3942
new best val f1: 0.836480741189585
ogbn-products,dgl,1,606,155.4402,0.8365

 F1-mic 0.8365,  F1-mac 0.3944
new best val f1: 0.8365498752649575
ogbn-products,dgl,1,607,155.6938,0.8365

 F1-mic 0.8366,  F1-mac 0.3954
new best val f1: 0.8366036462124693
ogbn-products,dgl,1,608,155.9481,0.8366

 F1-mic 0.8367,  F1-mac 0.3970
new best val f1: 0.8366592245867883
ogbn-products,dgl,1,609,156.2016,0.8367

epoch:611/50, Iteration 32/32:training loss 0.6943515539169312
Train F1-mic 0.8408, Train F1-mac 0.3965
 F1-mic 0.8367,  F1-mac 0.3971
new best val f1: 0.8367188696714234
ogbn-products,dgl,1,610,156.4555,0.8367

 F1-mic 0.8368,  F1-mac 0.3980
new best val f1: 0.8367803221828655
ogbn-products,dgl,1,611,156.7075,0.8368

 F1-mic 0.8368,  F1-mac 0.3982
new best val f1: 0.8368435821211148
ogbn-products,dgl,1,612,156.9610,0.8368

 F1-mic 0.8369,  F1-mac 0.3984
new best val f1: 0.8368996123521355
ogbn-products,dgl,1,613,157.2148,0.8369

 F1-mic 0.8369,  F1-mac 0.3987
new best val f1: 0.836946153592419
ogbn-products,dgl,1,614,157.4685,0.8369

 F1-mic 0.8370,  F1-mac 0.3990
new best val f1: 0.8370143839543877
ogbn-products,dgl,1,615,157.7222,0.8370

 F1-mic 0.8371,  F1-mac 0.3998
new best val f1: 0.8370808068895496
ogbn-products,dgl,1,616,157.9760,0.8371

 F1-mic 0.8371,  F1-mac 0.4001
new best val f1: 0.8371345778370614
ogbn-products,dgl,1,617,158.2295,0.8371

 F1-mic 0.8372,  F1-mac 0.4003
new best val f1: 0.8372014526289249
ogbn-products,dgl,1,618,158.4832,0.8372

 F1-mic 0.8373,  F1-mac 0.4006
new best val f1: 0.8372683274207884
ogbn-products,dgl,1,619,158.7370,0.8373

epoch:621/50, Iteration 32/32:training loss 0.6917511820793152
Train F1-mic 0.8414, Train F1-mac 0.4001
 F1-mic 0.8373,  F1-mac 0.4009
new best val f1: 0.8373284243621252
ogbn-products,dgl,1,620,158.9911,0.8373

 F1-mic 0.8374,  F1-mac 0.4012
new best val f1: 0.837378128599321
ogbn-products,dgl,1,621,159.2427,0.8374

 F1-mic 0.8374,  F1-mac 0.4014
new best val f1: 0.8374350625437453
ogbn-products,dgl,1,622,159.4964,0.8374

 F1-mic 0.8375,  F1-mac 0.4018
new best val f1: 0.8374978706252929
ogbn-products,dgl,1,623,159.7500,0.8375

 F1-mic 0.8375,  F1-mac 0.4021
new best val f1: 0.8375471230057869
ogbn-products,dgl,1,624,160.0042,0.8375

 F1-mic 0.8376,  F1-mac 0.4022
new best val f1: 0.8375936642460703
ogbn-products,dgl,1,625,160.2586,0.8376

 F1-mic 0.8376,  F1-mac 0.4025
new best val f1: 0.8376429166265644
ogbn-products,dgl,1,626,160.5122,0.8376

 F1-mic 0.8377,  F1-mac 0.4028
new best val f1: 0.8376962357173744
ogbn-products,dgl,1,627,160.7656,0.8377

 F1-mic 0.8378,  F1-mac 0.4030
new best val f1: 0.8377567845154129
ogbn-products,dgl,1,628,161.0192,0.8378

 F1-mic 0.8378,  F1-mac 0.4032
new best val f1: 0.8378114591763285
ogbn-products,dgl,1,629,161.2731,0.8378

epoch:631/50, Iteration 32/32:training loss 0.6892112493515015
Train F1-mic 0.8419, Train F1-mac 0.4027
 F1-mic 0.8379,  F1-mac 0.4035
new best val f1: 0.8378729116877707
ogbn-products,dgl,1,630,161.5268,0.8379

 F1-mic 0.8379,  F1-mac 0.4037
new best val f1: 0.8379406901930377
ogbn-products,dgl,1,631,161.7783,0.8379

 F1-mic 0.8380,  F1-mac 0.4040
new best val f1: 0.8379958167106549
ogbn-products,dgl,1,632,162.0328,0.8380

 F1-mic 0.8381,  F1-mac 0.4036
new best val f1: 0.8380518469416758
ogbn-products,dgl,1,633,162.2864,0.8381

 F1-mic 0.8381,  F1-mac 0.4038
new best val f1: 0.8381096845995036
ogbn-products,dgl,1,634,162.5400,0.8381

 F1-mic 0.8382,  F1-mac 0.4047
new best val f1: 0.8381657148305244
ogbn-products,dgl,1,635,162.7943,0.8382

 F1-mic 0.8382,  F1-mac 0.4044
new best val f1: 0.8382212932048434
ogbn-products,dgl,1,636,163.0478,0.8382

 F1-mic 0.8383,  F1-mac 0.4047
new best val f1: 0.8382791308626713
ogbn-products,dgl,1,637,163.3016,0.8383

 F1-mic 0.8383,  F1-mac 0.4049
new best val f1: 0.8383365166637973
ogbn-products,dgl,1,638,163.5551,0.8383

 F1-mic 0.8384,  F1-mac 0.4051
new best val f1: 0.8383884801845022
ogbn-products,dgl,1,639,163.8093,0.8384

epoch:641/50, Iteration 32/32:training loss 0.6867265105247498
Train F1-mic 0.8425, Train F1-mac 0.4047
 F1-mic 0.8384,  F1-mac 0.4061
new best val f1: 0.8384372807082944
ogbn-products,dgl,1,640,164.0629,0.8384

 F1-mic 0.8385,  F1-mac 0.4063
new best val f1: 0.8384933109393152
ogbn-products,dgl,1,641,164.3143,0.8385

 F1-mic 0.8385,  F1-mac 0.4064
new best val f1: 0.8385394003228968
ogbn-products,dgl,1,642,164.5680,0.8385

 F1-mic 0.8386,  F1-mac 0.4067
new best val f1: 0.8385900082734962
ogbn-products,dgl,1,643,164.8233,0.8386

 F1-mic 0.8387,  F1-mac 0.4068
new best val f1: 0.8386510089282365
ogbn-products,dgl,1,644,165.0768,0.8387

 F1-mic 0.8387,  F1-mac 0.4070
new best val f1: 0.8386925797448004
ogbn-products,dgl,1,645,165.3306,0.8387

 F1-mic 0.8387,  F1-mac 0.4072
new best val f1: 0.838742735838698
ogbn-products,dgl,1,646,165.5844,0.8387

 F1-mic 0.8388,  F1-mac 0.4074
new best val f1: 0.8387933437892974
ogbn-products,dgl,1,647,165.8380,0.8388

 F1-mic 0.8389,  F1-mac 0.4077
new best val f1: 0.8388638334347751
ogbn-products,dgl,1,648,166.0917,0.8389

 F1-mic 0.8389,  F1-mac 0.4079
new best val f1: 0.8389126339585674
ogbn-products,dgl,1,649,166.3453,0.8389

epoch:651/50, Iteration 32/32:training loss 0.6842941641807556
Train F1-mic 0.8430, Train F1-mac 0.4073
 F1-mic 0.8390,  F1-mac 0.4080
new best val f1: 0.8389713753297989
ogbn-products,dgl,1,650,166.5990,0.8390

 F1-mic 0.8390,  F1-mac 0.4083
new best val f1: 0.8390192721401877
ogbn-products,dgl,1,651,166.8508,0.8390

 F1-mic 0.8391,  F1-mac 0.4085
new best val f1: 0.8390626503835585
ogbn-products,dgl,1,652,167.1048,0.8391

 F1-mic 0.8391,  F1-mac 0.4087
new best val f1: 0.8391091916238419
ogbn-products,dgl,1,653,167.3586,0.8391

 F1-mic 0.8392,  F1-mac 0.4088
new best val f1: 0.8391607032878449
ogbn-products,dgl,1,654,167.6122,0.8392

 F1-mic 0.8392,  F1-mac 0.4090
new best val f1: 0.8392212520858836
ogbn-products,dgl,1,655,167.8657,0.8392

 F1-mic 0.8393,  F1-mac 0.4092
new best val f1: 0.8392686970395704
ogbn-products,dgl,1,656,168.1192,0.8393

 F1-mic 0.8393,  F1-mac 0.4094
new best val f1: 0.8393215642736788
ogbn-products,dgl,1,657,168.3730,0.8393

 F1-mic 0.8394,  F1-mac 0.4095
new best val f1: 0.8393744315077871
ogbn-products,dgl,1,658,168.6265,0.8394

 F1-mic 0.8394,  F1-mac 0.4097
new best val f1: 0.839417809751158
ogbn-products,dgl,1,659,168.8801,0.8394

epoch:661/50, Iteration 32/32:training loss 0.6819127798080444
Train F1-mic 0.8435, Train F1-mac 0.4091
 F1-mic 0.8395,  F1-mac 0.4099
new best val f1: 0.8394756474089858
ogbn-products,dgl,1,660,169.1340,0.8395

 F1-mic 0.8395,  F1-mac 0.4100
new best val f1: 0.8395185737956552
ogbn-products,dgl,1,661,169.3859,0.8395

 F1-mic 0.8396,  F1-mac 0.4101
new best val f1: 0.839564211322535
ogbn-products,dgl,1,662,169.6394,0.8396

 F1-mic 0.8396,  F1-mac 0.4103
new best val f1: 0.8396107525628183
ogbn-products,dgl,1,663,169.8929,0.8396

 F1-mic 0.8397,  F1-mac 0.4104
new best val f1: 0.8396541308061893
ogbn-products,dgl,1,664,170.1472,0.8397

 F1-mic 0.8397,  F1-mac 0.4106
new best val f1: 0.839703835043385
ogbn-products,dgl,1,665,170.4014,0.8397

 F1-mic 0.8398,  F1-mac 0.4107
new best val f1: 0.8397530874238791
ogbn-products,dgl,1,666,170.6551,0.8398

 F1-mic 0.8398,  F1-mac 0.4109
new best val f1: 0.8397946582404429
ogbn-products,dgl,1,667,170.9088,0.8398

 F1-mic 0.8398,  F1-mac 0.4110
new best val f1: 0.8398317104899888
ogbn-products,dgl,1,668,171.1625,0.8398

 F1-mic 0.8399,  F1-mac 0.4111
new best val f1: 0.839866503456026
ogbn-products,dgl,1,669,171.4169,0.8399

epoch:671/50, Iteration 32/32:training loss 0.6795845627784729
Train F1-mic 0.8439, Train F1-mac 0.4106
 F1-mic 0.8399,  F1-mac 0.4113
new best val f1: 0.8399089779859934
ogbn-products,dgl,1,670,171.6712,0.8399

 F1-mic 0.8399,  F1-mac 0.4113
new best val f1: 0.8399464820922411
ogbn-products,dgl,1,671,171.9225,0.8399

 F1-mic 0.8400,  F1-mac 0.4114
new best val f1: 0.8399957344727352
ogbn-products,dgl,1,672,172.1762,0.8400

 F1-mic 0.8400,  F1-mac 0.4116
new best val f1: 0.8400472461367382
ogbn-products,dgl,1,673,172.4300,0.8400

 F1-mic 0.8401,  F1-mac 0.4118
new best val f1: 0.8400942392337233
ogbn-products,dgl,1,674,172.6842,0.8401

 F1-mic 0.8401,  F1-mac 0.4119
new best val f1: 0.8401416841874103
ogbn-products,dgl,1,675,172.9377,0.8401

 F1-mic 0.8402,  F1-mac 0.4120
new best val f1: 0.8401769290101492
ogbn-products,dgl,1,676,173.1915,0.8402

 F1-mic 0.8402,  F1-mac 0.4121
new best val f1: 0.8402103664060809
ogbn-products,dgl,1,677,173.4450,0.8402

 F1-mic 0.8403,  F1-mac 0.4123
new best val f1: 0.8402740782010321
ogbn-products,dgl,1,678,173.6988,0.8403

 F1-mic 0.8403,  F1-mac 0.4124
new best val f1: 0.8403278491485439
ogbn-products,dgl,1,679,173.9522,0.8403

epoch:681/50, Iteration 32/32:training loss 0.6772992014884949
Train F1-mic 0.8444, Train F1-mac 0.4119
 F1-mic 0.8404,  F1-mac 0.4126
new best val f1: 0.8403870423764771
ogbn-products,dgl,1,680,174.2067,0.8404

 F1-mic 0.8404,  F1-mac 0.4126
new best val f1: 0.8404371984703747
ogbn-products,dgl,1,681,174.4582,0.8404

 F1-mic 0.8405,  F1-mac 0.4128
new best val f1: 0.8404927768446937
ogbn-products,dgl,1,682,174.7127,0.8405

 F1-mic 0.8405,  F1-mac 0.4128
new best val f1: 0.8405379625148718
ogbn-products,dgl,1,683,174.9662,0.8405

 F1-mic 0.8406,  F1-mac 0.4129
new best val f1: 0.8405817926149445
ogbn-products,dgl,1,684,175.2204,0.8406

 F1-mic 0.8406,  F1-mac 0.4131
new best val f1: 0.8406409858428777
ogbn-products,dgl,1,685,175.4742,0.8406

 F1-mic 0.8407,  F1-mac 0.4132
new best val f1: 0.8406839122295469
ogbn-products,dgl,1,686,175.7280,0.8407

 F1-mic 0.8407,  F1-mac 0.4133
new best val f1: 0.8407349720368481
ogbn-products,dgl,1,687,175.9819,0.8407

 F1-mic 0.8408,  F1-mac 0.4134
new best val f1: 0.8407774465668154
ogbn-products,dgl,1,688,176.2356,0.8408

 F1-mic 0.8408,  F1-mac 0.4136
new best val f1: 0.8408239878070988
ogbn-products,dgl,1,689,176.4901,0.8408

epoch:691/50, Iteration 32/32:training loss 0.675055980682373
Train F1-mic 0.8448, Train F1-mac 0.4130
 F1-mic 0.8409,  F1-mac 0.4136
new best val f1: 0.8408759513278035
ogbn-products,dgl,1,690,176.7436,0.8409

 F1-mic 0.8409,  F1-mac 0.4137
new best val f1: 0.8409152628608584
ogbn-products,dgl,1,691,176.9950,0.8409

 F1-mic 0.8410,  F1-mac 0.4138
new best val f1: 0.8409618041011419
ogbn-products,dgl,1,692,177.2493,0.8410

 F1-mic 0.8410,  F1-mac 0.4139
new best val f1: 0.841004730487811
ogbn-products,dgl,1,693,177.5031,0.8410

 F1-mic 0.8410,  F1-mac 0.4140
new best val f1: 0.8410359086002338
ogbn-products,dgl,1,694,177.7570,0.8410

 F1-mic 0.8411,  F1-mac 0.4147
new best val f1: 0.8410783831302011
ogbn-products,dgl,1,695,178.0114,0.8411

 F1-mic 0.8411,  F1-mac 0.4148
new best val f1: 0.8411434504952575
ogbn-products,dgl,1,696,178.2650,0.8411

 F1-mic 0.8412,  F1-mac 0.4149
new best val f1: 0.8411786953179963
ogbn-products,dgl,1,697,178.5187,0.8412

 F1-mic 0.8412,  F1-mac 0.4150
new best val f1: 0.8412148438541388
ogbn-products,dgl,1,698,178.7726,0.8412

 F1-mic 0.8413,  F1-mac 0.4150
new best val f1: 0.841257770240808
ogbn-products,dgl,1,699,179.0262,0.8413

epoch:701/50, Iteration 32/32:training loss 0.6728595495223999
Train F1-mic 0.8453, Train F1-mac 0.4144
 F1-mic 0.8413,  F1-mac 0.4151
new best val f1: 0.8413002447707755
ogbn-products,dgl,1,700,179.2800,0.8413

 F1-mic 0.8413,  F1-mac 0.4151
new best val f1: 0.8413187708955484
ogbn-products,dgl,1,701,179.5314,0.8413

 F1-mic 0.8414,  F1-mac 0.4152
new best val f1: 0.841372993699762
ogbn-products,dgl,1,702,179.7850,0.8414

 F1-mic 0.8414,  F1-mac 0.4153
new best val f1: 0.8414172756565365
ogbn-products,dgl,1,703,180.0384,0.8414

 F1-mic 0.8415,  F1-mac 0.4154
new best val f1: 0.8414588464731003
ogbn-products,dgl,1,704,180.2923,0.8415

 F1-mic 0.8415,  F1-mac 0.4155
new best val f1: 0.8414999654329623
ogbn-products,dgl,1,705,180.5464,0.8415

 F1-mic 0.8416,  F1-mac 0.4156
new best val f1: 0.841551928953667
ogbn-products,dgl,1,706,180.8000,0.8416

 F1-mic 0.8416,  F1-mac 0.4157
new best val f1: 0.8416020850475647
ogbn-products,dgl,1,707,181.0536,0.8416

 F1-mic 0.8416,  F1-mac 0.4158
new best val f1: 0.8416432040074268
ogbn-products,dgl,1,708,181.3073,0.8416

 F1-mic 0.8417,  F1-mac 0.4159
new best val f1: 0.8416915526745172
ogbn-products,dgl,1,709,181.5615,0.8417

epoch:711/50, Iteration 32/32:training loss 0.6707043647766113
Train F1-mic 0.8457, Train F1-mac 0.4152
 F1-mic 0.8417,  F1-mac 0.4160
new best val f1: 0.8417380939148007
ogbn-products,dgl,1,710,181.8151,0.8417

 F1-mic 0.8418,  F1-mac 0.4161
new best val f1: 0.8417887018654
ogbn-products,dgl,1,711,182.0666,0.8418

 F1-mic 0.8418,  F1-mac 0.4161
new best val f1: 0.8418379542458941
ogbn-products,dgl,1,712,182.3205,0.8418

 F1-mic 0.8419,  F1-mac 0.4162
new best val f1: 0.8418781694923525
ogbn-products,dgl,1,713,182.5743,0.8419

 F1-mic 0.8419,  F1-mac 0.4163
new best val f1: 0.8419206440223199
ogbn-products,dgl,1,714,182.8279,0.8419

 F1-mic 0.8420,  F1-mac 0.4164
new best val f1: 0.8419717038296209
ogbn-products,dgl,1,715,183.0817,0.8420

 F1-mic 0.8420,  F1-mac 0.4165
new best val f1: 0.842015082072992
ogbn-products,dgl,1,716,183.3355,0.8420

 F1-mic 0.8421,  F1-mac 0.4165
new best val f1: 0.8420638825967843
ogbn-products,dgl,1,717,183.5891,0.8421

 F1-mic 0.8421,  F1-mac 0.4166
new best val f1: 0.8421036459865411
ogbn-products,dgl,1,718,183.8426,0.8421

 F1-mic 0.8421,  F1-mac 0.4167
new best val f1: 0.8421411500927888
ogbn-products,dgl,1,719,184.0970,0.8421

epoch:721/50, Iteration 32/32:training loss 0.6685910224914551
Train F1-mic 0.8461, Train F1-mac 0.4160
 F1-mic 0.8422,  F1-mac 0.4167
new best val f1: 0.842185883906265
ogbn-products,dgl,1,720,184.3510,0.8422

 F1-mic 0.8422,  F1-mac 0.4167
new best val f1: 0.8422324251465485
ogbn-products,dgl,1,721,184.6023,0.8422

 F1-mic 0.8423,  F1-mac 0.4168
new best val f1: 0.8422794182435336
ogbn-products,dgl,1,722,184.8560,0.8423

 F1-mic 0.8423,  F1-mac 0.4169
new best val f1: 0.8423282187673259
ogbn-products,dgl,1,723,185.1101,0.8423

 F1-mic 0.8424,  F1-mac 0.4170
new best val f1: 0.8423747600076092
ogbn-products,dgl,1,724,185.3636,0.8424

 F1-mic 0.8424,  F1-mac 0.4170
new best val f1: 0.8424231086746998
ogbn-products,dgl,1,725,185.6175,0.8424

 F1-mic 0.8425,  F1-mac 0.4170
new best val f1: 0.842466035061369
ogbn-products,dgl,1,726,185.8718,0.8425

 F1-mic 0.8425,  F1-mac 0.4171
new best val f1: 0.8425071540212309
ogbn-products,dgl,1,727,186.1256,0.8425

 F1-mic 0.8426,  F1-mac 0.4172
new best val f1: 0.8425640879656553
ogbn-products,dgl,1,728,186.3792,0.8426

 F1-mic 0.8426,  F1-mac 0.4172
new best val f1: 0.8426092736358333
ogbn-products,dgl,1,729,186.6338,0.8426

epoch:731/50, Iteration 32/32:training loss 0.6665146946907043
Train F1-mic 0.8466, Train F1-mac 0.4166
 F1-mic 0.8426,  F1-mac 0.4173
new best val f1: 0.8426409036049579
ogbn-products,dgl,1,730,186.8875,0.8426

 F1-mic 0.8427,  F1-mac 0.4173
new best val f1: 0.8426869929885396
ogbn-products,dgl,1,731,187.1393,0.8427

 F1-mic 0.8427,  F1-mac 0.4174
new best val f1: 0.8427281119484016
ogbn-products,dgl,1,732,187.3929,0.8427

 F1-mic 0.8428,  F1-mac 0.4175
new best val f1: 0.8427606456309298
ogbn-products,dgl,1,733,187.6473,0.8428

 F1-mic 0.8428,  F1-mac 0.4175
new best val f1: 0.8428058313011079
ogbn-products,dgl,1,734,187.9011,0.8428

 F1-mic 0.8428,  F1-mac 0.4175
new best val f1: 0.8428383649836361
ogbn-products,dgl,1,735,188.1547,0.8428

 F1-mic 0.8429,  F1-mac 0.4176
new best val f1: 0.8428880692208318
ogbn-products,dgl,1,736,188.4083,0.8429

 F1-mic 0.8429,  F1-mac 0.4177
new best val f1: 0.8429219584734654
ogbn-products,dgl,1,737,188.6620,0.8429

 F1-mic 0.8430,  F1-mac 0.4177
new best val f1: 0.8429635292900292
ogbn-products,dgl,1,738,188.9156,0.8430

 F1-mic 0.8430,  F1-mac 0.4178
new best val f1: 0.8430141372406286
ogbn-products,dgl,1,739,189.1691,0.8430

epoch:741/50, Iteration 32/32:training loss 0.6644784808158875
Train F1-mic 0.8470, Train F1-mac 0.4172
 F1-mic 0.8431,  F1-mac 0.4179
new best val f1: 0.8430638414778244
ogbn-products,dgl,1,740,189.4227,0.8431

 F1-mic 0.8431,  F1-mac 0.4179
new best val f1: 0.8431063160077918
ogbn-products,dgl,1,741,189.6741,0.8431

 F1-mic 0.8431,  F1-mac 0.4180
new best val f1: 0.8431433682573378
ogbn-products,dgl,1,742,189.9280,0.8431

 F1-mic 0.8432,  F1-mac 0.4181
new best val f1: 0.8431894576409195
ogbn-products,dgl,1,743,190.1815,0.8432

 F1-mic 0.8432,  F1-mac 0.4182
new best val f1: 0.8432373544513082
ogbn-products,dgl,1,744,190.4358,0.8432

 F1-mic 0.8433,  F1-mac 0.4183
new best val f1: 0.8432798289812756
ogbn-products,dgl,1,745,190.6896,0.8433

 F1-mic 0.8433,  F1-mac 0.4183
new best val f1: 0.8433101033802948
ogbn-products,dgl,1,746,190.9437,0.8433

 F1-mic 0.8434,  F1-mac 0.4184
new best val f1: 0.8433584520473854
ogbn-products,dgl,1,747,191.1974,0.8434

 F1-mic 0.8434,  F1-mac 0.4190
new best val f1: 0.8434031858608616
ogbn-products,dgl,1,748,191.4508,0.8434

 F1-mic 0.8434,  F1-mac 0.4185
new best val f1: 0.8434492752444431
ogbn-products,dgl,1,749,191.7050,0.8434

epoch:751/50, Iteration 32/32:training loss 0.6624768972396851
Train F1-mic 0.8474, Train F1-mac 0.4179
 F1-mic 0.8435,  F1-mac 0.4185
new best val f1: 0.8434867793506908
ogbn-products,dgl,1,750,191.9592,0.8435

 F1-mic 0.8435,  F1-mac 0.4192
new best val f1: 0.8435310613074655
ogbn-products,dgl,1,751,192.2108,0.8435

 F1-mic 0.8436,  F1-mac 0.4192
new best val f1: 0.843556817139467
ogbn-products,dgl,1,752,192.4642,0.8436

 F1-mic 0.8436,  F1-mac 0.4193
new best val f1: 0.8436069732333645
ogbn-products,dgl,1,753,192.7178,0.8436

 F1-mic 0.8436,  F1-mac 0.4194
new best val f1: 0.8436404106292963
ogbn-products,dgl,1,754,192.9716,0.8436

 F1-mic 0.8437,  F1-mac 0.4194
new best val f1: 0.8436806258757548
ogbn-products,dgl,1,755,193.2260,0.8437

 F1-mic 0.8437,  F1-mac 0.4200
new best val f1: 0.8437221966923186
ogbn-products,dgl,1,756,193.4802,0.8437

 F1-mic 0.8438,  F1-mac 0.4195
new best val f1: 0.843762411938777
ogbn-products,dgl,1,757,193.7341,0.8438

 F1-mic 0.8438,  F1-mac 0.4201
new best val f1: 0.8437999160450248
ogbn-products,dgl,1,758,193.9879,0.8438

 F1-mic 0.8438,  F1-mac 0.4202
new best val f1: 0.843840583148185
ogbn-products,dgl,1,759,194.2417,0.8438

epoch:761/50, Iteration 32/32:training loss 0.6605129837989807
Train F1-mic 0.8478, Train F1-mac 0.4194
 F1-mic 0.8439,  F1-mac 0.4202
new best val f1: 0.8438898355286791
ogbn-products,dgl,1,760,194.4963,0.8439

 F1-mic 0.8439,  F1-mac 0.4202
new best val f1: 0.8439137839338735
ogbn-products,dgl,1,761,194.7477,0.8439

 F1-mic 0.8440,  F1-mac 0.4203
new best val f1: 0.8439589696040515
ogbn-products,dgl,1,762,195.0013,0.8440

 F1-mic 0.8440,  F1-mac 0.4204
new best val f1: 0.8440027997041243
ogbn-products,dgl,1,763,195.2551,0.8440

 F1-mic 0.8440,  F1-mac 0.4204
new best val f1: 0.8440362371000559
ogbn-products,dgl,1,764,195.5087,0.8440

 F1-mic 0.8441,  F1-mac 0.4205
new best val f1: 0.8440823264836375
ogbn-products,dgl,1,765,195.7623,0.8441

 F1-mic 0.8441,  F1-mac 0.4206
new best val f1: 0.8441238973002014
ogbn-products,dgl,1,766,196.0165,0.8441

 F1-mic 0.8442,  F1-mac 0.4206
new best val f1: 0.8441713422538882
ogbn-products,dgl,1,767,196.2702,0.8442

 F1-mic 0.8442,  F1-mac 0.4207
new best val f1: 0.8442097500735397
ogbn-products,dgl,1,768,196.5246,0.8442

 F1-mic 0.8442,  F1-mac 0.4208
new best val f1: 0.8442413800426644
ogbn-products,dgl,1,769,196.7783,0.8442

epoch:771/50, Iteration 32/32:training loss 0.6585851907730103
Train F1-mic 0.8482, Train F1-mac 0.4200
 F1-mic 0.8443,  F1-mac 0.4208
new best val f1: 0.8442721062983853
ogbn-products,dgl,1,770,197.0320,0.8443

 F1-mic 0.8443,  F1-mac 0.4209
new best val f1: 0.8443059955510189
ogbn-products,dgl,1,771,197.2834,0.8443

 F1-mic 0.8443,  F1-mac 0.4209
new best val f1: 0.8443340106665294
ogbn-products,dgl,1,772,197.5376,0.8443

 F1-mic 0.8444,  F1-mac 0.4210
new best val f1: 0.8443782926233038
ogbn-products,dgl,1,773,197.7914,0.8444

 F1-mic 0.8444,  F1-mac 0.4211
new best val f1: 0.8444221227233765
ogbn-products,dgl,1,774,198.0459,0.8444

 F1-mic 0.8445,  F1-mac 0.4211
new best val f1: 0.844464145396642
ogbn-products,dgl,1,775,198.2995,0.8445

 F1-mic 0.8445,  F1-mac 0.4212
new best val f1: 0.8445030050729951
ogbn-products,dgl,1,776,198.5531,0.8445

 F1-mic 0.8446,  F1-mac 0.4213
new best val f1: 0.8445612945875248
ogbn-products,dgl,1,777,198.8068,0.8446

 F1-mic 0.8446,  F1-mac 0.4214
new best val f1: 0.8445997024071762
ogbn-products,dgl,1,778,199.0608,0.8446

 F1-mic 0.8446,  F1-mac 0.4214
new best val f1: 0.8446367546567222
ogbn-products,dgl,1,779,199.3149,0.8446

epoch:781/50, Iteration 32/32:training loss 0.6566902995109558
Train F1-mic 0.8486, Train F1-mac 0.4212
 F1-mic 0.8447,  F1-mac 0.4215
new best val f1: 0.8446851033238127
ogbn-products,dgl,1,780,199.5693,0.8447

 F1-mic 0.8447,  F1-mac 0.4216
new best val f1: 0.8447248667135694
ogbn-products,dgl,1,781,199.8207,0.8447

 F1-mic 0.8448,  F1-mac 0.4217
new best val f1: 0.8447741190940634
ogbn-products,dgl,1,782,200.0743,0.8448

 F1-mic 0.8448,  F1-mac 0.4217
new best val f1: 0.8448093639168024
ogbn-products,dgl,1,783,200.3280,0.8448

 F1-mic 0.8449,  F1-mac 0.4218
new best val f1: 0.8448581644405946
ogbn-products,dgl,1,784,200.5821,0.8449

 F1-mic 0.8449,  F1-mac 0.4218
new best val f1: 0.8448897944097191
ogbn-products,dgl,1,785,200.8356,0.8449

 F1-mic 0.8449,  F1-mac 0.4219
new best val f1: 0.844929557799476
ogbn-products,dgl,1,786,201.0900,0.8449

 F1-mic 0.8450,  F1-mac 0.4219
new best val f1: 0.8449530543479685
ogbn-products,dgl,1,787,201.3442,0.8450

 F1-mic 0.8450,  F1-mac 0.4220
new best val f1: 0.8449995955882519
ogbn-products,dgl,1,788,201.5980,0.8450

 F1-mic 0.8451,  F1-mac 0.4221
new best val f1: 0.8450506553955531
ogbn-products,dgl,1,789,201.8516,0.8451

epoch:791/50, Iteration 32/32:training loss 0.6548278331756592
Train F1-mic 0.8490, Train F1-mac 0.4218
 F1-mic 0.8451,  F1-mac 0.4221
new best val f1: 0.8450868039316956
ogbn-products,dgl,1,790,202.1054,0.8451

 F1-mic 0.8451,  F1-mac 0.4222
new best val f1: 0.8451197894709255
ogbn-products,dgl,1,791,202.3569,0.8451

 F1-mic 0.8452,  F1-mac 0.4223
new best val f1: 0.8451667825679107
ogbn-products,dgl,1,792,202.6105,0.8452

 F1-mic 0.8452,  F1-mac 0.4224
new best val f1: 0.8452146793782994
ogbn-products,dgl,1,793,202.8642,0.8452

 F1-mic 0.8453,  F1-mac 0.4224
new best val f1: 0.84525037605774
ogbn-products,dgl,1,794,203.1181,0.8453

 F1-mic 0.8453,  F1-mac 0.4225
new best val f1: 0.8452874283072861
ogbn-products,dgl,1,795,203.3715,0.8453

 F1-mic 0.8453,  F1-mac 0.4225
new best val f1: 0.8453267398403408
ogbn-products,dgl,1,796,203.6258,0.8453

 F1-mic 0.8454,  F1-mac 0.4226
new best val f1: 0.8453818663579582
ogbn-products,dgl,1,797,203.8797,0.8454

 F1-mic 0.8454,  F1-mac 0.4226
new best val f1: 0.8454175630373988
ogbn-products,dgl,1,798,204.1334,0.8454

 F1-mic 0.8455,  F1-mac 0.4227
new best val f1: 0.8454555190003484
ogbn-products,dgl,1,799,204.3875,0.8455

epoch:801/50, Iteration 32/32:training loss 0.6529998779296875
Train F1-mic 0.8494, Train F1-mac 0.4224
 F1-mic 0.8455,  F1-mac 0.4227
new best val f1: 0.845493474963298
ogbn-products,dgl,1,800,204.6413,0.8455

 F1-mic 0.8455,  F1-mac 0.4228
new best val f1: 0.845520134508703
ogbn-products,dgl,1,801,204.8927,0.8455

 F1-mic 0.8456,  F1-mac 0.4228
new best val f1: 0.8455585423283544
ogbn-products,dgl,1,802,205.1470,0.8456

 F1-mic 0.8456,  F1-mac 0.4228
new best val f1: 0.8455978538614092
ogbn-products,dgl,1,803,205.4005,0.8456

 F1-mic 0.8456,  F1-mac 0.4229
new best val f1: 0.8456425876748855
ogbn-products,dgl,1,804,205.6542,0.8456

 F1-mic 0.8457,  F1-mac 0.4229
new best val f1: 0.8456945511955902
ogbn-products,dgl,1,805,205.9080,0.8457

 F1-mic 0.8457,  F1-mac 0.4230
new best val f1: 0.8457392850090665
ogbn-products,dgl,1,806,206.1615,0.8457

 F1-mic 0.8458,  F1-mac 0.4231
new best val f1: 0.8457799521122268
ogbn-products,dgl,1,807,206.4152,0.8458

 F1-mic 0.8458,  F1-mac 0.4232
new best val f1: 0.8458043523741229
ogbn-products,dgl,1,808,206.6688,0.8458

 F1-mic 0.8458,  F1-mac 0.4232
new best val f1: 0.8458373379133529
ogbn-products,dgl,1,809,206.9224,0.8458

epoch:811/50, Iteration 32/32:training loss 0.6512017250061035
Train F1-mic 0.8498, Train F1-mac 0.4230
 F1-mic 0.8459,  F1-mac 0.4233
new best val f1: 0.845876197589706
ogbn-products,dgl,1,810,207.1760,0.8459

 F1-mic 0.8459,  F1-mac 0.4233
new best val f1: 0.8459046645619182
ogbn-products,dgl,1,811,207.4275,0.8459

 F1-mic 0.8459,  F1-mac 0.4234
new best val f1: 0.845948494661991
ogbn-products,dgl,1,812,207.6819,0.8459

 F1-mic 0.8460,  F1-mac 0.4234
new best val f1: 0.8459778653476066
ogbn-products,dgl,1,813,207.9357,0.8460

 F1-mic 0.8460,  F1-mac 0.4235
new best val f1: 0.8460207917342757
ogbn-products,dgl,1,814,208.1892,0.8460

 F1-mic 0.8461,  F1-mac 0.4236
new best val f1: 0.8460555847003128
ogbn-products,dgl,1,815,208.4430,0.8461

 F1-mic 0.8461,  F1-mac 0.4236
new best val f1: 0.8460903776663498
ogbn-products,dgl,1,816,208.6965,0.8461

 F1-mic 0.8461,  F1-mac 0.4237
new best val f1: 0.8461242669189835
ogbn-products,dgl,1,817,208.9501,0.8461

 F1-mic 0.8462,  F1-mac 0.4237
new best val f1: 0.846151830177792
ogbn-products,dgl,1,818,209.2042,0.8462

 F1-mic 0.8462,  F1-mac 0.4238
new best val f1: 0.8461974677046719
ogbn-products,dgl,1,819,209.4579,0.8462

epoch:821/50, Iteration 32/32:training loss 0.6494366526603699
Train F1-mic 0.8501, Train F1-mac 0.4236
 F1-mic 0.8462,  F1-mac 0.4238
new best val f1: 0.8462300013872001
ogbn-products,dgl,1,820,209.7115,0.8462

 F1-mic 0.8463,  F1-mac 0.4238
new best val f1: 0.8462625350697283
ogbn-products,dgl,1,821,209.9629,0.8463

 F1-mic 0.8463,  F1-mac 0.4239
new best val f1: 0.8463027503161867
ogbn-products,dgl,1,822,210.2166,0.8463

 F1-mic 0.8463,  F1-mac 0.4239
new best val f1: 0.8463452248461542
ogbn-products,dgl,1,823,210.4704,0.8463

 F1-mic 0.8464,  F1-mac 0.4240
new best val f1: 0.8463845363792089
ogbn-products,dgl,1,824,210.7242,0.8464

 F1-mic 0.8464,  F1-mac 0.4240
new best val f1: 0.8464206849153514
ogbn-products,dgl,1,825,210.9778,0.8464

 F1-mic 0.8465,  F1-mac 0.4241
new best val f1: 0.8464590927350027
ogbn-products,dgl,1,826,211.2314,0.8465

 F1-mic 0.8465,  F1-mac 0.4241
new best val f1: 0.8464916264175311
ogbn-products,dgl,1,827,211.4850,0.8465

 F1-mic 0.8465,  F1-mac 0.4241
new best val f1: 0.8465200933897431
ogbn-products,dgl,1,828,211.7386,0.8465

 F1-mic 0.8466,  F1-mac 0.4242
new best val f1: 0.8465566937825874
ogbn-products,dgl,1,829,211.9921,0.8466

epoch:831/50, Iteration 32/32:training loss 0.6476991772651672
Train F1-mic 0.8505, Train F1-mac 0.4240
 F1-mic 0.8466,  F1-mac 0.4242
new best val f1: 0.8465946497455369
ogbn-products,dgl,1,830,212.2457,0.8466

 F1-mic 0.8466,  F1-mac 0.4243
new best val f1: 0.846637576132206
ogbn-products,dgl,1,831,212.4972,0.8466

 F1-mic 0.8467,  F1-mac 0.4243
new best val f1: 0.8466755320951556
ogbn-products,dgl,1,832,212.7508,0.8467

 F1-mic 0.8467,  F1-mac 0.4244
new best val f1: 0.8467229770488426
ogbn-products,dgl,1,833,213.0046,0.8467

 F1-mic 0.8468,  F1-mac 0.4244
new best val f1: 0.8467586737282832
ogbn-products,dgl,1,834,213.2585,0.8468

 F1-mic 0.8468,  F1-mac 0.4245
new best val f1: 0.8467844295602847
ogbn-products,dgl,1,835,213.5123,0.8468

 F1-mic 0.8468,  F1-mac 0.4245
new best val f1: 0.8468196743830235
ogbn-products,dgl,1,836,213.7666,0.8468

 F1-mic 0.8468,  F1-mac 0.4246
new best val f1: 0.8468476894985338
ogbn-products,dgl,1,837,214.0209,0.8468

 F1-mic 0.8469,  F1-mac 0.4246
new best val f1: 0.8468870010315889
ogbn-products,dgl,1,838,214.2746,0.8469

 F1-mic 0.8469,  F1-mac 0.4247
new best val f1: 0.846929927418258
ogbn-products,dgl,1,839,214.5282,0.8469

epoch:841/50, Iteration 32/32:training loss 0.6459907293319702
Train F1-mic 0.8508, Train F1-mac 0.4245
 F1-mic 0.8470,  F1-mac 0.4248
new best val f1: 0.8469638166708915
ogbn-products,dgl,1,840,214.7819,0.8470

 F1-mic 0.8470,  F1-mac 0.4248
new best val f1: 0.8469922836431037
ogbn-products,dgl,1,841,215.0332,0.8470

 F1-mic 0.8470,  F1-mac 0.4248
new best val f1: 0.8470248173256318
ogbn-products,dgl,1,842,215.2868,0.8470

 F1-mic 0.8471,  F1-mac 0.4249
new best val f1: 0.8470591584349672
ogbn-products,dgl,1,843,215.5403,0.8471

 F1-mic 0.8471,  F1-mac 0.4250
new best val f1: 0.8470998255381276
ogbn-products,dgl,1,844,215.7941,0.8471

 F1-mic 0.8471,  F1-mac 0.4251
new best val f1: 0.8471287443670414
ogbn-products,dgl,1,845,216.0487,0.8471

 F1-mic 0.8472,  F1-mac 0.4252
new best val f1: 0.8471721226104123
ogbn-products,dgl,1,846,216.3028,0.8472

 F1-mic 0.8472,  F1-mac 0.4252
new best val f1: 0.8472141452836779
ogbn-products,dgl,1,847,216.5563,0.8472

 F1-mic 0.8472,  F1-mac 0.4252
new best val f1: 0.8472403529723812
ogbn-products,dgl,1,848,216.8102,0.8472

 F1-mic 0.8473,  F1-mac 0.4253
new best val f1: 0.8472719829415057
ogbn-products,dgl,1,849,217.0640,0.8473

epoch:851/50, Iteration 32/32:training loss 0.6443151831626892
Train F1-mic 0.8512, Train F1-mac 0.4251
 F1-mic 0.8473,  F1-mac 0.4253
new best val f1: 0.8473158130415785
ogbn-products,dgl,1,850,217.3175,0.8473

 F1-mic 0.8473,  F1-mac 0.4254
new best val f1: 0.8473411170168782
ogbn-products,dgl,1,851,217.5688,0.8473

 F1-mic 0.8474,  F1-mac 0.4254
new best val f1: 0.84737455441281
ogbn-products,dgl,1,852,217.8228,0.8474

 F1-mic 0.8474,  F1-mac 0.4255
new best val f1: 0.8474224512231986
ogbn-products,dgl,1,853,218.0765,0.8474

 F1-mic 0.8475,  F1-mac 0.4255
new best val f1: 0.8474513700521126
ogbn-products,dgl,1,854,218.3303,0.8475

 F1-mic 0.8475,  F1-mac 0.4256
new best val f1: 0.8474726073170963
ogbn-products,dgl,1,855,218.5845,0.8475

 F1-mic 0.8475,  F1-mac 0.4256
new best val f1: 0.8475114669934495
ogbn-products,dgl,1,856,218.8390,0.8475

 F1-mic 0.8475,  F1-mac 0.4257
new best val f1: 0.8475385783955562
ogbn-products,dgl,1,857,219.0934,0.8475

 F1-mic 0.8476,  F1-mac 0.4257
new best val f1: 0.847578341785313
ogbn-products,dgl,1,858,219.3471,0.8476

 F1-mic 0.8476,  F1-mac 0.4258
new best val f1: 0.8476126828946483
ogbn-products,dgl,1,859,219.6014,0.8476

epoch:861/50, Iteration 32/32:training loss 0.6426642537117004
Train F1-mic 0.8515, Train F1-mac 0.4256
 F1-mic 0.8477,  F1-mac 0.4259
new best val f1: 0.8476542537112121
ogbn-products,dgl,1,860,219.8550,0.8477

 F1-mic 0.8477,  F1-mac 0.4260
new best val f1: 0.8477003430947937
ogbn-products,dgl,1,861,220.1064,0.8477

 F1-mic 0.8477,  F1-mac 0.4260
new best val f1: 0.8477419139113573
ogbn-products,dgl,1,862,220.3606,0.8477

 F1-mic 0.8478,  F1-mac 0.4260
new best val f1: 0.8477771587340963
ogbn-products,dgl,1,863,220.6142,0.8478

 F1-mic 0.8478,  F1-mac 0.4260
new best val f1: 0.8478038182795014
ogbn-products,dgl,1,864,220.8681,0.8478

 F1-mic 0.8479,  F1-mac 0.4261
new best val f1: 0.8478544262301008
ogbn-products,dgl,1,865,221.1224,0.8479

 F1-mic 0.8479,  F1-mac 0.4262
new best val f1: 0.8478837969157166
ogbn-products,dgl,1,866,221.3763,0.8479

 F1-mic 0.8479,  F1-mac 0.4262
new best val f1: 0.8479081971776127
ogbn-products,dgl,1,867,221.6299,0.8479

 F1-mic 0.8479,  F1-mac 0.4262
new best val f1: 0.8479470568539658
ogbn-products,dgl,1,868,221.8836,0.8479

 F1-mic 0.8480,  F1-mac 0.4263
new best val f1: 0.8479755238261779
ogbn-products,dgl,1,869,222.1371,0.8480

epoch:871/50, Iteration 32/32:training loss 0.6410409808158875
Train F1-mic 0.8518, Train F1-mac 0.4260
 F1-mic 0.8480,  F1-mac 0.4263
new best val f1: 0.8480225169231631
ogbn-products,dgl,1,870,222.3912,0.8480

 F1-mic 0.8481,  F1-mac 0.4263
new best val f1: 0.8480613765995162
ogbn-products,dgl,1,871,222.6425,0.8481

 F1-mic 0.8481,  F1-mac 0.4264
new best val f1: 0.8480916509985356
ogbn-products,dgl,1,872,222.8963,0.8481

 F1-mic 0.8481,  F1-mac 0.4264
new best val f1: 0.8481300588181868
ogbn-products,dgl,1,873,223.1506,0.8481

 F1-mic 0.8482,  F1-mac 0.4265
new best val f1: 0.8481693703512417
ogbn-products,dgl,1,874,223.4046,0.8482

 F1-mic 0.8482,  F1-mac 0.4265
new best val f1: 0.8481996447502611
ogbn-products,dgl,1,875,223.6585,0.8482

 F1-mic 0.8482,  F1-mac 0.4265
new best val f1: 0.8482258524389643
ogbn-products,dgl,1,876,223.9122,0.8482

 F1-mic 0.8483,  F1-mac 0.4266
new best val f1: 0.8482633565452122
ogbn-products,dgl,1,877,224.1655,0.8483

 F1-mic 0.8483,  F1-mac 0.4266
new best val f1: 0.8483004087947581
ogbn-products,dgl,1,878,224.4199,0.8483

 F1-mic 0.8483,  F1-mac 0.4267
new best val f1: 0.8483442388948308
ogbn-products,dgl,1,879,224.6741,0.8483

epoch:881/50, Iteration 32/32:training loss 0.6394466757774353
Train F1-mic 0.8522, Train F1-mac 0.4265
 F1-mic 0.8484,  F1-mac 0.4267
new best val f1: 0.8483772244340608
ogbn-products,dgl,1,880,224.9277,0.8484

 F1-mic 0.8484,  F1-mac 0.4268
new best val f1: 0.8484133729702033
ogbn-products,dgl,1,881,225.1799,0.8484

 F1-mic 0.8485,  F1-mac 0.4268
new best val f1: 0.8484544919300653
ogbn-products,dgl,1,882,225.4335,0.8485

 F1-mic 0.8485,  F1-mac 0.4269
new best val f1: 0.8484843144723827
ogbn-products,dgl,1,883,225.6883,0.8485

 F1-mic 0.8485,  F1-mac 0.4270
new best val f1: 0.8485222704353323
ogbn-products,dgl,1,884,225.9427,0.8485

 F1-mic 0.8486,  F1-mac 0.4270
new best val f1: 0.8485502855508427
ogbn-products,dgl,1,885,226.1963,0.8486

 F1-mic 0.8486,  F1-mac 0.4271
new best val f1: 0.8485814636632656
ogbn-products,dgl,1,886,226.4503,0.8486

 F1-mic 0.8486,  F1-mac 0.4272
new best val f1: 0.8486158047726009
ogbn-products,dgl,1,887,226.7038,0.8486

 F1-mic 0.8487,  F1-mac 0.4274
new best val f1: 0.8486551163056557
ogbn-products,dgl,1,888,226.9582,0.8487

 F1-mic 0.8487,  F1-mac 0.4276
new best val f1: 0.8486831314211661
ogbn-products,dgl,1,889,227.2120,0.8487

epoch:891/50, Iteration 32/32:training loss 0.6378752589225769
Train F1-mic 0.8525, Train F1-mac 0.4274
 F1-mic 0.8487,  F1-mac 0.4279
new best val f1: 0.8487093391098695
ogbn-products,dgl,1,890,227.4658,0.8487

 F1-mic 0.8487,  F1-mac 0.4282
new best val f1: 0.8487391616521869
ogbn-products,dgl,1,891,227.7171,0.8487

 F1-mic 0.8488,  F1-mac 0.4286
new best val f1: 0.8487811843254525
ogbn-products,dgl,1,892,227.9709,0.8488

 F1-mic 0.8488,  F1-mac 0.4288
new best val f1: 0.8488024215904362
ogbn-products,dgl,1,893,228.2253,0.8488

 F1-mic 0.8488,  F1-mac 0.4292
new best val f1: 0.8488313404193502
ogbn-products,dgl,1,894,228.4791,0.8488

 F1-mic 0.8489,  F1-mac 0.4295
new best val f1: 0.8488765260895281
ogbn-products,dgl,1,895,228.7329,0.8489

 F1-mic 0.8489,  F1-mac 0.4299
new best val f1: 0.8489266821834257
ogbn-products,dgl,1,896,228.9867,0.8489

 F1-mic 0.8490,  F1-mac 0.4303
new best val f1: 0.8489574084391469
ogbn-products,dgl,1,897,229.2405,0.8490

 F1-mic 0.8490,  F1-mac 0.4305
new best val f1: 0.8489827124144466
ogbn-products,dgl,1,898,229.4939,0.8490

 F1-mic 0.8490,  F1-mac 0.4306
new best val f1: 0.8490143423835712
ogbn-products,dgl,1,899,229.7474,0.8490

epoch:901/50, Iteration 32/32:training loss 0.6363304853439331
Train F1-mic 0.8529, Train F1-mac 0.4304
 F1-mic 0.8491,  F1-mac 0.4308
new best val f1: 0.8490527502032226
ogbn-products,dgl,1,900,230.0013,0.8491

 F1-mic 0.8491,  F1-mac 0.4311
new best val f1: 0.8490925135929792
ogbn-products,dgl,1,901,230.2529,0.8491

 F1-mic 0.8491,  F1-mac 0.4318
new best val f1: 0.8491318251260342
ogbn-products,dgl,1,902,230.5066,0.8491

 F1-mic 0.8492,  F1-mac 0.4323
new best val f1: 0.8491693292322819
ogbn-products,dgl,1,903,230.7605,0.8492

 F1-mic 0.8492,  F1-mac 0.4327
new best val f1: 0.8491986999178976
ogbn-products,dgl,1,904,231.0144,0.8492

 F1-mic 0.8492,  F1-mac 0.4329
new best val f1: 0.8492380114509526
ogbn-products,dgl,1,905,231.2686,0.8492

 F1-mic 0.8493,  F1-mac 0.4333
new best val f1: 0.8492764192706038
ogbn-products,dgl,1,906,231.5224,0.8493

 F1-mic 0.8493,  F1-mac 0.4336
new best val f1: 0.8493103085232374
ogbn-products,dgl,1,907,231.7762,0.8493

 F1-mic 0.8493,  F1-mac 0.4339
new best val f1: 0.8493464570593798
ogbn-products,dgl,1,908,232.0299,0.8493

 F1-mic 0.8494,  F1-mac 0.4342
new best val f1: 0.8493911908728561
ogbn-products,dgl,1,909,232.2834,0.8494

epoch:911/50, Iteration 32/32:training loss 0.6348074674606323
Train F1-mic 0.8532, Train F1-mac 0.4340
 F1-mic 0.8494,  F1-mac 0.4344
new best val f1: 0.8494219171285771
ogbn-products,dgl,1,910,232.5369,0.8494

 F1-mic 0.8495,  F1-mac 0.4348
new best val f1: 0.8494576138080179
ogbn-products,dgl,1,911,232.7882,0.8495

 F1-mic 0.8495,  F1-mac 0.4351
new best val f1: 0.8494847252101246
ogbn-products,dgl,1,912,233.0418,0.8495

 F1-mic 0.8495,  F1-mac 0.4354
new best val f1: 0.849510932898828
ogbn-products,dgl,1,913,233.2956,0.8495

 F1-mic 0.8495,  F1-mac 0.4362
new best val f1: 0.8495407554411455
ogbn-products,dgl,1,914,233.5495,0.8495

 F1-mic 0.8496,  F1-mac 0.4364
new best val f1: 0.8495814225443057
ogbn-products,dgl,1,915,233.8033,0.8496

 F1-mic 0.8496,  F1-mac 0.4362
new best val f1: 0.8496144080835356
ogbn-products,dgl,1,916,234.0569,0.8496

 F1-mic 0.8496,  F1-mac 0.4369
new best val f1: 0.8496374527753264
ogbn-products,dgl,1,917,234.3104,0.8496

 F1-mic 0.8497,  F1-mac 0.4371
new best val f1: 0.8496726975980653
ogbn-products,dgl,1,918,234.5639,0.8497

 F1-mic 0.8497,  F1-mac 0.4374
new best val f1: 0.8496835421589082
ogbn-products,dgl,1,919,234.8177,0.8497

epoch:921/50, Iteration 32/32:training loss 0.6333106160163879
Train F1-mic 0.8535, Train F1-mac 0.4371
 F1-mic 0.8497,  F1-mac 0.4379
new best val f1: 0.8497359575363146
ogbn-products,dgl,1,920,235.0713,0.8497

 F1-mic 0.8498,  F1-mac 0.4381
new best val f1: 0.849763972651825
ogbn-products,dgl,1,921,235.3226,0.8498

 F1-mic 0.8498,  F1-mac 0.4383
new best val f1: 0.8498109657488101
ogbn-products,dgl,1,922,235.5764,0.8498

 F1-mic 0.8498,  F1-mac 0.4384
new best val f1: 0.8498407882911276
ogbn-products,dgl,1,923,235.8306,0.8498

 F1-mic 0.8499,  F1-mac 0.4387
new best val f1: 0.849866995979831
ogbn-products,dgl,1,924,236.0845,0.8499

 F1-mic 0.8499,  F1-mac 0.4388
new best val f1: 0.8498986259489556
ogbn-products,dgl,1,925,236.3381,0.8499

 F1-mic 0.8499,  F1-mac 0.4389
new best val f1: 0.8499279966345713
ogbn-products,dgl,1,926,236.5924,0.8499

 F1-mic 0.8500,  F1-mac 0.4390
new best val f1: 0.849959626603696
ogbn-products,dgl,1,927,236.8462,0.8500

 F1-mic 0.8500,  F1-mac 0.4393
new best val f1: 0.8499930639996277
ogbn-products,dgl,1,928,237.0997,0.8500

 F1-mic 0.8500,  F1-mac 0.4394
new best val f1: 0.8500301162491737
ogbn-products,dgl,1,929,237.3535,0.8500

epoch:931/50, Iteration 32/32:training loss 0.6318383812904358
Train F1-mic 0.8538, Train F1-mac 0.4392
 F1-mic 0.8501,  F1-mac 0.4397
new best val f1: 0.8500658129286143
ogbn-products,dgl,1,930,237.6078,0.8501

 F1-mic 0.8501,  F1-mac 0.4398
new best val f1: 0.8501010577513531
ogbn-products,dgl,1,931,237.8592,0.8501

 F1-mic 0.8501,  F1-mac 0.4400
new best val f1: 0.8501390137143028
ogbn-products,dgl,1,932,238.1140,0.8501

 F1-mic 0.8502,  F1-mac 0.4402
new best val f1: 0.8501647695463043
ogbn-products,dgl,1,933,238.3677,0.8502

 F1-mic 0.8502,  F1-mac 0.4403
new best val f1: 0.8501936883752181
ogbn-products,dgl,1,934,238.6216,0.8502

 F1-mic 0.8502,  F1-mac 0.4405
new best val f1: 0.8502176367804126
ogbn-products,dgl,1,935,238.8757,0.8502

 F1-mic 0.8503,  F1-mac 0.4406
new best val f1: 0.8502524297464497
ogbn-products,dgl,1,936,239.1293,0.8503

 F1-mic 0.8503,  F1-mac 0.4407
new best val f1: 0.8502799930052582
ogbn-products,dgl,1,937,239.3828,0.8503

 F1-mic 0.8503,  F1-mac 0.4408
new best val f1: 0.8503116229743829
ogbn-products,dgl,1,938,239.6371,0.8503

 F1-mic 0.8503,  F1-mac 0.4410
new best val f1: 0.8503428010868057
ogbn-products,dgl,1,939,239.8910,0.8503

epoch:941/50, Iteration 32/32:training loss 0.630388081073761
Train F1-mic 0.8542, Train F1-mac 0.4407
 F1-mic 0.8504,  F1-mac 0.4411
new best val f1: 0.8503775940528429
ogbn-products,dgl,1,940,240.1445,0.8504

 F1-mic 0.8504,  F1-mac 0.4413
new best val f1: 0.8503983794611247
ogbn-products,dgl,1,941,240.3959,0.8504

 F1-mic 0.8504,  F1-mac 0.4413
new best val f1: 0.8504309131436529
ogbn-products,dgl,1,942,240.6496,0.8504

 F1-mic 0.8505,  F1-mac 0.4414
new best val f1: 0.8504643505395847
ogbn-products,dgl,1,943,240.9031,0.8505

 F1-mic 0.8505,  F1-mac 0.4416
new best val f1: 0.8504887508014808
ogbn-products,dgl,1,944,241.1574,0.8505

 F1-mic 0.8505,  F1-mac 0.4416
new best val f1: 0.8505167659169912
ogbn-products,dgl,1,945,241.4113,0.8505

 F1-mic 0.8505,  F1-mac 0.4420
new best val f1: 0.8505483958861159
ogbn-products,dgl,1,946,241.6654,0.8505

 F1-mic 0.8506,  F1-mac 0.4421
new best val f1: 0.8505822851387493
ogbn-products,dgl,1,947,241.9189,0.8506

 F1-mic 0.8506,  F1-mac 0.4423
new best val f1: 0.8506175299614883
ogbn-products,dgl,1,948,242.1727,0.8506

 F1-mic 0.8506,  F1-mac 0.4425
new best val f1: 0.8506478043605076
ogbn-products,dgl,1,949,242.4262,0.8506

epoch:951/50, Iteration 32/32:training loss 0.6289605498313904
Train F1-mic 0.8545, Train F1-mac 0.4422
 F1-mic 0.8507,  F1-mac 0.4425
new best val f1: 0.850661360061561
ogbn-products,dgl,1,950,242.6807,0.8507

 F1-mic 0.8507,  F1-mac 0.4426
new best val f1: 0.8506925381739838
ogbn-products,dgl,1,951,242.9321,0.8507

 F1-mic 0.8507,  F1-mac 0.4426
new best val f1: 0.8507196495760906
ogbn-products,dgl,1,952,243.1859,0.8507

 F1-mic 0.8508,  F1-mac 0.4427
new best val f1: 0.8507508276885135
ogbn-products,dgl,1,953,243.4397,0.8508

 F1-mic 0.8508,  F1-mac 0.4428
new best val f1: 0.850782457657638
ogbn-products,dgl,1,954,243.6935,0.8508

 F1-mic 0.8508,  F1-mac 0.4430
new best val f1: 0.8508145394834645
ogbn-products,dgl,1,955,243.9482,0.8508

 F1-mic 0.8508,  F1-mac 0.4432
new best val f1: 0.8508380360319571
ogbn-products,dgl,1,956,244.2028,0.8508

 F1-mic 0.8509,  F1-mac 0.4433
new best val f1: 0.8508624362938533
ogbn-products,dgl,1,957,244.4566,0.8509

 F1-mic 0.8509,  F1-mac 0.4435
new best val f1: 0.8509098812475402
ogbn-products,dgl,1,958,244.7101,0.8509

 F1-mic 0.8509,  F1-mac 0.4437
new best val f1: 0.850936992649647
ogbn-products,dgl,1,959,244.9635,0.8509

epoch:961/50, Iteration 32/32:training loss 0.6275575160980225
Train F1-mic 0.8547, Train F1-mac 0.4434
 F1-mic 0.8510,  F1-mac 0.4443
new best val f1: 0.8509690744754734
ogbn-products,dgl,1,960,245.2173,0.8510

 F1-mic 0.8510,  F1-mac 0.4440
new best val f1: 0.8510052230116159
ogbn-products,dgl,1,961,245.4687,0.8510

 F1-mic 0.8510,  F1-mac 0.4447
new best val f1: 0.8510359492673369
ogbn-products,dgl,1,962,245.7226,0.8510

 F1-mic 0.8511,  F1-mac 0.4442
new best val f1: 0.8510657718096545
ogbn-products,dgl,1,963,245.9761,0.8511

 F1-mic 0.8511,  F1-mac 0.4448
new best val f1: 0.8510924313550595
ogbn-products,dgl,1,964,246.2307,0.8511

 F1-mic 0.8511,  F1-mac 0.4449
new best val f1: 0.85112044647057
ogbn-products,dgl,1,965,246.4844,0.8511

 F1-mic 0.8512,  F1-mac 0.4450
new best val f1: 0.8511579505768176
ogbn-products,dgl,1,966,246.7380,0.8512

 F1-mic 0.8512,  F1-mac 0.4451
new best val f1: 0.8511868694057316
ogbn-products,dgl,1,967,246.9916,0.8512

 F1-mic 0.8512,  F1-mac 0.4452
new best val f1: 0.8512053955305048
ogbn-products,dgl,1,968,247.2452,0.8512

 F1-mic 0.8512,  F1-mac 0.4453
new best val f1: 0.8512270846521901
ogbn-products,dgl,1,969,247.4989,0.8512

epoch:971/50, Iteration 32/32:training loss 0.6261777877807617
Train F1-mic 0.8550, Train F1-mac 0.4450
 F1-mic 0.8513,  F1-mac 0.4449
new best val f1: 0.851266396185245
ogbn-products,dgl,1,970,247.7526,0.8513

 F1-mic 0.8513,  F1-mac 0.4450
new best val f1: 0.8512953150141589
ogbn-products,dgl,1,971,248.0041,0.8513

 F1-mic 0.8513,  F1-mac 0.4457
new best val f1: 0.8513350784039156
ogbn-products,dgl,1,972,248.2577,0.8513

 F1-mic 0.8514,  F1-mac 0.4458
new best val f1: 0.8513667083730402
ogbn-products,dgl,1,973,248.5112,0.8514

 F1-mic 0.8514,  F1-mac 0.4453
new best val f1: 0.8513978864854631
ogbn-products,dgl,1,974,248.7660,0.8514

 F1-mic 0.8514,  F1-mac 0.4455
new best val f1: 0.8514295164545876
ogbn-products,dgl,1,975,249.0196,0.8514

 F1-mic 0.8515,  F1-mac 0.4461
new best val f1: 0.8514593389969052
ogbn-products,dgl,1,976,249.2731,0.8515

 F1-mic 0.8515,  F1-mac 0.4456
new best val f1: 0.8514909689660298
ogbn-products,dgl,1,977,249.5269,0.8515

 F1-mic 0.8515,  F1-mac 0.4457
new best val f1: 0.8515176285114349
ogbn-products,dgl,1,978,249.7814,0.8515

 F1-mic 0.8515,  F1-mac 0.4465
new best val f1: 0.8515492584805595
ogbn-products,dgl,1,979,250.0359,0.8515

epoch:981/50, Iteration 32/32:training loss 0.6248127818107605
Train F1-mic 0.8553, Train F1-mac 0.4462
 F1-mic 0.8516,  F1-mac 0.4465
new best val f1: 0.8515881181569127
ogbn-products,dgl,1,980,250.2900,0.8516

 F1-mic 0.8516,  F1-mac 0.4461
new best val f1: 0.8516138739889143
ogbn-products,dgl,1,981,250.5422,0.8516

 F1-mic 0.8516,  F1-mac 0.4463
new best val f1: 0.851640985391021
ogbn-products,dgl,1,982,250.7959,0.8516

 F1-mic 0.8517,  F1-mac 0.4464
new best val f1: 0.8516699042199349
ogbn-products,dgl,1,983,251.0497,0.8517

 F1-mic 0.8517,  F1-mac 0.4465
new best val f1: 0.8517033416158667
ogbn-products,dgl,1,984,251.3031,0.8517

 F1-mic 0.8517,  F1-mac 0.4471
new best val f1: 0.851731356731377
ogbn-products,dgl,1,985,251.5571,0.8517

 F1-mic 0.8518,  F1-mac 0.4467
new best val f1: 0.8517589199901857
ogbn-products,dgl,1,986,251.8107,0.8518

 F1-mic 0.8518,  F1-mac 0.4473
new best val f1: 0.8517833202520818
ogbn-products,dgl,1,987,252.0646,0.8518

 F1-mic 0.8518,  F1-mac 0.4468
new best val f1: 0.8518059130871708
ogbn-products,dgl,1,988,252.3181,0.8518

 F1-mic 0.8518,  F1-mac 0.4474
new best val f1: 0.8518307652057686
ogbn-products,dgl,1,989,252.5717,0.8518

epoch:991/50, Iteration 32/32:training loss 0.6234726905822754
Train F1-mic 0.8556, Train F1-mac 0.4471
 F1-mic 0.8519,  F1-mac 0.4474
new best val f1: 0.8518520024707524
ogbn-products,dgl,1,990,252.8253,0.8519

 F1-mic 0.8519,  F1-mac 0.4475
new best val f1: 0.8518908621471054
ogbn-products,dgl,1,991,253.0774,0.8519

 F1-mic 0.8519,  F1-mac 0.4476
new best val f1: 0.8519170698358088
ogbn-products,dgl,1,992,253.3312,0.8519

 F1-mic 0.8520,  F1-mac 0.4478
new best val f1: 0.851959996222478
ogbn-products,dgl,1,993,253.5855,0.8520

 F1-mic 0.8520,  F1-mac 0.4479
new best val f1: 0.8519884631946901
ogbn-products,dgl,1,994,253.8397,0.8520

 F1-mic 0.8520,  F1-mac 0.4479
new best val f1: 0.8520119597431828
ogbn-products,dgl,1,995,254.0940,0.8520

 F1-mic 0.8520,  F1-mac 0.4480
new best val f1: 0.8520390711452895
ogbn-products,dgl,1,996,254.3478,0.8520

 F1-mic 0.8521,  F1-mac 0.4480
new best val f1: 0.8520666344040981
ogbn-products,dgl,1,997,254.6014,0.8521

 F1-mic 0.8521,  F1-mac 0.4481
new best val f1: 0.8520869679556783
ogbn-products,dgl,1,998,254.8550,0.8521

 F1-mic 0.8521,  F1-mac 0.4481
new best val f1: 0.8521213090650136
ogbn-products,dgl,1,999,255.1086,0.8521

epoch:1001/50, Iteration 32/32:training loss 0.6221540570259094
Train F1-mic 0.8559, Train F1-mac 0.4479
 F1-mic 0.8521,  F1-mac 0.4482
new best val f1: 0.8521416426165938
ogbn-products,dgl,1,1000,255.3620,0.8521

 F1-mic 0.8522,  F1-mac 0.4483
new best val f1: 0.852171917015613
ogbn-products,dgl,1,1001,255.6140,0.8522

 F1-mic 0.8522,  F1-mac 0.4483
new best val f1: 0.8521972209909127
ogbn-products,dgl,1,1002,255.8677,0.8522

 F1-mic 0.8522,  F1-mac 0.4483
new best val f1: 0.8522252361064231
ogbn-products,dgl,1,1003,256.1216,0.8522

 F1-mic 0.8523,  F1-mac 0.4484
new best val f1: 0.8522582216456531
ogbn-products,dgl,1,1004,256.3753,0.8523

 F1-mic 0.8523,  F1-mac 0.4484
new best val f1: 0.8522857849044617
ogbn-products,dgl,1,1005,256.6297,0.8523

 F1-mic 0.8523,  F1-mac 0.4485
new best val f1: 0.8523128963065685
ogbn-products,dgl,1,1006,256.8836,0.8523

 F1-mic 0.8524,  F1-mac 0.4485
new best val f1: 0.8523589856901501
ogbn-products,dgl,1,1007,257.1373,0.8524

 F1-mic 0.8524,  F1-mac 0.4486
new best val f1: 0.8523761562448179
ogbn-products,dgl,1,1008,257.3909,0.8524

 F1-mic 0.8524,  F1-mac 0.4487
new best val f1: 0.8524055269304335
ogbn-products,dgl,1,1009,257.6446,0.8524

epoch:1011/50, Iteration 32/32:training loss 0.620854377746582
Train F1-mic 0.8562, Train F1-mac 0.4484
 F1-mic 0.8524,  F1-mac 0.4488
new best val f1: 0.852435349472751
ogbn-products,dgl,1,1010,257.8982,0.8524

 F1-mic 0.8523,  F1-mac 0.4488
ogbn-products,dgl,1,1011,258.1495,0.8523

 F1-mic 0.8524,  F1-mac 0.4489
ogbn-products,dgl,1,1012,258.4041,0.8524

 F1-mic 0.8524,  F1-mac 0.4490
ogbn-products,dgl,1,1013,258.6577,0.8524

 F1-mic 0.8524,  F1-mac 0.4490
ogbn-products,dgl,1,1014,258.9113,0.8524

 F1-mic 0.8525,  F1-mac 0.4490
new best val f1: 0.8524592978779454
ogbn-products,dgl,1,1015,259.1653,0.8525

 F1-mic 0.8525,  F1-mac 0.4492
new best val f1: 0.85249092784707
ogbn-products,dgl,1,1016,259.4189,0.8525

 F1-mic 0.8525,  F1-mac 0.4492
new best val f1: 0.8525121651120536
ogbn-products,dgl,1,1017,259.6727,0.8525

 F1-mic 0.8525,  F1-mac 0.4492
new best val f1: 0.8525329505203356
ogbn-products,dgl,1,1018,259.9263,0.8525

 F1-mic 0.8526,  F1-mac 0.4493
new best val f1: 0.8525532840719157
ogbn-products,dgl,1,1019,260.1799,0.8526

epoch:1021/50, Iteration 32/32:training loss 0.6195740103721619
Train F1-mic 0.8563, Train F1-mac 0.4490
 F1-mic 0.8526,  F1-mac 0.4493
new best val f1: 0.8525953067451812
ogbn-products,dgl,1,1020,260.4341,0.8526

 F1-mic 0.8526,  F1-mac 0.4493
new best val f1: 0.8526093143029364
ogbn-products,dgl,1,1021,260.6853,0.8526

 F1-mic 0.8526,  F1-mac 0.4494
new best val f1: 0.8526468184091842
ogbn-products,dgl,1,1022,260.9398,0.8526

 F1-mic 0.8527,  F1-mac 0.4495
new best val f1: 0.8526667001040626
ogbn-products,dgl,1,1023,261.1934,0.8527

 F1-mic 0.8527,  F1-mac 0.4495
new best val f1: 0.8526901966525552
ogbn-products,dgl,1,1024,261.4471,0.8527

 F1-mic 0.8527,  F1-mac 0.4496
new best val f1: 0.8527159524845567
ogbn-products,dgl,1,1025,261.7014,0.8527

 F1-mic 0.8527,  F1-mac 0.4496
new best val f1: 0.8527475824536813
ogbn-products,dgl,1,1026,261.9551,0.8527

 F1-mic 0.8528,  F1-mac 0.4497
new best val f1: 0.8527656567217525
ogbn-products,dgl,1,1027,262.2096,0.8528

 F1-mic 0.8528,  F1-mac 0.4498
new best val f1: 0.8527999978310878
ogbn-products,dgl,1,1028,262.4634,0.8528

 F1-mic 0.8528,  F1-mac 0.4499
new best val f1: 0.8528216869527733
ogbn-products,dgl,1,1029,262.7173,0.8528

epoch:1031/50, Iteration 32/32:training loss 0.6183118224143982
Train F1-mic 0.8566, Train F1-mac 0.4496
 F1-mic 0.8529,  F1-mac 0.4499
new best val f1: 0.8528501539249854
ogbn-products,dgl,1,1030,262.9708,0.8529

 F1-mic 0.8529,  F1-mac 0.4499
new best val f1: 0.8528709393332674
ogbn-products,dgl,1,1031,263.2223,0.8529

 F1-mic 0.8529,  F1-mac 0.4499
ogbn-products,dgl,1,1032,263.4765,0.8529

 F1-mic 0.8529,  F1-mac 0.4500
new best val f1: 0.8529034730157956
ogbn-products,dgl,1,1033,263.7310,0.8529

 F1-mic 0.8529,  F1-mac 0.4501
new best val f1: 0.8529229028539721
ogbn-products,dgl,1,1034,263.9848,0.8529

 F1-mic 0.8529,  F1-mac 0.4502
new best val f1: 0.8529459475457628
ogbn-products,dgl,1,1035,264.2389,0.8529

 F1-mic 0.8530,  F1-mac 0.4503
new best val f1: 0.8529689922375537
ogbn-products,dgl,1,1036,264.4928,0.8530

 F1-mic 0.8530,  F1-mac 0.4503
new best val f1: 0.8530060444870997
ogbn-products,dgl,1,1037,264.7464,0.8530

 F1-mic 0.8530,  F1-mac 0.4504
new best val f1: 0.8530385781696279
ogbn-products,dgl,1,1038,265.0000,0.8530

 F1-mic 0.8531,  F1-mac 0.4504
new best val f1: 0.8530742748490685
ogbn-products,dgl,1,1039,265.2542,0.8531

epoch:1041/50, Iteration 32/32:training loss 0.6170679330825806
Train F1-mic 0.8568, Train F1-mac 0.4502
 F1-mic 0.8531,  F1-mac 0.4504
new best val f1: 0.853077437845981
ogbn-products,dgl,1,1040,265.5080,0.8531

 F1-mic 0.8531,  F1-mac 0.4505
new best val f1: 0.8531108752419126
ogbn-products,dgl,1,1041,265.7595,0.8531

 F1-mic 0.8531,  F1-mac 0.4505
new best val f1: 0.8531298532233876
ogbn-products,dgl,1,1042,266.0132,0.8531

 F1-mic 0.8532,  F1-mac 0.4506
new best val f1: 0.8531714240399514
ogbn-products,dgl,1,1043,266.2677,0.8532

 F1-mic 0.8532,  F1-mac 0.4506
new best val f1: 0.8531917575915314
ogbn-products,dgl,1,1044,266.5214,0.8532

 F1-mic 0.8532,  F1-mac 0.4506
new best val f1: 0.8532206764204454
ogbn-products,dgl,1,1045,266.7752,0.8532

 F1-mic 0.8532,  F1-mac 0.4507
new best val f1: 0.8532486915359558
ogbn-products,dgl,1,1046,267.0292,0.8532

 F1-mic 0.8533,  F1-mac 0.4508
new best val f1: 0.8532744473679573
ogbn-products,dgl,1,1047,267.2837,0.8533

 F1-mic 0.8533,  F1-mac 0.4509
new best val f1: 0.8533029143401695
ogbn-products,dgl,1,1048,267.5375,0.8533

 F1-mic 0.8533,  F1-mac 0.4510
new best val f1: 0.8533282183154691
ogbn-products,dgl,1,1049,267.7912,0.8533

epoch:1051/50, Iteration 32/32:training loss 0.6158434152603149
Train F1-mic 0.8571, Train F1-mac 0.4508
 F1-mic 0.8534,  F1-mac 0.4511
new best val f1: 0.8533621075681027
ogbn-products,dgl,1,1050,268.0448,0.8534

 F1-mic 0.8534,  F1-mac 0.4511
new best val f1: 0.8533847004031917
ogbn-products,dgl,1,1051,268.2963,0.8534

 F1-mic 0.8534,  F1-mac 0.4512
new best val f1: 0.8534054858114737
ogbn-products,dgl,1,1052,268.5499,0.8534

 F1-mic 0.8534,  F1-mac 0.4512
new best val f1: 0.8534271749331592
ogbn-products,dgl,1,1053,268.8033,0.8534

 F1-mic 0.8534,  F1-mac 0.4513
new best val f1: 0.8534497677682481
ogbn-products,dgl,1,1054,269.0579,0.8534

 F1-mic 0.8535,  F1-mac 0.4513
new best val f1: 0.8534651308961086
ogbn-products,dgl,1,1055,269.3117,0.8535

 F1-mic 0.8535,  F1-mac 0.4514
new best val f1: 0.8534836570208816
ogbn-products,dgl,1,1056,269.5653,0.8535

 F1-mic 0.8535,  F1-mac 0.4514
new best val f1: 0.8535103165662867
ogbn-products,dgl,1,1057,269.8195,0.8535

 F1-mic 0.8535,  F1-mac 0.4515
new best val f1: 0.8535338131147793
ogbn-products,dgl,1,1058,270.0731,0.8535

 F1-mic 0.8536,  F1-mac 0.4517
new best val f1: 0.853559117090079
ogbn-products,dgl,1,1059,270.3268,0.8536

epoch:1061/50, Iteration 32/32:training loss 0.6146339178085327
Train F1-mic 0.8573, Train F1-mac 0.4514
 F1-mic 0.8536,  F1-mac 0.4517
new best val f1: 0.8535893914890983
ogbn-products,dgl,1,1060,270.5809,0.8536

 F1-mic 0.8536,  F1-mac 0.4518
new best val f1: 0.8536115324674856
ogbn-products,dgl,1,1061,270.8329,0.8536

 F1-mic 0.8536,  F1-mac 0.4518
new best val f1: 0.8536359327293817
ogbn-products,dgl,1,1062,271.0864,0.8536

 F1-mic 0.8537,  F1-mac 0.4518
new best val f1: 0.8536580737077689
ogbn-products,dgl,1,1063,271.3399,0.8537

 F1-mic 0.8537,  F1-mac 0.4519
new best val f1: 0.8536860888232793
ogbn-products,dgl,1,1064,271.5936,0.8537

 F1-mic 0.8537,  F1-mac 0.4519
new best val f1: 0.8537073260882629
ogbn-products,dgl,1,1065,271.8478,0.8537

 F1-mic 0.8537,  F1-mac 0.4519
new best val f1: 0.8537303707800538
ogbn-products,dgl,1,1066,272.1023,0.8537

 F1-mic 0.8538,  F1-mac 0.4520
new best val f1: 0.8537502524749321
ogbn-products,dgl,1,1067,272.3565,0.8538

 F1-mic 0.8538,  F1-mac 0.4521
new best val f1: 0.8537827861574602
ogbn-products,dgl,1,1068,272.6102,0.8538

 F1-mic 0.8538,  F1-mac 0.4522
new best val f1: 0.8538193865503045
ogbn-products,dgl,1,1069,272.8639,0.8538

epoch:1071/50, Iteration 32/32:training loss 0.6134415864944458
Train F1-mic 0.8576, Train F1-mac 0.4519
 F1-mic 0.8538,  F1-mac 0.4523
new best val f1: 0.853847401665815
ogbn-products,dgl,1,1070,273.1180,0.8538

 F1-mic 0.8539,  F1-mac 0.4524
new best val f1: 0.8538663796472898
ogbn-products,dgl,1,1071,273.3695,0.8539

 F1-mic 0.8539,  F1-mac 0.4524
new best val f1: 0.8539002688999232
ogbn-products,dgl,1,1072,273.6238,0.8539

 F1-mic 0.8539,  F1-mac 0.4525
new best val f1: 0.8539242173051176
ogbn-products,dgl,1,1073,273.8776,0.8539

 F1-mic 0.8539,  F1-mac 0.4526
new best val f1: 0.853945906426803
ogbn-products,dgl,1,1074,274.1311,0.8539

 F1-mic 0.8540,  F1-mac 0.4527
new best val f1: 0.8539662399783833
ogbn-products,dgl,1,1075,274.3848,0.8540

 F1-mic 0.8540,  F1-mac 0.4527
new best val f1: 0.8539861216732615
ogbn-products,dgl,1,1076,274.6383,0.8540

 F1-mic 0.8540,  F1-mac 0.4529
new best val f1: 0.8540258850630182
ogbn-products,dgl,1,1077,274.8921,0.8540

 F1-mic 0.8540,  F1-mac 0.4529
new best val f1: 0.8540453149011947
ogbn-products,dgl,1,1078,275.1457,0.8540

 F1-mic 0.8541,  F1-mac 0.4530
new best val f1: 0.8540773967270212
ogbn-products,dgl,1,1079,275.3992,0.8541

epoch:1081/50, Iteration 32/32:training loss 0.6122654676437378
Train F1-mic 0.8578, Train F1-mac 0.4527
 F1-mic 0.8541,  F1-mac 0.4530
new best val f1: 0.8540990858487066
ogbn-products,dgl,1,1080,275.6529,0.8541

 F1-mic 0.8541,  F1-mac 0.4531
new best val f1: 0.8541234861106027
ogbn-products,dgl,1,1081,275.9043,0.8541

 F1-mic 0.8542,  F1-mac 0.4532
new best val f1: 0.8541515012261132
ogbn-products,dgl,1,1082,276.1579,0.8542

 F1-mic 0.8542,  F1-mac 0.4532
new best val f1: 0.8541713829209915
ogbn-products,dgl,1,1083,276.4114,0.8542

 F1-mic 0.8542,  F1-mac 0.4532
new best val f1: 0.8541939757560805
ogbn-products,dgl,1,1084,276.6653,0.8542

 F1-mic 0.8542,  F1-mac 0.4532
new best val f1: 0.8542183760179767
ogbn-products,dgl,1,1085,276.9190,0.8542

 F1-mic 0.8543,  F1-mac 0.4533
new best val f1: 0.8542536208407155
ogbn-products,dgl,1,1086,277.1726,0.8543

 F1-mic 0.8543,  F1-mac 0.4533
new best val f1: 0.8542771173892081
ogbn-products,dgl,1,1087,277.4271,0.8543

 F1-mic 0.8543,  F1-mac 0.4534
new best val f1: 0.8543001620809989
ogbn-products,dgl,1,1088,277.6806,0.8543

 F1-mic 0.8543,  F1-mac 0.4534
new best val f1: 0.8543286290532112
ogbn-products,dgl,1,1089,277.9344,0.8543

epoch:1091/50, Iteration 32/32:training loss 0.6111051440238953
Train F1-mic 0.8580, Train F1-mac 0.4531
 F1-mic 0.8544,  F1-mac 0.4535
new best val f1: 0.8543602590223357
ogbn-products,dgl,1,1090,278.1882,0.8544

 F1-mic 0.8544,  F1-mac 0.4535
new best val f1: 0.854367940586266
ogbn-products,dgl,1,1091,278.4397,0.8544

 F1-mic 0.8544,  F1-mac 0.4536
new best val f1: 0.85439685941518
ogbn-products,dgl,1,1092,278.6936,0.8544

 F1-mic 0.8544,  F1-mac 0.4536
new best val f1: 0.8544185485368654
ogbn-products,dgl,1,1093,278.9479,0.8544

 F1-mic 0.8544,  F1-mac 0.4537
new best val f1: 0.8544465636523758
ogbn-products,dgl,1,1094,279.2017,0.8544

 F1-mic 0.8545,  F1-mac 0.4537
new best val f1: 0.8544732231977807
ogbn-products,dgl,1,1095,279.4561,0.8545

 F1-mic 0.8545,  F1-mac 0.4537
new best val f1: 0.8544867788988342
ogbn-products,dgl,1,1096,279.7097,0.8545

 F1-mic 0.8545,  F1-mac 0.4537
new best val f1: 0.8545120828741339
ogbn-products,dgl,1,1097,279.9633,0.8545

 F1-mic 0.8545,  F1-mac 0.4538
new best val f1: 0.8545464239834692
ogbn-products,dgl,1,1098,280.2169,0.8545

 F1-mic 0.8546,  F1-mac 0.4538
new best val f1: 0.854575794669085
ogbn-products,dgl,1,1099,280.4707,0.8546

epoch:1101/50, Iteration 32/32:training loss 0.6099604964256287
Train F1-mic 0.8583, Train F1-mac 0.4535
 F1-mic 0.8546,  F1-mac 0.4539
new best val f1: 0.8545920615103489
ogbn-products,dgl,1,1100,280.7253,0.8546

 F1-mic 0.8546,  F1-mac 0.4539
new best val f1: 0.8546033579278937
ogbn-products,dgl,1,1101,280.9766,0.8546

 F1-mic 0.8546,  F1-mac 0.4540
new best val f1: 0.8546268544763863
ogbn-products,dgl,1,1102,281.2312,0.8546

 F1-mic 0.8547,  F1-mac 0.4541
new best val f1: 0.8546598400156162
ogbn-products,dgl,1,1103,281.4848,0.8547

 F1-mic 0.8547,  F1-mac 0.4541
new best val f1: 0.8546860477043194
ogbn-products,dgl,1,1104,281.7384,0.8547

 F1-mic 0.8547,  F1-mac 0.4542
new best val f1: 0.8547145146765316
ogbn-products,dgl,1,1105,281.9920,0.8547

 F1-mic 0.8547,  F1-mac 0.4542
new best val f1: 0.8547389149384278
ogbn-products,dgl,1,1106,282.2457,0.8547

 F1-mic 0.8548,  F1-mac 0.4542
new best val f1: 0.8547574410632007
ogbn-products,dgl,1,1107,282.4995,0.8548

 F1-mic 0.8548,  F1-mac 0.4543
new best val f1: 0.8547764190446755
ogbn-products,dgl,1,1108,282.7529,0.8548

 F1-mic 0.8548,  F1-mac 0.4543
new best val f1: 0.8547944933127467
ogbn-products,dgl,1,1109,283.0067,0.8548

epoch:1111/50, Iteration 32/32:training loss 0.6088321805000305
Train F1-mic 0.8585, Train F1-mac 0.4540
 F1-mic 0.8548,  F1-mac 0.4543
new best val f1: 0.8548152787210287
ogbn-products,dgl,1,1110,283.2609,0.8548

 F1-mic 0.8548,  F1-mac 0.4543
new best val f1: 0.8548342567025035
ogbn-products,dgl,1,1111,283.5124,0.8548

 F1-mic 0.8548,  F1-mac 0.4544
new best val f1: 0.8548482642602586
ogbn-products,dgl,1,1112,283.7661,0.8548

 F1-mic 0.8549,  F1-mac 0.4544
new best val f1: 0.8548753756623655
ogbn-products,dgl,1,1113,284.0200,0.8549

 F1-mic 0.8549,  F1-mac 0.4544
new best val f1: 0.8548979684974545
ogbn-products,dgl,1,1114,284.2737,0.8549

 F1-mic 0.8549,  F1-mac 0.4545
new best val f1: 0.854923724329456
ogbn-products,dgl,1,1115,284.5275,0.8549

 F1-mic 0.8549,  F1-mac 0.4545
new best val f1: 0.8549436060243343
ogbn-products,dgl,1,1116,284.7810,0.8549

 F1-mic 0.8550,  F1-mac 0.4546
new best val f1: 0.8549734285666518
ogbn-products,dgl,1,1117,285.0346,0.8550

 F1-mic 0.8550,  F1-mac 0.4546
new best val f1: 0.8549856286975999
ogbn-products,dgl,1,1118,285.2882,0.8550

 F1-mic 0.8550,  F1-mac 0.4547
new best val f1: 0.8550186142368299
ogbn-products,dgl,1,1119,285.5419,0.8550

epoch:1121/50, Iteration 32/32:training loss 0.6077173948287964
Train F1-mic 0.8587, Train F1-mac 0.4543
 F1-mic 0.8550,  F1-mac 0.4547
new best val f1: 0.8550335255079886
ogbn-products,dgl,1,1120,285.7957,0.8550

 F1-mic 0.8551,  F1-mac 0.4547
new best val f1: 0.8550588294832883
ogbn-products,dgl,1,1121,286.0469,0.8551

 F1-mic 0.8551,  F1-mac 0.4548
new best val f1: 0.8550791630348684
ogbn-products,dgl,1,1122,286.3011,0.8551

 F1-mic 0.8551,  F1-mac 0.4548
new best val f1: 0.8551013040132557
ogbn-products,dgl,1,1123,286.5549,0.8551

 F1-mic 0.8551,  F1-mac 0.4549
new best val f1: 0.8551157634277127
ogbn-products,dgl,1,1124,286.8089,0.8551

 F1-mic 0.8552,  F1-mac 0.4550
new best val f1: 0.8551591416710835
ogbn-products,dgl,1,1125,287.0634,0.8552

 F1-mic 0.8552,  F1-mac 0.4550
new best val f1: 0.8551726973721369
ogbn-products,dgl,1,1126,287.3178,0.8552

 F1-mic 0.8552,  F1-mac 0.4551
new best val f1: 0.8552047791979633
ogbn-products,dgl,1,1127,287.5719,0.8552

 F1-mic 0.8552,  F1-mac 0.4551
new best val f1: 0.8552327943134738
ogbn-products,dgl,1,1128,287.8257,0.8552

 F1-mic 0.8552,  F1-mac 0.4551
new best val f1: 0.8552499648681414
ogbn-products,dgl,1,1129,288.0796,0.8552

epoch:1131/50, Iteration 32/32:training loss 0.6066167950630188
Train F1-mic 0.8589, Train F1-mac 0.4548
 F1-mic 0.8553,  F1-mac 0.4552
new best val f1: 0.8552811429805642
ogbn-products,dgl,1,1130,288.3340,0.8553

 F1-mic 0.8553,  F1-mac 0.4553
new best val f1: 0.8553010246754427
ogbn-products,dgl,1,1131,288.5855,0.8553

 F1-mic 0.8553,  F1-mac 0.4553
new best val f1: 0.8553303953610584
ogbn-products,dgl,1,1132,288.8395,0.8553

 F1-mic 0.8553,  F1-mac 0.4553
new best val f1: 0.8553362694981815
ogbn-products,dgl,1,1133,289.0934,0.8553

 F1-mic 0.8554,  F1-mac 0.4554
new best val f1: 0.8553678994673061
ogbn-products,dgl,1,1134,289.3478,0.8554

 F1-mic 0.8554,  F1-mac 0.4554
new best val f1: 0.8553832625951666
ogbn-products,dgl,1,1135,289.6014,0.8554

 F1-mic 0.8554,  F1-mac 0.4554
new best val f1: 0.8553927515859041
ogbn-products,dgl,1,1136,289.8551,0.8554

 F1-mic 0.8554,  F1-mac 0.4555
new best val f1: 0.8554144407075895
ogbn-products,dgl,1,1137,290.1095,0.8554

 F1-mic 0.8554,  F1-mac 0.4557
new best val f1: 0.8554438113932052
ogbn-products,dgl,1,1138,290.3631,0.8554

 F1-mic 0.8555,  F1-mac 0.4557
new best val f1: 0.8554614338045746
ogbn-products,dgl,1,1139,290.6175,0.8555

epoch:1141/50, Iteration 32/32:training loss 0.6055324077606201
Train F1-mic 0.8592, Train F1-mac 0.4553
 F1-mic 0.8555,  F1-mac 0.4557
new best val f1: 0.8554908044901904
ogbn-products,dgl,1,1140,290.8712,0.8555

 F1-mic 0.8555,  F1-mac 0.4557
new best val f1: 0.8555070713314545
ogbn-products,dgl,1,1141,291.1226,0.8555

 F1-mic 0.8555,  F1-mac 0.4558
new best val f1: 0.8555292123098417
ogbn-products,dgl,1,1142,291.3763,0.8555

 F1-mic 0.8556,  F1-mac 0.4559
new best val f1: 0.8555522570016325
ogbn-products,dgl,1,1143,291.6298,0.8556

 F1-mic 0.8556,  F1-mac 0.4559
new best val f1: 0.8555734942666162
ogbn-products,dgl,1,1144,291.8835,0.8556

 F1-mic 0.8556,  F1-mac 0.4559
new best val f1: 0.855604672379039
ogbn-products,dgl,1,1145,292.1371,0.8556

 F1-mic 0.8556,  F1-mac 0.4560
new best val f1: 0.8556218429337068
ogbn-products,dgl,1,1146,292.3915,0.8556

 F1-mic 0.8556,  F1-mac 0.4560
new best val f1: 0.8556462431956029
ogbn-products,dgl,1,1147,292.6453,0.8556

 F1-mic 0.8557,  F1-mac 0.4560
new best val f1: 0.855670643457499
ogbn-products,dgl,1,1148,292.8998,0.8557

 F1-mic 0.8557,  F1-mac 0.4561
new best val f1: 0.8556891695822721
ogbn-products,dgl,1,1149,293.1538,0.8557

epoch:1151/50, Iteration 32/32:training loss 0.604461133480072
Train F1-mic 0.8594, Train F1-mac 0.4557
 F1-mic 0.8557,  F1-mac 0.4562
new best val f1: 0.8557022734266236
ogbn-products,dgl,1,1150,293.4075,0.8557

 F1-mic 0.8557,  F1-mac 0.4562
new best val f1: 0.8557226069782038
ogbn-products,dgl,1,1151,293.6588,0.8557

 F1-mic 0.8557,  F1-mac 0.4562
new best val f1: 0.8557420368163804
ogbn-products,dgl,1,1152,293.9127,0.8557

 F1-mic 0.8558,  F1-mac 0.4562
new best val f1: 0.8557610147978552
ogbn-products,dgl,1,1153,294.1664,0.8558

 F1-mic 0.8558,  F1-mac 0.4562
new best val f1: 0.8557790890659264
ogbn-products,dgl,1,1154,294.4209,0.8558

 F1-mic 0.8558,  F1-mac 0.4562
new best val f1: 0.8558052967546296
ogbn-products,dgl,1,1155,294.6746,0.8558

 F1-mic 0.8558,  F1-mac 0.4563
new best val f1: 0.855841445290772
ogbn-products,dgl,1,1156,294.9285,0.8558

 F1-mic 0.8559,  F1-mac 0.4564
new best val f1: 0.8558653936959664
ogbn-products,dgl,1,1157,295.1822,0.8559

 F1-mic 0.8559,  F1-mac 0.4564
new best val f1: 0.8558748826867038
ogbn-products,dgl,1,1158,295.4356,0.8559

 F1-mic 0.8559,  F1-mac 0.4564
new best val f1: 0.8558911495279677
ogbn-products,dgl,1,1159,295.6898,0.8559

epoch:1161/50, Iteration 32/32:training loss 0.6034048199653625
Train F1-mic 0.8596, Train F1-mac 0.4560
 F1-mic 0.8559,  F1-mac 0.4564
new best val f1: 0.855907416369232
ogbn-products,dgl,1,1160,295.9434,0.8559

 F1-mic 0.8559,  F1-mac 0.4565
new best val f1: 0.855930009204321
ogbn-products,dgl,1,1161,296.1948,0.8559

 F1-mic 0.8560,  F1-mac 0.4565
new best val f1: 0.8559553131796207
ogbn-products,dgl,1,1162,296.4484,0.8560

 F1-mic 0.8560,  F1-mac 0.4565
new best val f1: 0.8559742911610955
ogbn-products,dgl,1,1163,296.7025,0.8560

 F1-mic 0.8560,  F1-mac 0.4566
new best val f1: 0.8559937209992721
ogbn-products,dgl,1,1164,296.9569,0.8560

 F1-mic 0.8560,  F1-mac 0.4566
new best val f1: 0.8560190249745717
ogbn-products,dgl,1,1165,297.2106,0.8560

 F1-mic 0.8560,  F1-mac 0.4566
new best val f1: 0.8560316769622216
ogbn-products,dgl,1,1166,297.4649,0.8560

 F1-mic 0.8561,  F1-mac 0.4567
new best val f1: 0.8560502030869946
ogbn-products,dgl,1,1167,297.7185,0.8561

 F1-mic 0.8561,  F1-mac 0.4567
new best val f1: 0.8560827367695228
ogbn-products,dgl,1,1168,297.9724,0.8561

 F1-mic 0.8561,  F1-mac 0.4568
new best val f1: 0.8560976480406816
ogbn-products,dgl,1,1169,298.2259,0.8561

epoch:1171/50, Iteration 32/32:training loss 0.6023642420768738
Train F1-mic 0.8598, Train F1-mac 0.4564
 F1-mic 0.8561,  F1-mac 0.4568
new best val f1: 0.8561197890190688
ogbn-products,dgl,1,1170,298.4797,0.8561

 F1-mic 0.8561,  F1-mac 0.4569
new best val f1: 0.8561225001592795
ogbn-products,dgl,1,1171,298.7311,0.8561

 F1-mic 0.8561,  F1-mac 0.4569
new best val f1: 0.8561423818541579
ogbn-products,dgl,1,1172,298.9855,0.8561

 F1-mic 0.8562,  F1-mac 0.4569
new best val f1: 0.8561618116923344
ogbn-products,dgl,1,1173,299.2390,0.8562

 F1-mic 0.8562,  F1-mac 0.4569
new best val f1: 0.8561853082408268
ogbn-products,dgl,1,1174,299.4929,0.8562

 F1-mic 0.8562,  F1-mac 0.4570
new best val f1: 0.8562088047893196
ogbn-products,dgl,1,1175,299.7467,0.8562

 F1-mic 0.8562,  F1-mac 0.4570
new best val f1: 0.8562332050512158
ogbn-products,dgl,1,1176,300.0006,0.8562

 F1-mic 0.8563,  F1-mac 0.4571
new best val f1: 0.856259412739919
ogbn-products,dgl,1,1177,300.2547,0.8563

 F1-mic 0.8563,  F1-mac 0.4571
new best val f1: 0.8562774870079902
ogbn-products,dgl,1,1178,300.5083,0.8563

 F1-mic 0.8563,  F1-mac 0.4571
new best val f1: 0.8563041465533953
ogbn-products,dgl,1,1179,300.7620,0.8563

epoch:1181/50, Iteration 32/32:training loss 0.601335346698761
Train F1-mic 0.8600, Train F1-mac 0.4567
 F1-mic 0.8563,  F1-mac 0.4572
new best val f1: 0.8563267393884842
ogbn-products,dgl,1,1180,301.0158,0.8563

 F1-mic 0.8564,  F1-mac 0.4573
new best val f1: 0.8563511396503803
ogbn-products,dgl,1,1181,301.2673,0.8564

 F1-mic 0.8564,  F1-mac 0.4573
new best val f1: 0.8563665027782409
ogbn-products,dgl,1,1182,301.5209,0.8564

 F1-mic 0.8564,  F1-mac 0.4574
new best val f1: 0.8563850289030138
ogbn-products,dgl,1,1183,301.7746,0.8564

 F1-mic 0.8564,  F1-mac 0.4574
new best val f1: 0.8564008438875762
ogbn-products,dgl,1,1184,302.0285,0.8564

 F1-mic 0.8564,  F1-mac 0.4574
new best val f1: 0.85642208115256
ogbn-products,dgl,1,1185,302.2824,0.8564

 F1-mic 0.8564,  F1-mac 0.4574
new best val f1: 0.8564378961371223
ogbn-products,dgl,1,1186,302.5362,0.8564

 F1-mic 0.8565,  F1-mac 0.4574
new best val f1: 0.8564654593959309
ogbn-products,dgl,1,1187,302.7899,0.8565

 F1-mic 0.8565,  F1-mac 0.4575
new best val f1: 0.8564975412217574
ogbn-products,dgl,1,1188,303.0433,0.8565

 F1-mic 0.8565,  F1-mac 0.4575
new best val f1: 0.8565115487795124
ogbn-products,dgl,1,1189,303.2970,0.8565

epoch:1191/50, Iteration 32/32:training loss 0.600320041179657
Train F1-mic 0.8602, Train F1-mac 0.4571
 F1-mic 0.8565,  F1-mac 0.4575
new best val f1: 0.8565246526238641
ogbn-products,dgl,1,1190,303.5508,0.8565

 F1-mic 0.8566,  F1-mac 0.4575
new best val f1: 0.8565513121692692
ogbn-products,dgl,1,1191,303.8023,0.8566

 F1-mic 0.8566,  F1-mac 0.4576
new best val f1: 0.8565675790105333
ogbn-products,dgl,1,1192,304.0562,0.8566

 F1-mic 0.8566,  F1-mac 0.4576
new best val f1: 0.8565901718456221
ogbn-products,dgl,1,1193,304.3106,0.8566

 F1-mic 0.8566,  F1-mac 0.4576
new best val f1: 0.8566019201198686
ogbn-products,dgl,1,1194,304.5644,0.8566

 F1-mic 0.8566,  F1-mac 0.4576
new best val f1: 0.8566276759518701
ogbn-products,dgl,1,1195,304.8180,0.8566

 F1-mic 0.8567,  F1-mac 0.4576
new best val f1: 0.856658854064293
ogbn-products,dgl,1,1196,305.0715,0.8567

 F1-mic 0.8567,  F1-mac 0.4576
new best val f1: 0.8566796394725747
ogbn-products,dgl,1,1197,305.3258,0.8567

 F1-mic 0.8567,  F1-mac 0.4577
new best val f1: 0.8567022323076638
ogbn-products,dgl,1,1198,305.5801,0.8567

 F1-mic 0.8567,  F1-mac 0.4577
new best val f1: 0.856730699279876
ogbn-products,dgl,1,1199,305.8337,0.8567

epoch:1201/50, Iteration 32/32:training loss 0.5993194580078125
Train F1-mic 0.8604, Train F1-mac 0.4573
 F1-mic 0.8567,  F1-mac 0.4577
new best val f1: 0.8567474179778418
ogbn-products,dgl,1,1200,306.0872,0.8567

 F1-mic 0.8568,  F1-mac 0.4578
new best val f1: 0.8567835665139842
ogbn-products,dgl,1,1201,306.3387,0.8568

 F1-mic 0.8568,  F1-mac 0.4578
new best val f1: 0.8568057074923715
ogbn-products,dgl,1,1202,306.5922,0.8568

 F1-mic 0.8568,  F1-mac 0.4578
new best val f1: 0.8568260410439517
ogbn-products,dgl,1,1203,306.8458,0.8568

 F1-mic 0.8568,  F1-mac 0.4578
new best val f1: 0.856837789318198
ogbn-products,dgl,1,1204,307.0993,0.8568

 F1-mic 0.8569,  F1-mac 0.4579
new best val f1: 0.8568599302965851
ogbn-products,dgl,1,1205,307.3528,0.8569

 F1-mic 0.8569,  F1-mac 0.4579
new best val f1: 0.8568915602657098
ogbn-products,dgl,1,1206,307.6063,0.8569

 F1-mic 0.8569,  F1-mac 0.4579
new best val f1: 0.8569046641100615
ogbn-products,dgl,1,1207,307.8608,0.8569

 F1-mic 0.8569,  F1-mac 0.4579
new best val f1: 0.8569295162286594
ogbn-products,dgl,1,1208,308.1145,0.8569

 F1-mic 0.8570,  F1-mac 0.4580
new best val f1: 0.856961146197784
ogbn-products,dgl,1,1209,308.3681,0.8570

epoch:1211/50, Iteration 32/32:training loss 0.5983300805091858
Train F1-mic 0.8606, Train F1-mac 0.4576
 F1-mic 0.8570,  F1-mac 0.4580
new best val f1: 0.8569855464596802
ogbn-products,dgl,1,1210,308.6219,0.8570

 F1-mic 0.8570,  F1-mac 0.4580
new best val f1: 0.8569972947339265
ogbn-products,dgl,1,1211,308.8743,0.8570

 F1-mic 0.8570,  F1-mac 0.4581
new best val f1: 0.8570257617061386
ogbn-products,dgl,1,1212,309.1283,0.8570

 F1-mic 0.8570,  F1-mac 0.4581
ogbn-products,dgl,1,1213,309.3826,0.8570

 F1-mic 0.8570,  F1-mac 0.4581
new best val f1: 0.8570420285474027
ogbn-products,dgl,1,1214,309.6362,0.8570

 F1-mic 0.8571,  F1-mac 0.4581
new best val f1: 0.857057843531965
ogbn-products,dgl,1,1215,309.8898,0.8571

 F1-mic 0.8571,  F1-mac 0.4582
new best val f1: 0.8570831475072648
ogbn-products,dgl,1,1216,310.1434,0.8571

 F1-mic 0.8571,  F1-mac 0.4582
new best val f1: 0.8571084514825644
ogbn-products,dgl,1,1217,310.3970,0.8571

 F1-mic 0.8572,  F1-mac 0.4582
new best val f1: 0.8571536371527424
ogbn-products,dgl,1,1218,310.6509,0.8572

 F1-mic 0.8572,  F1-mac 0.4582
new best val f1: 0.8571653854269887
ogbn-products,dgl,1,1219,310.9045,0.8572

epoch:1221/50, Iteration 32/32:training loss 0.5973525643348694
Train F1-mic 0.8608, Train F1-mac 0.4579
 F1-mic 0.8572,  F1-mac 0.4583
new best val f1: 0.8571875264053759
ogbn-products,dgl,1,1220,311.1582,0.8572

 F1-mic 0.8572,  F1-mac 0.4583
new best val f1: 0.8572051488167455
ogbn-products,dgl,1,1221,311.4097,0.8572

 F1-mic 0.8572,  F1-mac 0.4583
new best val f1: 0.8572403936394845
ogbn-products,dgl,1,1222,311.6635,0.8572

 F1-mic 0.8572,  F1-mac 0.4583
new best val f1: 0.8572476233467128
ogbn-products,dgl,1,1223,311.9172,0.8572

 F1-mic 0.8573,  F1-mac 0.4584
new best val f1: 0.8572675050415911
ogbn-products,dgl,1,1224,312.1709,0.8573

 F1-mic 0.8573,  F1-mac 0.4584
new best val f1: 0.8572900978766802
ogbn-products,dgl,1,1225,312.4247,0.8573

 F1-mic 0.8573,  F1-mac 0.4584
new best val f1: 0.8573022980076282
ogbn-products,dgl,1,1226,312.6784,0.8573

 F1-mic 0.8573,  F1-mac 0.4584
new best val f1: 0.8573199204189975
ogbn-products,dgl,1,1227,312.9319,0.8573

 F1-mic 0.8573,  F1-mac 0.4584
new best val f1: 0.8573420613973849
ogbn-products,dgl,1,1228,313.1858,0.8573

 F1-mic 0.8574,  F1-mac 0.4585
new best val f1: 0.8573673653726847
ogbn-products,dgl,1,1229,313.4396,0.8574

epoch:1231/50, Iteration 32/32:training loss 0.5963865518569946
Train F1-mic 0.8610, Train F1-mac 0.4581
 F1-mic 0.8574,  F1-mac 0.4585
new best val f1: 0.8573890544943701
ogbn-products,dgl,1,1230,313.6944,0.8574

 F1-mic 0.8574,  F1-mac 0.4585
new best val f1: 0.8574066769057396
ogbn-products,dgl,1,1231,313.9463,0.8574

 F1-mic 0.8574,  F1-mac 0.4585
new best val f1: 0.8574256548872143
ogbn-products,dgl,1,1232,314.2006,0.8574

 F1-mic 0.8574,  F1-mac 0.4585
new best val f1: 0.8574374031614606
ogbn-products,dgl,1,1233,314.4542,0.8574

 F1-mic 0.8575,  F1-mac 0.4585
new best val f1: 0.8574636108501638
ogbn-products,dgl,1,1234,314.7080,0.8575

 F1-mic 0.8575,  F1-mac 0.4585
new best val f1: 0.8574690331305852
ogbn-products,dgl,1,1235,314.9625,0.8575

 F1-mic 0.8575,  F1-mac 0.4586
new best val f1: 0.8574956926759902
ogbn-products,dgl,1,1236,315.2168,0.8575

 F1-mic 0.8575,  F1-mac 0.4586
new best val f1: 0.857516929940974
ogbn-products,dgl,1,1237,315.4704,0.8575

 F1-mic 0.8575,  F1-mac 0.4586
new best val f1: 0.8575395227760629
ogbn-products,dgl,1,1238,315.7239,0.8575

 F1-mic 0.8576,  F1-mac 0.4587
new best val f1: 0.8575566933307306
ogbn-products,dgl,1,1239,315.9777,0.8576

epoch:1241/50, Iteration 32/32:training loss 0.5954333543777466
Train F1-mic 0.8612, Train F1-mac 0.4583
 F1-mic 0.8576,  F1-mac 0.4587
new best val f1: 0.8575761231689072
ogbn-products,dgl,1,1240,316.2313,0.8576

 F1-mic 0.8576,  F1-mac 0.4587
new best val f1: 0.8575987160039962
ogbn-products,dgl,1,1241,316.4826,0.8576

 F1-mic 0.8576,  F1-mac 0.4587
new best val f1: 0.857613627275155
ogbn-products,dgl,1,1242,316.7369,0.8576

 F1-mic 0.8576,  F1-mac 0.4587
new best val f1: 0.8576289904030155
ogbn-products,dgl,1,1243,316.9910,0.8576

 F1-mic 0.8576,  F1-mac 0.4588
new best val f1: 0.8576488720978939
ogbn-products,dgl,1,1244,317.2448,0.8576

 F1-mic 0.8577,  F1-mac 0.4588
new best val f1: 0.857658812945333
ogbn-products,dgl,1,1245,317.4992,0.8577

 F1-mic 0.8577,  F1-mac 0.4588
new best val f1: 0.8576814057804221
ogbn-products,dgl,1,1246,317.7531,0.8577

 F1-mic 0.8577,  F1-mac 0.4588
new best val f1: 0.8576990281917914
ogbn-products,dgl,1,1247,318.0074,0.8577

 F1-mic 0.8577,  F1-mac 0.4589
new best val f1: 0.8577229765969858
ogbn-products,dgl,1,1248,318.2615,0.8577

 F1-mic 0.8577,  F1-mac 0.4589
new best val f1: 0.8577396952949518
ogbn-products,dgl,1,1249,318.5152,0.8577

epoch:1251/50, Iteration 32/32:training loss 0.5944929122924805
Train F1-mic 0.8614, Train F1-mac 0.4585
 F1-mic 0.8578,  F1-mac 0.4589
new best val f1: 0.8577677104104621
ogbn-products,dgl,1,1250,318.7689,0.8578

 F1-mic 0.8578,  F1-mac 0.4589
new best val f1: 0.8577857846785333
ogbn-products,dgl,1,1251,319.0208,0.8578

 F1-mic 0.8578,  F1-mac 0.4590
new best val f1: 0.8577957255259725
ogbn-products,dgl,1,1252,319.2748,0.8578

 F1-mic 0.8578,  F1-mac 0.4590
new best val f1: 0.857821481357974
ogbn-products,dgl,1,1253,319.5285,0.8578

 F1-mic 0.8578,  F1-mac 0.4591
new best val f1: 0.8578345852023256
ogbn-products,dgl,1,1254,319.7823,0.8578

 F1-mic 0.8579,  F1-mac 0.4591
new best val f1: 0.8578571780374147
ogbn-products,dgl,1,1255,320.0358,0.8579

 F1-mic 0.8579,  F1-mac 0.4591
new best val f1: 0.8578847412962233
ogbn-products,dgl,1,1256,320.2894,0.8579

 F1-mic 0.8579,  F1-mac 0.4592
new best val f1: 0.8578928747168553
ogbn-products,dgl,1,1257,320.5432,0.8579

 F1-mic 0.8579,  F1-mac 0.4592
new best val f1: 0.8579208898323657
ogbn-products,dgl,1,1258,320.7969,0.8579

 F1-mic 0.8579,  F1-mac 0.4592
new best val f1: 0.8579267639694889
ogbn-products,dgl,1,1259,321.0509,0.8579

epoch:1261/50, Iteration 32/32:training loss 0.5935612916946411
Train F1-mic 0.8616, Train F1-mac 0.4588
 F1-mic 0.8579,  F1-mac 0.4593
new best val f1: 0.8579403196705423
ogbn-products,dgl,1,1260,321.3045,0.8579

 F1-mic 0.8580,  F1-mac 0.4593
new best val f1: 0.8579570383685081
ogbn-products,dgl,1,1261,321.5559,0.8580

 F1-mic 0.8580,  F1-mac 0.4593
new best val f1: 0.8579868609108257
ogbn-products,dgl,1,1262,321.8102,0.8580

 F1-mic 0.8580,  F1-mac 0.4593
new best val f1: 0.8579949943314576
ogbn-products,dgl,1,1263,322.0641,0.8580

 F1-mic 0.8580,  F1-mac 0.4594
new best val f1: 0.8580094537459146
ogbn-products,dgl,1,1264,322.3178,0.8580

 F1-mic 0.8580,  F1-mac 0.4594
new best val f1: 0.8580306910108985
ogbn-products,dgl,1,1265,322.5714,0.8580

 F1-mic 0.8580,  F1-mac 0.4594
new best val f1: 0.8580456022820572
ogbn-products,dgl,1,1266,322.8253,0.8580

 F1-mic 0.8581,  F1-mac 0.4594
new best val f1: 0.8580605135532159
ogbn-products,dgl,1,1267,323.0790,0.8581

 F1-mic 0.8581,  F1-mac 0.4595
new best val f1: 0.8580785878212871
ogbn-products,dgl,1,1268,323.3326,0.8581

 F1-mic 0.8581,  F1-mac 0.4595
new best val f1: 0.8580907879522351
ogbn-products,dgl,1,1269,323.5865,0.8581

epoch:1271/50, Iteration 32/32:training loss 0.5926438570022583
Train F1-mic 0.8617, Train F1-mac 0.4591
 F1-mic 0.8581,  F1-mac 0.4596
new best val f1: 0.858113832644026
ogbn-products,dgl,1,1270,323.8406,0.8581

 F1-mic 0.8581,  F1-mac 0.4596
new best val f1: 0.8581228697780615
ogbn-products,dgl,1,1271,324.0927,0.8581

 F1-mic 0.8581,  F1-mac 0.4596
new best val f1: 0.8581341661956059
ogbn-products,dgl,1,1272,324.3469,0.8581

 F1-mic 0.8582,  F1-mac 0.4596
new best val f1: 0.8581517886069755
ogbn-products,dgl,1,1273,324.6012,0.8582

 F1-mic 0.8582,  F1-mac 0.4597
new best val f1: 0.8581666998781341
ogbn-products,dgl,1,1274,324.8551,0.8582

 F1-mic 0.8582,  F1-mac 0.4597
new best val f1: 0.8581743814420645
ogbn-products,dgl,1,1275,325.1087,0.8582

 F1-mic 0.8582,  F1-mac 0.4597
new best val f1: 0.8581942631369428
ogbn-products,dgl,1,1276,325.3625,0.8582

 F1-mic 0.8582,  F1-mac 0.4598
new best val f1: 0.8582118855483123
ogbn-products,dgl,1,1277,325.6162,0.8582

 F1-mic 0.8582,  F1-mac 0.4599
new best val f1: 0.8582349302401031
ogbn-products,dgl,1,1278,325.8698,0.8582

 F1-mic 0.8582,  F1-mac 0.4599
new best val f1: 0.8582466785143494
ogbn-products,dgl,1,1279,326.1234,0.8582

epoch:1281/50, Iteration 32/32:training loss 0.5917354822158813
Train F1-mic 0.8619, Train F1-mac 0.4595
 F1-mic 0.8583,  F1-mac 0.4599
new best val f1: 0.8582647527824206
ogbn-products,dgl,1,1280,326.3779,0.8583

 F1-mic 0.8583,  F1-mac 0.4600
new best val f1: 0.8582850863340007
ogbn-products,dgl,1,1281,326.6293,0.8583

 F1-mic 0.8583,  F1-mac 0.4600
ogbn-products,dgl,1,1282,326.8830,0.8583

 F1-mic 0.8583,  F1-mac 0.4600
new best val f1: 0.8583135533062128
ogbn-products,dgl,1,1283,327.1367,0.8583

 F1-mic 0.8583,  F1-mac 0.4601
new best val f1: 0.8583411165650215
ogbn-products,dgl,1,1284,327.3909,0.8583

 F1-mic 0.8584,  F1-mac 0.4603
new best val f1: 0.8583619019733033
ogbn-products,dgl,1,1285,327.6447,0.8584

 F1-mic 0.8584,  F1-mac 0.4603
new best val f1: 0.8583849466650942
ogbn-products,dgl,1,1286,327.8984,0.8584

 F1-mic 0.8584,  F1-mac 0.4603
new best val f1: 0.8583876578053049
ogbn-products,dgl,1,1287,328.1521,0.8584

 F1-mic 0.8584,  F1-mac 0.4603
new best val f1: 0.8583994060795512
ogbn-products,dgl,1,1288,328.4057,0.8584

 F1-mic 0.8584,  F1-mac 0.4604
new best val f1: 0.8584179322043243
ogbn-products,dgl,1,1289,328.6595,0.8584

epoch:1291/50, Iteration 32/32:training loss 0.590837836265564
Train F1-mic 0.8621, Train F1-mac 0.4599
 F1-mic 0.8584,  F1-mac 0.4606
new best val f1: 0.8584337471888865
ogbn-products,dgl,1,1290,328.9134,0.8584

 F1-mic 0.8585,  F1-mac 0.4607
new best val f1: 0.8584504658868524
ogbn-products,dgl,1,1291,329.1649,0.8585

 F1-mic 0.8585,  F1-mac 0.4607
new best val f1: 0.8584662808714146
ogbn-products,dgl,1,1292,329.4188,0.8585

 F1-mic 0.8585,  F1-mac 0.4607
new best val f1: 0.8584807402858716
ogbn-products,dgl,1,1293,329.6730,0.8585

 F1-mic 0.8585,  F1-mac 0.4607
new best val f1: 0.8585001701240482
ogbn-products,dgl,1,1294,329.9267,0.8585

 F1-mic 0.8585,  F1-mac 0.4608
new best val f1: 0.8585195999622248
ogbn-products,dgl,1,1295,330.1803,0.8585

 F1-mic 0.8585,  F1-mac 0.4608
new best val f1: 0.85853360751998
ogbn-products,dgl,1,1296,330.4341,0.8585

 F1-mic 0.8585,  F1-mac 0.4608
new best val f1: 0.8585381260869978
ogbn-products,dgl,1,1297,330.6878,0.8585

 F1-mic 0.8586,  F1-mac 0.4608
new best val f1: 0.8585638819189991
ogbn-products,dgl,1,1298,330.9416,0.8586

 F1-mic 0.8586,  F1-mac 0.4608
new best val f1: 0.8585765339066491
ogbn-products,dgl,1,1299,331.1958,0.8586

epoch:1301/50, Iteration 32/32:training loss 0.5899502635002136
Train F1-mic 0.8622, Train F1-mac 0.4603
 F1-mic 0.8586,  F1-mac 0.4609
new best val f1: 0.8585991267417381
ogbn-products,dgl,1,1300,331.4503,0.8586

 F1-mic 0.8586,  F1-mac 0.4609
new best val f1: 0.8586090675891773
ogbn-products,dgl,1,1301,331.7016,0.8586

 F1-mic 0.8586,  F1-mac 0.4610
new best val f1: 0.8586275937139503
ogbn-products,dgl,1,1302,331.9559,0.8586

 F1-mic 0.8586,  F1-mac 0.4610
new best val f1: 0.8586379864180913
ogbn-products,dgl,1,1303,332.2095,0.8586

 F1-mic 0.8587,  F1-mac 0.4611
new best val f1: 0.8586660015336015
ogbn-products,dgl,1,1304,332.4632,0.8587

 F1-mic 0.8587,  F1-mac 0.4611
new best val f1: 0.8586867869418835
ogbn-products,dgl,1,1305,332.7170,0.8587

 F1-mic 0.8587,  F1-mac 0.4612
new best val f1: 0.8587026019264459
ogbn-products,dgl,1,1306,332.9708,0.8587

 F1-mic 0.8587,  F1-mac 0.4612
new best val f1: 0.8587233873347278
ogbn-products,dgl,1,1307,333.2246,0.8587

 F1-mic 0.8587,  F1-mac 0.4612
new best val f1: 0.8587251947615349
ogbn-products,dgl,1,1308,333.4781,0.8587

 F1-mic 0.8588,  F1-mac 0.4613
new best val f1: 0.8587514024502382
ogbn-products,dgl,1,1309,333.7320,0.8588

epoch:1311/50, Iteration 32/32:training loss 0.5890730023384094
Train F1-mic 0.8624, Train F1-mac 0.4607
 F1-mic 0.8588,  F1-mac 0.4613
new best val f1: 0.8587667655780987
ogbn-products,dgl,1,1310,333.9858,0.8588

 F1-mic 0.8588,  F1-mac 0.4614
new best val f1: 0.8587992992606269
ogbn-products,dgl,1,1311,334.2371,0.8588

 F1-mic 0.8588,  F1-mac 0.4614
ogbn-products,dgl,1,1312,334.4908,0.8588

 F1-mic 0.8588,  F1-mac 0.4615
new best val f1: 0.858825958806032
ogbn-products,dgl,1,1313,334.7445,0.8588

 F1-mic 0.8588,  F1-mac 0.4615
new best val f1: 0.8588480997844192
ogbn-products,dgl,1,1314,334.9984,0.8588

 F1-mic 0.8589,  F1-mac 0.4615
new best val f1: 0.8588666259091923
ogbn-products,dgl,1,1315,335.2523,0.8589

 F1-mic 0.8589,  F1-mac 0.4616
new best val f1: 0.8588761148999294
ogbn-products,dgl,1,1316,335.5059,0.8589

 F1-mic 0.8589,  F1-mac 0.4616
new best val f1: 0.8588869594607723
ogbn-products,dgl,1,1317,335.7601,0.8589

 F1-mic 0.8589,  F1-mac 0.4616
new best val f1: 0.8589158782896862
ogbn-products,dgl,1,1318,336.0138,0.8589

 F1-mic 0.8589,  F1-mac 0.4616
new best val f1: 0.8589271747072308
ogbn-products,dgl,1,1319,336.2674,0.8589

epoch:1321/50, Iteration 32/32:training loss 0.5882050395011902
Train F1-mic 0.8626, Train F1-mac 0.4611
 F1-mic 0.8589,  F1-mac 0.4617
new best val f1: 0.8589475082588108
ogbn-products,dgl,1,1320,336.5212,0.8589

 F1-mic 0.8590,  F1-mac 0.4617
new best val f1: 0.8589737159475141
ogbn-products,dgl,1,1321,336.7728,0.8590

 F1-mic 0.8590,  F1-mac 0.4617
new best val f1: 0.8589872716485676
ogbn-products,dgl,1,1322,337.0268,0.8590

 F1-mic 0.8590,  F1-mac 0.4618
new best val f1: 0.8590030866331299
ogbn-products,dgl,1,1323,337.2803,0.8590

 F1-mic 0.8590,  F1-mac 0.4617
new best val f1: 0.859017094190885
ogbn-products,dgl,1,1324,337.5340,0.8590

 F1-mic 0.8590,  F1-mac 0.4620
new best val f1: 0.8590320054620438
ogbn-products,dgl,1,1325,337.7876,0.8590

 F1-mic 0.8590,  F1-mac 0.4621
new best val f1: 0.8590464648765008
ogbn-products,dgl,1,1326,338.0412,0.8590

 F1-mic 0.8591,  F1-mac 0.4621
new best val f1: 0.8590555020105364
ogbn-products,dgl,1,1327,338.2949,0.8591

 F1-mic 0.8591,  F1-mac 0.4621
new best val f1: 0.8590848726961521
ogbn-products,dgl,1,1328,338.5491,0.8591

 F1-mic 0.8591,  F1-mac 0.4621
new best val f1: 0.8591056581044341
ogbn-products,dgl,1,1329,338.8028,0.8591

epoch:1331/50, Iteration 32/32:training loss 0.5873499512672424
Train F1-mic 0.8627, Train F1-mac 0.4616
 F1-mic 0.8591,  F1-mac 0.4621
new best val f1: 0.8591165026652767
ogbn-products,dgl,1,1330,339.0563,0.8591

 F1-mic 0.8591,  F1-mac 0.4622
new best val f1: 0.8591277990828212
ogbn-products,dgl,1,1331,339.3081,0.8591

 F1-mic 0.8591,  F1-mac 0.4622
new best val f1: 0.8591463252075943
ogbn-products,dgl,1,1332,339.5618,0.8591

 F1-mic 0.8592,  F1-mac 0.4622
new best val f1: 0.859154910484928
ogbn-products,dgl,1,1333,339.8153,0.8592

 F1-mic 0.8592,  F1-mac 0.4622
new best val f1: 0.8591711773261922
ogbn-products,dgl,1,1334,340.0696,0.8592

 F1-mic 0.8592,  F1-mac 0.4622
new best val f1: 0.8591856367406492
ogbn-products,dgl,1,1335,340.3235,0.8592

 F1-mic 0.8592,  F1-mac 0.4623
new best val f1: 0.8591973850148955
ogbn-products,dgl,1,1336,340.5771,0.8592

 F1-mic 0.8592,  F1-mac 0.4623
new best val f1: 0.8592091332891417
ogbn-products,dgl,1,1337,340.8310,0.8592

 F1-mic 0.8592,  F1-mac 0.4624
new best val f1: 0.8592281112706165
ogbn-products,dgl,1,1338,341.0846,0.8592

 F1-mic 0.8593,  F1-mac 0.4624
new best val f1: 0.8592516078191091
ogbn-products,dgl,1,1339,341.3389,0.8593

epoch:1341/50, Iteration 32/32:training loss 0.5865023732185364
Train F1-mic 0.8629, Train F1-mac 0.4619
 F1-mic 0.8593,  F1-mac 0.4624
new best val f1: 0.8592705858005839
ogbn-products,dgl,1,1340,341.5928,0.8593

 F1-mic 0.8593,  F1-mac 0.4624
new best val f1: 0.8592891119253568
ogbn-products,dgl,1,1341,341.8441,0.8593

 F1-mic 0.8593,  F1-mac 0.4624
new best val f1: 0.8593008601996033
ogbn-products,dgl,1,1342,342.0980,0.8593

 F1-mic 0.8593,  F1-mac 0.4625
new best val f1: 0.8593207418944815
ogbn-products,dgl,1,1343,342.3514,0.8593

 F1-mic 0.8593,  F1-mac 0.4625
new best val f1: 0.8593270678883065
ogbn-products,dgl,1,1344,342.6049,0.8593

 F1-mic 0.8593,  F1-mac 0.4625
new best val f1: 0.8593315864553243
ogbn-products,dgl,1,1345,342.8587,0.8593

 F1-mic 0.8593,  F1-mac 0.4625
new best val f1: 0.8593347494522368
ogbn-products,dgl,1,1346,343.1123,0.8593

 F1-mic 0.8594,  F1-mac 0.4625
new best val f1: 0.8593514681502026
ogbn-products,dgl,1,1347,343.3668,0.8594

 F1-mic 0.8594,  F1-mac 0.4625
new best val f1: 0.8593618608543435
ogbn-products,dgl,1,1348,343.6206,0.8594

 F1-mic 0.8594,  F1-mac 0.4626
new best val f1: 0.8593767721255023
ogbn-products,dgl,1,1349,343.8751,0.8594

epoch:1351/50, Iteration 32/32:training loss 0.5856645703315735
Train F1-mic 0.8630, Train F1-mac 0.4621
 F1-mic 0.8594,  F1-mac 0.4626
new best val f1: 0.8594011723873984
ogbn-products,dgl,1,1350,344.1289,0.8594

 F1-mic 0.8594,  F1-mac 0.4626
new best val f1: 0.859406142811118
ogbn-products,dgl,1,1351,344.3804,0.8594

 F1-mic 0.8594,  F1-mac 0.4626
new best val f1: 0.859422861509084
ogbn-products,dgl,1,1352,344.6348,0.8594

 F1-mic 0.8594,  F1-mac 0.4626
new best val f1: 0.8594364172101373
ogbn-products,dgl,1,1353,344.8885,0.8594

 F1-mic 0.8595,  F1-mac 0.4627
new best val f1: 0.8594617211854372
ogbn-products,dgl,1,1354,345.1423,0.8595

 F1-mic 0.8595,  F1-mac 0.4627
new best val f1: 0.859476180599894
ogbn-products,dgl,1,1355,345.3967,0.8595

 F1-mic 0.8595,  F1-mac 0.4627
new best val f1: 0.8594883807308421
ogbn-products,dgl,1,1356,345.6505,0.8595

 F1-mic 0.8595,  F1-mac 0.4627
new best val f1: 0.8595037438587027
ogbn-products,dgl,1,1357,345.9043,0.8595

 F1-mic 0.8595,  F1-mac 0.4628
new best val f1: 0.859517299559756
ogbn-products,dgl,1,1358,346.1577,0.8595

 F1-mic 0.8595,  F1-mac 0.4628
new best val f1: 0.8595304034041077
ogbn-products,dgl,1,1359,346.4115,0.8595

epoch:1361/50, Iteration 32/32:training loss 0.5848349332809448
Train F1-mic 0.8632, Train F1-mac 0.4623
 F1-mic 0.8595,  F1-mac 0.4628
new best val f1: 0.8595435072484593
ogbn-products,dgl,1,1360,346.6661,0.8595

 F1-mic 0.8596,  F1-mac 0.4628
new best val f1: 0.8595588703763198
ogbn-products,dgl,1,1361,346.9182,0.8596

 F1-mic 0.8596,  F1-mac 0.4628
new best val f1: 0.8595764927876892
ogbn-products,dgl,1,1362,347.1721,0.8596

 F1-mic 0.8596,  F1-mac 0.4628
new best val f1: 0.8595972781959712
ogbn-products,dgl,1,1363,347.4264,0.8596

 F1-mic 0.8596,  F1-mac 0.4629
new best val f1: 0.8596126413238317
ogbn-products,dgl,1,1364,347.6801,0.8596

 F1-mic 0.8596,  F1-mac 0.4629
new best val f1: 0.8596198710310602
ogbn-products,dgl,1,1365,347.9340,0.8596

 F1-mic 0.8596,  F1-mac 0.4629
new best val f1: 0.8596275525949904
ogbn-products,dgl,1,1366,348.1875,0.8596

 F1-mic 0.8596,  F1-mac 0.4629
new best val f1: 0.8596483380032723
ogbn-products,dgl,1,1367,348.4411,0.8596

 F1-mic 0.8597,  F1-mac 0.4630
new best val f1: 0.8596609899909222
ogbn-products,dgl,1,1368,348.6948,0.8597

 F1-mic 0.8597,  F1-mac 0.4630
new best val f1: 0.8596835828260111
ogbn-products,dgl,1,1369,348.9488,0.8597

epoch:1371/50, Iteration 32/32:training loss 0.5840153098106384
Train F1-mic 0.8633, Train F1-mac 0.4625
 F1-mic 0.8597,  F1-mac 0.4630
new best val f1: 0.8596989459538718
ogbn-products,dgl,1,1370,349.2025,0.8597

 F1-mic 0.8597,  F1-mac 0.4630
new best val f1: 0.8597192795054519
ogbn-products,dgl,1,1371,349.4540,0.8597

 F1-mic 0.8597,  F1-mac 0.4630
new best val f1: 0.8597287684961893
ogbn-products,dgl,1,1372,349.7079,0.8597

 F1-mic 0.8597,  F1-mac 0.4630
new best val f1: 0.859735546346716
ogbn-products,dgl,1,1373,349.9614,0.8597

 F1-mic 0.8598,  F1-mac 0.4631
new best val f1: 0.8597531687580854
ogbn-products,dgl,1,1374,350.2153,0.8598

 F1-mic 0.8598,  F1-mac 0.4631
new best val f1: 0.8597735023096655
ogbn-products,dgl,1,1375,350.4691,0.8598

 F1-mic 0.8598,  F1-mac 0.4631
new best val f1: 0.8597906728643332
ogbn-products,dgl,1,1376,350.7229,0.8598

 F1-mic 0.8598,  F1-mac 0.4631
new best val f1: 0.8597929321478422
ogbn-products,dgl,1,1377,350.9767,0.8598

 F1-mic 0.8598,  F1-mac 0.4631
new best val f1: 0.859813717556124
ogbn-products,dgl,1,1378,351.2312,0.8598

 F1-mic 0.8598,  F1-mac 0.4631
new best val f1: 0.8598349548211077
ogbn-products,dgl,1,1379,351.4854,0.8598

epoch:1381/50, Iteration 32/32:training loss 0.5832045674324036
Train F1-mic 0.8635, Train F1-mac 0.4627
 F1-mic 0.8598,  F1-mac 0.4632
new best val f1: 0.8598430882417397
ogbn-products,dgl,1,1380,351.7388,0.8598

 F1-mic 0.8599,  F1-mac 0.4632
new best val f1: 0.8598561920860913
ogbn-products,dgl,1,1381,351.9901,0.8599

 F1-mic 0.8599,  F1-mac 0.4632
new best val f1: 0.8598720070706537
ogbn-products,dgl,1,1382,352.2444,0.8599

 F1-mic 0.8599,  F1-mac 0.4632
new best val f1: 0.8598896294820231
ogbn-products,dgl,1,1383,352.4981,0.8599

 F1-mic 0.8599,  F1-mac 0.4633
new best val f1: 0.8599077037500943
ogbn-products,dgl,1,1384,352.7522,0.8599

 F1-mic 0.8599,  F1-mac 0.4633
new best val f1: 0.8599230668779548
ogbn-products,dgl,1,1385,353.0057,0.8599

 F1-mic 0.8599,  F1-mac 0.4633
new best val f1: 0.8599307484418851
ogbn-products,dgl,1,1386,353.2595,0.8599

 F1-mic 0.8599,  F1-mac 0.4633
new best val f1: 0.859947467139851
ogbn-products,dgl,1,1387,353.5134,0.8599

 F1-mic 0.8600,  F1-mac 0.4633
new best val f1: 0.8599506301367634
ogbn-products,dgl,1,1388,353.7672,0.8600

 F1-mic 0.8600,  F1-mac 0.4633
new best val f1: 0.8599673488347294
ogbn-products,dgl,1,1389,354.0213,0.8600

epoch:1391/50, Iteration 32/32:training loss 0.5824038982391357
Train F1-mic 0.8636, Train F1-mac 0.4629
 F1-mic 0.8600,  F1-mac 0.4633
new best val f1: 0.8599754822553614
ogbn-products,dgl,1,1390,354.2751,0.8600

 F1-mic 0.8600,  F1-mac 0.4634
new best val f1: 0.8599980750904503
ogbn-products,dgl,1,1391,354.5266,0.8600

 F1-mic 0.8600,  F1-mac 0.4634
new best val f1: 0.8600007862306611
ogbn-products,dgl,1,1392,354.7804,0.8600

 F1-mic 0.8600,  F1-mac 0.4634
new best val f1: 0.8600152456451181
ogbn-products,dgl,1,1393,355.0345,0.8600

 F1-mic 0.8600,  F1-mac 0.4634
new best val f1: 0.8600274457760662
ogbn-products,dgl,1,1394,355.2883,0.8600

 F1-mic 0.8600,  F1-mac 0.4634
new best val f1: 0.860035579196698
ogbn-products,dgl,1,1395,355.5429,0.8600

 F1-mic 0.8600,  F1-mac 0.4634
new best val f1: 0.8600468756142428
ogbn-products,dgl,1,1396,355.7967,0.8600

 F1-mic 0.8601,  F1-mac 0.4635
new best val f1: 0.8600613350286996
ogbn-products,dgl,1,1397,356.0503,0.8601

 F1-mic 0.8601,  F1-mac 0.4635
new best val f1: 0.8600821204369816
ogbn-products,dgl,1,1398,356.3041,0.8601

 F1-mic 0.8601,  F1-mac 0.4635
new best val f1: 0.8600830241503852
ogbn-products,dgl,1,1399,356.5576,0.8601

epoch:1401/50, Iteration 32/32:training loss 0.5816120505332947
Train F1-mic 0.8637, Train F1-mac 0.4630
 F1-mic 0.8601,  F1-mac 0.4635
new best val f1: 0.8601024539885617
ogbn-products,dgl,1,1400,356.8118,0.8601

 F1-mic 0.8601,  F1-mac 0.4635
new best val f1: 0.8601245949669489
ogbn-products,dgl,1,1401,357.0633,0.8601

 F1-mic 0.8601,  F1-mac 0.4635
new best val f1: 0.8601309209607738
ogbn-products,dgl,1,1402,357.3176,0.8601

 F1-mic 0.8601,  F1-mac 0.4636
new best val f1: 0.860140861808213
ogbn-products,dgl,1,1403,357.5713,0.8601

 F1-mic 0.8602,  F1-mac 0.4636
new best val f1: 0.8601620990731967
ogbn-products,dgl,1,1404,357.8253,0.8602

 F1-mic 0.8602,  F1-mac 0.4636
new best val f1: 0.8601720399206358
ogbn-products,dgl,1,1405,358.0791,0.8602

 F1-mic 0.8602,  F1-mac 0.4637
new best val f1: 0.8601919216155144
ogbn-products,dgl,1,1406,358.3326,0.8602

 F1-mic 0.8602,  F1-mac 0.4637
new best val f1: 0.8602077366000765
ogbn-products,dgl,1,1407,358.5864,0.8602

 F1-mic 0.8602,  F1-mac 0.4637
new best val f1: 0.8602140625939013
ogbn-products,dgl,1,1408,358.8398,0.8602

 F1-mic 0.8602,  F1-mac 0.4637
new best val f1: 0.8602163218774104
ogbn-products,dgl,1,1409,359.0936,0.8602

epoch:1411/50, Iteration 32/32:training loss 0.580828845500946
Train F1-mic 0.8638, Train F1-mac 0.4632
 F1-mic 0.8602,  F1-mac 0.4637
new best val f1: 0.8602393665692012
ogbn-products,dgl,1,1410,359.3472,0.8602

 F1-mic 0.8603,  F1-mac 0.4637
new best val f1: 0.8602601519774831
ogbn-products,dgl,1,1411,359.5986,0.8603

 F1-mic 0.8603,  F1-mac 0.4637
new best val f1: 0.8602678335414133
ogbn-products,dgl,1,1412,359.8523,0.8603

 F1-mic 0.8603,  F1-mac 0.4638
new best val f1: 0.8602786781022561
ogbn-products,dgl,1,1413,360.1060,0.8603

 F1-mic 0.8603,  F1-mac 0.4638
new best val f1: 0.8602881670929935
ogbn-products,dgl,1,1414,360.3597,0.8603

 F1-mic 0.8603,  F1-mac 0.4638
new best val f1: 0.8602976560837309
ogbn-products,dgl,1,1415,360.6132,0.8603

 F1-mic 0.8603,  F1-mac 0.4638
new best val f1: 0.8603066932177664
ogbn-products,dgl,1,1416,360.8667,0.8603

 F1-mic 0.8603,  F1-mac 0.4638
new best val f1: 0.8603301897662591
ogbn-products,dgl,1,1417,361.1202,0.8603

 F1-mic 0.8603,  F1-mac 0.4639
new best val f1: 0.8603405824704
ogbn-products,dgl,1,1418,361.3737,0.8603

 F1-mic 0.8604,  F1-mac 0.4638
new best val f1: 0.8603568493116641
ogbn-products,dgl,1,1419,361.6273,0.8604

epoch:1421/50, Iteration 32/32:training loss 0.5800544619560242
Train F1-mic 0.8640, Train F1-mac 0.4634
 F1-mic 0.8604,  F1-mac 0.4638
new best val f1: 0.8603699531560157
ogbn-products,dgl,1,1420,361.8815,0.8604

 F1-mic 0.8604,  F1-mac 0.4639
ogbn-products,dgl,1,1421,362.1328,0.8604

 F1-mic 0.8604,  F1-mac 0.4639
new best val f1: 0.8603830570003673
ogbn-products,dgl,1,1422,362.3868,0.8604

 F1-mic 0.8604,  F1-mac 0.4639
new best val f1: 0.8603916422777012
ogbn-products,dgl,1,1423,362.6406,0.8604

 F1-mic 0.8604,  F1-mac 0.4639
new best val f1: 0.8604101684024743
ogbn-products,dgl,1,1424,362.8944,0.8604

 F1-mic 0.8604,  F1-mac 0.4640
new best val f1: 0.8604305019540543
ogbn-products,dgl,1,1425,363.1479,0.8604

 F1-mic 0.8604,  F1-mac 0.4640
new best val f1: 0.8604363760911774
ogbn-products,dgl,1,1426,363.4015,0.8604

 F1-mic 0.8605,  F1-mac 0.4640
new best val f1: 0.8604612282097753
ogbn-products,dgl,1,1427,363.6555,0.8605

 F1-mic 0.8605,  F1-mac 0.4640
new best val f1: 0.8604738801974253
ogbn-products,dgl,1,1428,363.9094,0.8605

 F1-mic 0.8605,  F1-mac 0.4640
new best val f1: 0.8604815617613555
ogbn-products,dgl,1,1429,364.1630,0.8605

epoch:1431/50, Iteration 32/32:training loss 0.5792874097824097
Train F1-mic 0.8641, Train F1-mac 0.4636
 F1-mic 0.8605,  F1-mac 0.4640
new best val f1: 0.8604942137490054
ogbn-products,dgl,1,1430,364.4176,0.8605

 F1-mic 0.8605,  F1-mac 0.4640
new best val f1: 0.8604978286026196
ogbn-products,dgl,1,1431,364.6692,0.8605

 F1-mic 0.8605,  F1-mac 0.4641
new best val f1: 0.8605186140109015
ogbn-products,dgl,1,1432,364.9228,0.8605

 F1-mic 0.8605,  F1-mac 0.4641
new best val f1: 0.860529910428446
ogbn-products,dgl,1,1433,365.1766,0.8605

 F1-mic 0.8605,  F1-mac 0.4641
new best val f1: 0.8605416587026923
ogbn-products,dgl,1,1434,365.4302,0.8605

 F1-mic 0.8606,  F1-mac 0.4641
new best val f1: 0.860556569973851
ogbn-products,dgl,1,1435,365.6839,0.8606

 F1-mic 0.8606,  F1-mac 0.4641
new best val f1: 0.8605741923852206
ogbn-products,dgl,1,1436,365.9377,0.8606

 F1-mic 0.8606,  F1-mac 0.4642
ogbn-products,dgl,1,1437,366.1922,0.8606

 F1-mic 0.8606,  F1-mac 0.4642
new best val f1: 0.8605922666532917
ogbn-products,dgl,1,1438,366.4459,0.8606

 F1-mic 0.8606,  F1-mac 0.4642
new best val f1: 0.86061214834817
ogbn-products,dgl,1,1439,366.6994,0.8606

epoch:1441/50, Iteration 32/32:training loss 0.578528106212616
Train F1-mic 0.8642, Train F1-mac 0.4638
 F1-mic 0.8606,  F1-mac 0.4642
new best val f1: 0.860628867046136
ogbn-products,dgl,1,1440,366.9530,0.8606

 F1-mic 0.8606,  F1-mac 0.4642
new best val f1: 0.8606473931709089
ogbn-products,dgl,1,1441,367.2043,0.8606

 F1-mic 0.8607,  F1-mac 0.4643
new best val f1: 0.8606659192956819
ogbn-products,dgl,1,1442,367.4583,0.8607

 F1-mic 0.8607,  F1-mac 0.4643
new best val f1: 0.8606776675699283
ogbn-products,dgl,1,1443,367.7118,0.8607

 F1-mic 0.8607,  F1-mac 0.4643
new best val f1: 0.860684445420455
ogbn-products,dgl,1,1444,367.9654,0.8607

 F1-mic 0.8607,  F1-mac 0.4643
new best val f1: 0.8606970974081047
ogbn-products,dgl,1,1445,368.2191,0.8607

 F1-mic 0.8607,  F1-mac 0.4643
new best val f1: 0.8607115568225617
ogbn-products,dgl,1,1446,368.4733,0.8607

 F1-mic 0.8607,  F1-mac 0.4644
new best val f1: 0.8607224013834045
ogbn-products,dgl,1,1447,368.7270,0.8607

 F1-mic 0.8607,  F1-mac 0.4644
new best val f1: 0.8607336978009489
ogbn-products,dgl,1,1448,368.9812,0.8607

 F1-mic 0.8608,  F1-mac 0.4644
new best val f1: 0.8607562906360381
ogbn-products,dgl,1,1449,369.2352,0.8608

epoch:1451/50, Iteration 32/32:training loss 0.5777801275253296
Train F1-mic 0.8644, Train F1-mac 0.4640
 F1-mic 0.8608,  F1-mac 0.4644
new best val f1: 0.8607743649041092
ogbn-products,dgl,1,1450,369.4892,0.8608

 F1-mic 0.8608,  F1-mac 0.4644
new best val f1: 0.8607865650350573
ogbn-products,dgl,1,1451,369.7412,0.8608

 F1-mic 0.8608,  F1-mac 0.4645
new best val f1: 0.8608023800196196
ogbn-products,dgl,1,1452,369.9948,0.8608

 F1-mic 0.8608,  F1-mac 0.4645
new best val f1: 0.86083039513513
ogbn-products,dgl,1,1453,370.2491,0.8608

 F1-mic 0.8608,  F1-mac 0.4645
new best val f1: 0.8608403359825691
ogbn-products,dgl,1,1454,370.5035,0.8608

 F1-mic 0.8609,  F1-mac 0.4646
new best val f1: 0.8608507286867101
ogbn-products,dgl,1,1455,370.7571,0.8609

 F1-mic 0.8609,  F1-mac 0.4647
new best val f1: 0.8608678992413777
ogbn-products,dgl,1,1456,371.0109,0.8609

 F1-mic 0.8609,  F1-mac 0.4647
new best val f1: 0.8608773882321151
ogbn-products,dgl,1,1457,371.2652,0.8609

 F1-mic 0.8609,  F1-mac 0.4647
new best val f1: 0.86090404777752
ogbn-products,dgl,1,1458,371.5189,0.8609

 F1-mic 0.8609,  F1-mac 0.4647
new best val f1: 0.8609130849115558
ogbn-products,dgl,1,1459,371.7727,0.8609

epoch:1461/50, Iteration 32/32:training loss 0.5770389437675476
Train F1-mic 0.8645, Train F1-mac 0.4643
 F1-mic 0.8609,  F1-mac 0.4647
new best val f1: 0.8609284480394163
ogbn-products,dgl,1,1460,372.0265,0.8609

 F1-mic 0.8609,  F1-mac 0.4648
new best val f1: 0.8609370333167502
ogbn-products,dgl,1,1461,372.2785,0.8609

 F1-mic 0.8610,  F1-mac 0.4648
new best val f1: 0.8609627891487517
ogbn-products,dgl,1,1462,372.5322,0.8610

 F1-mic 0.8610,  F1-mac 0.4648
new best val f1: 0.8609713744260855
ogbn-products,dgl,1,1463,372.7859,0.8610

 F1-mic 0.8610,  F1-mac 0.4648
new best val f1: 0.8609831227003318
ogbn-products,dgl,1,1464,373.0395,0.8610

 F1-mic 0.8610,  F1-mac 0.4648
new best val f1: 0.8610061673921227
ogbn-products,dgl,1,1465,373.2932,0.8610

 F1-mic 0.8610,  F1-mac 0.4648
new best val f1: 0.8610224342333868
ogbn-products,dgl,1,1466,373.5467,0.8610

 F1-mic 0.8610,  F1-mac 0.4648
new best val f1: 0.8610409603581598
ogbn-products,dgl,1,1467,373.8003,0.8610

 F1-mic 0.8611,  F1-mac 0.4649
new best val f1: 0.8610585827695292
ogbn-products,dgl,1,1468,374.0545,0.8611

 F1-mic 0.8611,  F1-mac 0.4649
new best val f1: 0.8610685236169683
ogbn-products,dgl,1,1469,374.3079,0.8611

epoch:1471/50, Iteration 32/32:training loss 0.5763057470321655
Train F1-mic 0.8647, Train F1-mac 0.4645
 F1-mic 0.8611,  F1-mac 0.4649
new best val f1: 0.8610820793180217
ogbn-products,dgl,1,1470,374.5616,0.8611

 F1-mic 0.8611,  F1-mac 0.4650
new best val f1: 0.861089760881952
ogbn-products,dgl,1,1471,374.8132,0.8611

 F1-mic 0.8611,  F1-mac 0.4650
new best val f1: 0.8611082870067251
ogbn-products,dgl,1,1472,375.0668,0.8611

 F1-mic 0.8611,  F1-mac 0.4650
new best val f1: 0.8611114500036375
ogbn-products,dgl,1,1473,375.3204,0.8611

 F1-mic 0.8611,  F1-mac 0.4650
new best val f1: 0.8611241019912873
ogbn-products,dgl,1,1474,375.5741,0.8611

 F1-mic 0.8611,  F1-mac 0.4650
new best val f1: 0.8611376576923407
ogbn-products,dgl,1,1475,375.8280,0.8611

 F1-mic 0.8611,  F1-mac 0.4650
new best val f1: 0.8611403688325514
ogbn-products,dgl,1,1476,376.0816,0.8611

 F1-mic 0.8612,  F1-mac 0.4650
new best val f1: 0.861163865381044
ogbn-products,dgl,1,1477,376.3352,0.8612

 F1-mic 0.8612,  F1-mac 0.4650
new best val f1: 0.8611756136552902
ogbn-products,dgl,1,1478,376.5890,0.8612

 F1-mic 0.8612,  F1-mac 0.4651
new best val f1: 0.8611887174996419
ogbn-products,dgl,1,1479,376.8427,0.8612

epoch:1481/50, Iteration 32/32:training loss 0.5755816102027893
Train F1-mic 0.8648, Train F1-mac 0.4647
 F1-mic 0.8612,  F1-mac 0.4651
new best val f1: 0.861196850920274
ogbn-products,dgl,1,1480,377.0966,0.8612

 F1-mic 0.8612,  F1-mac 0.4652
new best val f1: 0.8612171844718539
ogbn-products,dgl,1,1481,377.3481,0.8612

 F1-mic 0.8612,  F1-mac 0.4652
new best val f1: 0.8612262216058897
ogbn-products,dgl,1,1482,377.6023,0.8612

 F1-mic 0.8612,  F1-mac 0.4652
new best val f1: 0.8612329994564164
ogbn-products,dgl,1,1483,377.8567,0.8612

 F1-mic 0.8613,  F1-mac 0.4652
new best val f1: 0.8612510737244876
ogbn-products,dgl,1,1484,378.1103,0.8613

 F1-mic 0.8613,  F1-mac 0.4652
new best val f1: 0.8612592071451197
ogbn-products,dgl,1,1485,378.3639,0.8613

 F1-mic 0.8613,  F1-mac 0.4652
new best val f1: 0.8612768295564891
ogbn-products,dgl,1,1486,378.6177,0.8613

 F1-mic 0.8613,  F1-mac 0.4653
new best val f1: 0.8612899334008407
ogbn-products,dgl,1,1487,378.8720,0.8613

 F1-mic 0.8613,  F1-mac 0.4653
new best val f1: 0.8613034891018941
ogbn-products,dgl,1,1488,379.1265,0.8613

 F1-mic 0.8613,  F1-mac 0.4653
new best val f1: 0.8613247263668778
ogbn-products,dgl,1,1489,379.3803,0.8613

epoch:1491/50, Iteration 32/32:training loss 0.5748647451400757
Train F1-mic 0.8649, Train F1-mac 0.4649
 F1-mic 0.8613,  F1-mac 0.4653
new best val f1: 0.8613310523607027
ogbn-products,dgl,1,1490,379.6338,0.8613

 F1-mic 0.8613,  F1-mac 0.4654
new best val f1: 0.8613428006349491
ogbn-products,dgl,1,1491,379.8854,0.8613

 F1-mic 0.8614,  F1-mac 0.4654
new best val f1: 0.8613563563360025
ogbn-products,dgl,1,1492,380.1390,0.8614

 F1-mic 0.8614,  F1-mac 0.4654
new best val f1: 0.8613735268906701
ogbn-products,dgl,1,1493,380.3925,0.8614

 F1-mic 0.8614,  F1-mac 0.4654
new best val f1: 0.8613897937319343
ogbn-products,dgl,1,1494,380.6477,0.8614

 F1-mic 0.8614,  F1-mac 0.4654
ogbn-products,dgl,1,1495,380.9018,0.8614

 F1-mic 0.8614,  F1-mac 0.4655
new best val f1: 0.8614101272835143
ogbn-products,dgl,1,1496,381.1554,0.8614

 F1-mic 0.8614,  F1-mac 0.4655
new best val f1: 0.8614300089783926
ogbn-products,dgl,1,1497,381.4091,0.8614

 F1-mic 0.8614,  F1-mac 0.4655
new best val f1: 0.8614381423990247
ogbn-products,dgl,1,1498,381.6630,0.8614

 F1-mic 0.8615,  F1-mac 0.4655
new best val f1: 0.8614553129536924
ogbn-products,dgl,1,1499,381.9168,0.8615

epoch:1501/50, Iteration 32/32:training loss 0.5741556882858276
Train F1-mic 0.8650, Train F1-mac 0.4651
 F1-mic 0.8615,  F1-mac 0.4655
new best val f1: 0.8614720316516582
ogbn-products,dgl,1,1500,382.1706,0.8615

 F1-mic 0.8615,  F1-mac 0.4655
new best val f1: 0.8614855873527116
ogbn-products,dgl,1,1501,382.4226,0.8615

 F1-mic 0.8615,  F1-mac 0.4655
new best val f1: 0.8615004986238705
ogbn-products,dgl,1,1502,382.6764,0.8615

 F1-mic 0.8615,  F1-mac 0.4655
new best val f1: 0.8615113431847132
ogbn-products,dgl,1,1503,382.9301,0.8615

 F1-mic 0.8615,  F1-mac 0.4655
new best val f1: 0.8615194766053452
ogbn-products,dgl,1,1504,383.1839,0.8615

 F1-mic 0.8615,  F1-mac 0.4656
new best val f1: 0.8615248988857664
ogbn-products,dgl,1,1505,383.4379,0.8615

 F1-mic 0.8615,  F1-mac 0.4656
new best val f1: 0.8615479435775574
ogbn-products,dgl,1,1506,383.6915,0.8615

 F1-mic 0.8616,  F1-mac 0.4656
new best val f1: 0.8615551732847858
ogbn-products,dgl,1,1507,383.9453,0.8616

 F1-mic 0.8616,  F1-mac 0.4656
new best val f1: 0.8615705364126464
ogbn-products,dgl,1,1508,384.1991,0.8616

 F1-mic 0.8616,  F1-mac 0.4656
new best val f1: 0.8615800254033837
ogbn-products,dgl,1,1509,384.4531,0.8616

epoch:1511/50, Iteration 32/32:training loss 0.5734547972679138
Train F1-mic 0.8652, Train F1-mac 0.4652
 F1-mic 0.8616,  F1-mac 0.4656
new best val f1: 0.8615971959580513
ogbn-products,dgl,1,1510,384.7073,0.8616

 F1-mic 0.8616,  F1-mac 0.4656
new best val f1: 0.861598099671455
ogbn-products,dgl,1,1511,384.9586,0.8616

 F1-mic 0.8616,  F1-mac 0.4656
new best val f1: 0.8616075886621923
ogbn-products,dgl,1,1512,385.2126,0.8616

 F1-mic 0.8616,  F1-mac 0.4657
new best val f1: 0.8616238555034564
ogbn-products,dgl,1,1513,385.4669,0.8616

 F1-mic 0.8616,  F1-mac 0.4657
new best val f1: 0.8616378630612117
ogbn-products,dgl,1,1514,385.7219,0.8616

 F1-mic 0.8617,  F1-mac 0.4657
new best val f1: 0.8616554854725811
ogbn-products,dgl,1,1515,385.9755,0.8617

 F1-mic 0.8617,  F1-mac 0.4657
new best val f1: 0.8616703967437398
ogbn-products,dgl,1,1516,386.2296,0.8617

 F1-mic 0.8617,  F1-mac 0.4657
new best val f1: 0.8616771745942667
ogbn-products,dgl,1,1517,386.4840,0.8617

 F1-mic 0.8617,  F1-mac 0.4657
new best val f1: 0.8616862117283022
ogbn-products,dgl,1,1518,386.7384,0.8617

 F1-mic 0.8617,  F1-mac 0.4658
new best val f1: 0.8617083527066894
ogbn-products,dgl,1,1519,386.9920,0.8617

epoch:1521/50, Iteration 32/32:training loss 0.5727623701095581
Train F1-mic 0.8653, Train F1-mac 0.4654
 F1-mic 0.8617,  F1-mac 0.4658
new best val f1: 0.8617128712737072
ogbn-products,dgl,1,1520,387.2455,0.8617

 F1-mic 0.8617,  F1-mac 0.4658
new best val f1: 0.8617268788314624
ogbn-products,dgl,1,1521,387.4973,0.8617

 F1-mic 0.8617,  F1-mac 0.4658
new best val f1: 0.8617363678221998
ogbn-products,dgl,1,1522,387.7511,0.8617

 F1-mic 0.8618,  F1-mac 0.4658
new best val f1: 0.8617562495170781
ogbn-products,dgl,1,1523,388.0047,0.8618

 F1-mic 0.8618,  F1-mac 0.4658
new best val f1: 0.8617643829377102
ogbn-products,dgl,1,1524,388.2585,0.8618

 F1-mic 0.8618,  F1-mac 0.4658
new best val f1: 0.8617761312119565
ogbn-products,dgl,1,1525,388.5123,0.8618

 F1-mic 0.8618,  F1-mac 0.4658
new best val f1: 0.8617901387697117
ogbn-products,dgl,1,1526,388.7659,0.8618

 F1-mic 0.8618,  F1-mac 0.4659
new best val f1: 0.8617928499099223
ogbn-products,dgl,1,1527,389.0201,0.8618

 F1-mic 0.8618,  F1-mac 0.4659
new best val f1: 0.8618041463274668
ogbn-products,dgl,1,1528,389.2738,0.8618

 F1-mic 0.8618,  F1-mac 0.4659
new best val f1: 0.8618249317357488
ogbn-products,dgl,1,1529,389.5273,0.8618

epoch:1531/50, Iteration 32/32:training loss 0.5720766186714172
Train F1-mic 0.8654, Train F1-mac 0.4655
 F1-mic 0.8618,  F1-mac 0.4659
new best val f1: 0.8618393911502058
ogbn-products,dgl,1,1530,389.7808,0.8618

 F1-mic 0.8618,  F1-mac 0.4659
new best val f1: 0.8618493319976449
ogbn-products,dgl,1,1531,390.0323,0.8618

 F1-mic 0.8619,  F1-mac 0.4660
new best val f1: 0.8618646951255055
ogbn-products,dgl,1,1532,390.2862,0.8619

 F1-mic 0.8619,  F1-mac 0.4660
new best val f1: 0.8618872879605943
ogbn-products,dgl,1,1533,390.5405,0.8619

 F1-mic 0.8619,  F1-mac 0.4660
new best val f1: 0.8619012955183497
ogbn-products,dgl,1,1534,390.7949,0.8619

 F1-mic 0.8619,  F1-mac 0.4660
new best val f1: 0.8619284069204565
ogbn-products,dgl,1,1535,391.0488,0.8619

 F1-mic 0.8619,  F1-mac 0.4660
ogbn-products,dgl,1,1536,391.3026,0.8619

 F1-mic 0.8619,  F1-mac 0.4660
new best val f1: 0.8619410589081064
ogbn-products,dgl,1,1537,391.5562,0.8619

 F1-mic 0.8619,  F1-mac 0.4660
new best val f1: 0.8619455774751241
ogbn-products,dgl,1,1538,391.8099,0.8619

 F1-mic 0.8620,  F1-mac 0.4660
new best val f1: 0.861954162752458
ogbn-products,dgl,1,1539,392.0638,0.8620

epoch:1541/50, Iteration 32/32:training loss 0.5713997483253479
Train F1-mic 0.8655, Train F1-mac 0.4657
 F1-mic 0.8620,  F1-mac 0.4660
new best val f1: 0.8619622961730901
ogbn-products,dgl,1,1540,392.3183,0.8620

 F1-mic 0.8620,  F1-mac 0.4660
new best val f1: 0.8619677184535114
ogbn-products,dgl,1,1541,392.5698,0.8620

 F1-mic 0.8620,  F1-mac 0.4660
new best val f1: 0.8619731407339327
ogbn-products,dgl,1,1542,392.8241,0.8620

 F1-mic 0.8620,  F1-mac 0.4661
new best val f1: 0.8619817260112665
ogbn-products,dgl,1,1543,393.0776,0.8620

 F1-mic 0.8620,  F1-mac 0.4661
new best val f1: 0.8620016077061449
ogbn-products,dgl,1,1544,393.3312,0.8620

 F1-mic 0.8620,  F1-mac 0.4661
new best val f1: 0.8620174226907072
ogbn-products,dgl,1,1545,393.5846,0.8620

 F1-mic 0.8620,  F1-mac 0.4661
ogbn-products,dgl,1,1546,393.8385,0.8620

 F1-mic 0.8620,  F1-mac 0.4661
new best val f1: 0.8620327858185678
ogbn-products,dgl,1,1547,394.0921,0.8620

 F1-mic 0.8620,  F1-mac 0.4661
new best val f1: 0.8620458896629194
ogbn-products,dgl,1,1548,394.3463,0.8620

 F1-mic 0.8621,  F1-mac 0.4661
new best val f1: 0.8620644157876924
ogbn-products,dgl,1,1549,394.6008,0.8621

epoch:1551/50, Iteration 32/32:training loss 0.5707301497459412
Train F1-mic 0.8656, Train F1-mac 0.4658
 F1-mic 0.8621,  F1-mac 0.4661
new best val f1: 0.8620748084918334
ogbn-products,dgl,1,1550,394.8545,0.8621

 F1-mic 0.8621,  F1-mac 0.4661
new best val f1: 0.8620802307722547
ogbn-products,dgl,1,1551,395.1064,0.8621

 F1-mic 0.8621,  F1-mac 0.4662
new best val f1: 0.862098305040326
ogbn-products,dgl,1,1552,395.3608,0.8621

 F1-mic 0.8621,  F1-mac 0.4662
new best val f1: 0.8621037273207474
ogbn-products,dgl,1,1553,395.6146,0.8621

 F1-mic 0.8621,  F1-mac 0.4662
new best val f1: 0.8621254164424329
ogbn-products,dgl,1,1554,395.8684,0.8621

 F1-mic 0.8621,  F1-mac 0.4662
ogbn-products,dgl,1,1555,396.1220,0.8621

 F1-mic 0.8621,  F1-mac 0.4662
new best val f1: 0.8621258682991345
ogbn-products,dgl,1,1556,396.3759,0.8621

 F1-mic 0.8621,  F1-mac 0.4662
new best val f1: 0.8621430388538022
ogbn-products,dgl,1,1557,396.6297,0.8621

 F1-mic 0.8622,  F1-mac 0.4663
new best val f1: 0.8621507204177324
ogbn-products,dgl,1,1558,396.8835,0.8622

 F1-mic 0.8622,  F1-mac 0.4663
new best val f1: 0.862166083545593
ogbn-products,dgl,1,1559,397.1378,0.8622

epoch:1561/50, Iteration 32/32:training loss 0.5700669288635254
Train F1-mic 0.8657, Train F1-mac 0.4660
 F1-mic 0.8622,  F1-mac 0.4663
new best val f1: 0.862171957682716
ogbn-products,dgl,1,1560,397.3915,0.8622

 F1-mic 0.8622,  F1-mac 0.4663
new best val f1: 0.8621760243930322
ogbn-products,dgl,1,1561,397.6431,0.8622

 F1-mic 0.8622,  F1-mac 0.4663
new best val f1: 0.8621791873899447
ogbn-products,dgl,1,1562,397.8977,0.8622

 F1-mic 0.8622,  F1-mac 0.4663
new best val f1: 0.8621877726672785
ogbn-products,dgl,1,1563,398.1513,0.8622

 F1-mic 0.8622,  F1-mac 0.4665
new best val f1: 0.8622108173590692
ogbn-products,dgl,1,1564,398.4052,0.8622

 F1-mic 0.8622,  F1-mac 0.4665
new best val f1: 0.8622221137766138
ogbn-products,dgl,1,1565,398.6587,0.8622

 F1-mic 0.8622,  F1-mac 0.4665
new best val f1: 0.8622297953405441
ogbn-products,dgl,1,1566,398.9128,0.8622

 F1-mic 0.8622,  F1-mac 0.4665
new best val f1: 0.862244254755001
ogbn-products,dgl,1,1567,399.1668,0.8622

 F1-mic 0.8622,  F1-mac 0.4665
new best val f1: 0.8622447066117028
ogbn-products,dgl,1,1568,399.4205,0.8622

 F1-mic 0.8623,  F1-mac 0.4665
new best val f1: 0.862262780879774
ogbn-products,dgl,1,1569,399.6741,0.8623

epoch:1571/50, Iteration 32/32:training loss 0.56941157579422
Train F1-mic 0.8658, Train F1-mac 0.4662
 F1-mic 0.8623,  F1-mac 0.4666
new best val f1: 0.8622813070045471
ogbn-products,dgl,1,1570,399.9279,0.8623

 F1-mic 0.8623,  F1-mac 0.4666
new best val f1: 0.8622921515653897
ogbn-products,dgl,1,1571,400.1794,0.8623

 F1-mic 0.8623,  F1-mac 0.4666
new best val f1: 0.8623093221200574
ogbn-products,dgl,1,1572,400.4331,0.8623

 F1-mic 0.8623,  F1-mac 0.4666
new best val f1: 0.8623170036839877
ogbn-products,dgl,1,1573,400.6876,0.8623

 F1-mic 0.8623,  F1-mac 0.4666
new best val f1: 0.8623355298087608
ogbn-products,dgl,1,1574,400.9413,0.8623

 F1-mic 0.8624,  F1-mac 0.4666
new best val f1: 0.8623504410799194
ogbn-products,dgl,1,1575,401.1951,0.8624

 F1-mic 0.8624,  F1-mac 0.4668
new best val f1: 0.8623662560644818
ogbn-products,dgl,1,1576,401.4497,0.8624

 F1-mic 0.8624,  F1-mac 0.4668
new best val f1: 0.8623775524820263
ogbn-products,dgl,1,1577,401.7033,0.8624

 F1-mic 0.8624,  F1-mac 0.4668
new best val f1: 0.8623820710490441
ogbn-products,dgl,1,1578,401.9568,0.8624

 F1-mic 0.8624,  F1-mac 0.4669
new best val f1: 0.8623911081830797
ogbn-products,dgl,1,1579,402.2103,0.8624

epoch:1581/50, Iteration 32/32:training loss 0.5687630772590637
Train F1-mic 0.8660, Train F1-mac 0.4665
 F1-mic 0.8624,  F1-mac 0.4669
new best val f1: 0.8624118935913616
ogbn-products,dgl,1,1580,402.4638,0.8624

 F1-mic 0.8624,  F1-mac 0.4669
new best val f1: 0.862421382582099
ogbn-products,dgl,1,1581,402.7158,0.8624

 F1-mic 0.8624,  F1-mac 0.4669
new best val f1: 0.8624426198470827
ogbn-products,dgl,1,1582,402.9696,0.8624

 F1-mic 0.8624,  F1-mac 0.4669
ogbn-products,dgl,1,1583,403.2233,0.8624

 F1-mic 0.8625,  F1-mac 0.4669
new best val f1: 0.8624507532677147
ogbn-products,dgl,1,1584,403.4769,0.8625

 F1-mic 0.8625,  F1-mac 0.4670
new best val f1: 0.8624665682522769
ogbn-products,dgl,1,1585,403.7313,0.8625

 F1-mic 0.8625,  F1-mac 0.4670
new best val f1: 0.8624823832368392
ogbn-products,dgl,1,1586,403.9854,0.8625

 F1-mic 0.8625,  F1-mac 0.4670
new best val f1: 0.8624869018038571
ogbn-products,dgl,1,1587,404.2396,0.8625

 F1-mic 0.8625,  F1-mac 0.4670
new best val f1: 0.8624918722275767
ogbn-products,dgl,1,1588,404.4935,0.8625

 F1-mic 0.8625,  F1-mac 0.4670
new best val f1: 0.8625144650626657
ogbn-products,dgl,1,1589,404.7471,0.8625

epoch:1591/50, Iteration 32/32:training loss 0.5681214332580566
Train F1-mic 0.8661, Train F1-mac 0.4667
 F1-mic 0.8625,  F1-mac 0.4671
new best val f1: 0.8625167243461747
ogbn-products,dgl,1,1590,405.0007,0.8625

 F1-mic 0.8625,  F1-mac 0.4671
new best val f1: 0.8625325393307369
ogbn-products,dgl,1,1591,405.2521,0.8625

 F1-mic 0.8625,  F1-mac 0.4671
new best val f1: 0.8625469987451939
ogbn-products,dgl,1,1592,405.5060,0.8625

 F1-mic 0.8626,  F1-mac 0.4672
new best val f1: 0.8625533247390189
ogbn-products,dgl,1,1593,405.7599,0.8626

 F1-mic 0.8626,  F1-mac 0.4672
new best val f1: 0.8625691397235812
ogbn-products,dgl,1,1594,406.0135,0.8626

 F1-mic 0.8626,  F1-mac 0.4672
new best val f1: 0.862573658290599
ogbn-products,dgl,1,1595,406.2673,0.8626

 F1-mic 0.8626,  F1-mac 0.4672
new best val f1: 0.8625876658483542
ogbn-products,dgl,1,1596,406.5208,0.8626

 F1-mic 0.8626,  F1-mac 0.4672
new best val f1: 0.8626034808329165
ogbn-products,dgl,1,1597,406.7747,0.8626

 F1-mic 0.8626,  F1-mac 0.4672
new best val f1: 0.8626156809638645
ogbn-products,dgl,1,1598,407.0289,0.8626

 F1-mic 0.8626,  F1-mac 0.4672
new best val f1: 0.8626351108020411
ogbn-products,dgl,1,1599,407.2825,0.8626

epoch:1601/50, Iteration 32/32:training loss 0.5674867630004883
Train F1-mic 0.8662, Train F1-mac 0.4669
 F1-mic 0.8626,  F1-mac 0.4674
new best val f1: 0.8626396293690588
ogbn-products,dgl,1,1600,407.5364,0.8626

 F1-mic 0.8626,  F1-mac 0.4674
new best val f1: 0.8626468590762875
ogbn-products,dgl,1,1601,407.7882,0.8626

 F1-mic 0.8627,  F1-mac 0.4674
new best val f1: 0.8626554443536213
ogbn-products,dgl,1,1602,408.0419,0.8627

 F1-mic 0.8627,  F1-mac 0.4675
new best val f1: 0.862682555755728
ogbn-products,dgl,1,1603,408.2955,0.8627

 F1-mic 0.8627,  F1-mac 0.4675
new best val f1: 0.8626979188835886
ogbn-products,dgl,1,1604,408.5498,0.8627

 F1-mic 0.8627,  F1-mac 0.4675
new best val f1: 0.8627146375815545
ogbn-products,dgl,1,1605,408.8036,0.8627

 F1-mic 0.8627,  F1-mac 0.4675
ogbn-products,dgl,1,1606,409.0571,0.8627

 F1-mic 0.8627,  F1-mac 0.4675
new best val f1: 0.8627354229898364
ogbn-products,dgl,1,1607,409.3107,0.8627

 F1-mic 0.8627,  F1-mac 0.4675
new best val f1: 0.8627480749774863
ogbn-products,dgl,1,1608,409.5643,0.8627

 F1-mic 0.8628,  F1-mac 0.4675
new best val f1: 0.862750786117697
ogbn-products,dgl,1,1609,409.8185,0.8628

epoch:1611/50, Iteration 32/32:training loss 0.5668595433235168
Train F1-mic 0.8663, Train F1-mac 0.4672
 F1-mic 0.8628,  F1-mac 0.4677
new best val f1: 0.8627715715259788
ogbn-products,dgl,1,1610,410.0720,0.8628

 F1-mic 0.8628,  F1-mac 0.4677
new best val f1: 0.8627819642301198
ogbn-products,dgl,1,1611,410.3233,0.8628

 F1-mic 0.8628,  F1-mac 0.4677
new best val f1: 0.8627833198002252
ogbn-products,dgl,1,1612,410.5770,0.8628

 F1-mic 0.8628,  F1-mac 0.4678
new best val f1: 0.8628013940682964
ogbn-products,dgl,1,1613,410.8305,0.8628

 F1-mic 0.8628,  F1-mac 0.4678
new best val f1: 0.8628054607786123
ogbn-products,dgl,1,1614,411.0844,0.8628

 F1-mic 0.8628,  F1-mac 0.4678
new best val f1: 0.8628239869033854
ogbn-products,dgl,1,1615,411.3382,0.8628

 F1-mic 0.8628,  F1-mac 0.4678
new best val f1: 0.8628352833209298
ogbn-products,dgl,1,1616,411.5921,0.8628

 F1-mic 0.8629,  F1-mac 0.4678
new best val f1: 0.8628574242993171
ogbn-products,dgl,1,1617,411.8461,0.8629

 F1-mic 0.8629,  F1-mac 0.4680
ogbn-products,dgl,1,1618,412.0996,0.8629

 F1-mic 0.8629,  F1-mac 0.4680
new best val f1: 0.862867817003458
ogbn-products,dgl,1,1619,412.3533,0.8629

epoch:1621/50, Iteration 32/32:training loss 0.5662403702735901
Train F1-mic 0.8664, Train F1-mac 0.4677
 F1-mic 0.8629,  F1-mac 0.4682
ogbn-products,dgl,1,1620,412.6070,0.8629

 F1-mic 0.8629,  F1-mac 0.4682
new best val f1: 0.8628818245612132
ogbn-products,dgl,1,1621,412.8591,0.8629

 F1-mic 0.8629,  F1-mac 0.4684
new best val f1: 0.8628854394148275
ogbn-products,dgl,1,1622,413.1134,0.8629

 F1-mic 0.8629,  F1-mac 0.4684
new best val f1: 0.8629066766798111
ogbn-products,dgl,1,1623,413.3671,0.8629

 F1-mic 0.8629,  F1-mac 0.4684
new best val f1: 0.862915261957145
ogbn-products,dgl,1,1624,413.6213,0.8629

 F1-mic 0.8629,  F1-mac 0.4684
new best val f1: 0.862925654661286
ogbn-products,dgl,1,1625,413.8752,0.8629

 F1-mic 0.8629,  F1-mac 0.4686
new best val f1: 0.8629446326427608
ogbn-products,dgl,1,1626,414.1287,0.8629

 F1-mic 0.8630,  F1-mac 0.4687
new best val f1: 0.862962706910832
ogbn-products,dgl,1,1627,414.3822,0.8630

 F1-mic 0.8630,  F1-mac 0.4687
new best val f1: 0.8629785218953943
ogbn-products,dgl,1,1628,414.6360,0.8630

 F1-mic 0.8630,  F1-mac 0.4687
new best val f1: 0.8629875590294299
ogbn-products,dgl,1,1629,414.8903,0.8630

epoch:1631/50, Iteration 32/32:training loss 0.565626859664917
Train F1-mic 0.8665, Train F1-mac 0.4684
 F1-mic 0.8630,  F1-mac 0.4688
new best val f1: 0.8629911738830441
ogbn-products,dgl,1,1630,415.1439,0.8630

 F1-mic 0.8630,  F1-mac 0.4689
new best val f1: 0.8629970480201674
ogbn-products,dgl,1,1631,415.3954,0.8630

 F1-mic 0.8630,  F1-mac 0.4691
new best val f1: 0.8630164778583438
ogbn-products,dgl,1,1632,415.6499,0.8630

 F1-mic 0.8630,  F1-mac 0.4693
new best val f1: 0.8630232557088705
ogbn-products,dgl,1,1633,415.9034,0.8630

 F1-mic 0.8630,  F1-mac 0.4693
new best val f1: 0.8630359076965205
ogbn-products,dgl,1,1634,416.1571,0.8630

 F1-mic 0.8630,  F1-mac 0.4693
new best val f1: 0.8630413299769417
ogbn-products,dgl,1,1635,416.4106,0.8630

 F1-mic 0.8630,  F1-mac 0.4694
new best val f1: 0.8630467522573632
ogbn-products,dgl,1,1636,416.6642,0.8630

 F1-mic 0.8631,  F1-mac 0.4695
new best val f1: 0.8630702488058557
ogbn-products,dgl,1,1637,416.9178,0.8631

 F1-mic 0.8631,  F1-mac 0.4695
new best val f1: 0.8630765747996806
ogbn-products,dgl,1,1638,417.1717,0.8631

 F1-mic 0.8631,  F1-mac 0.4695
new best val f1: 0.8630815452234002
ogbn-products,dgl,1,1639,417.4255,0.8631

epoch:1641/50, Iteration 32/32:training loss 0.5650210976600647
Train F1-mic 0.8666, Train F1-mac 0.4692
 F1-mic 0.8631,  F1-mac 0.4695
new best val f1: 0.8630969083512607
ogbn-products,dgl,1,1640,417.6795,0.8631

 F1-mic 0.8631,  F1-mac 0.4695
new best val f1: 0.8631059454852964
ogbn-products,dgl,1,1641,417.9315,0.8631

 F1-mic 0.8631,  F1-mac 0.4695
ogbn-products,dgl,1,1642,418.1853,0.8631

 F1-mic 0.8631,  F1-mac 0.4695
new best val f1: 0.8631176937595426
ogbn-products,dgl,1,1643,418.4395,0.8631

 F1-mic 0.8631,  F1-mac 0.4696
new best val f1: 0.8631204048997533
ogbn-products,dgl,1,1644,418.6932,0.8631

 F1-mic 0.8631,  F1-mac 0.4696
new best val f1: 0.8631335087441051
ogbn-products,dgl,1,1645,418.9470,0.8631

 F1-mic 0.8631,  F1-mac 0.4696
new best val f1: 0.8631398347379299
ogbn-products,dgl,1,1646,419.2006,0.8631

 F1-mic 0.8631,  F1-mac 0.4696
new best val f1: 0.8631448051616495
ogbn-products,dgl,1,1647,419.4542,0.8631

 F1-mic 0.8632,  F1-mac 0.4697
new best val f1: 0.8631669461400368
ogbn-products,dgl,1,1648,419.7084,0.8632

 F1-mic 0.8632,  F1-mac 0.4697
new best val f1: 0.8631773388441777
ogbn-products,dgl,1,1649,419.9622,0.8632

epoch:1651/50, Iteration 32/32:training loss 0.5644221305847168
Train F1-mic 0.8667, Train F1-mac 0.4694
 F1-mic 0.8632,  F1-mac 0.4699
new best val f1: 0.8631967686823542
ogbn-products,dgl,1,1650,420.2160,0.8632

 F1-mic 0.8632,  F1-mac 0.4699
new best val f1: 0.8632071613864952
ogbn-products,dgl,1,1651,420.4674,0.8632

 F1-mic 0.8632,  F1-mac 0.4701
new best val f1: 0.863219813374145
ogbn-products,dgl,1,1652,420.7210,0.8632

 F1-mic 0.8632,  F1-mac 0.4701
new best val f1: 0.8632297542215842
ogbn-products,dgl,1,1653,420.9746,0.8632

 F1-mic 0.8633,  F1-mac 0.4701
new best val f1: 0.8632523470566732
ogbn-products,dgl,1,1654,421.2284,0.8633

 F1-mic 0.8633,  F1-mac 0.4703
new best val f1: 0.8632600286206034
ogbn-products,dgl,1,1655,421.4836,0.8633

 F1-mic 0.8633,  F1-mac 0.4703
new best val f1: 0.8632695176113409
ogbn-products,dgl,1,1656,421.7373,0.8633

 F1-mic 0.8633,  F1-mac 0.4703
new best val f1: 0.8632790066020782
ogbn-products,dgl,1,1657,421.9910,0.8633

 F1-mic 0.8633,  F1-mac 0.4704
new best val f1: 0.8632943697299388
ogbn-products,dgl,1,1658,422.2448,0.8633

 F1-mic 0.8633,  F1-mac 0.4705
new best val f1: 0.8633142514248171
ogbn-products,dgl,1,1659,422.4985,0.8633

epoch:1661/50, Iteration 32/32:training loss 0.5638313889503479
Train F1-mic 0.8669, Train F1-mac 0.4701
 F1-mic 0.8633,  F1-mac 0.4704
new best val f1: 0.8633192218485367
ogbn-products,dgl,1,1660,422.7522,0.8633

 F1-mic 0.8633,  F1-mac 0.4706
new best val f1: 0.86334542953724
ogbn-products,dgl,1,1661,423.0037,0.8633

 F1-mic 0.8633,  F1-mac 0.4706
new best val f1: 0.8633458813939417
ogbn-products,dgl,1,1662,423.2575,0.8633

 F1-mic 0.8634,  F1-mac 0.4707
new best val f1: 0.8633567259547845
ogbn-products,dgl,1,1663,423.5110,0.8634

 F1-mic 0.8634,  F1-mac 0.4707
new best val f1: 0.8633720890826451
ogbn-products,dgl,1,1664,423.7648,0.8634

 F1-mic 0.8634,  F1-mac 0.4708
new best val f1: 0.8633779632197682
ogbn-products,dgl,1,1665,424.0185,0.8634

 F1-mic 0.8634,  F1-mac 0.4708
new best val f1: 0.8633928744909269
ogbn-products,dgl,1,1666,424.2722,0.8634

 F1-mic 0.8634,  F1-mac 0.4708
new best val f1: 0.8634068820486821
ogbn-products,dgl,1,1667,424.5258,0.8634

 F1-mic 0.8634,  F1-mac 0.4709
new best val f1: 0.8634163710394195
ogbn-products,dgl,1,1668,424.7795,0.8634

 F1-mic 0.8634,  F1-mac 0.4709
new best val f1: 0.863423600746648
ogbn-products,dgl,1,1669,425.0331,0.8634

epoch:1671/50, Iteration 32/32:training loss 0.5632463693618774
Train F1-mic 0.8670, Train F1-mac 0.4707
 F1-mic 0.8634,  F1-mac 0.4709
new best val f1: 0.8634312823105783
ogbn-products,dgl,1,1670,425.2866,0.8634

 F1-mic 0.8634,  F1-mac 0.4709
new best val f1: 0.863438060161105
ogbn-products,dgl,1,1671,425.5381,0.8634

 F1-mic 0.8635,  F1-mac 0.4709
new best val f1: 0.863452519575562
ogbn-products,dgl,1,1672,425.7918,0.8635

 F1-mic 0.8634,  F1-mac 0.4710
ogbn-products,dgl,1,1673,426.0455,0.8634

 F1-mic 0.8635,  F1-mac 0.4710
new best val f1: 0.8634597492827905
ogbn-products,dgl,1,1674,426.2999,0.8635

 F1-mic 0.8635,  F1-mac 0.4710
new best val f1: 0.8634624604230011
ogbn-products,dgl,1,1675,426.5535,0.8635

 F1-mic 0.8635,  F1-mac 0.4710
new best val f1: 0.8634719494137385
ogbn-products,dgl,1,1676,426.8071,0.8635

 F1-mic 0.8635,  F1-mac 0.4711
new best val f1: 0.8634918311086168
ogbn-products,dgl,1,1677,427.0608,0.8635

 F1-mic 0.8635,  F1-mac 0.4711
new best val f1: 0.8634945422488275
ogbn-products,dgl,1,1678,427.3145,0.8635

 F1-mic 0.8635,  F1-mac 0.4712
new best val f1: 0.8635139720870041
ogbn-products,dgl,1,1679,427.5685,0.8635

epoch:1681/50, Iteration 32/32:training loss 0.5626665949821472
Train F1-mic 0.8671, Train F1-mac 0.4710
 F1-mic 0.8635,  F1-mac 0.4712
new best val f1: 0.8635216536509344
ogbn-products,dgl,1,1680,427.8229,0.8635

 F1-mic 0.8635,  F1-mac 0.4712
new best val f1: 0.8635324982117771
ogbn-products,dgl,1,1681,428.0745,0.8635

 F1-mic 0.8635,  F1-mac 0.4714
new best val f1: 0.8635401797757074
ogbn-products,dgl,1,1682,428.3283,0.8635

 F1-mic 0.8636,  F1-mac 0.4715
new best val f1: 0.8635505724798482
ogbn-products,dgl,1,1683,428.5825,0.8636

 F1-mic 0.8636,  F1-mac 0.4717
new best val f1: 0.8635641281809018
ogbn-products,dgl,1,1684,428.8363,0.8636

 F1-mic 0.8636,  F1-mac 0.4717
new best val f1: 0.8635690986046213
ogbn-products,dgl,1,1685,429.0914,0.8636

 F1-mic 0.8636,  F1-mac 0.4717
ogbn-products,dgl,1,1686,429.3454,0.8636

 F1-mic 0.8636,  F1-mac 0.4717
new best val f1: 0.8635776838819551
ogbn-products,dgl,1,1687,429.5990,0.8636

 F1-mic 0.8636,  F1-mac 0.4719
new best val f1: 0.8635817505922712
ogbn-products,dgl,1,1688,429.8527,0.8636

 F1-mic 0.8636,  F1-mac 0.4718
new best val f1: 0.8635844617324818
ogbn-products,dgl,1,1689,430.1065,0.8636

epoch:1691/50, Iteration 32/32:training loss 0.5620946884155273
Train F1-mic 0.8671, Train F1-mac 0.4716
 F1-mic 0.8636,  F1-mac 0.4719
new best val f1: 0.863604795284062
ogbn-products,dgl,1,1690,430.3600,0.8636

 F1-mic 0.8636,  F1-mac 0.4719
new best val f1: 0.863612928704694
ogbn-products,dgl,1,1691,430.6123,0.8636

 F1-mic 0.8636,  F1-mac 0.4719
new best val f1: 0.8636282918325545
ogbn-products,dgl,1,1692,430.8660,0.8636

 F1-mic 0.8636,  F1-mac 0.4719
new best val f1: 0.8636404919635027
ogbn-products,dgl,1,1693,431.1195,0.8636

 F1-mic 0.8637,  F1-mac 0.4719
new best val f1: 0.8636549513779596
ogbn-products,dgl,1,1694,431.3734,0.8637

 F1-mic 0.8637,  F1-mac 0.4719
new best val f1: 0.8636621810851881
ogbn-products,dgl,1,1695,431.6269,0.8637

 F1-mic 0.8637,  F1-mac 0.4720
new best val f1: 0.8636685070790129
ogbn-products,dgl,1,1696,431.8813,0.8637

 F1-mic 0.8637,  F1-mac 0.4720
new best val f1: 0.8636856776336806
ogbn-products,dgl,1,1697,432.1351,0.8637

 F1-mic 0.8637,  F1-mac 0.4720
new best val f1: 0.8636892924872949
ogbn-products,dgl,1,1698,432.3889,0.8637

 F1-mic 0.8637,  F1-mac 0.4721
new best val f1: 0.863705559328559
ogbn-products,dgl,1,1699,432.6423,0.8637

epoch:1701/50, Iteration 32/32:training loss 0.5615267157554626
Train F1-mic 0.8672, Train F1-mac 0.4720
 F1-mic 0.8637,  F1-mac 0.4721
new best val f1: 0.8637186631729107
ogbn-products,dgl,1,1700,432.8961,0.8637

 F1-mic 0.8637,  F1-mac 0.4721
new best val f1: 0.8637249891667356
ogbn-products,dgl,1,1701,433.1473,0.8637

 F1-mic 0.8637,  F1-mac 0.4723
new best val f1: 0.8637394485811926
ogbn-products,dgl,1,1702,433.4011,0.8637

 F1-mic 0.8637,  F1-mac 0.4723
new best val f1: 0.8637439671482103
ogbn-products,dgl,1,1703,433.6551,0.8637

 F1-mic 0.8638,  F1-mac 0.4723
new best val f1: 0.8637570709925619
ogbn-products,dgl,1,1704,433.9092,0.8638

 F1-mic 0.8638,  F1-mac 0.4723
new best val f1: 0.8637778564008439
ogbn-products,dgl,1,1705,434.1631,0.8638

 F1-mic 0.8638,  F1-mac 0.4723
new best val f1: 0.8637832786812651
ogbn-products,dgl,1,1706,434.4168,0.8638

 F1-mic 0.8638,  F1-mac 0.4723
new best val f1: 0.8638013529493365
ogbn-products,dgl,1,1707,434.6705,0.8638

 F1-mic 0.8638,  F1-mac 0.4723
new best val f1: 0.8638121975101792
ogbn-products,dgl,1,1708,434.9249,0.8638

 F1-mic 0.8638,  F1-mac 0.4723
new best val f1: 0.8638266569246362
ogbn-products,dgl,1,1709,435.1790,0.8638

epoch:1711/50, Iteration 32/32:training loss 0.5609649419784546
Train F1-mic 0.8674, Train F1-mac 0.4722
 F1-mic 0.8638,  F1-mac 0.4723
new best val f1: 0.8638302717782504
ogbn-products,dgl,1,1710,435.4334,0.8638

 F1-mic 0.8639,  F1-mac 0.4725
new best val f1: 0.863853768326743
ogbn-products,dgl,1,1711,435.6848,0.8639

 F1-mic 0.8639,  F1-mac 0.4726
new best val f1: 0.8638573831803571
ogbn-products,dgl,1,1712,435.9385,0.8639

 F1-mic 0.8639,  F1-mac 0.4726
new best val f1: 0.863865968457691
ogbn-products,dgl,1,1713,436.1920,0.8639

 F1-mic 0.8639,  F1-mac 0.4726
new best val f1: 0.8638831390123587
ogbn-products,dgl,1,1714,436.4458,0.8639

 F1-mic 0.8639,  F1-mac 0.4726
new best val f1: 0.8638998577103246
ogbn-products,dgl,1,1715,436.6995,0.8639

 F1-mic 0.8639,  F1-mac 0.4727
new best val f1: 0.8639016651371317
ogbn-products,dgl,1,1716,436.9538,0.8639

 F1-mic 0.8639,  F1-mac 0.4728
new best val f1: 0.8639120578412727
ogbn-products,dgl,1,1717,437.2076,0.8639

 F1-mic 0.8639,  F1-mac 0.4728
new best val f1: 0.8639292283959404
ogbn-products,dgl,1,1718,437.4612,0.8639

 F1-mic 0.8639,  F1-mac 0.4728
new best val f1: 0.8639436878103973
ogbn-products,dgl,1,1719,437.7150,0.8639

epoch:1721/50, Iteration 32/32:training loss 0.5604100227355957
Train F1-mic 0.8675, Train F1-mac 0.4727
 F1-mic 0.8639,  F1-mac 0.4728
ogbn-products,dgl,1,1720,437.9692,0.8639

 F1-mic 0.8640,  F1-mac 0.4728
new best val f1: 0.8639500138042222
ogbn-products,dgl,1,1721,438.2207,0.8640

 F1-mic 0.8640,  F1-mac 0.4728
new best val f1: 0.8639613102217667
ogbn-products,dgl,1,1722,438.4742,0.8640

 F1-mic 0.8640,  F1-mac 0.4730
new best val f1: 0.8639658287887846
ogbn-products,dgl,1,1723,438.7286,0.8640

 F1-mic 0.8640,  F1-mac 0.4730
new best val f1: 0.8639748659228201
ogbn-products,dgl,1,1724,438.9824,0.8640

 F1-mic 0.8640,  F1-mac 0.4730
new best val f1: 0.8639811919166451
ogbn-products,dgl,1,1725,439.2367,0.8640

 F1-mic 0.8640,  F1-mac 0.4730
new best val f1: 0.8639852586269611
ogbn-products,dgl,1,1726,439.4904,0.8640

 F1-mic 0.8640,  F1-mac 0.4731
new best val f1: 0.864001977324927
ogbn-products,dgl,1,1727,439.7439,0.8640

 F1-mic 0.8640,  F1-mac 0.4731
ogbn-products,dgl,1,1728,439.9978,0.8640

 F1-mic 0.8640,  F1-mac 0.4731
new best val f1: 0.8640128218857698
ogbn-products,dgl,1,1729,440.2517,0.8640

epoch:1731/50, Iteration 32/32:training loss 0.5598604083061218
Train F1-mic 0.8675, Train F1-mac 0.4730
 F1-mic 0.8640,  F1-mac 0.4732
new best val f1: 0.864030896153841
ogbn-products,dgl,1,1730,440.5051,0.8640

 F1-mic 0.8640,  F1-mac 0.4732
new best val f1: 0.8640340591507535
ogbn-products,dgl,1,1731,440.7566,0.8640

 F1-mic 0.8640,  F1-mac 0.4731
new best val f1: 0.8640381258610694
ogbn-products,dgl,1,1732,441.0103,0.8640

 F1-mic 0.8641,  F1-mac 0.4731
new best val f1: 0.8640562001291406
ogbn-products,dgl,1,1733,441.2641,0.8641

 F1-mic 0.8641,  F1-mac 0.4731
new best val f1: 0.8640620742662638
ogbn-products,dgl,1,1734,441.5177,0.8641

 F1-mic 0.8641,  F1-mac 0.4731
new best val f1: 0.8640684002600887
ogbn-products,dgl,1,1735,441.7716,0.8641

 F1-mic 0.8641,  F1-mac 0.4733
new best val f1: 0.8640828596745458
ogbn-products,dgl,1,1736,442.0253,0.8641

 F1-mic 0.8641,  F1-mac 0.4733
new best val f1: 0.8640995783725116
ogbn-products,dgl,1,1737,442.2792,0.8641

 F1-mic 0.8641,  F1-mac 0.4733
new best val f1: 0.8641013857993187
ogbn-products,dgl,1,1738,442.5327,0.8641

 F1-mic 0.8641,  F1-mac 0.4735
new best val f1: 0.864123526777706
ogbn-products,dgl,1,1739,442.7869,0.8641

epoch:1741/50, Iteration 32/32:training loss 0.559317409992218
Train F1-mic 0.8676, Train F1-mac 0.4734
 F1-mic 0.8641,  F1-mac 0.4735
ogbn-products,dgl,1,1740,443.0404,0.8641

 F1-mic 0.8641,  F1-mac 0.4735
new best val f1: 0.8641416010457771
ogbn-products,dgl,1,1741,443.2918,0.8641

 F1-mic 0.8641,  F1-mac 0.4735
new best val f1: 0.8641483788963038
ogbn-products,dgl,1,1742,443.5457,0.8641

 F1-mic 0.8642,  F1-mac 0.4736
new best val f1: 0.8641650975942697
ogbn-products,dgl,1,1743,443.7994,0.8642

 F1-mic 0.8642,  F1-mac 0.4737
new best val f1: 0.8641791051520249
ogbn-products,dgl,1,1744,444.0531,0.8642

 F1-mic 0.8642,  F1-mac 0.4737
new best val f1: 0.8641813644355338
ogbn-products,dgl,1,1745,444.3070,0.8642

 F1-mic 0.8642,  F1-mac 0.4737
new best val f1: 0.86420576469743
ogbn-products,dgl,1,1746,444.5607,0.8642

 F1-mic 0.8642,  F1-mac 0.4737
new best val f1: 0.8642129944046585
ogbn-products,dgl,1,1747,444.8144,0.8642

 F1-mic 0.8642,  F1-mac 0.4737
new best val f1: 0.8642193203984833
ogbn-products,dgl,1,1748,445.0687,0.8642

 F1-mic 0.8642,  F1-mac 0.4737
new best val f1: 0.8642247426789047
ogbn-products,dgl,1,1749,445.3224,0.8642

epoch:1751/50, Iteration 32/32:training loss 0.558779776096344
Train F1-mic 0.8677, Train F1-mac 0.4736
 F1-mic 0.8642,  F1-mac 0.4737
new best val f1: 0.8642369428098529
ogbn-products,dgl,1,1750,445.5760,0.8642

 F1-mic 0.8642,  F1-mac 0.4737
new best val f1: 0.8642405576634671
ogbn-products,dgl,1,1751,445.8288,0.8642

 F1-mic 0.8642,  F1-mac 0.4737
ogbn-products,dgl,1,1752,446.0827,0.8642

 F1-mic 0.8642,  F1-mac 0.4737
new best val f1: 0.8642482392273974
ogbn-products,dgl,1,1753,446.3363,0.8642

 F1-mic 0.8643,  F1-mac 0.4738
new best val f1: 0.8642617949284508
ogbn-products,dgl,1,1754,446.5902,0.8643

 F1-mic 0.8643,  F1-mac 0.4738
new best val f1: 0.8642739950593988
ogbn-products,dgl,1,1755,446.8440,0.8643

 F1-mic 0.8643,  F1-mac 0.4738
new best val f1: 0.8642866470470488
ogbn-products,dgl,1,1756,447.0981,0.8643

 F1-mic 0.8643,  F1-mac 0.4738
new best val f1: 0.8642974916078914
ogbn-products,dgl,1,1757,447.3518,0.8643

 F1-mic 0.8643,  F1-mac 0.4738
new best val f1: 0.8643060768852252
ogbn-products,dgl,1,1758,447.6060,0.8643

 F1-mic 0.8643,  F1-mac 0.4738
new best val f1: 0.8643309290038231
ogbn-products,dgl,1,1759,447.8601,0.8643

epoch:1761/50, Iteration 32/32:training loss 0.5582471489906311
Train F1-mic 0.8678, Train F1-mac 0.4737
 F1-mic 0.8643,  F1-mac 0.4739
ogbn-products,dgl,1,1760,448.1136,0.8643

 F1-mic 0.8643,  F1-mac 0.4738
ogbn-products,dgl,1,1761,448.3651,0.8643

 F1-mic 0.8644,  F1-mac 0.4739
new best val f1: 0.8643503588419997
ogbn-products,dgl,1,1762,448.6191,0.8644

 F1-mic 0.8643,  F1-mac 0.4740
ogbn-products,dgl,1,1763,448.8727,0.8643

 F1-mic 0.8644,  F1-mac 0.4740
new best val f1: 0.8643598478327371
ogbn-products,dgl,1,1764,449.1263,0.8644

 F1-mic 0.8644,  F1-mac 0.4740
new best val f1: 0.8643684331100709
ogbn-products,dgl,1,1765,449.3800,0.8644

 F1-mic 0.8644,  F1-mac 0.4740
new best val f1: 0.8643774702441066
ogbn-products,dgl,1,1766,449.6342,0.8644

 F1-mic 0.8644,  F1-mac 0.4740
new best val f1: 0.8643883148049493
ogbn-products,dgl,1,1767,449.8878,0.8644

 F1-mic 0.8644,  F1-mac 0.4740
ogbn-products,dgl,1,1768,450.1414,0.8644

 F1-mic 0.8644,  F1-mac 0.4741
new best val f1: 0.8643959963688795
ogbn-products,dgl,1,1769,450.3950,0.8644

epoch:1771/50, Iteration 32/32:training loss 0.5577199459075928
Train F1-mic 0.8679, Train F1-mac 0.4739
 F1-mic 0.8644,  F1-mac 0.4741
new best val f1: 0.8644172336338632
ogbn-products,dgl,1,1770,450.6486,0.8644

 F1-mic 0.8644,  F1-mac 0.4741
ogbn-products,dgl,1,1771,450.9001,0.8644

 F1-mic 0.8644,  F1-mac 0.4741
ogbn-products,dgl,1,1772,451.1536,0.8644

 F1-mic 0.8644,  F1-mac 0.4742
new best val f1: 0.8644316930483202
ogbn-products,dgl,1,1773,451.4071,0.8644

 F1-mic 0.8644,  F1-mac 0.4742
new best val f1: 0.8644429894658647
ogbn-products,dgl,1,1774,451.6609,0.8644

 F1-mic 0.8644,  F1-mac 0.4742
new best val f1: 0.8644447968926718
ogbn-products,dgl,1,1775,451.9145,0.8644

 F1-mic 0.8645,  F1-mac 0.4742
new best val f1: 0.8644597081638306
ogbn-products,dgl,1,1776,452.1682,0.8645

 F1-mic 0.8645,  F1-mac 0.4743
new best val f1: 0.8644655823009538
ogbn-products,dgl,1,1777,452.4216,0.8645

 F1-mic 0.8645,  F1-mac 0.4744
new best val f1: 0.864473263864884
ogbn-products,dgl,1,1778,452.6758,0.8645

 F1-mic 0.8645,  F1-mac 0.4744
new best val f1: 0.8644809454288143
ogbn-products,dgl,1,1779,452.9293,0.8645

epoch:1781/50, Iteration 32/32:training loss 0.5571975111961365
Train F1-mic 0.8680, Train F1-mac 0.4742
 F1-mic 0.8645,  F1-mac 0.4745
new best val f1: 0.8644967604133765
ogbn-products,dgl,1,1780,453.1831,0.8645

 F1-mic 0.8645,  F1-mac 0.4745
new best val f1: 0.8645067012608157
ogbn-products,dgl,1,1781,453.4346,0.8645

 F1-mic 0.8645,  F1-mac 0.4745
new best val f1: 0.8645112198278335
ogbn-products,dgl,1,1782,453.6888,0.8645

 F1-mic 0.8645,  F1-mac 0.4741
new best val f1: 0.8645175458216585
ogbn-products,dgl,1,1783,453.9426,0.8645

 F1-mic 0.8645,  F1-mac 0.4741
new best val f1: 0.8645252273855888
ogbn-products,dgl,1,1784,454.1963,0.8645

 F1-mic 0.8645,  F1-mac 0.4741
new best val f1: 0.8645455609371688
ogbn-products,dgl,1,1785,454.4508,0.8645

 F1-mic 0.8646,  F1-mac 0.4741
new best val f1: 0.864551435074292
ogbn-products,dgl,1,1786,454.7042,0.8646

 F1-mic 0.8646,  F1-mac 0.4741
new best val f1: 0.8645686056289597
ogbn-products,dgl,1,1787,454.9578,0.8646

 F1-mic 0.8646,  F1-mac 0.4741
ogbn-products,dgl,1,1788,455.2114,0.8646

 F1-mic 0.8646,  F1-mac 0.4741
new best val f1: 0.864580353903206
ogbn-products,dgl,1,1789,455.4652,0.8646

epoch:1791/50, Iteration 32/32:training loss 0.5566813349723816
Train F1-mic 0.8681, Train F1-mac 0.4740
 F1-mic 0.8646,  F1-mac 0.4741
new best val f1: 0.8645939096042595
ogbn-products,dgl,1,1790,455.7189,0.8646

 F1-mic 0.8646,  F1-mac 0.4742
new best val f1: 0.864602946738295
ogbn-products,dgl,1,1791,455.9704,0.8646

 F1-mic 0.8646,  F1-mac 0.4742
new best val f1: 0.8646043023084002
ogbn-products,dgl,1,1792,456.2241,0.8646

 F1-mic 0.8646,  F1-mac 0.4742
new best val f1: 0.8646196654362609
ogbn-products,dgl,1,1793,456.4783,0.8646

 F1-mic 0.8646,  F1-mac 0.4742
new best val f1: 0.8646323174239107
ogbn-products,dgl,1,1794,456.7320,0.8646

 F1-mic 0.8646,  F1-mac 0.4742
new best val f1: 0.864641806414648
ogbn-products,dgl,1,1795,456.9859,0.8646

 F1-mic 0.8647,  F1-mac 0.4742
new best val f1: 0.8646621399662282
ogbn-products,dgl,1,1796,457.2397,0.8647

 F1-mic 0.8647,  F1-mac 0.4742
new best val f1: 0.8646630436796318
ogbn-products,dgl,1,1797,457.4932,0.8647

 F1-mic 0.8647,  F1-mac 0.4742
new best val f1: 0.8646797623775977
ogbn-products,dgl,1,1798,457.7467,0.8647

 F1-mic 0.8647,  F1-mac 0.4743
new best val f1: 0.8646847328013173
ogbn-products,dgl,1,1799,458.0011,0.8647

epoch:1801/50, Iteration 32/32:training loss 0.5561689734458923
Train F1-mic 0.8682, Train F1-mac 0.4742
 F1-mic 0.8647,  F1-mac 0.4743
new best val f1: 0.8647037107827921
ogbn-products,dgl,1,1800,458.2556,0.8647

 F1-mic 0.8647,  F1-mac 0.4743
new best val f1: 0.8647154590570384
ogbn-products,dgl,1,1801,458.5076,0.8647

 F1-mic 0.8647,  F1-mac 0.4744
new best val f1: 0.864734437038513
ogbn-products,dgl,1,1802,458.7615,0.8647

 F1-mic 0.8647,  F1-mac 0.4744
new best val f1: 0.8647371481787238
ogbn-products,dgl,1,1803,459.0151,0.8647

 F1-mic 0.8647,  F1-mac 0.4744
new best val f1: 0.8647461853127593
ogbn-products,dgl,1,1804,459.2698,0.8647

 F1-mic 0.8648,  F1-mac 0.4744
new best val f1: 0.8647588373004093
ogbn-products,dgl,1,1805,459.5236,0.8648

 F1-mic 0.8648,  F1-mac 0.4745
new best val f1: 0.8647696818612519
ogbn-products,dgl,1,1806,459.7771,0.8648

 F1-mic 0.8648,  F1-mac 0.4745
new best val f1: 0.8647827857056036
ogbn-products,dgl,1,1807,460.0314,0.8648

 F1-mic 0.8648,  F1-mac 0.4745
new best val f1: 0.8647891116994285
ogbn-products,dgl,1,1808,460.2851,0.8648

 F1-mic 0.8648,  F1-mac 0.4745
new best val f1: 0.8647990525468677
ogbn-products,dgl,1,1809,460.5396,0.8648

epoch:1811/50, Iteration 32/32:training loss 0.5556631684303284
Train F1-mic 0.8683, Train F1-mac 0.4744
 F1-mic 0.8648,  F1-mac 0.4745
new best val f1: 0.8648112526778158
ogbn-products,dgl,1,1810,460.7934,0.8648

 F1-mic 0.8648,  F1-mac 0.4745
new best val f1: 0.8648157712448336
ogbn-products,dgl,1,1811,461.0446,0.8648

 F1-mic 0.8648,  F1-mac 0.4747
new best val f1: 0.8648257120922728
ogbn-products,dgl,1,1812,461.2983,0.8648

 F1-mic 0.8648,  F1-mac 0.4747
new best val f1: 0.8648365566531154
ogbn-products,dgl,1,1813,461.5521,0.8648

 F1-mic 0.8648,  F1-mac 0.4747
new best val f1: 0.8648424307902386
ogbn-products,dgl,1,1814,461.8058,0.8648

 F1-mic 0.8649,  F1-mac 0.4747
new best val f1: 0.8648577939180991
ogbn-products,dgl,1,1815,462.0593,0.8649

 F1-mic 0.8649,  F1-mac 0.4747
new best val f1: 0.8648659273387312
ogbn-products,dgl,1,1816,462.3130,0.8649

 F1-mic 0.8649,  F1-mac 0.4747
new best val f1: 0.8648763200428722
ogbn-products,dgl,1,1817,462.5665,0.8649

 F1-mic 0.8649,  F1-mac 0.4747
new best val f1: 0.8648799348964864
ogbn-products,dgl,1,1818,462.8201,0.8649

 F1-mic 0.8649,  F1-mac 0.4747
new best val f1: 0.8649011721614701
ogbn-products,dgl,1,1819,463.0744,0.8649

epoch:1821/50, Iteration 32/32:training loss 0.5551611185073853
Train F1-mic 0.8684, Train F1-mac 0.4746
 F1-mic 0.8649,  F1-mac 0.4747
new best val f1: 0.8649129204357163
ogbn-products,dgl,1,1820,463.3280,0.8649

 F1-mic 0.8649,  F1-mac 0.4747
new best val f1: 0.8649201501429449
ogbn-products,dgl,1,1821,463.5794,0.8649

 F1-mic 0.8649,  F1-mac 0.4747
ogbn-products,dgl,1,1822,463.8333,0.8649

 F1-mic 0.8649,  F1-mac 0.4747
new best val f1: 0.8649264761367698
ogbn-products,dgl,1,1823,464.0875,0.8649

 F1-mic 0.8649,  F1-mac 0.4748
new best val f1: 0.8649337058439982
ogbn-products,dgl,1,1824,464.3411,0.8649

 F1-mic 0.8649,  F1-mac 0.4748
new best val f1: 0.8649373206976125
ogbn-products,dgl,1,1825,464.5951,0.8649

 F1-mic 0.8650,  F1-mac 0.4748
new best val f1: 0.8649581061058944
ogbn-products,dgl,1,1826,464.8485,0.8650

 F1-mic 0.8650,  F1-mac 0.4748
new best val f1: 0.8649734692337551
ogbn-products,dgl,1,1827,465.1022,0.8650

 F1-mic 0.8650,  F1-mac 0.4748
new best val f1: 0.8649820545110888
ogbn-products,dgl,1,1828,465.3556,0.8650

 F1-mic 0.8650,  F1-mac 0.4749
new best val f1: 0.8649883805049137
ogbn-products,dgl,1,1829,465.6093,0.8650

epoch:1831/50, Iteration 32/32:training loss 0.5546634793281555
Train F1-mic 0.8685, Train F1-mac 0.4747
 F1-mic 0.8650,  F1-mac 0.4748
new best val f1: 0.8649928990719316
ogbn-products,dgl,1,1830,465.8629,0.8650

 F1-mic 0.8650,  F1-mac 0.4748
ogbn-products,dgl,1,1831,466.1150,0.8650

 F1-mic 0.8650,  F1-mac 0.4749
new best val f1: 0.8650172993338275
ogbn-products,dgl,1,1832,466.3686,0.8650

 F1-mic 0.8650,  F1-mac 0.4750
ogbn-products,dgl,1,1833,466.6224,0.8650

 F1-mic 0.8650,  F1-mac 0.4750
new best val f1: 0.865029047608074
ogbn-products,dgl,1,1834,466.8761,0.8650

 F1-mic 0.8650,  F1-mac 0.4750
new best val f1: 0.8650493811596541
ogbn-products,dgl,1,1835,467.1305,0.8650

 F1-mic 0.8651,  F1-mac 0.4750
new best val f1: 0.8650557071534789
ogbn-products,dgl,1,1836,467.3844,0.8651

 F1-mic 0.8651,  F1-mac 0.4750
new best val f1: 0.8650665517143218
ogbn-products,dgl,1,1837,467.6382,0.8651

 F1-mic 0.8651,  F1-mac 0.4750
ogbn-products,dgl,1,1838,467.8921,0.8651

 F1-mic 0.8651,  F1-mac 0.4751
new best val f1: 0.8650841741256912
ogbn-products,dgl,1,1839,468.1456,0.8651

epoch:1841/50, Iteration 32/32:training loss 0.5541714429855347
Train F1-mic 0.8686, Train F1-mac 0.4749
 F1-mic 0.8651,  F1-mac 0.4750
ogbn-products,dgl,1,1840,468.3991,0.8651

 F1-mic 0.8651,  F1-mac 0.4751
new best val f1: 0.8650914038329196
ogbn-products,dgl,1,1841,468.6504,0.8651

 F1-mic 0.8651,  F1-mac 0.4751
new best val f1: 0.8651045076772713
ogbn-products,dgl,1,1842,468.9042,0.8651

 F1-mic 0.8651,  F1-mac 0.4751
ogbn-products,dgl,1,1843,469.1579,0.8651

 F1-mic 0.8651,  F1-mac 0.4751
new best val f1: 0.8651280042257639
ogbn-products,dgl,1,1844,469.4116,0.8651

 F1-mic 0.8651,  F1-mac 0.4752
new best val f1: 0.8651343302195887
ogbn-products,dgl,1,1845,469.6650,0.8651

 F1-mic 0.8651,  F1-mac 0.4751
new best val f1: 0.8651397525000102
ogbn-products,dgl,1,1846,469.9186,0.8651

 F1-mic 0.8651,  F1-mac 0.4751
new best val f1: 0.8651424636402208
ogbn-products,dgl,1,1847,470.1720,0.8651

 F1-mic 0.8652,  F1-mac 0.4752
new best val f1: 0.8651655083320117
ogbn-products,dgl,1,1848,470.4257,0.8652

 F1-mic 0.8652,  F1-mac 0.4752
new best val f1: 0.8651709306124329
ogbn-products,dgl,1,1849,470.6795,0.8652

epoch:1851/50, Iteration 32/32:training loss 0.5536828637123108
Train F1-mic 0.8687, Train F1-mac 0.4750
 F1-mic 0.8652,  F1-mac 0.4752
ogbn-products,dgl,1,1850,470.9330,0.8652

 F1-mic 0.8652,  F1-mac 0.4752
new best val f1: 0.8651817751732758
ogbn-products,dgl,1,1851,471.1850,0.8652

 F1-mic 0.8652,  F1-mac 0.4752
new best val f1: 0.8651939753042238
ogbn-products,dgl,1,1852,471.4385,0.8652

 F1-mic 0.8652,  F1-mac 0.4752
new best val f1: 0.8651957827310309
ogbn-products,dgl,1,1853,471.6925,0.8652

 F1-mic 0.8652,  F1-mac 0.4752
new best val f1: 0.865202108724856
ogbn-products,dgl,1,1854,471.9461,0.8652

 F1-mic 0.8652,  F1-mac 0.4753
new best val f1: 0.865214308855804
ogbn-products,dgl,1,1855,472.2000,0.8652

 F1-mic 0.8652,  F1-mac 0.4753
new best val f1: 0.8652197311362253
ogbn-products,dgl,1,1856,472.4538,0.8652

 F1-mic 0.8652,  F1-mac 0.4752
new best val f1: 0.8652242497032432
ogbn-products,dgl,1,1857,472.7077,0.8652

 F1-mic 0.8652,  F1-mac 0.4752
new best val f1: 0.8652337386939805
ogbn-products,dgl,1,1858,472.9613,0.8652

 F1-mic 0.8652,  F1-mac 0.4753
new best val f1: 0.8652423239713142
ogbn-products,dgl,1,1859,473.2148,0.8652

epoch:1861/50, Iteration 32/32:training loss 0.5532013773918152
Train F1-mic 0.8687, Train F1-mac 0.4751
 F1-mic 0.8653,  F1-mac 0.4754
new best val f1: 0.8652554278156659
ogbn-products,dgl,1,1860,473.4687,0.8653

 F1-mic 0.8653,  F1-mac 0.4754
new best val f1: 0.8652603982393855
ogbn-products,dgl,1,1861,473.7200,0.8653

 F1-mic 0.8653,  F1-mac 0.4754
new best val f1: 0.8652680798033158
ogbn-products,dgl,1,1862,473.9738,0.8653

 F1-mic 0.8653,  F1-mac 0.4754
new best val f1: 0.8652762132239479
ogbn-products,dgl,1,1863,474.2276,0.8653

 F1-mic 0.8653,  F1-mac 0.4755
new best val f1: 0.8652897689250013
ogbn-products,dgl,1,1864,474.4813,0.8653

 F1-mic 0.8653,  F1-mac 0.4755
new best val f1: 0.8653028727693529
ogbn-products,dgl,1,1865,474.7351,0.8653

 F1-mic 0.8653,  F1-mac 0.4755
new best val f1: 0.8653236581776348
ogbn-products,dgl,1,1866,474.9889,0.8653

 F1-mic 0.8653,  F1-mac 0.4755
ogbn-products,dgl,1,1867,475.2423,0.8653

 F1-mic 0.8653,  F1-mac 0.4755
new best val f1: 0.865329532314758
ogbn-products,dgl,1,1868,475.4959,0.8653

 F1-mic 0.8653,  F1-mac 0.4755
new best val f1: 0.865343991729215
ogbn-products,dgl,1,1869,475.7496,0.8653

epoch:1871/50, Iteration 32/32:training loss 0.5527226328849792
Train F1-mic 0.8688, Train F1-mac 0.4754
 F1-mic 0.8654,  F1-mac 0.4756
new best val f1: 0.8653503177230398
ogbn-products,dgl,1,1870,476.0031,0.8654

 F1-mic 0.8654,  F1-mac 0.4756
new best val f1: 0.8653575474302684
ogbn-products,dgl,1,1871,476.2545,0.8654

 F1-mic 0.8654,  F1-mac 0.4756
new best val f1: 0.8653688438478129
ogbn-products,dgl,1,1872,476.5086,0.8654

 F1-mic 0.8654,  F1-mac 0.4756
new best val f1: 0.86538330326227
ogbn-products,dgl,1,1873,476.7624,0.8654

 F1-mic 0.8654,  F1-mac 0.4757
new best val f1: 0.8653927922530072
ogbn-products,dgl,1,1874,477.0163,0.8654

 F1-mic 0.8654,  F1-mac 0.4757
new best val f1: 0.8654049923839553
ogbn-products,dgl,1,1875,477.2700,0.8654

 F1-mic 0.8654,  F1-mac 0.4759
new best val f1: 0.865419903655114
ogbn-products,dgl,1,1876,477.5238,0.8654

 F1-mic 0.8654,  F1-mac 0.4759
ogbn-products,dgl,1,1877,477.7773,0.8654

 F1-mic 0.8654,  F1-mac 0.4759
new best val f1: 0.8654438520603083
ogbn-products,dgl,1,1878,478.0317,0.8654

 F1-mic 0.8655,  F1-mac 0.4760
new best val f1: 0.8654592151881689
ogbn-products,dgl,1,1879,478.2856,0.8655

epoch:1881/50, Iteration 32/32:training loss 0.5522500276565552
Train F1-mic 0.8689, Train F1-mac 0.4758
 F1-mic 0.8655,  F1-mac 0.4760
new best val f1: 0.8654650893252921
ogbn-products,dgl,1,1880,478.5393,0.8655

 F1-mic 0.8655,  F1-mac 0.4760
ogbn-products,dgl,1,1881,478.7915,0.8655

 F1-mic 0.8655,  F1-mac 0.4760
new best val f1: 0.8654840673067669
ogbn-products,dgl,1,1882,479.0455,0.8655

 F1-mic 0.8655,  F1-mac 0.4760
new best val f1: 0.8654998822913293
ogbn-products,dgl,1,1883,479.2998,0.8655

 F1-mic 0.8655,  F1-mac 0.4760
ogbn-products,dgl,1,1884,479.5537,0.8655

 F1-mic 0.8655,  F1-mac 0.4760
new best val f1: 0.8655089194253648
ogbn-products,dgl,1,1885,479.8076,0.8655

 F1-mic 0.8655,  F1-mac 0.4760
new best val f1: 0.8655166009892951
ogbn-products,dgl,1,1886,480.0618,0.8655

 F1-mic 0.8655,  F1-mac 0.4760
new best val f1: 0.8655202158429093
ogbn-products,dgl,1,1887,480.3153,0.8655

 F1-mic 0.8655,  F1-mac 0.4760
new best val f1: 0.8655396456810859
ogbn-products,dgl,1,1888,480.5699,0.8655

 F1-mic 0.8655,  F1-mac 0.4761
ogbn-products,dgl,1,1889,480.8237,0.8655

epoch:1891/50, Iteration 32/32:training loss 0.5517802834510803
Train F1-mic 0.8690, Train F1-mac 0.4760
 F1-mic 0.8656,  F1-mac 0.4761
new best val f1: 0.865559979232666
ogbn-products,dgl,1,1890,481.0772,0.8656

 F1-mic 0.8656,  F1-mac 0.4761
new best val f1: 0.8655649496563855
ogbn-products,dgl,1,1891,481.3288,0.8656

 F1-mic 0.8656,  F1-mac 0.4762
ogbn-products,dgl,1,1892,481.5824,0.8656

 F1-mic 0.8656,  F1-mac 0.4762
ogbn-products,dgl,1,1893,481.8360,0.8656

 F1-mic 0.8656,  F1-mac 0.4762
new best val f1: 0.8655834757811586
ogbn-products,dgl,1,1894,482.0901,0.8656

 F1-mic 0.8656,  F1-mac 0.4763
new best val f1: 0.8655929647718961
ogbn-products,dgl,1,1895,482.3438,0.8656

 F1-mic 0.8656,  F1-mac 0.4764
new best val f1: 0.8655997426224227
ogbn-products,dgl,1,1896,482.5978,0.8656

 F1-mic 0.8656,  F1-mac 0.4765
new best val f1: 0.8656101353265635
ogbn-products,dgl,1,1897,482.8513,0.8656

 F1-mic 0.8656,  F1-mac 0.4765
new best val f1: 0.8656146538935815
ogbn-products,dgl,1,1898,483.1051,0.8656

 F1-mic 0.8656,  F1-mac 0.4765
ogbn-products,dgl,1,1899,483.3589,0.8656

epoch:1901/50, Iteration 32/32:training loss 0.5513172745704651
Train F1-mic 0.8691, Train F1-mac 0.4763
 F1-mic 0.8656,  F1-mac 0.4765
new best val f1: 0.8656232391709152
ogbn-products,dgl,1,1900,483.6134,0.8656

 F1-mic 0.8656,  F1-mac 0.4765
new best val f1: 0.8656291133080384
ogbn-products,dgl,1,1901,483.8648,0.8656

 F1-mic 0.8656,  F1-mac 0.4765
ogbn-products,dgl,1,1902,484.1190,0.8656

 F1-mic 0.8656,  F1-mac 0.4765
new best val f1: 0.8656417652956881
ogbn-products,dgl,1,1903,484.3728,0.8656

 F1-mic 0.8656,  F1-mac 0.4765
new best val f1: 0.8656426690090918
ogbn-products,dgl,1,1904,484.6265,0.8656

 F1-mic 0.8657,  F1-mac 0.4765
new best val f1: 0.8656521579998292
ogbn-products,dgl,1,1905,484.8801,0.8657

 F1-mic 0.8657,  F1-mac 0.4765
new best val f1: 0.8656593877070576
ogbn-products,dgl,1,1906,485.1338,0.8657

 F1-mic 0.8657,  F1-mac 0.4766
new best val f1: 0.8656648099874791
ogbn-products,dgl,1,1907,485.3875,0.8657

 F1-mic 0.8657,  F1-mac 0.4766
ogbn-products,dgl,1,1908,485.6413,0.8657

 F1-mic 0.8657,  F1-mac 0.4767
new best val f1: 0.8656779138318307
ogbn-products,dgl,1,1909,485.8951,0.8657

epoch:1911/50, Iteration 32/32:training loss 0.5508561134338379
Train F1-mic 0.8692, Train F1-mac 0.4766
 F1-mic 0.8657,  F1-mac 0.4767
new best val f1: 0.8656824323988485
ogbn-products,dgl,1,1910,486.1486,0.8657

 F1-mic 0.8657,  F1-mac 0.4767
new best val f1: 0.8656901139627787
ogbn-products,dgl,1,1911,486.4001,0.8657

 F1-mic 0.8657,  F1-mac 0.4768
new best val f1: 0.8656914695328841
ogbn-products,dgl,1,1912,486.6545,0.8657

 F1-mic 0.8657,  F1-mac 0.4768
new best val f1: 0.865701862237025
ogbn-products,dgl,1,1913,486.9082,0.8657

 F1-mic 0.8657,  F1-mac 0.4768
new best val f1: 0.8657054770906393
ogbn-products,dgl,1,1914,487.1618,0.8657

 F1-mic 0.8657,  F1-mac 0.4768
new best val f1: 0.8657190327916927
ogbn-products,dgl,1,1915,487.4164,0.8657

 F1-mic 0.8657,  F1-mac 0.4769
new best val f1: 0.8657240032154123
ogbn-products,dgl,1,1916,487.6699,0.8657

 F1-mic 0.8657,  F1-mac 0.4769
new best val f1: 0.8657276180690265
ogbn-products,dgl,1,1917,487.9237,0.8657

 F1-mic 0.8657,  F1-mac 0.4768
new best val f1: 0.8657339440628514
ogbn-products,dgl,1,1918,488.1782,0.8657

 F1-mic 0.8657,  F1-mac 0.4769
new best val f1: 0.8657470479072031
ogbn-products,dgl,1,1919,488.4322,0.8657

epoch:1921/50, Iteration 32/32:training loss 0.5504013299942017
Train F1-mic 0.8692, Train F1-mac 0.4768
 F1-mic 0.8658,  F1-mac 0.4769
new best val f1: 0.8657542776144316
ogbn-products,dgl,1,1920,488.6857,0.8658

 F1-mic 0.8658,  F1-mac 0.4769
new best val f1: 0.865759699894853
ogbn-products,dgl,1,1921,488.9372,0.8658

 F1-mic 0.8658,  F1-mac 0.4770
new best val f1: 0.8657782260196261
ogbn-products,dgl,1,1922,489.1910,0.8658

 F1-mic 0.8658,  F1-mac 0.4770
new best val f1: 0.8657845520134508
ogbn-products,dgl,1,1923,489.4448,0.8658

 F1-mic 0.8658,  F1-mac 0.4770
new best val f1: 0.8657976558578026
ogbn-products,dgl,1,1924,489.6984,0.8658

 F1-mic 0.8658,  F1-mac 0.4770
ogbn-products,dgl,1,1925,489.9523,0.8658

 F1-mic 0.8658,  F1-mac 0.4769
new best val f1: 0.8658017225681185
ogbn-products,dgl,1,1926,490.2061,0.8658

 F1-mic 0.8658,  F1-mac 0.4769
new best val f1: 0.8658044337083292
ogbn-products,dgl,1,1927,490.4603,0.8658

 F1-mic 0.8658,  F1-mac 0.4770
new best val f1: 0.8658161819825755
ogbn-products,dgl,1,1928,490.7141,0.8658

 F1-mic 0.8658,  F1-mac 0.4771
new best val f1: 0.8658387748176645
ogbn-products,dgl,1,1929,490.9679,0.8658

epoch:1931/50, Iteration 32/32:training loss 0.5499500632286072
Train F1-mic 0.8693, Train F1-mac 0.4770
 F1-mic 0.8658,  F1-mac 0.4771
ogbn-products,dgl,1,1930,491.2215,0.8658

 F1-mic 0.8658,  F1-mac 0.4771
ogbn-products,dgl,1,1931,491.4728,0.8658

 F1-mic 0.8659,  F1-mac 0.4772
new best val f1: 0.8658514268053144
ogbn-products,dgl,1,1932,491.7266,0.8659

 F1-mic 0.8659,  F1-mac 0.4772
new best val f1: 0.8658532342321213
ogbn-products,dgl,1,1933,491.9802,0.8659

 F1-mic 0.8659,  F1-mac 0.4772
new best val f1: 0.8658663380764732
ogbn-products,dgl,1,1934,492.2340,0.8659

 F1-mic 0.8659,  F1-mac 0.4772
new best val f1: 0.8658780863507194
ogbn-products,dgl,1,1935,492.4875,0.8659

 F1-mic 0.8659,  F1-mac 0.4772
new best val f1: 0.8658929976218783
ogbn-products,dgl,1,1936,492.7412,0.8659

 F1-mic 0.8659,  F1-mac 0.4773
new best val f1: 0.865905649609528
ogbn-products,dgl,1,1937,492.9950,0.8659

 F1-mic 0.8659,  F1-mac 0.4772
ogbn-products,dgl,1,1938,493.2488,0.8659

 F1-mic 0.8659,  F1-mac 0.4773
ogbn-products,dgl,1,1939,493.5024,0.8659

epoch:1941/50, Iteration 32/32:training loss 0.5495018362998962
Train F1-mic 0.8694, Train F1-mac 0.4772
 F1-mic 0.8659,  F1-mac 0.4773
new best val f1: 0.8659151386002654
ogbn-products,dgl,1,1940,493.7563,0.8659

 F1-mic 0.8659,  F1-mac 0.4772
new best val f1: 0.865928242444617
ogbn-products,dgl,1,1941,494.0080,0.8659

 F1-mic 0.8659,  F1-mac 0.4773
new best val f1: 0.8659291461580206
ogbn-products,dgl,1,1942,494.2618,0.8659

 F1-mic 0.8660,  F1-mac 0.4773
new best val f1: 0.8659553538467238
ogbn-products,dgl,1,1943,494.5161,0.8660

 F1-mic 0.8659,  F1-mac 0.4773
ogbn-products,dgl,1,1944,494.7701,0.8659

 F1-mic 0.8660,  F1-mac 0.4773
ogbn-products,dgl,1,1945,495.0240,0.8660

 F1-mic 0.8660,  F1-mac 0.4773
new best val f1: 0.8659684576910756
ogbn-products,dgl,1,1946,495.2778,0.8660

 F1-mic 0.8660,  F1-mac 0.4774
new best val f1: 0.8659815615354272
ogbn-products,dgl,1,1947,495.5317,0.8660

 F1-mic 0.8660,  F1-mac 0.4775
new best val f1: 0.8659951172364806
ogbn-products,dgl,1,1948,495.7856,0.8660

 F1-mic 0.8660,  F1-mac 0.4775
new best val f1: 0.866002346943709
ogbn-products,dgl,1,1949,496.0392,0.8660

epoch:1951/50, Iteration 32/32:training loss 0.5490572452545166
Train F1-mic 0.8695, Train F1-mac 0.4775
 F1-mic 0.8660,  F1-mac 0.4775
ogbn-products,dgl,1,1950,496.2932,0.8660

 F1-mic 0.8660,  F1-mac 0.4775
new best val f1: 0.8660122877911482
ogbn-products,dgl,1,1951,496.5445,0.8660

 F1-mic 0.8660,  F1-mac 0.4776
new best val f1: 0.8660172582148679
ogbn-products,dgl,1,1952,496.7982,0.8660

 F1-mic 0.8660,  F1-mac 0.4776
new best val f1: 0.8660321694860266
ogbn-products,dgl,1,1953,497.0517,0.8660

 F1-mic 0.8660,  F1-mac 0.4776
ogbn-products,dgl,1,1954,497.3054,0.8660

 F1-mic 0.8660,  F1-mac 0.4776
new best val f1: 0.8660452733303782
ogbn-products,dgl,1,1955,497.5592,0.8660

 F1-mic 0.8661,  F1-mac 0.4776
new best val f1: 0.8660520511809049
ogbn-products,dgl,1,1956,497.8127,0.8661

 F1-mic 0.8661,  F1-mac 0.4776
new best val f1: 0.8660543104644138
ogbn-products,dgl,1,1957,498.0672,0.8661

 F1-mic 0.8661,  F1-mac 0.4776
ogbn-products,dgl,1,1958,498.3210,0.8661

 F1-mic 0.8661,  F1-mac 0.4776
new best val f1: 0.8660687698788707
ogbn-products,dgl,1,1959,498.5748,0.8661

epoch:1961/50, Iteration 32/32:training loss 0.5486175417900085
Train F1-mic 0.8695, Train F1-mac 0.4776
 F1-mic 0.8661,  F1-mac 0.4776
new best val f1: 0.8660737403025904
ogbn-products,dgl,1,1960,498.8285,0.8661

 F1-mic 0.8661,  F1-mac 0.4776
new best val f1: 0.8660886515737491
ogbn-products,dgl,1,1961,499.0800,0.8661

 F1-mic 0.8661,  F1-mac 0.4776
new best val f1: 0.8660913627139598
ogbn-products,dgl,1,1962,499.3343,0.8661

 F1-mic 0.8661,  F1-mac 0.4776
new best val f1: 0.8660963331376794
ogbn-products,dgl,1,1963,499.5880,0.8661

 F1-mic 0.8661,  F1-mac 0.4777
new best val f1: 0.8661044665583114
ogbn-products,dgl,1,1964,499.8425,0.8661

 F1-mic 0.8661,  F1-mac 0.4777
new best val f1: 0.8661071776985221
ogbn-products,dgl,1,1965,500.0964,0.8661

 F1-mic 0.8661,  F1-mac 0.4777
ogbn-products,dgl,1,1966,500.3500,0.8661

 F1-mic 0.8661,  F1-mac 0.4778
new best val f1: 0.8661284149635058
ogbn-products,dgl,1,1967,500.6036,0.8661

 F1-mic 0.8661,  F1-mac 0.4777
ogbn-products,dgl,1,1968,500.8574,0.8661

 F1-mic 0.8661,  F1-mac 0.4778
new best val f1: 0.8661460373748753
ogbn-products,dgl,1,1969,501.1113,0.8661

epoch:1971/50, Iteration 32/32:training loss 0.5481811165809631
Train F1-mic 0.8696, Train F1-mac 0.4777
 F1-mic 0.8662,  F1-mac 0.4778
new best val f1: 0.8661577856491215
ogbn-products,dgl,1,1970,501.3654,0.8662

 F1-mic 0.8662,  F1-mac 0.4778
new best val f1: 0.8661668227831572
ogbn-products,dgl,1,1971,501.6169,0.8662

 F1-mic 0.8662,  F1-mac 0.4779
ogbn-products,dgl,1,1972,501.8705,0.8662

 F1-mic 0.8662,  F1-mac 0.4779
new best val f1: 0.866173148776982
ogbn-products,dgl,1,1973,502.1240,0.8662

 F1-mic 0.8662,  F1-mac 0.4779
new best val f1: 0.8661844451945265
ogbn-products,dgl,1,1974,502.3777,0.8662

 F1-mic 0.8662,  F1-mac 0.4779
new best val f1: 0.8661889637615444
ogbn-products,dgl,1,1975,502.6316,0.8662

 F1-mic 0.8662,  F1-mac 0.4779
new best val f1: 0.8662079417430192
ogbn-products,dgl,1,1976,502.8853,0.8662

 F1-mic 0.8662,  F1-mac 0.4780
new best val f1: 0.8662151714502476
ogbn-products,dgl,1,1977,503.1389,0.8662

 F1-mic 0.8662,  F1-mac 0.4779
new best val f1: 0.8662174307337566
ogbn-products,dgl,1,1978,503.3927,0.8662

 F1-mic 0.8662,  F1-mac 0.4780
new best val f1: 0.8662291790080027
ogbn-products,dgl,1,1979,503.6462,0.8662

epoch:1981/50, Iteration 32/32:training loss 0.547748327255249
Train F1-mic 0.8697, Train F1-mac 0.4779
 F1-mic 0.8662,  F1-mac 0.4780
new best val f1: 0.8662422828523546
ogbn-products,dgl,1,1980,503.8999,0.8662

 F1-mic 0.8662,  F1-mac 0.4780
new best val f1: 0.8662490607028812
ogbn-products,dgl,1,1981,504.1512,0.8662

 F1-mic 0.8663,  F1-mac 0.4780
new best val f1: 0.8662558385534079
ogbn-products,dgl,1,1982,504.4056,0.8663

 F1-mic 0.8663,  F1-mac 0.4780
new best val f1: 0.866268038684356
ogbn-products,dgl,1,1983,504.6592,0.8663

 F1-mic 0.8663,  F1-mac 0.4780
ogbn-products,dgl,1,1984,504.9139,0.8663

 F1-mic 0.8663,  F1-mac 0.4780
new best val f1: 0.8662793351019005
ogbn-products,dgl,1,1985,505.1677,0.8663

 F1-mic 0.8663,  F1-mac 0.4780
new best val f1: 0.8662901796627434
ogbn-products,dgl,1,1986,505.4219,0.8663

 F1-mic 0.8663,  F1-mac 0.4780
ogbn-products,dgl,1,1987,505.6762,0.8663

 F1-mic 0.8663,  F1-mac 0.4782
new best val f1: 0.8662978612266735
ogbn-products,dgl,1,1988,505.9307,0.8663

 F1-mic 0.8663,  F1-mac 0.4781
new best val f1: 0.8663041872204984
ogbn-products,dgl,1,1989,506.1850,0.8663

epoch:1991/50, Iteration 32/32:training loss 0.5473201870918274
Train F1-mic 0.8698, Train F1-mac 0.4780
 F1-mic 0.8663,  F1-mac 0.4782
new best val f1: 0.8663186466349554
ogbn-products,dgl,1,1990,506.4387,0.8663

 F1-mic 0.8663,  F1-mac 0.4783
new best val f1: 0.8663263281988857
ogbn-products,dgl,1,1991,506.6902,0.8663

 F1-mic 0.8663,  F1-mac 0.4784
new best val f1: 0.8663340097628159
ogbn-products,dgl,1,1992,506.9444,0.8663

 F1-mic 0.8663,  F1-mac 0.4783
new best val f1: 0.8663376246164302
ogbn-products,dgl,1,1993,507.1979,0.8663

 F1-mic 0.8663,  F1-mac 0.4784
new best val f1: 0.8663489210339747
ogbn-products,dgl,1,1994,507.4516,0.8663

 F1-mic 0.8664,  F1-mac 0.4783
new best val f1: 0.8663529877442907
ogbn-products,dgl,1,1995,507.7052,0.8664

 F1-mic 0.8664,  F1-mac 0.4784
new best val f1: 0.866368802728853
ogbn-products,dgl,1,1996,507.9591,0.8664

 F1-mic 0.8664,  F1-mac 0.4784
new best val f1: 0.8663823584299064
ogbn-products,dgl,1,1997,508.2127,0.8664

 F1-mic 0.8664,  F1-mac 0.4784
new best val f1: 0.8663918474206438
ogbn-products,dgl,1,1998,508.4662,0.8664

 F1-mic 0.8664,  F1-mac 0.4784
new best val f1: 0.8664008845546795
ogbn-products,dgl,1,1999,508.7201,0.8664

training using time 6707.196344137192
Test F1-mic 0.8664, Test F1-mac 0.4784
Namespace(csv='full.csv', dataset='ogbn-arxiv', gpu=0, log_dir='test', lr=0.001, n_epochs=50, n_hidden=128, online=False)
Inited proc group
Max label: tensor(39)
----Data statistics------'
    #Nodes 169343
    #Edges 2484941
    #Classes/Labels (multi binary labels) 40
    #Train samples 90941
    #Val samples 29799
    #Test samples 48603
Running on: 0
GCN(
  (layers): ModuleList(
    (0): GraphConv(in=128, out=128, normalization=both, activation=<function relu at 0x1459eb8b7c20>)
    (1): GraphConv(in=128, out=40, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0.1, inplace=False)
)
Namespace(csv='full.csv', dataset='ogbn-arxiv', gpu=0, log_dir='test', lr=0.001, n_epochs=50, n_hidden=128, online=False)
epoch:1/50, Iteration 32/32:training loss 3.75253963470459
Train F1-mic 0.0086, Train F1-mac 0.0017
 F1-mic 0.0054,  F1-mac 0.0013
new best val f1: 0.005431763471390655
ogbn-arxiv,dgl,1,0,0.2352,0.0054

 F1-mic 0.0105,  F1-mac 0.0042
new best val f1: 0.01049317943336831
ogbn-arxiv,dgl,1,1,0.2516,0.0105

 F1-mic 0.0338,  F1-mac 0.0073
new best val f1: 0.03382507252638726
ogbn-arxiv,dgl,1,2,0.2678,0.0338

 F1-mic 0.0627,  F1-mac 0.0078
new best val f1: 0.06267102853733308
ogbn-arxiv,dgl,1,3,0.2839,0.0627

 F1-mic 0.0815,  F1-mac 0.0077
new best val f1: 0.08149702693249387
ogbn-arxiv,dgl,1,4,0.2999,0.0815

 F1-mic 0.1168,  F1-mac 0.0092
new best val f1: 0.11680348949653313
ogbn-arxiv,dgl,1,5,0.3160,0.1168

 F1-mic 0.1651,  F1-mac 0.0126
new best val f1: 0.1650515400283933
ogbn-arxiv,dgl,1,6,0.3321,0.1651

 F1-mic 0.1993,  F1-mac 0.0148
new best val f1: 0.1993292595107298
ogbn-arxiv,dgl,1,7,0.3482,0.1993

 F1-mic 0.2226,  F1-mac 0.0163
new best val f1: 0.22262000288048062
ogbn-arxiv,dgl,1,8,0.3642,0.2226

 F1-mic 0.2342,  F1-mac 0.0171
new best val f1: 0.234244799703722
ogbn-arxiv,dgl,1,9,0.3803,0.2342

epoch:11/50, Iteration 32/32:training loss 3.386303663253784
Train F1-mic 0.2459, Train F1-mac 0.0192
 F1-mic 0.2405,  F1-mac 0.0175
new best val f1: 0.24049955764047487
ogbn-arxiv,dgl,1,10,0.3963,0.2405

 F1-mic 0.2449,  F1-mac 0.0177
new best val f1: 0.24486142830689464
ogbn-arxiv,dgl,1,11,0.4125,0.2449

 F1-mic 0.2476,  F1-mac 0.0179
new best val f1: 0.24761845976585808
ogbn-arxiv,dgl,1,12,0.4285,0.2476

 F1-mic 0.2508,  F1-mac 0.0181
new best val f1: 0.25076641359586854
ogbn-arxiv,dgl,1,13,0.4446,0.2508

 F1-mic 0.2538,  F1-mac 0.0183
new best val f1: 0.2538320679793428
ogbn-arxiv,dgl,1,14,0.4606,0.2538

 F1-mic 0.2572,  F1-mac 0.0186
new best val f1: 0.25720634528732794
ogbn-arxiv,dgl,1,15,0.4766,0.2572

 F1-mic 0.2597,  F1-mac 0.0187
new best val f1: 0.2596753286834146
ogbn-arxiv,dgl,1,16,0.4926,0.2597

 F1-mic 0.2616,  F1-mac 0.0189
new best val f1: 0.26162994053864985
ogbn-arxiv,dgl,1,17,0.5087,0.2616

 F1-mic 0.2635,  F1-mac 0.0191
new best val f1: 0.2635022529473489
ogbn-arxiv,dgl,1,18,0.5247,0.2635

 F1-mic 0.2646,  F1-mac 0.0193
new best val f1: 0.26463387033722197
ogbn-arxiv,dgl,1,19,0.5407,0.2646

epoch:21/50, Iteration 32/32:training loss 3.090336322784424
Train F1-mic 0.2730, Train F1-mac 0.0212
 F1-mic 0.2661,  F1-mac 0.0196
new best val f1: 0.26609468551323995
ogbn-arxiv,dgl,1,20,0.5567,0.2661

 F1-mic 0.2672,  F1-mac 0.0200
new best val f1: 0.26716457831821083
ogbn-arxiv,dgl,1,21,0.5728,0.2672

 F1-mic 0.2678,  F1-mac 0.0203
new best val f1: 0.2678435487521346
ogbn-arxiv,dgl,1,22,0.5889,0.2678

 F1-mic 0.2683,  F1-mac 0.0209
new best val f1: 0.26833734543135196
ogbn-arxiv,dgl,1,23,0.6049,0.2683

 F1-mic 0.2691,  F1-mac 0.0217
new best val f1: 0.26905746558854393
ogbn-arxiv,dgl,1,24,0.6209,0.2691

 F1-mic 0.2703,  F1-mac 0.0228
new best val f1: 0.27033310700985536
ogbn-arxiv,dgl,1,25,0.6369,0.2703

 F1-mic 0.2726,  F1-mac 0.0242
new best val f1: 0.27255519206633333
ogbn-arxiv,dgl,1,26,0.6530,0.2726

 F1-mic 0.2765,  F1-mac 0.0258
new best val f1: 0.27648499063843796
ogbn-arxiv,dgl,1,27,0.6691,0.2765

 F1-mic 0.2815,  F1-mac 0.0275
new best val f1: 0.2814641071538794
ogbn-arxiv,dgl,1,28,0.6851,0.2815

 F1-mic 0.2874,  F1-mac 0.0290
new best val f1: 0.2873896673044874
ogbn-arxiv,dgl,1,29,0.7012,0.2874

epoch:31/50, Iteration 32/32:training loss 2.9455809593200684
Train F1-mic 0.2916, Train F1-mac 0.0304
 F1-mic 0.2915,  F1-mac 0.0299
new best val f1: 0.29148406476966443
ogbn-arxiv,dgl,1,30,0.7172,0.2915

 F1-mic 0.2939,  F1-mac 0.0304
new best val f1: 0.29385017385758083
ogbn-arxiv,dgl,1,31,0.7334,0.2939

 F1-mic 0.2945,  F1-mac 0.0304
new best val f1: 0.2945291442915046
ogbn-arxiv,dgl,1,32,0.7494,0.2945

 F1-mic 0.2941,  F1-mac 0.0301
ogbn-arxiv,dgl,1,33,0.7654,0.2941

 F1-mic 0.2927,  F1-mac 0.0295
ogbn-arxiv,dgl,1,34,0.7815,0.2927

 F1-mic 0.2904,  F1-mac 0.0287
ogbn-arxiv,dgl,1,35,0.7975,0.2904

 F1-mic 0.2877,  F1-mac 0.0277
ogbn-arxiv,dgl,1,36,0.8135,0.2877

 F1-mic 0.2858,  F1-mac 0.0269
ogbn-arxiv,dgl,1,37,0.8296,0.2858

 F1-mic 0.2843,  F1-mac 0.0261
ogbn-arxiv,dgl,1,38,0.8456,0.2843

 F1-mic 0.2832,  F1-mac 0.0256
ogbn-arxiv,dgl,1,39,0.8617,0.2832

epoch:41/50, Iteration 32/32:training loss 2.846414804458618
Train F1-mic 0.2930, Train F1-mac 0.0278
 F1-mic 0.2832,  F1-mac 0.0254
ogbn-arxiv,dgl,1,40,0.8777,0.2832

 F1-mic 0.2842,  F1-mac 0.0254
ogbn-arxiv,dgl,1,41,0.8939,0.2842

 F1-mic 0.2857,  F1-mac 0.0256
ogbn-arxiv,dgl,1,42,0.9099,0.2857

 F1-mic 0.2883,  F1-mac 0.0260
ogbn-arxiv,dgl,1,43,0.9260,0.2883

 F1-mic 0.2913,  F1-mac 0.0267
ogbn-arxiv,dgl,1,44,0.9419,0.2913

 F1-mic 0.2950,  F1-mac 0.0274
new best val f1: 0.29502294097072196
ogbn-arxiv,dgl,1,45,0.9579,0.2950

 F1-mic 0.2983,  F1-mac 0.0280
new best val f1: 0.2983354936938049
ogbn-arxiv,dgl,1,46,0.9740,0.2983

 F1-mic 0.3007,  F1-mac 0.0285
new best val f1: 0.30072217764335535
ogbn-arxiv,dgl,1,47,0.9900,0.3007

 F1-mic 0.3031,  F1-mac 0.0290
new best val f1: 0.3031088615929058
ogbn-arxiv,dgl,1,48,1.0060,0.3031

 F1-mic 0.3045,  F1-mac 0.0294
new best val f1: 0.30452852704565564
ogbn-arxiv,dgl,1,49,1.0221,0.3045

epoch:51/50, Iteration 32/32:training loss 2.7520620822906494
Train F1-mic 0.3091, Train F1-mac 0.0316
 F1-mic 0.3053,  F1-mac 0.0296
new best val f1: 0.3053103717877497
ogbn-arxiv,dgl,1,50,1.0381,0.3053

 F1-mic 0.3057,  F1-mac 0.0298
new best val f1: 0.30572186902043086
ogbn-arxiv,dgl,1,51,1.0542,0.3057

 F1-mic 0.3059,  F1-mac 0.0301
new best val f1: 0.30594819249840544
ogbn-arxiv,dgl,1,52,1.0703,0.3059

 F1-mic 0.3064,  F1-mac 0.0303
new best val f1: 0.30635968973108657
ogbn-arxiv,dgl,1,53,1.0864,0.3064

 F1-mic 0.3073,  F1-mac 0.0305
new best val f1: 0.3072855585046191
ogbn-arxiv,dgl,1,54,1.1024,0.3073

 F1-mic 0.3086,  F1-mac 0.0309
new best val f1: 0.30858177478756454
ogbn-arxiv,dgl,1,55,1.1185,0.3086

 F1-mic 0.3106,  F1-mac 0.0313
new best val f1: 0.3106392609509701
ogbn-arxiv,dgl,1,56,1.1345,0.3106

 F1-mic 0.3130,  F1-mac 0.0320
new best val f1: 0.31302594490052055
ogbn-arxiv,dgl,1,57,1.1506,0.3130

 F1-mic 0.3159,  F1-mac 0.0329
new best val f1: 0.31592700039092236
ogbn-arxiv,dgl,1,58,1.1666,0.3159

 F1-mic 0.3197,  F1-mac 0.0342
new best val f1: 0.3196510503466864
ogbn-arxiv,dgl,1,59,1.1827,0.3197

epoch:61/50, Iteration 32/32:training loss 2.6494123935699463
Train F1-mic 0.3196, Train F1-mac 0.0363
 F1-mic 0.3236,  F1-mac 0.0357
new best val f1: 0.323560274057157
ogbn-arxiv,dgl,1,60,1.1987,0.3236

 F1-mic 0.3275,  F1-mac 0.0369
new best val f1: 0.32749007262926155
ogbn-arxiv,dgl,1,61,1.2148,0.3275

 F1-mic 0.3305,  F1-mac 0.0388
new best val f1: 0.33049400242783367
ogbn-arxiv,dgl,1,62,1.2308,0.3305

 F1-mic 0.3334,  F1-mac 0.0405
new best val f1: 0.33337448305660144
ogbn-arxiv,dgl,1,63,1.2468,0.3334

 F1-mic 0.3353,  F1-mac 0.0421
new best val f1: 0.33526737032693454
ogbn-arxiv,dgl,1,64,1.2628,0.3353

 F1-mic 0.3371,  F1-mac 0.0440
new best val f1: 0.3370985330123655
ogbn-arxiv,dgl,1,65,1.2789,0.3371

 F1-mic 0.3388,  F1-mac 0.0458
new best val f1: 0.33880624652799207
ogbn-arxiv,dgl,1,66,1.2949,0.3388

 F1-mic 0.3406,  F1-mac 0.0477
new best val f1: 0.34059625949015493
ogbn-arxiv,dgl,1,67,1.3109,0.3406

 F1-mic 0.3424,  F1-mac 0.0494
new best val f1: 0.3424479970372199
ogbn-arxiv,dgl,1,68,1.3270,0.3424

 F1-mic 0.3443,  F1-mac 0.0514
new best val f1: 0.34432030944591896
ogbn-arxiv,dgl,1,69,1.3430,0.3443

epoch:71/50, Iteration 32/32:training loss 2.54252290725708
Train F1-mic 0.3445, Train F1-mac 0.0550
 F1-mic 0.3467,  F1-mac 0.0532
new best val f1: 0.3467069933954694
ogbn-arxiv,dgl,1,70,1.3591,0.3467

 F1-mic 0.3492,  F1-mac 0.0547
new best val f1: 0.34919655165319013
ogbn-arxiv,dgl,1,71,1.3752,0.3492

 F1-mic 0.3524,  F1-mac 0.0563
new best val f1: 0.35236508034483466
ogbn-arxiv,dgl,1,72,1.3913,0.3524

 F1-mic 0.3564,  F1-mac 0.0582
new best val f1: 0.3563977532251096
ogbn-arxiv,dgl,1,73,1.4073,0.3564

 F1-mic 0.3601,  F1-mac 0.0598
new best val f1: 0.36012180318087356
ogbn-arxiv,dgl,1,74,1.4233,0.3601

 F1-mic 0.3643,  F1-mac 0.0614
new best val f1: 0.36427792523095287
ogbn-arxiv,dgl,1,75,1.4394,0.3643

 F1-mic 0.3686,  F1-mac 0.0630
new best val f1: 0.36855749645083635
ogbn-arxiv,dgl,1,76,1.4554,0.3686

 F1-mic 0.3723,  F1-mac 0.0642
new best val f1: 0.37232269612986846
ogbn-arxiv,dgl,1,77,1.4715,0.3723

 F1-mic 0.3761,  F1-mac 0.0655
new best val f1: 0.37606732094726664
ogbn-arxiv,dgl,1,78,1.4874,0.3761

 F1-mic 0.3800,  F1-mac 0.0671
new best val f1: 0.3799971195193712
ogbn-arxiv,dgl,1,79,1.5035,0.3800

epoch:81/50, Iteration 32/32:training loss 2.4344260692596436
Train F1-mic 0.3751, Train F1-mac 0.0699
 F1-mic 0.3832,  F1-mac 0.0684
new best val f1: 0.3831656482110158
ogbn-arxiv,dgl,1,80,1.5195,0.3832

 F1-mic 0.3861,  F1-mac 0.0699
new best val f1: 0.3861284282863198
ogbn-arxiv,dgl,1,81,1.5356,0.3861

 F1-mic 0.3896,  F1-mac 0.0718
new best val f1: 0.38956443017920706
ogbn-arxiv,dgl,1,82,1.5517,0.3896

 F1-mic 0.3926,  F1-mac 0.0732
new best val f1: 0.39263008456268134
ogbn-arxiv,dgl,1,83,1.5677,0.3926

 F1-mic 0.3951,  F1-mac 0.0745
new best val f1: 0.39507849309713394
ogbn-arxiv,dgl,1,84,1.5837,0.3951

 F1-mic 0.3981,  F1-mac 0.0758
new best val f1: 0.39806184803407196
ogbn-arxiv,dgl,1,85,1.5997,0.3981

 F1-mic 0.4018,  F1-mac 0.0775
new best val f1: 0.401785897989836
ogbn-arxiv,dgl,1,86,1.6158,0.4018

 F1-mic 0.4058,  F1-mac 0.0791
new best val f1: 0.4057979960084768
ogbn-arxiv,dgl,1,87,1.6318,0.4058

 F1-mic 0.4100,  F1-mac 0.0806
new best val f1: 0.409954118058556
ogbn-arxiv,dgl,1,88,1.6478,0.4100

 F1-mic 0.4143,  F1-mac 0.0823
new best val f1: 0.4142748390017077
ogbn-arxiv,dgl,1,89,1.6639,0.4143

epoch:91/50, Iteration 32/32:training loss 2.328965902328491
Train F1-mic 0.4052, Train F1-mac 0.0830
 F1-mic 0.4190,  F1-mac 0.0839
new best val f1: 0.41902763203917454
ogbn-arxiv,dgl,1,90,1.6799,0.4190

 F1-mic 0.4236,  F1-mac 0.0856
new best val f1: 0.4235746764603008
ogbn-arxiv,dgl,1,91,1.6961,0.4236

 F1-mic 0.4277,  F1-mac 0.0868
new best val f1: 0.42766907392547787
ogbn-arxiv,dgl,1,92,1.7121,0.4277

 F1-mic 0.4315,  F1-mac 0.0881
new best val f1: 0.43153714791268033
ogbn-arxiv,dgl,1,93,1.7282,0.4315

 F1-mic 0.4355,  F1-mac 0.0897
new best val f1: 0.435508096208053
ogbn-arxiv,dgl,1,94,1.7442,0.4355

 F1-mic 0.4389,  F1-mac 0.0911
new best val f1: 0.4389029483776722
ogbn-arxiv,dgl,1,95,1.7602,0.4389

 F1-mic 0.4421,  F1-mac 0.0922
new best val f1: 0.4420714770693167
ogbn-arxiv,dgl,1,96,1.7762,0.4421

 F1-mic 0.4456,  F1-mac 0.0938
new best val f1: 0.4455897784087402
ogbn-arxiv,dgl,1,97,1.7923,0.4456

 F1-mic 0.4487,  F1-mac 0.0954
new best val f1: 0.44869658251548256
ogbn-arxiv,dgl,1,98,1.8082,0.4487

 F1-mic 0.4518,  F1-mac 0.0968
new best val f1: 0.4518445363454931
ogbn-arxiv,dgl,1,99,1.8243,0.4518

epoch:101/50, Iteration 32/32:training loss 2.2287662029266357
Train F1-mic 0.4341, Train F1-mac 0.0951
 F1-mic 0.4546,  F1-mac 0.0981
new best val f1: 0.45458099294282245
ogbn-arxiv,dgl,1,100,1.8404,0.4546

 F1-mic 0.4576,  F1-mac 0.0994
new best val f1: 0.45764664732629673
ogbn-arxiv,dgl,1,101,1.8565,0.4576

 F1-mic 0.4607,  F1-mac 0.1007
new best val f1: 0.4606711519865029
ogbn-arxiv,dgl,1,102,1.8726,0.4607

 F1-mic 0.4645,  F1-mac 0.1025
new best val f1: 0.46447750138880317
ogbn-arxiv,dgl,1,103,1.8886,0.4645

 F1-mic 0.4682,  F1-mac 0.1042
new best val f1: 0.46818097648293316
ogbn-arxiv,dgl,1,104,1.9045,0.4682

 F1-mic 0.4716,  F1-mac 0.1056
new best val f1: 0.4716375532374545
ogbn-arxiv,dgl,1,105,1.9206,0.4716

 F1-mic 0.4753,  F1-mac 0.1072
new best val f1: 0.47529987860831635
ogbn-arxiv,dgl,1,106,1.9366,0.4753

 F1-mic 0.4796,  F1-mac 0.1093
new best val f1: 0.4795588749665659
ogbn-arxiv,dgl,1,107,1.9527,0.4796

 F1-mic 0.4831,  F1-mac 0.1113
new best val f1: 0.48307717630598934
ogbn-arxiv,dgl,1,108,1.9687,0.4831

 F1-mic 0.4868,  F1-mac 0.1134
new best val f1: 0.4867600765384853
ogbn-arxiv,dgl,1,109,1.9848,0.4868

epoch:111/50, Iteration 32/32:training loss 2.135666847229004
Train F1-mic 0.4609, Train F1-mac 0.1114
 F1-mic 0.4900,  F1-mac 0.1150
new best val f1: 0.4900314795383001
ogbn-arxiv,dgl,1,110,2.0009,0.4900

 F1-mic 0.4934,  F1-mac 0.1168
new best val f1: 0.4934469065695533
ogbn-arxiv,dgl,1,111,2.0171,0.4934

 F1-mic 0.4964,  F1-mac 0.1185
new best val f1: 0.49638911178322326
ogbn-arxiv,dgl,1,112,2.0331,0.4964

 F1-mic 0.4988,  F1-mac 0.1200
new best val f1: 0.49883752031767586
ogbn-arxiv,dgl,1,113,2.0491,0.4988

 F1-mic 0.5021,  F1-mac 0.1224
new best val f1: 0.5020883484558566
ogbn-arxiv,dgl,1,114,2.0651,0.5021

 F1-mic 0.5043,  F1-mac 0.1242
new best val f1: 0.5042692837890665
ogbn-arxiv,dgl,1,115,2.0811,0.5043

 F1-mic 0.5066,  F1-mac 0.1257
new best val f1: 0.5066353928769829
ogbn-arxiv,dgl,1,116,2.0972,0.5066

 F1-mic 0.5094,  F1-mac 0.1273
new best val f1: 0.5094129991975804
ogbn-arxiv,dgl,1,117,2.1132,0.5094

 F1-mic 0.5117,  F1-mac 0.1287
new best val f1: 0.5116968088389605
ogbn-arxiv,dgl,1,118,2.1292,0.5117

 F1-mic 0.5139,  F1-mac 0.1305
new best val f1: 0.5138983190338045
ogbn-arxiv,dgl,1,119,2.1453,0.5139

epoch:121/50, Iteration 32/32:training loss 2.050560235977173
Train F1-mic 0.4858, Train F1-mac 0.1316
 F1-mic 0.5165,  F1-mac 0.1322
new best val f1: 0.5164907515996955
ogbn-arxiv,dgl,1,120,2.1613,0.5165

 F1-mic 0.5192,  F1-mac 0.1336
new best val f1: 0.5191860584737568
ogbn-arxiv,dgl,1,121,2.1775,0.5192

 F1-mic 0.5221,  F1-mac 0.1355
new best val f1: 0.5220665391025245
ogbn-arxiv,dgl,1,122,2.1936,0.5221

 F1-mic 0.5251,  F1-mac 0.1374
new best val f1: 0.5250910437627307
ogbn-arxiv,dgl,1,123,2.2096,0.5251

 F1-mic 0.5276,  F1-mac 0.1391
new best val f1: 0.5276423266053536
ogbn-arxiv,dgl,1,124,2.2256,0.5276

 F1-mic 0.5303,  F1-mac 0.1409
new best val f1: 0.5302964837561467
ogbn-arxiv,dgl,1,125,2.2416,0.5303

 F1-mic 0.5327,  F1-mac 0.1427
new best val f1: 0.5327037425673312
ogbn-arxiv,dgl,1,126,2.2577,0.5327

 F1-mic 0.5350,  F1-mac 0.1441
new best val f1: 0.5349669773470773
ogbn-arxiv,dgl,1,127,2.2738,0.5350

 F1-mic 0.5378,  F1-mac 0.1459
new best val f1: 0.5377651585293088
ogbn-arxiv,dgl,1,128,2.2898,0.5378

 F1-mic 0.5400,  F1-mac 0.1474
new best val f1: 0.540048968170689
ogbn-arxiv,dgl,1,129,2.3061,0.5400

epoch:131/50, Iteration 32/32:training loss 1.9733060598373413
Train F1-mic 0.5096, Train F1-mac 0.1512
 F1-mic 0.5427,  F1-mac 0.1494
new best val f1: 0.5427237001831162
ogbn-arxiv,dgl,1,130,2.3221,0.5427

 F1-mic 0.5449,  F1-mac 0.1508
new best val f1: 0.544863485793058
ogbn-arxiv,dgl,1,131,2.3382,0.5449

 F1-mic 0.5473,  F1-mac 0.1524
new best val f1: 0.5472913194658766
ogbn-arxiv,dgl,1,132,2.3543,0.5473

 F1-mic 0.5492,  F1-mac 0.1535
new best val f1: 0.5492047815978438
ogbn-arxiv,dgl,1,133,2.3703,0.5492

 F1-mic 0.5512,  F1-mac 0.1551
new best val f1: 0.5512005431763471
ogbn-arxiv,dgl,1,134,2.3863,0.5512

 F1-mic 0.5532,  F1-mac 0.1568
new best val f1: 0.5531757298932165
ogbn-arxiv,dgl,1,135,2.4023,0.5532

 F1-mic 0.5551,  F1-mac 0.1581
new best val f1: 0.5550891920251836
ogbn-arxiv,dgl,1,136,2.4183,0.5551

 F1-mic 0.5570,  F1-mac 0.1595
new best val f1: 0.5570026541571508
ogbn-arxiv,dgl,1,137,2.4344,0.5570

 F1-mic 0.5589,  F1-mac 0.1607
new best val f1: 0.5588543917042158
ogbn-arxiv,dgl,1,138,2.4504,0.5589

 F1-mic 0.5605,  F1-mac 0.1616
new best val f1: 0.5604798057733061
ogbn-arxiv,dgl,1,139,2.4665,0.5605

epoch:141/50, Iteration 32/32:training loss 1.9032320976257324
Train F1-mic 0.5283, Train F1-mac 0.1660
 F1-mic 0.5619,  F1-mac 0.1626
new best val f1: 0.5618583215027879
ogbn-arxiv,dgl,1,140,2.4825,0.5619

 F1-mic 0.5635,  F1-mac 0.1635
new best val f1: 0.5634837355718783
ogbn-arxiv,dgl,1,141,2.4986,0.5635

 F1-mic 0.5653,  F1-mac 0.1649
new best val f1: 0.5653148982573092
ogbn-arxiv,dgl,1,142,2.5147,0.5653

 F1-mic 0.5664,  F1-mac 0.1657
new best val f1: 0.5663847910622801
ogbn-arxiv,dgl,1,143,2.5307,0.5664

 F1-mic 0.5684,  F1-mac 0.1668
new best val f1: 0.5683599777791495
ogbn-arxiv,dgl,1,144,2.5467,0.5684

 F1-mic 0.5698,  F1-mac 0.1677
new best val f1: 0.5698207929551674
ogbn-arxiv,dgl,1,145,2.5627,0.5698

 F1-mic 0.5713,  F1-mac 0.1686
new best val f1: 0.5712816081311853
ogbn-arxiv,dgl,1,146,2.5788,0.5713

 F1-mic 0.5726,  F1-mac 0.1696
new best val f1: 0.572639548999033
ogbn-arxiv,dgl,1,147,2.5949,0.5726

 F1-mic 0.5741,  F1-mac 0.1705
new best val f1: 0.5741209390366849
ogbn-arxiv,dgl,1,148,2.6109,0.5741

 F1-mic 0.5751,  F1-mac 0.1712
new best val f1: 0.5750879575334856
ogbn-arxiv,dgl,1,149,2.6269,0.5751

epoch:151/50, Iteration 32/32:training loss 1.839528203010559
Train F1-mic 0.5421, Train F1-mac 0.1760
 F1-mic 0.5766,  F1-mac 0.1722
new best val f1: 0.5766104972944057
ogbn-arxiv,dgl,1,150,2.6429,0.5766

 F1-mic 0.5778,  F1-mac 0.1729
new best val f1: 0.5778449889924491
ogbn-arxiv,dgl,1,151,2.6591,0.5778

 F1-mic 0.5791,  F1-mac 0.1737
new best val f1: 0.5791000555521264
ogbn-arxiv,dgl,1,152,2.6752,0.5791

 F1-mic 0.5800,  F1-mac 0.1743
new best val f1: 0.5800259243256589
ogbn-arxiv,dgl,1,153,2.6912,0.5800

 F1-mic 0.5812,  F1-mac 0.1752
new best val f1: 0.5812192663004341
ogbn-arxiv,dgl,1,154,2.7074,0.5812

 F1-mic 0.5827,  F1-mac 0.1760
new best val f1: 0.5826800814764521
ogbn-arxiv,dgl,1,155,2.7235,0.5827

 F1-mic 0.5840,  F1-mac 0.1770
new best val f1: 0.5839968726210316
ogbn-arxiv,dgl,1,156,2.7395,0.5840

 F1-mic 0.5852,  F1-mac 0.1779
new best val f1: 0.585231364319075
ogbn-arxiv,dgl,1,157,2.7556,0.5852

 F1-mic 0.5861,  F1-mac 0.1784
new best val f1: 0.5861160833693393
ogbn-arxiv,dgl,1,158,2.7716,0.5861

 F1-mic 0.5869,  F1-mac 0.1788
new best val f1: 0.5868979281114335
ogbn-arxiv,dgl,1,159,2.7876,0.5869

epoch:161/50, Iteration 32/32:training loss 1.7811846733093262
Train F1-mic 0.5536, Train F1-mac 0.1847
 F1-mic 0.5878,  F1-mac 0.1793
new best val f1: 0.5878443717466
ogbn-arxiv,dgl,1,160,2.8036,0.5878

 F1-mic 0.5888,  F1-mac 0.1803
new best val f1: 0.5887702405201325
ogbn-arxiv,dgl,1,161,2.8198,0.5888

 F1-mic 0.5900,  F1-mac 0.1814
new best val f1: 0.5900047322181758
ogbn-arxiv,dgl,1,162,2.8358,0.5900

 F1-mic 0.5907,  F1-mac 0.1822
new best val f1: 0.5907454272370019
ogbn-arxiv,dgl,1,163,2.8518,0.5907

 F1-mic 0.5914,  F1-mac 0.1829
new best val f1: 0.5914038228092916
ogbn-arxiv,dgl,1,164,2.8679,0.5914

 F1-mic 0.5927,  F1-mac 0.1841
new best val f1: 0.592679464230603
ogbn-arxiv,dgl,1,165,2.8839,0.5927

 F1-mic 0.5936,  F1-mac 0.1849
new best val f1: 0.5936259078657696
ogbn-arxiv,dgl,1,166,2.8999,0.5936

 F1-mic 0.5944,  F1-mac 0.1857
new best val f1: 0.5944489023311318
ogbn-arxiv,dgl,1,167,2.9160,0.5944

 F1-mic 0.5958,  F1-mac 0.1868
new best val f1: 0.5958068431989795
ogbn-arxiv,dgl,1,168,2.9321,0.5958

 F1-mic 0.5967,  F1-mac 0.1877
new best val f1: 0.5967121371108779
ogbn-arxiv,dgl,1,169,2.9482,0.5967

epoch:171/50, Iteration 32/32:training loss 1.7276902198791504
Train F1-mic 0.5635, Train F1-mac 0.1929
 F1-mic 0.5975,  F1-mac 0.1881
new best val f1: 0.5975145567146061
ogbn-arxiv,dgl,1,170,2.9642,0.5975

 F1-mic 0.5984,  F1-mac 0.1891
new best val f1: 0.5983787009032364
ogbn-arxiv,dgl,1,171,2.9803,0.5984

 F1-mic 0.5992,  F1-mac 0.1901
new best val f1: 0.5992222702302327
ogbn-arxiv,dgl,1,172,2.9964,0.5992

 F1-mic 0.6001,  F1-mac 0.1907
new best val f1: 0.600065839557229
ogbn-arxiv,dgl,1,173,3.0125,0.6001

 F1-mic 0.6009,  F1-mac 0.1919
new best val f1: 0.6009299837458593
ogbn-arxiv,dgl,1,174,3.0284,0.6009

 F1-mic 0.6017,  F1-mac 0.1932
new best val f1: 0.6016912536263194
ogbn-arxiv,dgl,1,175,3.0445,0.6017

 F1-mic 0.6024,  F1-mac 0.1943
new best val f1: 0.6024319486451454
ogbn-arxiv,dgl,1,176,3.0605,0.6024

 F1-mic 0.6032,  F1-mac 0.1949
new best val f1: 0.6032137933872395
ogbn-arxiv,dgl,1,177,3.0766,0.6032

 F1-mic 0.6038,  F1-mac 0.1957
new best val f1: 0.6038310392362611
ogbn-arxiv,dgl,1,178,3.0926,0.6038

 F1-mic 0.6046,  F1-mac 0.1968
new best val f1: 0.6046334588399893
ogbn-arxiv,dgl,1,179,3.1087,0.6046

epoch:181/50, Iteration 32/32:training loss 1.6786463260650635
Train F1-mic 0.5720, Train F1-mac 0.2031
 F1-mic 0.6055,  F1-mac 0.1983
new best val f1: 0.6054770281669856
ogbn-arxiv,dgl,1,180,3.1247,0.6055

 F1-mic 0.6063,  F1-mac 0.1990
new best val f1: 0.6063000226323478
ogbn-arxiv,dgl,1,181,3.1413,0.6063

 F1-mic 0.6067,  F1-mac 0.2000
new best val f1: 0.6066909450033948
ogbn-arxiv,dgl,1,182,3.1574,0.6067

 F1-mic 0.6073,  F1-mac 0.2015
new best val f1: 0.6073493405756847
ogbn-arxiv,dgl,1,183,3.1734,0.6073

 F1-mic 0.6081,  F1-mac 0.2023
new best val f1: 0.6080900355945106
ogbn-arxiv,dgl,1,184,3.1894,0.6081

 F1-mic 0.6087,  F1-mac 0.2034
new best val f1: 0.6086661317202642
ogbn-arxiv,dgl,1,185,3.2054,0.6087

 F1-mic 0.6094,  F1-mac 0.2044
new best val f1: 0.6093656770158221
ogbn-arxiv,dgl,1,186,3.2215,0.6094

 F1-mic 0.6098,  F1-mac 0.2049
new best val f1: 0.6098388988334054
ogbn-arxiv,dgl,1,187,3.2376,0.6098

 F1-mic 0.6105,  F1-mac 0.2061
new best val f1: 0.610476719544061
ogbn-arxiv,dgl,1,188,3.2536,0.6105

 F1-mic 0.6112,  F1-mac 0.2071
new best val f1: 0.6111556899779849
ogbn-arxiv,dgl,1,189,3.2697,0.6112

epoch:191/50, Iteration 32/32:training loss 1.6336603164672852
Train F1-mic 0.5804, Train F1-mac 0.2156
 F1-mic 0.6119,  F1-mac 0.2084
new best val f1: 0.6118758101351769
ogbn-arxiv,dgl,1,190,3.2857,0.6119

 F1-mic 0.6125,  F1-mac 0.2093
new best val f1: 0.6124519062609304
ogbn-arxiv,dgl,1,191,3.3019,0.6125

 F1-mic 0.6132,  F1-mac 0.2104
new best val f1: 0.6132337510030245
ogbn-arxiv,dgl,1,192,3.3180,0.6132

 F1-mic 0.6137,  F1-mac 0.2109
new best val f1: 0.6136863979589737
ogbn-arxiv,dgl,1,193,3.3340,0.6137

 F1-mic 0.6143,  F1-mac 0.2118
new best val f1: 0.6143447935312635
ogbn-arxiv,dgl,1,194,3.3500,0.6143

 F1-mic 0.6153,  F1-mac 0.2133
new best val f1: 0.6152912371664301
ogbn-arxiv,dgl,1,195,3.3660,0.6153

 F1-mic 0.6160,  F1-mac 0.2140
new best val f1: 0.6159702076003539
ogbn-arxiv,dgl,1,196,3.3820,0.6160

 F1-mic 0.6165,  F1-mac 0.2153
new best val f1: 0.6165257288644734
ogbn-arxiv,dgl,1,197,3.3981,0.6165

 F1-mic 0.6169,  F1-mac 0.2162
new best val f1: 0.6168549266506183
ogbn-arxiv,dgl,1,198,3.4141,0.6169

 F1-mic 0.6175,  F1-mac 0.2179
new best val f1: 0.6175338970845421
ogbn-arxiv,dgl,1,199,3.4303,0.6175

epoch:201/50, Iteration 32/32:training loss 1.592331051826477
Train F1-mic 0.5883, Train F1-mac 0.2294
 F1-mic 0.6181,  F1-mac 0.2190
new best val f1: 0.6181305680719297
ogbn-arxiv,dgl,1,200,3.4463,0.6181

 F1-mic 0.6188,  F1-mac 0.2205
new best val f1: 0.6188095385058535
ogbn-arxiv,dgl,1,201,3.4625,0.6188

 F1-mic 0.6195,  F1-mac 0.2222
new best val f1: 0.6195090838014115
ogbn-arxiv,dgl,1,202,3.4785,0.6195

 F1-mic 0.6201,  F1-mac 0.2234
new best val f1: 0.6201469045120671
ogbn-arxiv,dgl,1,203,3.4946,0.6201

 F1-mic 0.6210,  F1-mac 0.2250
new best val f1: 0.6210316235623315
ogbn-arxiv,dgl,1,204,3.5106,0.6210

 F1-mic 0.6215,  F1-mac 0.2267
new best val f1: 0.6215254202415489
ogbn-arxiv,dgl,1,205,3.5266,0.6215

 F1-mic 0.6220,  F1-mac 0.2272
new best val f1: 0.6219986420591321
ogbn-arxiv,dgl,1,206,3.5426,0.6220

 F1-mic 0.6223,  F1-mac 0.2281
new best val f1: 0.622348414706911
ogbn-arxiv,dgl,1,207,3.5586,0.6223

 F1-mic 0.6226,  F1-mac 0.2291
new best val f1: 0.6226158879081538
ogbn-arxiv,dgl,1,208,3.5746,0.6226

 F1-mic 0.6231,  F1-mac 0.2301
new best val f1: 0.6230891097257371
ogbn-arxiv,dgl,1,209,3.5907,0.6231

epoch:211/50, Iteration 32/32:training loss 1.554296612739563
Train F1-mic 0.5962, Train F1-mac 0.2439
 F1-mic 0.6238,  F1-mac 0.2316
new best val f1: 0.623788655021295
ogbn-arxiv,dgl,1,210,3.6067,0.6238

 F1-mic 0.6244,  F1-mac 0.2321
new best val f1: 0.6243853260086826
ogbn-arxiv,dgl,1,211,3.6229,0.6244

 F1-mic 0.6248,  F1-mac 0.2332
new best val f1: 0.6247968232413637
ogbn-arxiv,dgl,1,212,3.6389,0.6248

 F1-mic 0.6255,  F1-mac 0.2348
new best val f1: 0.6254757936752875
ogbn-arxiv,dgl,1,213,3.6549,0.6255

 F1-mic 0.6258,  F1-mac 0.2357
new best val f1: 0.6257844165997983
ogbn-arxiv,dgl,1,214,3.6709,0.6258

 F1-mic 0.6262,  F1-mac 0.2365
new best val f1: 0.6261547641092113
ogbn-arxiv,dgl,1,215,3.6870,0.6262

 F1-mic 0.6268,  F1-mac 0.2378
new best val f1: 0.6268131596815011
ogbn-arxiv,dgl,1,216,3.7030,0.6268

 F1-mic 0.6277,  F1-mac 0.2399
new best val f1: 0.6276773038701314
ogbn-arxiv,dgl,1,217,3.7191,0.6277

 F1-mic 0.6284,  F1-mac 0.2409
new best val f1: 0.6283974240273235
ogbn-arxiv,dgl,1,218,3.7352,0.6284

 F1-mic 0.6289,  F1-mac 0.2419
new best val f1: 0.6288500709832726
ogbn-arxiv,dgl,1,219,3.7513,0.6289

epoch:221/50, Iteration 32/32:training loss 1.518520712852478
Train F1-mic 0.6039, Train F1-mac 0.2566
 F1-mic 0.6291,  F1-mac 0.2432
new best val f1: 0.6291175441845154
ogbn-arxiv,dgl,1,220,3.7673,0.6291

 F1-mic 0.6293,  F1-mac 0.2436
new best val f1: 0.62934386766249
ogbn-arxiv,dgl,1,221,3.7834,0.6293

 F1-mic 0.6296,  F1-mac 0.2444
new best val f1: 0.6296319157253667
ogbn-arxiv,dgl,1,222,3.7996,0.6296

 F1-mic 0.6301,  F1-mac 0.2458
new best val f1: 0.6300639878196819
ogbn-arxiv,dgl,1,223,3.8156,0.6301

 F1-mic 0.6305,  F1-mac 0.2466
new best val f1: 0.6305372096372652
ogbn-arxiv,dgl,1,224,3.8316,0.6305

 F1-mic 0.6311,  F1-mac 0.2472
new best val f1: 0.6310515811781165
ogbn-arxiv,dgl,1,225,3.8476,0.6311

 F1-mic 0.6315,  F1-mac 0.2477
new best val f1: 0.6315042281340658
ogbn-arxiv,dgl,1,226,3.8637,0.6315

 F1-mic 0.6321,  F1-mac 0.2490
new best val f1: 0.6321420488447215
ogbn-arxiv,dgl,1,227,3.8798,0.6321

 F1-mic 0.6325,  F1-mac 0.2496
new best val f1: 0.6324712466308664
ogbn-arxiv,dgl,1,228,3.8958,0.6325

 F1-mic 0.6328,  F1-mac 0.2502
new best val f1: 0.6328004444170113
ogbn-arxiv,dgl,1,229,3.9118,0.6328

epoch:231/50, Iteration 32/32:training loss 1.4855402708053589
Train F1-mic 0.6097, Train F1-mac 0.2663
 F1-mic 0.6330,  F1-mac 0.2507
new best val f1: 0.6329650433100837
ogbn-arxiv,dgl,1,230,3.9279,0.6330

 F1-mic 0.6333,  F1-mac 0.2515
new best val f1: 0.6333353908194967
ogbn-arxiv,dgl,1,231,3.9441,0.6333

 F1-mic 0.6336,  F1-mac 0.2521
new best val f1: 0.6336234388823735
ogbn-arxiv,dgl,1,232,3.9602,0.6336

 F1-mic 0.6339,  F1-mac 0.2523
new best val f1: 0.6338909120836163
ogbn-arxiv,dgl,1,233,3.9762,0.6339

 F1-mic 0.6344,  F1-mac 0.2530
new best val f1: 0.6343847087628336
ogbn-arxiv,dgl,1,234,3.9923,0.6344

 F1-mic 0.6350,  F1-mac 0.2534
new best val f1: 0.6349608048885871
ogbn-arxiv,dgl,1,235,4.0084,0.6350

 F1-mic 0.6354,  F1-mac 0.2541
new best val f1: 0.6353928769829023
ogbn-arxiv,dgl,1,236,4.0244,0.6354

 F1-mic 0.6359,  F1-mac 0.2546
new best val f1: 0.6359072485237537
ogbn-arxiv,dgl,1,237,4.0405,0.6359

 F1-mic 0.6361,  F1-mac 0.2550
new best val f1: 0.6360512725551921
ogbn-arxiv,dgl,1,238,4.0566,0.6361

 F1-mic 0.6365,  F1-mac 0.2559
new best val f1: 0.6364833446495072
ogbn-arxiv,dgl,1,239,4.0726,0.6365

epoch:241/50, Iteration 32/32:training loss 1.45487642288208
Train F1-mic 0.6146, Train F1-mac 0.2734
 F1-mic 0.6369,  F1-mac 0.2568
new best val f1: 0.6369154167438223
ogbn-arxiv,dgl,1,240,4.0887,0.6369

 F1-mic 0.6373,  F1-mac 0.2576
new best val f1: 0.6373269139765035
ogbn-arxiv,dgl,1,241,4.1048,0.6373

 F1-mic 0.6376,  F1-mac 0.2585
new best val f1: 0.6376149620393803
ogbn-arxiv,dgl,1,242,4.1209,0.6376

 F1-mic 0.6378,  F1-mac 0.2589
new best val f1: 0.6377795609324527
ogbn-arxiv,dgl,1,243,4.1370,0.6378

 F1-mic 0.6382,  F1-mac 0.2592
new best val f1: 0.6381910581651339
ogbn-arxiv,dgl,1,244,4.1530,0.6382

 F1-mic 0.6387,  F1-mac 0.2599
new best val f1: 0.6386642799827171
ogbn-arxiv,dgl,1,245,4.1691,0.6387

 F1-mic 0.6389,  F1-mac 0.2605
new best val f1: 0.6389317531839598
ogbn-arxiv,dgl,1,246,4.1851,0.6389

 F1-mic 0.6390,  F1-mac 0.2609
new best val f1: 0.639014052630496
ogbn-arxiv,dgl,1,247,4.2012,0.6390

 F1-mic 0.6394,  F1-mac 0.2618
new best val f1: 0.6394255498631771
ogbn-arxiv,dgl,1,248,4.2172,0.6394

 F1-mic 0.6398,  F1-mac 0.2629
new best val f1: 0.6398164722342242
ogbn-arxiv,dgl,1,249,4.2334,0.6398

epoch:251/50, Iteration 32/32:training loss 1.4265090227127075
Train F1-mic 0.6189, Train F1-mac 0.2804
 F1-mic 0.6402,  F1-mac 0.2637
new best val f1: 0.6402279694669053
ogbn-arxiv,dgl,1,250,4.2494,0.6402

 F1-mic 0.6407,  F1-mac 0.2644
new best val f1: 0.6406806164228546
ogbn-arxiv,dgl,1,251,4.2655,0.6407

 F1-mic 0.6408,  F1-mac 0.2648
new best val f1: 0.6407834907310248
ogbn-arxiv,dgl,1,252,4.2816,0.6408

 F1-mic 0.6411,  F1-mac 0.2657
new best val f1: 0.6410921136555356
ogbn-arxiv,dgl,1,253,4.2977,0.6411

 F1-mic 0.6415,  F1-mac 0.2667
new best val f1: 0.6414624611649486
ogbn-arxiv,dgl,1,254,4.3137,0.6415

 F1-mic 0.6420,  F1-mac 0.2672
new best val f1: 0.641956257844166
ogbn-arxiv,dgl,1,255,4.3298,0.6420

 F1-mic 0.6425,  F1-mac 0.2680
new best val f1: 0.6424706293850174
ogbn-arxiv,dgl,1,256,4.3458,0.6425

 F1-mic 0.6428,  F1-mac 0.2686
new best val f1: 0.6428409768944304
ogbn-arxiv,dgl,1,257,4.3619,0.6428

 F1-mic 0.6431,  F1-mac 0.2692
new best val f1: 0.6431084500956731
ogbn-arxiv,dgl,1,258,4.3780,0.6431

 F1-mic 0.6434,  F1-mac 0.2696
new best val f1: 0.6434170730201839
ogbn-arxiv,dgl,1,259,4.3941,0.6434

epoch:261/50, Iteration 32/32:training loss 1.4003205299377441
Train F1-mic 0.6233, Train F1-mac 0.2873
 F1-mic 0.6438,  F1-mac 0.2701
new best val f1: 0.643807995391231
ogbn-arxiv,dgl,1,260,4.4101,0.6438

 F1-mic 0.6438,  F1-mac 0.2701
ogbn-arxiv,dgl,1,261,4.4263,0.6438

 F1-mic 0.6442,  F1-mac 0.2708
new best val f1: 0.6442194926239121
ogbn-arxiv,dgl,1,262,4.4424,0.6442

 F1-mic 0.6444,  F1-mac 0.2710
new best val f1: 0.6444252412402527
ogbn-arxiv,dgl,1,263,4.4584,0.6444

 F1-mic 0.6448,  F1-mac 0.2718
new best val f1: 0.6448161636112997
ogbn-arxiv,dgl,1,264,4.4745,0.6448

 F1-mic 0.6450,  F1-mac 0.2721
new best val f1: 0.6450219122276403
ogbn-arxiv,dgl,1,265,4.4905,0.6450

 F1-mic 0.6454,  F1-mac 0.2726
new best val f1: 0.6453716848754192
ogbn-arxiv,dgl,1,266,4.5066,0.6454

 F1-mic 0.6458,  F1-mac 0.2733
new best val f1: 0.6458037569697344
ogbn-arxiv,dgl,1,267,4.5226,0.6458

 F1-mic 0.6462,  F1-mac 0.2741
new best val f1: 0.6461946793407815
ogbn-arxiv,dgl,1,268,4.5386,0.6462

 F1-mic 0.6464,  F1-mac 0.2748
new best val f1: 0.6464415776803901
ogbn-arxiv,dgl,1,269,4.5547,0.6464

epoch:271/50, Iteration 32/32:training loss 1.3761476278305054
Train F1-mic 0.6271, Train F1-mac 0.2940
 F1-mic 0.6466,  F1-mac 0.2754
new best val f1: 0.6465856017118284
ogbn-arxiv,dgl,1,270,4.5707,0.6466

 F1-mic 0.6469,  F1-mac 0.2758
new best val f1: 0.6469147994979734
ogbn-arxiv,dgl,1,271,4.5868,0.6469

 F1-mic 0.6471,  F1-mac 0.2762
new best val f1: 0.647120548114314
ogbn-arxiv,dgl,1,272,4.6029,0.6471

 F1-mic 0.6473,  F1-mac 0.2767
new best val f1: 0.6473468715922885
ogbn-arxiv,dgl,1,273,4.6189,0.6473

 F1-mic 0.6478,  F1-mac 0.2778
new best val f1: 0.6477995185482378
ogbn-arxiv,dgl,1,274,4.6349,0.6478

 F1-mic 0.6479,  F1-mac 0.2782
new best val f1: 0.6479435425796761
ogbn-arxiv,dgl,1,275,4.6510,0.6479

 F1-mic 0.6482,  F1-mac 0.2787
new best val f1: 0.6481904409192848
ogbn-arxiv,dgl,1,276,4.6670,0.6482

 F1-mic 0.6486,  F1-mac 0.2792
new best val f1: 0.6486225130136
ogbn-arxiv,dgl,1,277,4.6831,0.6486

 F1-mic 0.6489,  F1-mac 0.2797
new best val f1: 0.6488694113532086
ogbn-arxiv,dgl,1,278,4.6992,0.6489

 F1-mic 0.6491,  F1-mac 0.2803
new best val f1: 0.6491368845544514
ogbn-arxiv,dgl,1,279,4.7152,0.6491

epoch:281/50, Iteration 32/32:training loss 1.353773832321167
Train F1-mic 0.6304, Train F1-mac 0.3001
 F1-mic 0.6494,  F1-mac 0.2809
new best val f1: 0.6493837828940601
ogbn-arxiv,dgl,1,280,4.7313,0.6494

 F1-mic 0.6498,  F1-mac 0.2818
new best val f1: 0.6498158549883752
ogbn-arxiv,dgl,1,281,4.7475,0.6498

 F1-mic 0.6500,  F1-mac 0.2821
new best val f1: 0.6499598790198136
ogbn-arxiv,dgl,1,282,4.7636,0.6500

 F1-mic 0.6499,  F1-mac 0.2823
ogbn-arxiv,dgl,1,283,4.7796,0.6499

 F1-mic 0.6500,  F1-mac 0.2824
new best val f1: 0.6499804538814477
ogbn-arxiv,dgl,1,284,4.7956,0.6500

 F1-mic 0.6502,  F1-mac 0.2828
new best val f1: 0.6502273522210563
ogbn-arxiv,dgl,1,285,4.8117,0.6502

 F1-mic 0.6504,  F1-mac 0.2832
new best val f1: 0.6503919511141287
ogbn-arxiv,dgl,1,286,4.8278,0.6504

 F1-mic 0.6506,  F1-mac 0.2836
new best val f1: 0.6505565500072013
ogbn-arxiv,dgl,1,287,4.8438,0.6506

 F1-mic 0.6509,  F1-mac 0.2844
new best val f1: 0.6509063226549802
ogbn-arxiv,dgl,1,288,4.8598,0.6509

 F1-mic 0.6512,  F1-mac 0.2847
new best val f1: 0.6511737958562228
ogbn-arxiv,dgl,1,289,4.8759,0.6512

epoch:291/50, Iteration 32/32:training loss 1.3327429294586182
Train F1-mic 0.6337, Train F1-mac 0.3062
 F1-mic 0.6513,  F1-mac 0.2852
new best val f1: 0.6513383947492953
ogbn-arxiv,dgl,1,290,4.8919,0.6513

 F1-mic 0.6515,  F1-mac 0.2859
new best val f1: 0.6515441433656358
ogbn-arxiv,dgl,1,291,4.9080,0.6515

 F1-mic 0.6519,  F1-mac 0.2867
new best val f1: 0.6519350657366829
ogbn-arxiv,dgl,1,292,4.9242,0.6519

 F1-mic 0.6522,  F1-mac 0.2874
new best val f1: 0.6522436886611938
ogbn-arxiv,dgl,1,293,4.9402,0.6522

 F1-mic 0.6525,  F1-mac 0.2884
new best val f1: 0.6524700121391683
ogbn-arxiv,dgl,1,294,4.9562,0.6525

 F1-mic 0.6527,  F1-mac 0.2887
new best val f1: 0.652696335617143
ogbn-arxiv,dgl,1,295,4.9723,0.6527

 F1-mic 0.6529,  F1-mac 0.2894
new best val f1: 0.6528815093718495
ogbn-arxiv,dgl,1,296,4.9884,0.6529

 F1-mic 0.6531,  F1-mac 0.2896
new best val f1: 0.65308725798819
ogbn-arxiv,dgl,1,297,5.0045,0.6531

 F1-mic 0.6533,  F1-mac 0.2898
new best val f1: 0.6532724317428965
ogbn-arxiv,dgl,1,298,5.0205,0.6533

 F1-mic 0.6535,  F1-mac 0.2905
new best val f1: 0.6534987552208711
ogbn-arxiv,dgl,1,299,5.0366,0.6535

epoch:301/50, Iteration 32/32:training loss 1.3131705522537231
Train F1-mic 0.6364, Train F1-mac 0.3119
 F1-mic 0.6537,  F1-mac 0.2910
new best val f1: 0.6537456535604798
ogbn-arxiv,dgl,1,300,5.0528,0.6537

 F1-mic 0.6538,  F1-mac 0.2912
new best val f1: 0.6538073781453819
ogbn-arxiv,dgl,1,301,5.0689,0.6538

 F1-mic 0.6541,  F1-mac 0.2920
new best val f1: 0.6540748513466247
ogbn-arxiv,dgl,1,302,5.0850,0.6541

 F1-mic 0.6543,  F1-mac 0.2936
new best val f1: 0.6542600251013312
ogbn-arxiv,dgl,1,303,5.1010,0.6543

 F1-mic 0.6546,  F1-mac 0.2943
new best val f1: 0.6545892228874761
ogbn-arxiv,dgl,1,304,5.1170,0.6546

 F1-mic 0.6548,  F1-mac 0.2948
new best val f1: 0.6548361212270848
ogbn-arxiv,dgl,1,305,5.1331,0.6548

 F1-mic 0.6552,  F1-mac 0.2955
new best val f1: 0.6551653190132296
ogbn-arxiv,dgl,1,306,5.1492,0.6552

 F1-mic 0.6554,  F1-mac 0.2959
new best val f1: 0.6553916424912043
ogbn-arxiv,dgl,1,307,5.1653,0.6554

 F1-mic 0.6554,  F1-mac 0.2965
new best val f1: 0.6554122173528383
ogbn-arxiv,dgl,1,308,5.1813,0.6554

 F1-mic 0.6555,  F1-mac 0.2966
new best val f1: 0.6554945167993745
ogbn-arxiv,dgl,1,309,5.1974,0.6555

epoch:311/50, Iteration 32/32:training loss 1.2950881719589233
Train F1-mic 0.6390, Train F1-mac 0.3182
 F1-mic 0.6557,  F1-mac 0.2974
new best val f1: 0.6557002654157151
ogbn-arxiv,dgl,1,310,5.2135,0.6557

 F1-mic 0.6561,  F1-mac 0.2978
new best val f1: 0.6560911877867621
ogbn-arxiv,dgl,1,311,5.2296,0.6561

 F1-mic 0.6564,  F1-mac 0.2981
new best val f1: 0.656399810711273
ogbn-arxiv,dgl,1,312,5.2457,0.6564

 F1-mic 0.6569,  F1-mac 0.2989
new best val f1: 0.6569141822521244
ogbn-arxiv,dgl,1,313,5.2618,0.6569

 F1-mic 0.6571,  F1-mac 0.3002
new best val f1: 0.657140505730099
ogbn-arxiv,dgl,1,314,5.2778,0.6571

 F1-mic 0.6573,  F1-mac 0.3008
new best val f1: 0.6573462543464396
ogbn-arxiv,dgl,1,315,5.2939,0.6573

 F1-mic 0.6575,  F1-mac 0.3014
new best val f1: 0.657510853239512
ogbn-arxiv,dgl,1,316,5.3099,0.6575

 F1-mic 0.6577,  F1-mac 0.3020
new best val f1: 0.6576960269942185
ogbn-arxiv,dgl,1,317,5.3260,0.6577

 F1-mic 0.6580,  F1-mac 0.3031
new best val f1: 0.6580252247803634
ogbn-arxiv,dgl,1,318,5.3420,0.6580

 F1-mic 0.6581,  F1-mac 0.3037
new best val f1: 0.6580869493652656
ogbn-arxiv,dgl,1,319,5.3581,0.6581

epoch:321/50, Iteration 32/32:training loss 1.2781509160995483
Train F1-mic 0.6416, Train F1-mac 0.3237
 F1-mic 0.6583,  F1-mac 0.3041
new best val f1: 0.658251548258338
ogbn-arxiv,dgl,1,320,5.3742,0.6583

 F1-mic 0.6583,  F1-mac 0.3041
new best val f1: 0.658272123119972
ogbn-arxiv,dgl,1,321,5.3903,0.6583

 F1-mic 0.6585,  F1-mac 0.3046
new best val f1: 0.6585395963212147
ogbn-arxiv,dgl,1,322,5.4065,0.6585

 F1-mic 0.6588,  F1-mac 0.3057
new best val f1: 0.6587864946608234
ogbn-arxiv,dgl,1,323,5.4225,0.6588

 F1-mic 0.6590,  F1-mac 0.3061
new best val f1: 0.659012818138798
ogbn-arxiv,dgl,1,324,5.4385,0.6590

 F1-mic 0.6591,  F1-mac 0.3066
new best val f1: 0.6591156924469683
ogbn-arxiv,dgl,1,325,5.4546,0.6591

 F1-mic 0.6591,  F1-mac 0.3069
new best val f1: 0.6591362673086023
ogbn-arxiv,dgl,1,326,5.4707,0.6591

 F1-mic 0.6593,  F1-mac 0.3076
new best val f1: 0.6593420159249429
ogbn-arxiv,dgl,1,327,5.4868,0.6593

 F1-mic 0.6595,  F1-mac 0.3082
new best val f1: 0.6595477645412835
ogbn-arxiv,dgl,1,328,5.5028,0.6595

 F1-mic 0.6597,  F1-mac 0.3089
new best val f1: 0.6597123634343559
ogbn-arxiv,dgl,1,329,5.5189,0.6597

epoch:331/50, Iteration 32/32:training loss 1.2621567249298096
Train F1-mic 0.6442, Train F1-mac 0.3303
 F1-mic 0.6599,  F1-mac 0.3099
new best val f1: 0.6598769623274283
ogbn-arxiv,dgl,1,330,5.5349,0.6599

 F1-mic 0.6602,  F1-mac 0.3109
new best val f1: 0.6602267349752073
ogbn-arxiv,dgl,1,331,5.5511,0.6602

 F1-mic 0.6606,  F1-mac 0.3116
new best val f1: 0.6605559327613522
ogbn-arxiv,dgl,1,332,5.5672,0.6606

 F1-mic 0.6606,  F1-mac 0.3126
new best val f1: 0.6605970824846203
ogbn-arxiv,dgl,1,333,5.5832,0.6606

 F1-mic 0.6607,  F1-mac 0.3130
new best val f1: 0.6607411065160587
ogbn-arxiv,dgl,1,334,5.5993,0.6607

 F1-mic 0.6611,  F1-mac 0.3146
new best val f1: 0.6610703043022036
ogbn-arxiv,dgl,1,335,5.6153,0.6611

 F1-mic 0.6612,  F1-mac 0.3148
new best val f1: 0.6612143283336419
ogbn-arxiv,dgl,1,336,5.6314,0.6612

 F1-mic 0.6613,  F1-mac 0.3153
new best val f1: 0.6613172026418123
ogbn-arxiv,dgl,1,337,5.6475,0.6613

 F1-mic 0.6615,  F1-mac 0.3158
new best val f1: 0.6614612266732506
ogbn-arxiv,dgl,1,338,5.6636,0.6615

 F1-mic 0.6617,  F1-mac 0.3173
new best val f1: 0.6617492747361274
ogbn-arxiv,dgl,1,339,5.6796,0.6617

epoch:341/50, Iteration 32/32:training loss 1.2472094297409058
Train F1-mic 0.6468, Train F1-mac 0.3385
 F1-mic 0.6621,  F1-mac 0.3186
new best val f1: 0.6620578976606383
ogbn-arxiv,dgl,1,340,5.6957,0.6621

 F1-mic 0.6623,  F1-mac 0.3195
new best val f1: 0.6622636462769788
ogbn-arxiv,dgl,1,341,5.7118,0.6623

 F1-mic 0.6625,  F1-mac 0.3201
new best val f1: 0.6624693948933194
ogbn-arxiv,dgl,1,342,5.7279,0.6625

 F1-mic 0.6628,  F1-mac 0.3206
new best val f1: 0.6628191675410983
ogbn-arxiv,dgl,1,343,5.7440,0.6628

 F1-mic 0.6629,  F1-mac 0.3211
new best val f1: 0.6629220418492686
ogbn-arxiv,dgl,1,344,5.7600,0.6629

 F1-mic 0.6632,  F1-mac 0.3217
new best val f1: 0.6631895150505113
ogbn-arxiv,dgl,1,345,5.7761,0.6632

 F1-mic 0.6634,  F1-mac 0.3225
new best val f1: 0.6633746888052178
ogbn-arxiv,dgl,1,346,5.7922,0.6634

 F1-mic 0.6636,  F1-mac 0.3229
new best val f1: 0.6635598625599243
ogbn-arxiv,dgl,1,347,5.8083,0.6636

 F1-mic 0.6638,  F1-mac 0.3236
new best val f1: 0.663827335761167
ogbn-arxiv,dgl,1,348,5.8243,0.6638

 F1-mic 0.6640,  F1-mac 0.3242
new best val f1: 0.6640330843775075
ogbn-arxiv,dgl,1,349,5.8404,0.6640

epoch:351/50, Iteration 32/32:training loss 1.2332779169082642
Train F1-mic 0.6494, Train F1-mac 0.3466
 F1-mic 0.6643,  F1-mac 0.3256
new best val f1: 0.6642799827171162
ogbn-arxiv,dgl,1,350,5.8565,0.6643

 F1-mic 0.6646,  F1-mac 0.3259
new best val f1: 0.6646091805032611
ogbn-arxiv,dgl,1,351,5.8726,0.6646

 F1-mic 0.6647,  F1-mac 0.3260
new best val f1: 0.6646914799497974
ogbn-arxiv,dgl,1,352,5.8887,0.6647

 F1-mic 0.6649,  F1-mac 0.3272
new best val f1: 0.6648972285661379
ogbn-arxiv,dgl,1,353,5.9048,0.6649

 F1-mic 0.6651,  F1-mac 0.3276
new best val f1: 0.6650824023208444
ogbn-arxiv,dgl,1,354,5.9208,0.6651

 F1-mic 0.6654,  F1-mac 0.3284
new best val f1: 0.6653704503837212
ogbn-arxiv,dgl,1,355,5.9368,0.6654

 F1-mic 0.6656,  F1-mac 0.3292
new best val f1: 0.6655761990000617
ogbn-arxiv,dgl,1,356,5.9529,0.6656

 F1-mic 0.6659,  F1-mac 0.3311
new best val f1: 0.6659259716478406
ogbn-arxiv,dgl,1,357,5.9690,0.6659

 F1-mic 0.6660,  F1-mac 0.3313
new best val f1: 0.666049420817645
ogbn-arxiv,dgl,1,358,5.9850,0.6660

 F1-mic 0.6662,  F1-mac 0.3318
new best val f1: 0.6662345945723515
ogbn-arxiv,dgl,1,359,6.0011,0.6662

epoch:361/50, Iteration 32/32:training loss 1.2203201055526733
Train F1-mic 0.6518, Train F1-mac 0.3545
 F1-mic 0.6665,  F1-mac 0.3332
new best val f1: 0.6665020677735942
ogbn-arxiv,dgl,1,360,6.0171,0.6665

 F1-mic 0.6667,  F1-mac 0.3346
new best val f1: 0.6667489661132029
ogbn-arxiv,dgl,1,361,6.0333,0.6667

 F1-mic 0.6669,  F1-mac 0.3350
new best val f1: 0.6669135650062753
ogbn-arxiv,dgl,1,362,6.0494,0.6669

 F1-mic 0.6671,  F1-mac 0.3356
new best val f1: 0.6670575890377137
ogbn-arxiv,dgl,1,363,6.0655,0.6671

 F1-mic 0.6672,  F1-mac 0.3379
new best val f1: 0.6672427627924202
ogbn-arxiv,dgl,1,364,6.0815,0.6672

 F1-mic 0.6674,  F1-mac 0.3385
new best val f1: 0.6674279365471267
ogbn-arxiv,dgl,1,365,6.0976,0.6674

 F1-mic 0.6677,  F1-mac 0.3392
new best val f1: 0.6677365594716376
ogbn-arxiv,dgl,1,366,6.1136,0.6677

 F1-mic 0.6680,  F1-mac 0.3402
new best val f1: 0.6679834578112462
ogbn-arxiv,dgl,1,367,6.1297,0.6680

 F1-mic 0.6680,  F1-mac 0.3405
new best val f1: 0.6680246075345143
ogbn-arxiv,dgl,1,368,6.1457,0.6680

 F1-mic 0.6683,  F1-mac 0.3412
new best val f1: 0.6683126555973911
ogbn-arxiv,dgl,1,369,6.1618,0.6683

epoch:371/50, Iteration 32/32:training loss 1.2082703113555908
Train F1-mic 0.6541, Train F1-mac 0.3626
 F1-mic 0.6686,  F1-mac 0.3417
new best val f1: 0.6685801287986338
ogbn-arxiv,dgl,1,370,6.1778,0.6686

 F1-mic 0.6687,  F1-mac 0.3426
new best val f1: 0.6687447276917062
ogbn-arxiv,dgl,1,371,6.1940,0.6687

 F1-mic 0.6688,  F1-mac 0.3431
new best val f1: 0.6687653025533403
ogbn-arxiv,dgl,1,372,6.2101,0.6688

 F1-mic 0.6689,  F1-mac 0.3437
new best val f1: 0.6689299014464127
ogbn-arxiv,dgl,1,373,6.2261,0.6689

 F1-mic 0.6692,  F1-mac 0.3443
new best val f1: 0.6691767997860214
ogbn-arxiv,dgl,1,374,6.2421,0.6692

 F1-mic 0.6695,  F1-mac 0.3452
new best val f1: 0.6694854227105322
ogbn-arxiv,dgl,1,375,6.2582,0.6695

 F1-mic 0.6695,  F1-mac 0.3455
new best val f1: 0.6695265724338004
ogbn-arxiv,dgl,1,376,6.2743,0.6695

 F1-mic 0.6698,  F1-mac 0.3464
new best val f1: 0.669752895911775
ogbn-arxiv,dgl,1,377,6.2904,0.6698

 F1-mic 0.6699,  F1-mac 0.3472
new best val f1: 0.6699380696664815
ogbn-arxiv,dgl,1,378,6.3065,0.6699

 F1-mic 0.6703,  F1-mac 0.3486
new best val f1: 0.6702672674526264
ogbn-arxiv,dgl,1,379,6.3226,0.6703

epoch:381/50, Iteration 32/32:training loss 1.1970880031585693
Train F1-mic 0.6561, Train F1-mac 0.3697
 F1-mic 0.6704,  F1-mac 0.3497
new best val f1: 0.6703907166224307
ogbn-arxiv,dgl,1,380,6.3386,0.6704

 F1-mic 0.6704,  F1-mac 0.3501
new best val f1: 0.6704112914840648
ogbn-arxiv,dgl,1,381,6.3547,0.6704

 F1-mic 0.6707,  F1-mac 0.3507
new best val f1: 0.6707404892702097
ogbn-arxiv,dgl,1,382,6.3709,0.6707

 F1-mic 0.6710,  F1-mac 0.3509
new best val f1: 0.6709873876098184
ogbn-arxiv,dgl,1,383,6.3869,0.6710

 F1-mic 0.6712,  F1-mac 0.3517
new best val f1: 0.6711519865028908
ogbn-arxiv,dgl,1,384,6.4029,0.6712

 F1-mic 0.6715,  F1-mac 0.3527
new best val f1: 0.6714606094274016
ogbn-arxiv,dgl,1,385,6.4190,0.6715

 F1-mic 0.6715,  F1-mac 0.3533
ogbn-arxiv,dgl,1,386,6.4350,0.6715

 F1-mic 0.6717,  F1-mac 0.3539
new best val f1: 0.6716663580437422
ogbn-arxiv,dgl,1,387,6.4511,0.6717

 F1-mic 0.6718,  F1-mac 0.3545
new best val f1: 0.6718309569368146
ogbn-arxiv,dgl,1,388,6.4672,0.6718

 F1-mic 0.6722,  F1-mac 0.3553
new best val f1: 0.6722218793078617
ogbn-arxiv,dgl,1,389,6.4832,0.6722

epoch:391/50, Iteration 32/32:training loss 1.1867135763168335
Train F1-mic 0.6581, Train F1-mac 0.3766
 F1-mic 0.6724,  F1-mac 0.3558
new best val f1: 0.6723659033393
ogbn-arxiv,dgl,1,390,6.4993,0.6724

 F1-mic 0.6725,  F1-mac 0.3563
new best val f1: 0.6725305022323725
ogbn-arxiv,dgl,1,391,6.5158,0.6725

 F1-mic 0.6728,  F1-mac 0.3569
new best val f1: 0.6727774005719811
ogbn-arxiv,dgl,1,392,6.5319,0.6728

 F1-mic 0.6730,  F1-mac 0.3576
new best val f1: 0.6729625743266876
ogbn-arxiv,dgl,1,393,6.5479,0.6730

 F1-mic 0.6732,  F1-mac 0.3578
new best val f1: 0.6731683229430282
ogbn-arxiv,dgl,1,394,6.5639,0.6732

 F1-mic 0.6733,  F1-mac 0.3583
new best val f1: 0.6733329218361006
ogbn-arxiv,dgl,1,395,6.5800,0.6733

 F1-mic 0.6736,  F1-mac 0.3602
new best val f1: 0.6736415447606114
ogbn-arxiv,dgl,1,396,6.5960,0.6736

 F1-mic 0.6740,  F1-mac 0.3622
new best val f1: 0.6739707425467564
ogbn-arxiv,dgl,1,397,6.6121,0.6740

 F1-mic 0.6741,  F1-mac 0.3626
new best val f1: 0.6740530419932926
ogbn-arxiv,dgl,1,398,6.6281,0.6741

 F1-mic 0.6742,  F1-mac 0.3635
new best val f1: 0.674217640886365
ogbn-arxiv,dgl,1,399,6.6442,0.6742

epoch:401/50, Iteration 32/32:training loss 1.1770834922790527
Train F1-mic 0.6603, Train F1-mac 0.3837
 F1-mic 0.6743,  F1-mac 0.3639
new best val f1: 0.6742999403329013
ogbn-arxiv,dgl,1,400,6.6602,0.6743

 F1-mic 0.6745,  F1-mac 0.3646
new best val f1: 0.67454683867251
ogbn-arxiv,dgl,1,401,6.6763,0.6745

 F1-mic 0.6747,  F1-mac 0.3651
new best val f1: 0.6746908627039483
ogbn-arxiv,dgl,1,402,6.6924,0.6747

 F1-mic 0.6748,  F1-mac 0.3663
new best val f1: 0.6748348867353867
ogbn-arxiv,dgl,1,403,6.7085,0.6748

 F1-mic 0.6749,  F1-mac 0.3669
new best val f1: 0.674917186181923
ogbn-arxiv,dgl,1,404,6.7245,0.6749

 F1-mic 0.6751,  F1-mac 0.3669
new best val f1: 0.6750612102133613
ogbn-arxiv,dgl,1,405,6.7405,0.6751

 F1-mic 0.6752,  F1-mac 0.3672
new best val f1: 0.6751846593831656
ogbn-arxiv,dgl,1,406,6.7565,0.6752

 F1-mic 0.6755,  F1-mac 0.3678
new best val f1: 0.6755138571693106
ogbn-arxiv,dgl,1,407,6.7726,0.6755

 F1-mic 0.6755,  F1-mac 0.3681
new best val f1: 0.6755344320309445
ogbn-arxiv,dgl,1,408,6.7886,0.6755

 F1-mic 0.6756,  F1-mac 0.3685
new best val f1: 0.6756167314774808
ogbn-arxiv,dgl,1,409,6.8047,0.6756

epoch:411/50, Iteration 32/32:training loss 1.1681493520736694
Train F1-mic 0.6621, Train F1-mac 0.3899
 F1-mic 0.6757,  F1-mac 0.3689
new best val f1: 0.6757401806472851
ogbn-arxiv,dgl,1,410,6.8207,0.6757

 F1-mic 0.6759,  F1-mac 0.3695
new best val f1: 0.6759047795403575
ogbn-arxiv,dgl,1,411,6.8369,0.6759

 F1-mic 0.6760,  F1-mac 0.3697
new best val f1: 0.6759665041252597
ogbn-arxiv,dgl,1,412,6.8530,0.6760

 F1-mic 0.6763,  F1-mac 0.3709
new best val f1: 0.6762751270497706
ogbn-arxiv,dgl,1,413,6.8690,0.6763

 F1-mic 0.6765,  F1-mac 0.3712
new best val f1: 0.6765014505277452
ogbn-arxiv,dgl,1,414,6.8850,0.6765

 F1-mic 0.6764,  F1-mac 0.3712
ogbn-arxiv,dgl,1,415,6.9011,0.6764

 F1-mic 0.6766,  F1-mac 0.3715
new best val f1: 0.6766248996975496
ogbn-arxiv,dgl,1,416,6.9171,0.6766

 F1-mic 0.6768,  F1-mac 0.3724
new best val f1: 0.6768100734522561
ogbn-arxiv,dgl,1,417,6.9332,0.6768

 F1-mic 0.6768,  F1-mac 0.3725
new best val f1: 0.6768306483138901
ogbn-arxiv,dgl,1,418,6.9492,0.6768

 F1-mic 0.6770,  F1-mac 0.3734
new best val f1: 0.6770363969302307
ogbn-arxiv,dgl,1,419,6.9653,0.6770

epoch:421/50, Iteration 32/32:training loss 1.1598498821258545
Train F1-mic 0.6638, Train F1-mac 0.3959
 F1-mic 0.6772,  F1-mac 0.3737
new best val f1: 0.6771804209616691
ogbn-arxiv,dgl,1,420,6.9814,0.6772

 F1-mic 0.6774,  F1-mac 0.3750
new best val f1: 0.6774478941629117
ogbn-arxiv,dgl,1,421,6.9975,0.6774

 F1-mic 0.6775,  F1-mac 0.3756
new best val f1: 0.6774890438861799
ogbn-arxiv,dgl,1,422,7.0136,0.6775

 F1-mic 0.6776,  F1-mac 0.3774
new best val f1: 0.6775713433327161
ogbn-arxiv,dgl,1,423,7.0296,0.6776

 F1-mic 0.6778,  F1-mac 0.3781
new best val f1: 0.6778182416723247
ogbn-arxiv,dgl,1,424,7.0456,0.6778

 F1-mic 0.6781,  F1-mac 0.3785
new best val f1: 0.6780857148735675
ogbn-arxiv,dgl,1,425,7.0616,0.6781

 F1-mic 0.6782,  F1-mac 0.3787
new best val f1: 0.6782091640433718
ogbn-arxiv,dgl,1,426,7.0777,0.6782

 F1-mic 0.6784,  F1-mac 0.3789
new best val f1: 0.6783943377980783
ogbn-arxiv,dgl,1,427,7.0937,0.6784

 F1-mic 0.6787,  F1-mac 0.3798
new best val f1: 0.6786823858609551
ogbn-arxiv,dgl,1,428,7.1097,0.6787

 F1-mic 0.6788,  F1-mac 0.3803
new best val f1: 0.6788058350307594
ogbn-arxiv,dgl,1,429,7.1258,0.6788

epoch:431/50, Iteration 32/32:training loss 1.1521270275115967
Train F1-mic 0.6655, Train F1-mac 0.4020
 F1-mic 0.6789,  F1-mac 0.3807
new best val f1: 0.6788881344772957
ogbn-arxiv,dgl,1,430,7.1419,0.6789

 F1-mic 0.6791,  F1-mac 0.3812
new best val f1: 0.6791144579552703
ogbn-arxiv,dgl,1,431,7.1581,0.6791

 F1-mic 0.6792,  F1-mac 0.3819
new best val f1: 0.6791556076785383
ogbn-arxiv,dgl,1,432,7.1742,0.6792

 F1-mic 0.6793,  F1-mac 0.3828
new best val f1: 0.6793407814332448
ogbn-arxiv,dgl,1,433,7.1902,0.6793

 F1-mic 0.6794,  F1-mac 0.3833
new best val f1: 0.679402506018147
ogbn-arxiv,dgl,1,434,7.2062,0.6794

 F1-mic 0.6796,  F1-mac 0.3843
new best val f1: 0.6796288294961217
ogbn-arxiv,dgl,1,435,7.2223,0.6796

 F1-mic 0.6799,  F1-mac 0.3848
new best val f1: 0.6798551529740963
ogbn-arxiv,dgl,1,436,7.2384,0.6799

 F1-mic 0.6799,  F1-mac 0.3857
new best val f1: 0.6799374524206325
ogbn-arxiv,dgl,1,437,7.2544,0.6799

 F1-mic 0.6801,  F1-mac 0.3859
new best val f1: 0.6800609015904368
ogbn-arxiv,dgl,1,438,7.2704,0.6801

 F1-mic 0.6802,  F1-mac 0.3861
new best val f1: 0.6801637758986071
ogbn-arxiv,dgl,1,439,7.2865,0.6802

epoch:441/50, Iteration 32/32:training loss 1.1449434757232666
Train F1-mic 0.6671, Train F1-mac 0.4073
 F1-mic 0.6804,  F1-mac 0.3867
new best val f1: 0.6804106742382158
ogbn-arxiv,dgl,1,440,7.3026,0.6804

 F1-mic 0.6805,  F1-mac 0.3867
new best val f1: 0.6804518239614838
ogbn-arxiv,dgl,1,441,7.3188,0.6805

 F1-mic 0.6806,  F1-mac 0.3869
new best val f1: 0.6806369977161904
ogbn-arxiv,dgl,1,442,7.3349,0.6806

 F1-mic 0.6808,  F1-mac 0.3871
new best val f1: 0.6808015966092628
ogbn-arxiv,dgl,1,443,7.3509,0.6808

 F1-mic 0.6809,  F1-mac 0.3873
new best val f1: 0.680883896055799
ogbn-arxiv,dgl,1,444,7.3669,0.6809

 F1-mic 0.6811,  F1-mac 0.3880
new best val f1: 0.6811102195337736
ogbn-arxiv,dgl,1,445,7.3830,0.6811

 F1-mic 0.6814,  F1-mac 0.3888
new best val f1: 0.6813982675966505
ogbn-arxiv,dgl,1,446,7.3990,0.6814

 F1-mic 0.6815,  F1-mac 0.3890
new best val f1: 0.6815217167664548
ogbn-arxiv,dgl,1,447,7.4151,0.6815

 F1-mic 0.6816,  F1-mac 0.3893
new best val f1: 0.6815628664897229
ogbn-arxiv,dgl,1,448,7.4312,0.6816

 F1-mic 0.6815,  F1-mac 0.3897
ogbn-arxiv,dgl,1,449,7.4473,0.6815

epoch:451/50, Iteration 32/32:training loss 1.1382379531860352
Train F1-mic 0.6686, Train F1-mac 0.4120
 F1-mic 0.6817,  F1-mac 0.3904
new best val f1: 0.6817274653827953
ogbn-arxiv,dgl,1,450,7.4633,0.6817

 F1-mic 0.6821,  F1-mac 0.3921
new best val f1: 0.6820772380305743
ogbn-arxiv,dgl,1,451,7.4795,0.6821

 F1-mic 0.6821,  F1-mac 0.3931
new best val f1: 0.6821389626154765
ogbn-arxiv,dgl,1,452,7.4956,0.6821

 F1-mic 0.6823,  F1-mac 0.3936
new best val f1: 0.6822829866469148
ogbn-arxiv,dgl,1,453,7.5116,0.6823

 F1-mic 0.6824,  F1-mac 0.3941
new best val f1: 0.682365286093451
ogbn-arxiv,dgl,1,454,7.5276,0.6824

 F1-mic 0.6826,  F1-mac 0.3955
new best val f1: 0.6825710347097915
ogbn-arxiv,dgl,1,455,7.5436,0.6826

 F1-mic 0.6827,  F1-mac 0.3959
new best val f1: 0.68271505874123
ogbn-arxiv,dgl,1,456,7.5597,0.6827

 F1-mic 0.6830,  F1-mac 0.3962
new best val f1: 0.6829825319424727
ogbn-arxiv,dgl,1,457,7.5758,0.6830

 F1-mic 0.6831,  F1-mac 0.3965
new best val f1: 0.683105981112277
ogbn-arxiv,dgl,1,458,7.5918,0.6831

 F1-mic 0.6835,  F1-mac 0.3975
new best val f1: 0.683455753760056
ogbn-arxiv,dgl,1,459,7.6079,0.6835

epoch:461/50, Iteration 32/32:training loss 1.1319712400436401
Train F1-mic 0.6703, Train F1-mac 0.4177
 F1-mic 0.6836,  F1-mac 0.3980
new best val f1: 0.6835586280682262
ogbn-arxiv,dgl,1,460,7.6240,0.6836

 F1-mic 0.6836,  F1-mac 0.3982
new best val f1: 0.6835792029298603
ogbn-arxiv,dgl,1,461,7.6401,0.6836

 F1-mic 0.6837,  F1-mac 0.3991
new best val f1: 0.6837232269612987
ogbn-arxiv,dgl,1,462,7.6562,0.6837

 F1-mic 0.6837,  F1-mac 0.3993
new best val f1: 0.6837438018229327
ogbn-arxiv,dgl,1,463,7.6723,0.6837

 F1-mic 0.6839,  F1-mac 0.3994
new best val f1: 0.6838878258543711
ogbn-arxiv,dgl,1,464,7.6883,0.6839

 F1-mic 0.6840,  F1-mac 0.3998
new best val f1: 0.6840318498858096
ogbn-arxiv,dgl,1,465,7.7043,0.6840

 F1-mic 0.6841,  F1-mac 0.4001
new best val f1: 0.6841347241939798
ogbn-arxiv,dgl,1,466,7.7204,0.6841

 F1-mic 0.6842,  F1-mac 0.4004
new best val f1: 0.684196448778882
ogbn-arxiv,dgl,1,467,7.7365,0.6842

 F1-mic 0.6843,  F1-mac 0.4006
new best val f1: 0.6843198979486863
ogbn-arxiv,dgl,1,468,7.7525,0.6843

 F1-mic 0.6844,  F1-mac 0.4009
new best val f1: 0.6844021973952226
ogbn-arxiv,dgl,1,469,7.7686,0.6844

epoch:471/50, Iteration 32/32:training loss 1.1261026859283447
Train F1-mic 0.6715, Train F1-mac 0.4222
 F1-mic 0.6844,  F1-mac 0.4012
ogbn-arxiv,dgl,1,470,7.7847,0.6844

 F1-mic 0.6844,  F1-mac 0.4013
ogbn-arxiv,dgl,1,471,7.8012,0.6844

 F1-mic 0.6844,  F1-mac 0.4021
new best val f1: 0.6844433471184906
ogbn-arxiv,dgl,1,472,7.8173,0.6844

 F1-mic 0.6846,  F1-mac 0.4029
new best val f1: 0.684566796288295
ogbn-arxiv,dgl,1,473,7.8333,0.6846

 F1-mic 0.6848,  F1-mac 0.4040
new best val f1: 0.6847519700430015
ogbn-arxiv,dgl,1,474,7.8494,0.6848

 F1-mic 0.6848,  F1-mac 0.4044
new best val f1: 0.6848342694895376
ogbn-arxiv,dgl,1,475,7.8654,0.6848

 F1-mic 0.6850,  F1-mac 0.4052
new best val f1: 0.6849782935209761
ogbn-arxiv,dgl,1,476,7.8815,0.6850

 F1-mic 0.6852,  F1-mac 0.4056
new best val f1: 0.6852046169989506
ogbn-arxiv,dgl,1,477,7.8976,0.6852

 F1-mic 0.6853,  F1-mac 0.4059
new best val f1: 0.685328066168755
ogbn-arxiv,dgl,1,478,7.9136,0.6853

 F1-mic 0.6854,  F1-mac 0.4064
new best val f1: 0.6853897907536571
ogbn-arxiv,dgl,1,479,7.9297,0.6854

epoch:481/50, Iteration 32/32:training loss 1.1205992698669434
Train F1-mic 0.6729, Train F1-mac 0.4267
 F1-mic 0.6856,  F1-mac 0.4068
new best val f1: 0.6855749645083636
ogbn-arxiv,dgl,1,480,7.9458,0.6856

 F1-mic 0.6856,  F1-mac 0.4072
new best val f1: 0.6856161142316318
ogbn-arxiv,dgl,1,481,7.9619,0.6856

 F1-mic 0.6856,  F1-mac 0.4072
new best val f1: 0.6856366890932658
ogbn-arxiv,dgl,1,482,7.9780,0.6856

 F1-mic 0.6858,  F1-mac 0.4086
new best val f1: 0.6858218628479723
ogbn-arxiv,dgl,1,483,7.9941,0.6858

 F1-mic 0.6860,  F1-mac 0.4090
new best val f1: 0.6860276114643129
ogbn-arxiv,dgl,1,484,8.0101,0.6860

 F1-mic 0.6862,  F1-mac 0.4097
new best val f1: 0.6861716354957513
ogbn-arxiv,dgl,1,485,8.0262,0.6862

 F1-mic 0.6863,  F1-mac 0.4103
new best val f1: 0.6863362343888237
ogbn-arxiv,dgl,1,486,8.0422,0.6863

 F1-mic 0.6865,  F1-mac 0.4110
new best val f1: 0.6864802584202622
ogbn-arxiv,dgl,1,487,8.0584,0.6865

 F1-mic 0.6866,  F1-mac 0.4115
new best val f1: 0.6866242824517005
ogbn-arxiv,dgl,1,488,8.0744,0.6866

 F1-mic 0.6866,  F1-mac 0.4117
ogbn-arxiv,dgl,1,489,8.0905,0.6866

epoch:491/50, Iteration 32/32:training loss 1.115416169166565
Train F1-mic 0.6742, Train F1-mac 0.4310
 F1-mic 0.6867,  F1-mac 0.4119
new best val f1: 0.6866654321749687
ogbn-arxiv,dgl,1,490,8.1065,0.6867

 F1-mic 0.6868,  F1-mac 0.4125
new best val f1: 0.6867683064831389
ogbn-arxiv,dgl,1,491,8.1226,0.6868

 F1-mic 0.6870,  F1-mac 0.4131
new best val f1: 0.6870152048227476
ogbn-arxiv,dgl,1,492,8.1388,0.6870

 F1-mic 0.6871,  F1-mac 0.4137
new best val f1: 0.6870769294076498
ogbn-arxiv,dgl,1,493,8.1548,0.6871

 F1-mic 0.6873,  F1-mac 0.4140
new best val f1: 0.6872621031623563
ogbn-arxiv,dgl,1,494,8.1708,0.6873

 F1-mic 0.6873,  F1-mac 0.4141
new best val f1: 0.6873032528856243
ogbn-arxiv,dgl,1,495,8.1869,0.6873

 F1-mic 0.6873,  F1-mac 0.4147
ogbn-arxiv,dgl,1,496,8.2029,0.6873

 F1-mic 0.6874,  F1-mac 0.4149
new best val f1: 0.6874267020554287
ogbn-arxiv,dgl,1,497,8.2191,0.6874

 F1-mic 0.6877,  F1-mac 0.4153
new best val f1: 0.6876941752566714
ogbn-arxiv,dgl,1,498,8.2351,0.6877

 F1-mic 0.6877,  F1-mac 0.4154
ogbn-arxiv,dgl,1,499,8.2511,0.6877

epoch:501/50, Iteration 32/32:training loss 1.1105294227600098
Train F1-mic 0.6755, Train F1-mac 0.4345
 F1-mic 0.6878,  F1-mac 0.4153
new best val f1: 0.6877970495648417
ogbn-arxiv,dgl,1,500,8.2672,0.6878

 F1-mic 0.6878,  F1-mac 0.4157
ogbn-arxiv,dgl,1,501,8.2834,0.6878

 F1-mic 0.6879,  F1-mac 0.4161
new best val f1: 0.6878587741497438
ogbn-arxiv,dgl,1,502,8.2995,0.6879

 F1-mic 0.6880,  F1-mac 0.4164
new best val f1: 0.6880027981811823
ogbn-arxiv,dgl,1,503,8.3155,0.6880

 F1-mic 0.6881,  F1-mac 0.4171
new best val f1: 0.6881262473509866
ogbn-arxiv,dgl,1,504,8.3315,0.6881

 F1-mic 0.6882,  F1-mac 0.4180
new best val f1: 0.6882085467975227
ogbn-arxiv,dgl,1,505,8.3476,0.6882

 F1-mic 0.6883,  F1-mac 0.4183
new best val f1: 0.6882702713824249
ogbn-arxiv,dgl,1,506,8.3637,0.6883

 F1-mic 0.6884,  F1-mac 0.4183
new best val f1: 0.6883937205522292
ogbn-arxiv,dgl,1,507,8.3798,0.6884

 F1-mic 0.6886,  F1-mac 0.4191
new best val f1: 0.6885583194453018
ogbn-arxiv,dgl,1,508,8.3958,0.6886

 F1-mic 0.6888,  F1-mac 0.4194
new best val f1: 0.6888052177849104
ogbn-arxiv,dgl,1,509,8.4118,0.6888

epoch:511/50, Iteration 32/32:training loss 1.1059070825576782
Train F1-mic 0.6767, Train F1-mac 0.4385
 F1-mic 0.6889,  F1-mac 0.4194
new best val f1: 0.6888669423698126
ogbn-arxiv,dgl,1,510,8.4279,0.6889

 F1-mic 0.6889,  F1-mac 0.4204
new best val f1: 0.6889080920930807
ogbn-arxiv,dgl,1,511,8.4440,0.6889

 F1-mic 0.6890,  F1-mac 0.4204
new best val f1: 0.6890109664012509
ogbn-arxiv,dgl,1,512,8.4601,0.6890

 F1-mic 0.6891,  F1-mac 0.4205
new best val f1: 0.6890932658477872
ogbn-arxiv,dgl,1,513,8.4761,0.6891

 F1-mic 0.6891,  F1-mac 0.4205
ogbn-arxiv,dgl,1,514,8.4921,0.6891

 F1-mic 0.6893,  F1-mac 0.4210
new best val f1: 0.6892578647408596
ogbn-arxiv,dgl,1,515,8.5081,0.6893

 F1-mic 0.6893,  F1-mac 0.4212
new best val f1: 0.6892990144641278
ogbn-arxiv,dgl,1,516,8.5243,0.6893

 F1-mic 0.6896,  F1-mac 0.4221
new best val f1: 0.6895870625270045
ogbn-arxiv,dgl,1,517,8.5403,0.6896

 F1-mic 0.6897,  F1-mac 0.4231
new best val f1: 0.6897310865584428
ogbn-arxiv,dgl,1,518,8.5563,0.6897

 F1-mic 0.6898,  F1-mac 0.4232
new best val f1: 0.6898339608666132
ogbn-arxiv,dgl,1,519,8.5724,0.6898

epoch:521/50, Iteration 32/32:training loss 1.1015211343765259
Train F1-mic 0.6778, Train F1-mac 0.4419
 F1-mic 0.6899,  F1-mac 0.4236
new best val f1: 0.6898956854515154
ogbn-arxiv,dgl,1,520,8.5884,0.6899

 F1-mic 0.6900,  F1-mac 0.4241
new best val f1: 0.6899779848980515
ogbn-arxiv,dgl,1,521,8.6046,0.6900

 F1-mic 0.6900,  F1-mac 0.4242
new best val f1: 0.6900191346213197
ogbn-arxiv,dgl,1,522,8.6207,0.6900

 F1-mic 0.6903,  F1-mac 0.4246
new best val f1: 0.6902660329609284
ogbn-arxiv,dgl,1,523,8.6367,0.6903

 F1-mic 0.6903,  F1-mac 0.4247
new best val f1: 0.6903483324074645
ogbn-arxiv,dgl,1,524,8.6527,0.6903

 F1-mic 0.6904,  F1-mac 0.4248
new best val f1: 0.6904306318540008
ogbn-arxiv,dgl,1,525,8.6687,0.6904

 F1-mic 0.6904,  F1-mac 0.4248
ogbn-arxiv,dgl,1,526,8.6848,0.6904

 F1-mic 0.6906,  F1-mac 0.4252
new best val f1: 0.6905540810238051
ogbn-arxiv,dgl,1,527,8.7009,0.6906

 F1-mic 0.6906,  F1-mac 0.4252
new best val f1: 0.6905952307470732
ogbn-arxiv,dgl,1,528,8.7169,0.6906

 F1-mic 0.6907,  F1-mac 0.4252
new best val f1: 0.6906775301936094
ogbn-arxiv,dgl,1,529,8.7330,0.6907

epoch:531/50, Iteration 32/32:training loss 1.0973316431045532
Train F1-mic 0.6789, Train F1-mac 0.4446
 F1-mic 0.6907,  F1-mac 0.4253
new best val f1: 0.6907186799168775
ogbn-arxiv,dgl,1,530,8.7490,0.6907

 F1-mic 0.6909,  F1-mac 0.4256
new best val f1: 0.69088327880995
ogbn-arxiv,dgl,1,531,8.7652,0.6909

 F1-mic 0.6909,  F1-mac 0.4257
new best val f1: 0.690903853671584
ogbn-arxiv,dgl,1,532,8.7813,0.6909

 F1-mic 0.6910,  F1-mac 0.4261
new best val f1: 0.6909861531181203
ogbn-arxiv,dgl,1,533,8.7973,0.6910

 F1-mic 0.6909,  F1-mac 0.4262
ogbn-arxiv,dgl,1,534,8.8133,0.6909

 F1-mic 0.6910,  F1-mac 0.4262
new best val f1: 0.6910273028413884
ogbn-arxiv,dgl,1,535,8.8293,0.6910

 F1-mic 0.6911,  F1-mac 0.4263
new best val f1: 0.6910684525646565
ogbn-arxiv,dgl,1,536,8.8454,0.6911

 F1-mic 0.6912,  F1-mac 0.4264
new best val f1: 0.6911507520111927
ogbn-arxiv,dgl,1,537,8.8614,0.6912

 F1-mic 0.6913,  F1-mac 0.4272
new best val f1: 0.6912947760426311
ogbn-arxiv,dgl,1,538,8.8774,0.6913

 F1-mic 0.6913,  F1-mac 0.4272
new best val f1: 0.6913359257658992
ogbn-arxiv,dgl,1,539,8.8935,0.6913

epoch:541/50, Iteration 32/32:training loss 1.0933306217193604
Train F1-mic 0.6797, Train F1-mac 0.4470
 F1-mic 0.6914,  F1-mac 0.4273
new best val f1: 0.6913976503508014
ogbn-arxiv,dgl,1,540,8.9096,0.6914

 F1-mic 0.6915,  F1-mac 0.4276
new best val f1: 0.6915210995206057
ogbn-arxiv,dgl,1,541,8.9257,0.6915

 F1-mic 0.6917,  F1-mac 0.4281
new best val f1: 0.6916856984136782
ogbn-arxiv,dgl,1,542,8.9419,0.6917

 F1-mic 0.6918,  F1-mac 0.4281
new best val f1: 0.6917679978602144
ogbn-arxiv,dgl,1,543,8.9579,0.6918

 F1-mic 0.6918,  F1-mac 0.4287
new best val f1: 0.6918297224451165
ogbn-arxiv,dgl,1,544,8.9738,0.6918

 F1-mic 0.6919,  F1-mac 0.4290
new best val f1: 0.6919120218916528
ogbn-arxiv,dgl,1,545,8.9899,0.6919

 F1-mic 0.6922,  F1-mac 0.4294
new best val f1: 0.6921794950928954
ogbn-arxiv,dgl,1,546,9.0059,0.6922

 F1-mic 0.6923,  F1-mac 0.4301
new best val f1: 0.692344093985968
ogbn-arxiv,dgl,1,547,9.0220,0.6923

 F1-mic 0.6923,  F1-mac 0.4302
ogbn-arxiv,dgl,1,548,9.0380,0.6923

 F1-mic 0.6927,  F1-mac 0.4310
new best val f1: 0.6926527169104788
ogbn-arxiv,dgl,1,549,9.0541,0.6927

epoch:551/50, Iteration 32/32:training loss 1.0895092487335205
Train F1-mic 0.6808, Train F1-mac 0.4496
 F1-mic 0.6927,  F1-mac 0.4314
new best val f1: 0.692714441495381
ogbn-arxiv,dgl,1,550,9.0701,0.6927

 F1-mic 0.6928,  F1-mac 0.4317
new best val f1: 0.6927967409419171
ogbn-arxiv,dgl,1,551,9.0862,0.6928

 F1-mic 0.6930,  F1-mac 0.4321
new best val f1: 0.6929613398349896
ogbn-arxiv,dgl,1,552,9.1023,0.6930

 F1-mic 0.6931,  F1-mac 0.4322
new best val f1: 0.693084789004794
ogbn-arxiv,dgl,1,553,9.1184,0.6931

 F1-mic 0.6930,  F1-mac 0.4324
ogbn-arxiv,dgl,1,554,9.1344,0.6930

 F1-mic 0.6931,  F1-mac 0.4325
new best val f1: 0.693105363866428
ogbn-arxiv,dgl,1,555,9.1504,0.6931

 F1-mic 0.6933,  F1-mac 0.4327
new best val f1: 0.6932905376211345
ogbn-arxiv,dgl,1,556,9.1664,0.6933

 F1-mic 0.6933,  F1-mac 0.4331
new best val f1: 0.6933316873444026
ogbn-arxiv,dgl,1,557,9.1825,0.6933

 F1-mic 0.6934,  F1-mac 0.4332
new best val f1: 0.6934345616525729
ogbn-arxiv,dgl,1,558,9.1985,0.6934

 F1-mic 0.6934,  F1-mac 0.4333
ogbn-arxiv,dgl,1,559,9.2146,0.6934

epoch:561/50, Iteration 32/32:training loss 1.085847020149231
Train F1-mic 0.6819, Train F1-mac 0.4525
 F1-mic 0.6935,  F1-mac 0.4336
new best val f1: 0.693475711375841
ogbn-arxiv,dgl,1,560,9.2306,0.6935

 F1-mic 0.6935,  F1-mac 0.4336
new best val f1: 0.6935374359607431
ogbn-arxiv,dgl,1,561,9.2467,0.6935

 F1-mic 0.6937,  F1-mac 0.4337
new best val f1: 0.6936814599921816
ogbn-arxiv,dgl,1,562,9.2628,0.6937

 F1-mic 0.6938,  F1-mac 0.4340
new best val f1: 0.6937843343003518
ogbn-arxiv,dgl,1,563,9.2788,0.6938

 F1-mic 0.6938,  F1-mac 0.4346
new best val f1: 0.693846058885254
ogbn-arxiv,dgl,1,564,9.2948,0.6938

 F1-mic 0.6939,  F1-mac 0.4344
new best val f1: 0.6938666337468881
ogbn-arxiv,dgl,1,565,9.3109,0.6939

 F1-mic 0.6939,  F1-mac 0.4346
new best val f1: 0.6939077834701561
ogbn-arxiv,dgl,1,566,9.3269,0.6939

 F1-mic 0.6941,  F1-mac 0.4348
new best val f1: 0.6940518075015946
ogbn-arxiv,dgl,1,567,9.3430,0.6941

 F1-mic 0.6939,  F1-mac 0.4346
ogbn-arxiv,dgl,1,568,9.3589,0.6939

 F1-mic 0.6942,  F1-mac 0.4349
new best val f1: 0.6941546818097648
ogbn-arxiv,dgl,1,569,9.3750,0.6942

epoch:571/50, Iteration 32/32:training loss 1.0823417901992798
Train F1-mic 0.6828, Train F1-mac 0.4548
 F1-mic 0.6943,  F1-mac 0.4354
new best val f1: 0.6942781309795691
ogbn-arxiv,dgl,1,570,9.3910,0.6943

 F1-mic 0.6943,  F1-mac 0.4350
ogbn-arxiv,dgl,1,571,9.4072,0.6943

 F1-mic 0.6943,  F1-mac 0.4353
new best val f1: 0.6943398555644713
ogbn-arxiv,dgl,1,572,9.4233,0.6943

 F1-mic 0.6944,  F1-mac 0.4350
new best val f1: 0.6944221550110076
ogbn-arxiv,dgl,1,573,9.4393,0.6944

 F1-mic 0.6945,  F1-mac 0.4353
new best val f1: 0.6944633047342756
ogbn-arxiv,dgl,1,574,9.4553,0.6945

 F1-mic 0.6947,  F1-mac 0.4360
new best val f1: 0.6946896282122502
ogbn-arxiv,dgl,1,575,9.4714,0.6947

 F1-mic 0.6948,  F1-mac 0.4359
new best val f1: 0.6947925025204206
ogbn-arxiv,dgl,1,576,9.4874,0.6948

 F1-mic 0.6949,  F1-mac 0.4363
new best val f1: 0.6949159516902249
ogbn-arxiv,dgl,1,577,9.5035,0.6949

 F1-mic 0.6950,  F1-mac 0.4363
new best val f1: 0.694957101413493
ogbn-arxiv,dgl,1,578,9.5195,0.6950

 F1-mic 0.6950,  F1-mac 0.4367
new best val f1: 0.6949982511367611
ogbn-arxiv,dgl,1,579,9.5356,0.6950

epoch:581/50, Iteration 32/32:training loss 1.078978180885315
Train F1-mic 0.6837, Train F1-mac 0.4566
 F1-mic 0.6952,  F1-mac 0.4369
new best val f1: 0.6951834248914676
ogbn-arxiv,dgl,1,580,9.5516,0.6952

 F1-mic 0.6953,  F1-mac 0.4369
new best val f1: 0.6952862991996379
ogbn-arxiv,dgl,1,581,9.5677,0.6953

 F1-mic 0.6953,  F1-mac 0.4369
new best val f1: 0.6953480237845401
ogbn-arxiv,dgl,1,582,9.5838,0.6953

 F1-mic 0.6956,  F1-mac 0.4372
new best val f1: 0.6955537724008806
ogbn-arxiv,dgl,1,583,9.5999,0.6956

 F1-mic 0.6957,  F1-mac 0.4374
new best val f1: 0.6957389461555871
ogbn-arxiv,dgl,1,584,9.6159,0.6957

 F1-mic 0.6958,  F1-mac 0.4375
new best val f1: 0.6957595210172212
ogbn-arxiv,dgl,1,585,9.6319,0.6958

 F1-mic 0.6958,  F1-mac 0.4376
new best val f1: 0.6958006707404892
ogbn-arxiv,dgl,1,586,9.6480,0.6958

 F1-mic 0.6959,  F1-mac 0.4378
new best val f1: 0.6959035450486596
ogbn-arxiv,dgl,1,587,9.6640,0.6959

 F1-mic 0.6960,  F1-mac 0.4382
new best val f1: 0.6960064193568298
ogbn-arxiv,dgl,1,588,9.6800,0.6960

 F1-mic 0.6960,  F1-mac 0.4379
ogbn-arxiv,dgl,1,589,9.6961,0.6960

epoch:591/50, Iteration 32/32:training loss 1.0757452249526978
Train F1-mic 0.6846, Train F1-mac 0.4586
 F1-mic 0.6962,  F1-mac 0.4389
new best val f1: 0.6962327428348044
ogbn-arxiv,dgl,1,590,9.7121,0.6962

 F1-mic 0.6962,  F1-mac 0.4389
ogbn-arxiv,dgl,1,591,9.7282,0.6962

 F1-mic 0.6964,  F1-mac 0.4394
new best val f1: 0.6963767668662428
ogbn-arxiv,dgl,1,592,9.7443,0.6964

 F1-mic 0.6965,  F1-mac 0.4394
new best val f1: 0.6964590663127791
ogbn-arxiv,dgl,1,593,9.7603,0.6965

 F1-mic 0.6965,  F1-mac 0.4395
new best val f1: 0.6964796411744131
ogbn-arxiv,dgl,1,594,9.7764,0.6965

 F1-mic 0.6966,  F1-mac 0.4396
new best val f1: 0.6966236652058515
ogbn-arxiv,dgl,1,595,9.7924,0.6966

 F1-mic 0.6967,  F1-mac 0.4403
new best val f1: 0.6966853897907537
ogbn-arxiv,dgl,1,596,9.8084,0.6967

 F1-mic 0.6968,  F1-mac 0.4403
new best val f1: 0.6968499886838261
ogbn-arxiv,dgl,1,597,9.8245,0.6968

 F1-mic 0.6969,  F1-mac 0.4407
new best val f1: 0.6968911384070942
ogbn-arxiv,dgl,1,598,9.8405,0.6969

 F1-mic 0.6970,  F1-mac 0.4408
new best val f1: 0.6969734378536304
ogbn-arxiv,dgl,1,599,9.8566,0.6970

epoch:601/50, Iteration 32/32:training loss 1.072635531425476
Train F1-mic 0.6855, Train F1-mac 0.4614
 F1-mic 0.6970,  F1-mac 0.4408
new best val f1: 0.6970145875768985
ogbn-arxiv,dgl,1,600,9.8726,0.6970

 F1-mic 0.6973,  F1-mac 0.4409
new best val f1: 0.6972820607781413
ogbn-arxiv,dgl,1,601,9.8888,0.6973

 F1-mic 0.6973,  F1-mac 0.4410
new best val f1: 0.6973026356397753
ogbn-arxiv,dgl,1,602,9.9049,0.6973

 F1-mic 0.6973,  F1-mac 0.4414
ogbn-arxiv,dgl,1,603,9.9208,0.6973

 F1-mic 0.6973,  F1-mac 0.4417
new best val f1: 0.6973232105014093
ogbn-arxiv,dgl,1,604,9.9368,0.6973

 F1-mic 0.6977,  F1-mac 0.4419
new best val f1: 0.6976729831491884
ogbn-arxiv,dgl,1,605,9.9529,0.6977

 F1-mic 0.6978,  F1-mac 0.4430
new best val f1: 0.6977552825957245
ogbn-arxiv,dgl,1,606,9.9689,0.6978

 F1-mic 0.6978,  F1-mac 0.4438
new best val f1: 0.6978375820422608
ogbn-arxiv,dgl,1,607,9.9850,0.6978

 F1-mic 0.6979,  F1-mac 0.4441
new best val f1: 0.6978581569038949
ogbn-arxiv,dgl,1,608,10.0010,0.6979

 F1-mic 0.6980,  F1-mac 0.4442
new best val f1: 0.6979610312120651
ogbn-arxiv,dgl,1,609,10.0170,0.6980

epoch:611/50, Iteration 32/32:training loss 1.069643497467041
Train F1-mic 0.6863, Train F1-mac 0.4637
 F1-mic 0.6979,  F1-mac 0.4443
ogbn-arxiv,dgl,1,610,10.0331,0.6979

 F1-mic 0.6981,  F1-mac 0.4448
new best val f1: 0.6981050552435035
ogbn-arxiv,dgl,1,611,10.0492,0.6981

 F1-mic 0.6982,  F1-mac 0.4450
new best val f1: 0.6981667798284057
ogbn-arxiv,dgl,1,612,10.0653,0.6982

 F1-mic 0.6983,  F1-mac 0.4451
new best val f1: 0.6982696541365759
ogbn-arxiv,dgl,1,613,10.0814,0.6983

 F1-mic 0.6984,  F1-mac 0.4454
new best val f1: 0.6983931033063803
ogbn-arxiv,dgl,1,614,10.0974,0.6984

 F1-mic 0.6984,  F1-mac 0.4454
ogbn-arxiv,dgl,1,615,10.1134,0.6984

 F1-mic 0.6983,  F1-mac 0.4452
ogbn-arxiv,dgl,1,616,10.1295,0.6983

 F1-mic 0.6984,  F1-mac 0.4452
ogbn-arxiv,dgl,1,617,10.1455,0.6984

 F1-mic 0.6985,  F1-mac 0.4453
new best val f1: 0.6984959776145505
ogbn-arxiv,dgl,1,618,10.1615,0.6985

 F1-mic 0.6986,  F1-mac 0.4455
new best val f1: 0.6986194267843548
ogbn-arxiv,dgl,1,619,10.1776,0.6986

epoch:621/50, Iteration 32/32:training loss 1.0667632818222046
Train F1-mic 0.6871, Train F1-mac 0.4654
 F1-mic 0.6989,  F1-mac 0.4463
new best val f1: 0.6989074748472317
ogbn-arxiv,dgl,1,620,10.1936,0.6989

 F1-mic 0.6988,  F1-mac 0.4466
ogbn-arxiv,dgl,1,621,10.2097,0.6988

 F1-mic 0.6989,  F1-mac 0.4469
new best val f1: 0.6989486245704998
ogbn-arxiv,dgl,1,622,10.2258,0.6989

 F1-mic 0.6991,  F1-mac 0.4474
new best val f1: 0.6991337983252063
ogbn-arxiv,dgl,1,623,10.2419,0.6991

 F1-mic 0.6993,  F1-mac 0.4476
new best val f1: 0.6992572474950106
ogbn-arxiv,dgl,1,624,10.2579,0.6993

 F1-mic 0.6993,  F1-mac 0.4479
new best val f1: 0.6993395469415468
ogbn-arxiv,dgl,1,625,10.2739,0.6993

 F1-mic 0.6994,  F1-mac 0.4483
new best val f1: 0.699421846388083
ogbn-arxiv,dgl,1,626,10.2900,0.6994

 F1-mic 0.6996,  F1-mac 0.4486
new best val f1: 0.6995864452811554
ogbn-arxiv,dgl,1,627,10.3061,0.6996

 F1-mic 0.6995,  F1-mac 0.4487
ogbn-arxiv,dgl,1,628,10.3221,0.6995

 F1-mic 0.6998,  F1-mac 0.4495
new best val f1: 0.6998333436207641
ogbn-arxiv,dgl,1,629,10.3381,0.6998

epoch:631/50, Iteration 32/32:training loss 1.0639857053756714
Train F1-mic 0.6879, Train F1-mac 0.4675
 F1-mic 0.7000,  F1-mac 0.4495
new best val f1: 0.6999773676522025
ogbn-arxiv,dgl,1,630,10.3541,0.7000

 F1-mic 0.7001,  F1-mac 0.4500
new best val f1: 0.7000802419603728
ogbn-arxiv,dgl,1,631,10.3703,0.7001

 F1-mic 0.7002,  F1-mac 0.4505
new best val f1: 0.7002242659918112
ogbn-arxiv,dgl,1,632,10.3869,0.7002

 F1-mic 0.7003,  F1-mac 0.4510
new best val f1: 0.7003065654383475
ogbn-arxiv,dgl,1,633,10.4029,0.7003

 F1-mic 0.7003,  F1-mac 0.4510
ogbn-arxiv,dgl,1,634,10.4189,0.7003

 F1-mic 0.7003,  F1-mac 0.4511
ogbn-arxiv,dgl,1,635,10.4349,0.7003

 F1-mic 0.7006,  F1-mac 0.4514
new best val f1: 0.7005534637779561
ogbn-arxiv,dgl,1,636,10.4510,0.7006

 F1-mic 0.7006,  F1-mac 0.4519
new best val f1: 0.7005946135012242
ogbn-arxiv,dgl,1,637,10.4671,0.7006

 F1-mic 0.7006,  F1-mac 0.4520
ogbn-arxiv,dgl,1,638,10.4830,0.7006

 F1-mic 0.7006,  F1-mac 0.4523
ogbn-arxiv,dgl,1,639,10.4991,0.7006

epoch:641/50, Iteration 32/32:training loss 1.0613096952438354
Train F1-mic 0.6883, Train F1-mac 0.4687
 F1-mic 0.7007,  F1-mac 0.4524
new best val f1: 0.7006563380861264
ogbn-arxiv,dgl,1,640,10.5152,0.7007

 F1-mic 0.7007,  F1-mac 0.4527
new best val f1: 0.7007386375326626
ogbn-arxiv,dgl,1,641,10.5313,0.7007

 F1-mic 0.7007,  F1-mac 0.4525
ogbn-arxiv,dgl,1,642,10.5474,0.7007

 F1-mic 0.7007,  F1-mac 0.4525
ogbn-arxiv,dgl,1,643,10.5634,0.7007

 F1-mic 0.7008,  F1-mac 0.4528
new best val f1: 0.7008209369791988
ogbn-arxiv,dgl,1,644,10.5794,0.7008

 F1-mic 0.7008,  F1-mac 0.4529
new best val f1: 0.7008415118408329
ogbn-arxiv,dgl,1,645,10.5954,0.7008

 F1-mic 0.7009,  F1-mac 0.4533
new best val f1: 0.700882661564101
ogbn-arxiv,dgl,1,646,10.6115,0.7009

 F1-mic 0.7010,  F1-mac 0.4534
new best val f1: 0.7010266855955394
ogbn-arxiv,dgl,1,647,10.6275,0.7010

 F1-mic 0.7010,  F1-mac 0.4535
new best val f1: 0.7010472604571735
ogbn-arxiv,dgl,1,648,10.6435,0.7010

 F1-mic 0.7011,  F1-mac 0.4540
new best val f1: 0.7011295599037096
ogbn-arxiv,dgl,1,649,10.6596,0.7011

epoch:651/50, Iteration 32/32:training loss 1.0587245225906372
Train F1-mic 0.6890, Train F1-mac 0.4701
 F1-mic 0.7011,  F1-mac 0.4541
ogbn-arxiv,dgl,1,650,10.6756,0.7011

 F1-mic 0.7013,  F1-mac 0.4544
new best val f1: 0.701273583935148
ogbn-arxiv,dgl,1,651,10.6919,0.7013

 F1-mic 0.7014,  F1-mac 0.4552
new best val f1: 0.7013764582433183
ogbn-arxiv,dgl,1,652,10.7080,0.7014

 F1-mic 0.7014,  F1-mac 0.4555
new best val f1: 0.7014176079665865
ogbn-arxiv,dgl,1,653,10.7240,0.7014

 F1-mic 0.7014,  F1-mac 0.4558
new best val f1: 0.7014381828282205
ogbn-arxiv,dgl,1,654,10.7401,0.7014

 F1-mic 0.7014,  F1-mac 0.4559
ogbn-arxiv,dgl,1,655,10.7561,0.7014

 F1-mic 0.7015,  F1-mac 0.4559
new best val f1: 0.7015204822747567
ogbn-arxiv,dgl,1,656,10.7721,0.7015

 F1-mic 0.7017,  F1-mac 0.4563
new best val f1: 0.7016645063061951
ogbn-arxiv,dgl,1,657,10.7882,0.7017

 F1-mic 0.7017,  F1-mac 0.4564
new best val f1: 0.7017468057527313
ogbn-arxiv,dgl,1,658,10.8042,0.7017

 F1-mic 0.7020,  F1-mac 0.4567
new best val f1: 0.70199370409234
ogbn-arxiv,dgl,1,659,10.8203,0.7020

epoch:661/50, Iteration 32/32:training loss 1.0562304258346558
Train F1-mic 0.6898, Train F1-mac 0.4720
 F1-mic 0.7020,  F1-mac 0.4567
ogbn-arxiv,dgl,1,660,10.8363,0.7020

 F1-mic 0.7019,  F1-mac 0.4568
ogbn-arxiv,dgl,1,661,10.8525,0.7019

 F1-mic 0.7020,  F1-mac 0.4568
new best val f1: 0.702034853815608
ogbn-arxiv,dgl,1,662,10.8686,0.7020

 F1-mic 0.7020,  F1-mac 0.4568
ogbn-arxiv,dgl,1,663,10.8846,0.7020

 F1-mic 0.7019,  F1-mac 0.4565
ogbn-arxiv,dgl,1,664,10.9006,0.7019

 F1-mic 0.7021,  F1-mac 0.4569
new best val f1: 0.7020965784005102
ogbn-arxiv,dgl,1,665,10.9167,0.7021

 F1-mic 0.7023,  F1-mac 0.4572
new best val f1: 0.7022817521552167
ogbn-arxiv,dgl,1,666,10.9327,0.7023

 F1-mic 0.7021,  F1-mac 0.4572
ogbn-arxiv,dgl,1,667,10.9487,0.7021

 F1-mic 0.7022,  F1-mac 0.4573
ogbn-arxiv,dgl,1,668,10.9647,0.7022

 F1-mic 0.7024,  F1-mac 0.4575
new best val f1: 0.702364051601753
ogbn-arxiv,dgl,1,669,10.9808,0.7024

epoch:671/50, Iteration 32/32:training loss 1.0538192987442017
Train F1-mic 0.6903, Train F1-mac 0.4731
 F1-mic 0.7024,  F1-mac 0.4576
ogbn-arxiv,dgl,1,670,10.9969,0.7024

 F1-mic 0.7025,  F1-mac 0.4579
new best val f1: 0.7024875007715573
ogbn-arxiv,dgl,1,671,11.0129,0.7025

 F1-mic 0.7024,  F1-mac 0.4577
ogbn-arxiv,dgl,1,672,11.0291,0.7024

 F1-mic 0.7027,  F1-mac 0.4585
new best val f1: 0.7026520996646297
ogbn-arxiv,dgl,1,673,11.0451,0.7027

 F1-mic 0.7026,  F1-mac 0.4586
ogbn-arxiv,dgl,1,674,11.0611,0.7026

 F1-mic 0.7027,  F1-mac 0.4586
new best val f1: 0.702734399111166
ogbn-arxiv,dgl,1,675,11.0771,0.7027

 F1-mic 0.7028,  F1-mac 0.4587
new best val f1: 0.7027549739728001
ogbn-arxiv,dgl,1,676,11.0932,0.7028

 F1-mic 0.7028,  F1-mac 0.4588
new best val f1: 0.702775548834434
ogbn-arxiv,dgl,1,677,11.1092,0.7028

 F1-mic 0.7029,  F1-mac 0.4591
new best val f1: 0.7029401477275066
ogbn-arxiv,dgl,1,678,11.1253,0.7029

 F1-mic 0.7029,  F1-mac 0.4594
ogbn-arxiv,dgl,1,679,11.1413,0.7029

epoch:681/50, Iteration 32/32:training loss 1.051491618156433
Train F1-mic 0.6909, Train F1-mac 0.4744
 F1-mic 0.7030,  F1-mac 0.4595
new best val f1: 0.7030018723124087
ogbn-arxiv,dgl,1,680,11.1574,0.7030

 F1-mic 0.7030,  F1-mac 0.4594
ogbn-arxiv,dgl,1,681,11.1735,0.7030

 F1-mic 0.7030,  F1-mac 0.4597
new best val f1: 0.7030430220356768
ogbn-arxiv,dgl,1,682,11.1896,0.7030

 F1-mic 0.7031,  F1-mac 0.4598
new best val f1: 0.7030635968973109
ogbn-arxiv,dgl,1,683,11.2056,0.7031

 F1-mic 0.7031,  F1-mac 0.4598
new best val f1: 0.703145896343847
ogbn-arxiv,dgl,1,684,11.2216,0.7031

 F1-mic 0.7033,  F1-mac 0.4602
new best val f1: 0.7033310700985536
ogbn-arxiv,dgl,1,685,11.2377,0.7033

 F1-mic 0.7032,  F1-mac 0.4601
ogbn-arxiv,dgl,1,686,11.2538,0.7032

 F1-mic 0.7034,  F1-mac 0.4604
new best val f1: 0.7033927946834557
ogbn-arxiv,dgl,1,687,11.2699,0.7034

 F1-mic 0.7033,  F1-mac 0.4604
ogbn-arxiv,dgl,1,688,11.2859,0.7033

 F1-mic 0.7036,  F1-mac 0.4605
new best val f1: 0.7035573935765282
ogbn-arxiv,dgl,1,689,11.3020,0.7036

epoch:691/50, Iteration 32/32:training loss 1.0492340326309204
Train F1-mic 0.6915, Train F1-mac 0.4758
 F1-mic 0.7036,  F1-mac 0.4604
new best val f1: 0.7035779684381622
ogbn-arxiv,dgl,1,690,11.3180,0.7036

 F1-mic 0.7038,  F1-mac 0.4608
new best val f1: 0.7037631421928687
ogbn-arxiv,dgl,1,691,11.3341,0.7038

 F1-mic 0.7037,  F1-mac 0.4607
ogbn-arxiv,dgl,1,692,11.3501,0.7037

 F1-mic 0.7038,  F1-mac 0.4610
new best val f1: 0.7038248667777709
ogbn-arxiv,dgl,1,693,11.3661,0.7038

 F1-mic 0.7039,  F1-mac 0.4610
new best val f1: 0.7039277410859412
ogbn-arxiv,dgl,1,694,11.3821,0.7039

 F1-mic 0.7040,  F1-mac 0.4612
new best val f1: 0.7040306153941115
ogbn-arxiv,dgl,1,695,11.3982,0.7040

 F1-mic 0.7039,  F1-mac 0.4610
ogbn-arxiv,dgl,1,696,11.4143,0.7039

 F1-mic 0.7041,  F1-mac 0.4612
new best val f1: 0.7041129148406476
ogbn-arxiv,dgl,1,697,11.4303,0.7041

 F1-mic 0.7042,  F1-mac 0.4615
new best val f1: 0.7041952142871839
ogbn-arxiv,dgl,1,698,11.4463,0.7042

 F1-mic 0.7041,  F1-mac 0.4612
ogbn-arxiv,dgl,1,699,11.4624,0.7041

epoch:701/50, Iteration 32/32:training loss 1.0470479726791382
Train F1-mic 0.6920, Train F1-mac 0.4768
 F1-mic 0.7043,  F1-mac 0.4614
new best val f1: 0.7042775137337202
ogbn-arxiv,dgl,1,700,11.4787,0.7043

 F1-mic 0.7043,  F1-mac 0.4617
new best val f1: 0.7043392383186223
ogbn-arxiv,dgl,1,701,11.4948,0.7043

 F1-mic 0.7044,  F1-mac 0.4617
new best val f1: 0.7044215377651585
ogbn-arxiv,dgl,1,702,11.5109,0.7044

 F1-mic 0.7043,  F1-mac 0.4617
ogbn-arxiv,dgl,1,703,11.5269,0.7043

 F1-mic 0.7045,  F1-mac 0.4618
new best val f1: 0.7044832623500606
ogbn-arxiv,dgl,1,704,11.5429,0.7045

 F1-mic 0.7045,  F1-mac 0.4618
new best val f1: 0.7045244120733288
ogbn-arxiv,dgl,1,705,11.5589,0.7045

 F1-mic 0.7045,  F1-mac 0.4625
ogbn-arxiv,dgl,1,706,11.5750,0.7045

 F1-mic 0.7047,  F1-mac 0.4627
new best val f1: 0.7047301606896693
ogbn-arxiv,dgl,1,707,11.5911,0.7047

 F1-mic 0.7048,  F1-mac 0.4628
new best val f1: 0.7047507355513034
ogbn-arxiv,dgl,1,708,11.6071,0.7048

 F1-mic 0.7048,  F1-mac 0.4628
new best val f1: 0.7048124601362056
ogbn-arxiv,dgl,1,709,11.6232,0.7048

epoch:711/50, Iteration 32/32:training loss 1.044933557510376
Train F1-mic 0.6926, Train F1-mac 0.4784
 F1-mic 0.7049,  F1-mac 0.4632
new best val f1: 0.7048947595827418
ogbn-arxiv,dgl,1,710,11.6393,0.7049

 F1-mic 0.7049,  F1-mac 0.4632
new best val f1: 0.7049153344443758
ogbn-arxiv,dgl,1,711,11.6554,0.7049

 F1-mic 0.7050,  F1-mac 0.4630
new best val f1: 0.704977059029278
ogbn-arxiv,dgl,1,712,11.6715,0.7050

 F1-mic 0.7051,  F1-mac 0.4632
new best val f1: 0.7050593584758142
ogbn-arxiv,dgl,1,713,11.6875,0.7051

 F1-mic 0.7052,  F1-mac 0.4635
new best val f1: 0.7051622327839845
ogbn-arxiv,dgl,1,714,11.7035,0.7052

 F1-mic 0.7052,  F1-mac 0.4636
new best val f1: 0.7052033825072527
ogbn-arxiv,dgl,1,715,11.7196,0.7052

 F1-mic 0.7053,  F1-mac 0.4637
new best val f1: 0.7052651070921548
ogbn-arxiv,dgl,1,716,11.7357,0.7053

 F1-mic 0.7052,  F1-mac 0.4636
ogbn-arxiv,dgl,1,717,11.7517,0.7052

 F1-mic 0.7053,  F1-mac 0.4635
new best val f1: 0.705347406538691
ogbn-arxiv,dgl,1,718,11.7678,0.7053

 F1-mic 0.7053,  F1-mac 0.4635
ogbn-arxiv,dgl,1,719,11.7838,0.7053

epoch:721/50, Iteration 32/32:training loss 1.0428838729858398
Train F1-mic 0.6934, Train F1-mac 0.4798
 F1-mic 0.7055,  F1-mac 0.4639
new best val f1: 0.7054502808468613
ogbn-arxiv,dgl,1,720,11.7999,0.7055

 F1-mic 0.7056,  F1-mac 0.4639
new best val f1: 0.7055531551550316
ogbn-arxiv,dgl,1,721,11.8160,0.7056

 F1-mic 0.7056,  F1-mac 0.4639
new best val f1: 0.7055737300166657
ogbn-arxiv,dgl,1,722,11.8321,0.7056

 F1-mic 0.7057,  F1-mac 0.4642
new best val f1: 0.7056560294632018
ogbn-arxiv,dgl,1,723,11.8481,0.7057

 F1-mic 0.7056,  F1-mac 0.4642
ogbn-arxiv,dgl,1,724,11.8642,0.7056

 F1-mic 0.7058,  F1-mac 0.4643
new best val f1: 0.7057589037713722
ogbn-arxiv,dgl,1,725,11.8802,0.7058

 F1-mic 0.7059,  F1-mac 0.4645
new best val f1: 0.7059029278028105
ogbn-arxiv,dgl,1,726,11.8964,0.7059

 F1-mic 0.7060,  F1-mac 0.4645
new best val f1: 0.7059852272493468
ogbn-arxiv,dgl,1,727,11.9125,0.7060

 F1-mic 0.7059,  F1-mac 0.4645
ogbn-arxiv,dgl,1,728,11.9285,0.7059

 F1-mic 0.7059,  F1-mac 0.4647
ogbn-arxiv,dgl,1,729,11.9445,0.7059

epoch:731/50, Iteration 32/32:training loss 1.0409008264541626
Train F1-mic 0.6939, Train F1-mac 0.4809
 F1-mic 0.7061,  F1-mac 0.4648
new best val f1: 0.7061292512807852
ogbn-arxiv,dgl,1,730,11.9606,0.7061

 F1-mic 0.7062,  F1-mac 0.4653
new best val f1: 0.7062321255889554
ogbn-arxiv,dgl,1,731,11.9767,0.7062

 F1-mic 0.7062,  F1-mac 0.4654
ogbn-arxiv,dgl,1,732,11.9928,0.7062

 F1-mic 0.7062,  F1-mac 0.4657
ogbn-arxiv,dgl,1,733,12.0088,0.7062

 F1-mic 0.7062,  F1-mac 0.4655
ogbn-arxiv,dgl,1,734,12.0248,0.7062

 F1-mic 0.7064,  F1-mac 0.4657
new best val f1: 0.7063761496203939
ogbn-arxiv,dgl,1,735,12.0409,0.7064

 F1-mic 0.7062,  F1-mac 0.4659
ogbn-arxiv,dgl,1,736,12.0569,0.7062

 F1-mic 0.7064,  F1-mac 0.4663
ogbn-arxiv,dgl,1,737,12.0730,0.7064

 F1-mic 0.7063,  F1-mac 0.4663
ogbn-arxiv,dgl,1,738,12.0890,0.7063

 F1-mic 0.7063,  F1-mac 0.4663
ogbn-arxiv,dgl,1,739,12.1050,0.7063

epoch:741/50, Iteration 32/32:training loss 1.0389750003814697
Train F1-mic 0.6944, Train F1-mac 0.4820
 F1-mic 0.7065,  F1-mac 0.4666
new best val f1: 0.70645844906693
ogbn-arxiv,dgl,1,740,12.1211,0.7065

 F1-mic 0.7064,  F1-mac 0.4666
ogbn-arxiv,dgl,1,741,12.1373,0.7064

 F1-mic 0.7064,  F1-mac 0.4666
ogbn-arxiv,dgl,1,742,12.1534,0.7064

 F1-mic 0.7065,  F1-mac 0.4665
ogbn-arxiv,dgl,1,743,12.1694,0.7065

 F1-mic 0.7064,  F1-mac 0.4665
ogbn-arxiv,dgl,1,744,12.1855,0.7064

 F1-mic 0.7066,  F1-mac 0.4665
new best val f1: 0.7065613233751002
ogbn-arxiv,dgl,1,745,12.2015,0.7066

 F1-mic 0.7066,  F1-mac 0.4666
new best val f1: 0.7065818982367343
ogbn-arxiv,dgl,1,746,12.2176,0.7066

 F1-mic 0.7066,  F1-mac 0.4666
new best val f1: 0.7066230479600024
ogbn-arxiv,dgl,1,747,12.2337,0.7066

 F1-mic 0.7067,  F1-mac 0.4671
new best val f1: 0.7067053474065387
ogbn-arxiv,dgl,1,748,12.2497,0.7067

 F1-mic 0.7068,  F1-mac 0.4673
new best val f1: 0.7067670719914408
ogbn-arxiv,dgl,1,749,12.2658,0.7068

epoch:751/50, Iteration 32/32:training loss 1.0371043682098389
Train F1-mic 0.6948, Train F1-mac 0.4828
 F1-mic 0.7068,  F1-mac 0.4673
new best val f1: 0.7068493714379771
ogbn-arxiv,dgl,1,750,12.2818,0.7068

 F1-mic 0.7069,  F1-mac 0.4675
new best val f1: 0.7068699462996111
ogbn-arxiv,dgl,1,751,12.2980,0.7069

 F1-mic 0.7070,  F1-mac 0.4675
new best val f1: 0.7069728206077814
ogbn-arxiv,dgl,1,752,12.3141,0.7070

 F1-mic 0.7070,  F1-mac 0.4676
ogbn-arxiv,dgl,1,753,12.3301,0.7070

 F1-mic 0.7070,  F1-mac 0.4675
ogbn-arxiv,dgl,1,754,12.3462,0.7070

 F1-mic 0.7073,  F1-mac 0.4679
new best val f1: 0.7072814435322923
ogbn-arxiv,dgl,1,755,12.3622,0.7073

 F1-mic 0.7074,  F1-mac 0.4684
new best val f1: 0.7074048927020966
ogbn-arxiv,dgl,1,756,12.3783,0.7074

 F1-mic 0.7074,  F1-mac 0.4683
ogbn-arxiv,dgl,1,757,12.3944,0.7074

 F1-mic 0.7075,  F1-mac 0.4684
new best val f1: 0.707548916733535
ogbn-arxiv,dgl,1,758,12.4104,0.7075

 F1-mic 0.7075,  F1-mac 0.4685
ogbn-arxiv,dgl,1,759,12.4265,0.7075

epoch:761/50, Iteration 32/32:training loss 1.0352942943572998
Train F1-mic 0.6953, Train F1-mac 0.4838
 F1-mic 0.7076,  F1-mac 0.4687
new best val f1: 0.7076106413184371
ogbn-arxiv,dgl,1,760,12.4425,0.7076

 F1-mic 0.7077,  F1-mac 0.4686
new best val f1: 0.7076929407649732
ogbn-arxiv,dgl,1,761,12.4587,0.7077

 F1-mic 0.7078,  F1-mac 0.4692
new best val f1: 0.7077752402115096
ogbn-arxiv,dgl,1,762,12.4748,0.7078

 F1-mic 0.7077,  F1-mac 0.4691
ogbn-arxiv,dgl,1,763,12.4908,0.7077

 F1-mic 0.7079,  F1-mac 0.4693
new best val f1: 0.7078781145196799
ogbn-arxiv,dgl,1,764,12.5069,0.7079

 F1-mic 0.7080,  F1-mac 0.4695
new best val f1: 0.7079604139662161
ogbn-arxiv,dgl,1,765,12.5229,0.7080

 F1-mic 0.7079,  F1-mac 0.4695
ogbn-arxiv,dgl,1,766,12.5390,0.7079

 F1-mic 0.7081,  F1-mac 0.4699
new best val f1: 0.7080632882743864
ogbn-arxiv,dgl,1,767,12.5551,0.7081

 F1-mic 0.7081,  F1-mac 0.4698
new best val f1: 0.7081250128592886
ogbn-arxiv,dgl,1,768,12.5711,0.7081

 F1-mic 0.7082,  F1-mac 0.4700
new best val f1: 0.7081867374441907
ogbn-arxiv,dgl,1,769,12.5872,0.7082

epoch:771/50, Iteration 32/32:training loss 1.0335345268249512
Train F1-mic 0.6957, Train F1-mac 0.4846
 F1-mic 0.7081,  F1-mac 0.4698
ogbn-arxiv,dgl,1,770,12.6032,0.7081

 F1-mic 0.7080,  F1-mac 0.4698
ogbn-arxiv,dgl,1,771,12.6194,0.7080

 F1-mic 0.7082,  F1-mac 0.4704
new best val f1: 0.7082073123058248
ogbn-arxiv,dgl,1,772,12.6355,0.7082

 F1-mic 0.7081,  F1-mac 0.4701
ogbn-arxiv,dgl,1,773,12.6515,0.7081

 F1-mic 0.7081,  F1-mac 0.4703
ogbn-arxiv,dgl,1,774,12.6675,0.7081

 F1-mic 0.7082,  F1-mac 0.4699
new best val f1: 0.7082278871674588
ogbn-arxiv,dgl,1,775,12.6836,0.7082

 F1-mic 0.7082,  F1-mac 0.4702
ogbn-arxiv,dgl,1,776,12.6996,0.7082

 F1-mic 0.7084,  F1-mac 0.4702
new best val f1: 0.7083513363372632
ogbn-arxiv,dgl,1,777,12.7157,0.7084

 F1-mic 0.7083,  F1-mac 0.4701
ogbn-arxiv,dgl,1,778,12.7317,0.7083

 F1-mic 0.7084,  F1-mac 0.4701
ogbn-arxiv,dgl,1,779,12.7477,0.7084

epoch:781/50, Iteration 32/32:training loss 1.031821370124817
Train F1-mic 0.6960, Train F1-mac 0.4852
 F1-mic 0.7084,  F1-mac 0.4704
new best val f1: 0.7084336357837994
ogbn-arxiv,dgl,1,780,12.7637,0.7084

 F1-mic 0.7085,  F1-mac 0.4708
new best val f1: 0.7084542106454335
ogbn-arxiv,dgl,1,781,12.7798,0.7085

 F1-mic 0.7085,  F1-mac 0.4707
ogbn-arxiv,dgl,1,782,12.7960,0.7085

 F1-mic 0.7085,  F1-mac 0.4706
new best val f1: 0.7084953603687014
ogbn-arxiv,dgl,1,783,12.8120,0.7085

 F1-mic 0.7085,  F1-mac 0.4707
new best val f1: 0.7085365100919696
ogbn-arxiv,dgl,1,784,12.8280,0.7085

 F1-mic 0.7085,  F1-mac 0.4706
ogbn-arxiv,dgl,1,785,12.8440,0.7085

 F1-mic 0.7085,  F1-mac 0.4707
ogbn-arxiv,dgl,1,786,12.8601,0.7085

 F1-mic 0.7086,  F1-mac 0.4710
new best val f1: 0.7085982346768718
ogbn-arxiv,dgl,1,787,12.8762,0.7086

 F1-mic 0.7086,  F1-mac 0.4710
ogbn-arxiv,dgl,1,788,12.8922,0.7086

 F1-mic 0.7086,  F1-mac 0.4710
ogbn-arxiv,dgl,1,789,12.9083,0.7086

epoch:791/50, Iteration 32/32:training loss 1.0301543474197388
Train F1-mic 0.6964, Train F1-mac 0.4860
 F1-mic 0.7086,  F1-mac 0.4708
new best val f1: 0.70863938440014
ogbn-arxiv,dgl,1,790,12.9243,0.7086

 F1-mic 0.7087,  F1-mac 0.4708
new best val f1: 0.7086599592617739
ogbn-arxiv,dgl,1,791,12.9405,0.7087

 F1-mic 0.7088,  F1-mac 0.4710
new best val f1: 0.7087628335699442
ogbn-arxiv,dgl,1,792,12.9566,0.7088

 F1-mic 0.7087,  F1-mac 0.4710
ogbn-arxiv,dgl,1,793,12.9726,0.7087

 F1-mic 0.7088,  F1-mac 0.4712
new best val f1: 0.7088245581548465
ogbn-arxiv,dgl,1,794,12.9886,0.7088

 F1-mic 0.7088,  F1-mac 0.4713
new best val f1: 0.7088451330164806
ogbn-arxiv,dgl,1,795,13.0046,0.7088

 F1-mic 0.7087,  F1-mac 0.4717
ogbn-arxiv,dgl,1,796,13.0207,0.7087

 F1-mic 0.7088,  F1-mac 0.4714
ogbn-arxiv,dgl,1,797,13.0368,0.7088

 F1-mic 0.7090,  F1-mac 0.4718
new best val f1: 0.7089891570479189
ogbn-arxiv,dgl,1,798,13.0528,0.7090

 F1-mic 0.7089,  F1-mac 0.4717
ogbn-arxiv,dgl,1,799,13.0689,0.7089

epoch:801/50, Iteration 32/32:training loss 1.0285327434539795
Train F1-mic 0.6968, Train F1-mac 0.4867
 F1-mic 0.7090,  F1-mac 0.4723
new best val f1: 0.709030306771187
ogbn-arxiv,dgl,1,800,13.0850,0.7090

 F1-mic 0.7091,  F1-mac 0.4724
new best val f1: 0.709050881632821
ogbn-arxiv,dgl,1,801,13.1011,0.7091

 F1-mic 0.7092,  F1-mac 0.4727
new best val f1: 0.7091537559409913
ogbn-arxiv,dgl,1,802,13.1172,0.7092

 F1-mic 0.7093,  F1-mac 0.4729
new best val f1: 0.7092977799724297
ogbn-arxiv,dgl,1,803,13.1333,0.7093

 F1-mic 0.7092,  F1-mac 0.4726
ogbn-arxiv,dgl,1,804,13.1493,0.7092

 F1-mic 0.7093,  F1-mac 0.4728
ogbn-arxiv,dgl,1,805,13.1654,0.7093

 F1-mic 0.7095,  F1-mac 0.4734
new best val f1: 0.7094829537271362
ogbn-arxiv,dgl,1,806,13.1814,0.7095

 F1-mic 0.7094,  F1-mac 0.4732
ogbn-arxiv,dgl,1,807,13.1975,0.7094

 F1-mic 0.7093,  F1-mac 0.4731
ogbn-arxiv,dgl,1,808,13.2135,0.7093

 F1-mic 0.7096,  F1-mac 0.4735
new best val f1: 0.7095652531736724
ogbn-arxiv,dgl,1,809,13.2296,0.7096

epoch:811/50, Iteration 32/32:training loss 1.026955246925354
Train F1-mic 0.6973, Train F1-mac 0.4878
 F1-mic 0.7095,  F1-mac 0.4734
ogbn-arxiv,dgl,1,810,13.2456,0.7095

 F1-mic 0.7095,  F1-mac 0.4734
ogbn-arxiv,dgl,1,811,13.2618,0.7095

 F1-mic 0.7096,  F1-mac 0.4735
new best val f1: 0.7096269777585746
ogbn-arxiv,dgl,1,812,13.2779,0.7096

 F1-mic 0.7097,  F1-mac 0.4737
new best val f1: 0.7097092772051108
ogbn-arxiv,dgl,1,813,13.2939,0.7097

 F1-mic 0.7098,  F1-mac 0.4736
new best val f1: 0.709771001790013
ogbn-arxiv,dgl,1,814,13.3099,0.7098

 F1-mic 0.7096,  F1-mac 0.4737
ogbn-arxiv,dgl,1,815,13.3260,0.7096

 F1-mic 0.7099,  F1-mac 0.4741
new best val f1: 0.7099150258214514
ogbn-arxiv,dgl,1,816,13.3420,0.7099

 F1-mic 0.7098,  F1-mac 0.4743
ogbn-arxiv,dgl,1,817,13.3585,0.7098

 F1-mic 0.7099,  F1-mac 0.4741
ogbn-arxiv,dgl,1,818,13.3745,0.7099

 F1-mic 0.7099,  F1-mac 0.4745
new best val f1: 0.7099356006830854
ogbn-arxiv,dgl,1,819,13.3906,0.7099

epoch:821/50, Iteration 32/32:training loss 1.025414228439331
Train F1-mic 0.6977, Train F1-mac 0.4887
 F1-mic 0.7101,  F1-mac 0.4745
new best val f1: 0.7100590498528897
ogbn-arxiv,dgl,1,820,13.4066,0.7101

 F1-mic 0.7101,  F1-mac 0.4745
new best val f1: 0.7100796247145239
ogbn-arxiv,dgl,1,821,13.4228,0.7101

 F1-mic 0.7100,  F1-mac 0.4745
ogbn-arxiv,dgl,1,822,13.4389,0.7100

 F1-mic 0.7100,  F1-mac 0.4745
ogbn-arxiv,dgl,1,823,13.4549,0.7100

 F1-mic 0.7102,  F1-mac 0.4747
new best val f1: 0.7102442236075962
ogbn-arxiv,dgl,1,824,13.4709,0.7102

 F1-mic 0.7102,  F1-mac 0.4746
ogbn-arxiv,dgl,1,825,13.4870,0.7102

 F1-mic 0.7102,  F1-mac 0.4747
ogbn-arxiv,dgl,1,826,13.5030,0.7102

 F1-mic 0.7103,  F1-mac 0.4748
new best val f1: 0.7102853733308643
ogbn-arxiv,dgl,1,827,13.5191,0.7103

 F1-mic 0.7103,  F1-mac 0.4748
ogbn-arxiv,dgl,1,828,13.5351,0.7103

 F1-mic 0.7103,  F1-mac 0.4749
new best val f1: 0.7103470979157664
ogbn-arxiv,dgl,1,829,13.5512,0.7103

epoch:831/50, Iteration 32/32:training loss 1.0239102840423584
Train F1-mic 0.6982, Train F1-mac 0.4896
 F1-mic 0.7104,  F1-mac 0.4750
new best val f1: 0.7104499722239368
ogbn-arxiv,dgl,1,830,13.5672,0.7104

 F1-mic 0.7104,  F1-mac 0.4749
ogbn-arxiv,dgl,1,831,13.5834,0.7104

 F1-mic 0.7104,  F1-mac 0.4750
ogbn-arxiv,dgl,1,832,13.5995,0.7104

 F1-mic 0.7106,  F1-mac 0.4752
new best val f1: 0.7105939962553752
ogbn-arxiv,dgl,1,833,13.6155,0.7106

 F1-mic 0.7105,  F1-mac 0.4751
ogbn-arxiv,dgl,1,834,13.6316,0.7105

 F1-mic 0.7107,  F1-mac 0.4751
new best val f1: 0.7106762957019114
ogbn-arxiv,dgl,1,835,13.6476,0.7107

 F1-mic 0.7108,  F1-mac 0.4753
new best val f1: 0.7107585951484476
ogbn-arxiv,dgl,1,836,13.6636,0.7108

 F1-mic 0.7107,  F1-mac 0.4754
ogbn-arxiv,dgl,1,837,13.6797,0.7107

 F1-mic 0.7109,  F1-mac 0.4755
new best val f1: 0.710882044318252
ogbn-arxiv,dgl,1,838,13.6957,0.7109

 F1-mic 0.7110,  F1-mac 0.4759
new best val f1: 0.7109849186264222
ogbn-arxiv,dgl,1,839,13.7118,0.7110

epoch:841/50, Iteration 32/32:training loss 1.0224429368972778
Train F1-mic 0.6988, Train F1-mac 0.4908
 F1-mic 0.7110,  F1-mac 0.4760
new best val f1: 0.7110466432113244
ogbn-arxiv,dgl,1,840,13.7279,0.7110

 F1-mic 0.7111,  F1-mac 0.4759
new best val f1: 0.7110672180729585
ogbn-arxiv,dgl,1,841,13.7440,0.7111

 F1-mic 0.7110,  F1-mac 0.4759
ogbn-arxiv,dgl,1,842,13.7600,0.7110

 F1-mic 0.7111,  F1-mac 0.4763
new best val f1: 0.7111495175194946
ogbn-arxiv,dgl,1,843,13.7761,0.7111

 F1-mic 0.7112,  F1-mac 0.4763
new best val f1: 0.7111906672427627
ogbn-arxiv,dgl,1,844,13.7921,0.7112

 F1-mic 0.7114,  F1-mac 0.4764
new best val f1: 0.7114169907207374
ogbn-arxiv,dgl,1,845,13.8081,0.7114

 F1-mic 0.7115,  F1-mac 0.4766
new best val f1: 0.7114581404440055
ogbn-arxiv,dgl,1,846,13.8241,0.7115

 F1-mic 0.7114,  F1-mac 0.4766
ogbn-arxiv,dgl,1,847,13.8402,0.7114

 F1-mic 0.7115,  F1-mac 0.4766
ogbn-arxiv,dgl,1,848,13.8562,0.7115

 F1-mic 0.7117,  F1-mac 0.4770
new best val f1: 0.7116638890603459
ogbn-arxiv,dgl,1,849,13.8723,0.7117

epoch:851/50, Iteration 32/32:training loss 1.0210118293762207
Train F1-mic 0.6993, Train F1-mac 0.4916
 F1-mic 0.7116,  F1-mac 0.4770
ogbn-arxiv,dgl,1,850,13.8883,0.7116

 F1-mic 0.7116,  F1-mac 0.4772
ogbn-arxiv,dgl,1,851,13.9045,0.7116

 F1-mic 0.7118,  F1-mac 0.4771
new best val f1: 0.7117873382301504
ogbn-arxiv,dgl,1,852,13.9206,0.7118

 F1-mic 0.7119,  F1-mac 0.4774
new best val f1: 0.7119107873999547
ogbn-arxiv,dgl,1,853,13.9366,0.7119

 F1-mic 0.7118,  F1-mac 0.4772
ogbn-arxiv,dgl,1,854,13.9527,0.7118

 F1-mic 0.7117,  F1-mac 0.4772
ogbn-arxiv,dgl,1,855,13.9687,0.7117

 F1-mic 0.7120,  F1-mac 0.4774
new best val f1: 0.712034236569759
ogbn-arxiv,dgl,1,856,13.9848,0.7120

 F1-mic 0.7120,  F1-mac 0.4775
ogbn-arxiv,dgl,1,857,14.0009,0.7120

 F1-mic 0.7119,  F1-mac 0.4775
ogbn-arxiv,dgl,1,858,14.0169,0.7119

 F1-mic 0.7122,  F1-mac 0.4778
new best val f1: 0.7121576857395634
ogbn-arxiv,dgl,1,859,14.0330,0.7122

epoch:861/50, Iteration 32/32:training loss 1.0196096897125244
Train F1-mic 0.6996, Train F1-mac 0.4924
 F1-mic 0.7121,  F1-mac 0.4777
ogbn-arxiv,dgl,1,860,14.0490,0.7121

 F1-mic 0.7119,  F1-mac 0.4776
ogbn-arxiv,dgl,1,861,14.0651,0.7119

 F1-mic 0.7121,  F1-mac 0.4778
ogbn-arxiv,dgl,1,862,14.0812,0.7121

 F1-mic 0.7121,  F1-mac 0.4779
ogbn-arxiv,dgl,1,863,14.0972,0.7121

 F1-mic 0.7121,  F1-mac 0.4781
ogbn-arxiv,dgl,1,864,14.1132,0.7121

 F1-mic 0.7122,  F1-mac 0.4782
ogbn-arxiv,dgl,1,865,14.1292,0.7122

 F1-mic 0.7122,  F1-mac 0.4782
new best val f1: 0.7122399851860995
ogbn-arxiv,dgl,1,866,14.1453,0.7122

 F1-mic 0.7121,  F1-mac 0.4781
ogbn-arxiv,dgl,1,867,14.1613,0.7121

 F1-mic 0.7121,  F1-mac 0.4782
ogbn-arxiv,dgl,1,868,14.1773,0.7121

 F1-mic 0.7121,  F1-mac 0.4781
ogbn-arxiv,dgl,1,869,14.1934,0.7121

epoch:871/50, Iteration 32/32:training loss 1.0182355642318726
Train F1-mic 0.6999, Train F1-mac 0.4930
 F1-mic 0.7123,  F1-mac 0.4782
new best val f1: 0.7123222846326358
ogbn-arxiv,dgl,1,870,14.2094,0.7123

 F1-mic 0.7122,  F1-mac 0.4782
ogbn-arxiv,dgl,1,871,14.2255,0.7122

 F1-mic 0.7121,  F1-mac 0.4783
ogbn-arxiv,dgl,1,872,14.2416,0.7121

 F1-mic 0.7123,  F1-mac 0.4784
ogbn-arxiv,dgl,1,873,14.2576,0.7123

 F1-mic 0.7124,  F1-mac 0.4784
new best val f1: 0.7124251589408062
ogbn-arxiv,dgl,1,874,14.2737,0.7124

 F1-mic 0.7124,  F1-mac 0.4787
ogbn-arxiv,dgl,1,875,14.2897,0.7124

 F1-mic 0.7124,  F1-mac 0.4787
ogbn-arxiv,dgl,1,876,14.3057,0.7124

 F1-mic 0.7124,  F1-mac 0.4787
ogbn-arxiv,dgl,1,877,14.3218,0.7124

 F1-mic 0.7125,  F1-mac 0.4786
new best val f1: 0.7124868835257083
ogbn-arxiv,dgl,1,878,14.3378,0.7125

 F1-mic 0.7124,  F1-mac 0.4789
ogbn-arxiv,dgl,1,879,14.3539,0.7124

epoch:881/50, Iteration 32/32:training loss 1.016891598701477
Train F1-mic 0.7003, Train F1-mac 0.4937
 F1-mic 0.7124,  F1-mac 0.4787
ogbn-arxiv,dgl,1,880,14.3700,0.7124

 F1-mic 0.7124,  F1-mac 0.4788
ogbn-arxiv,dgl,1,881,14.3861,0.7124

 F1-mic 0.7124,  F1-mac 0.4786
ogbn-arxiv,dgl,1,882,14.4022,0.7124

 F1-mic 0.7126,  F1-mac 0.4789
new best val f1: 0.7125691829722445
ogbn-arxiv,dgl,1,883,14.4182,0.7126

 F1-mic 0.7126,  F1-mac 0.4788
ogbn-arxiv,dgl,1,884,14.4342,0.7126

 F1-mic 0.7126,  F1-mac 0.4789
new best val f1: 0.7126309075571465
ogbn-arxiv,dgl,1,885,14.4503,0.7126

 F1-mic 0.7126,  F1-mac 0.4788
ogbn-arxiv,dgl,1,886,14.4663,0.7126

 F1-mic 0.7127,  F1-mac 0.4788
new best val f1: 0.7126720572804147
ogbn-arxiv,dgl,1,887,14.4823,0.7127

 F1-mic 0.7126,  F1-mac 0.4789
ogbn-arxiv,dgl,1,888,14.4984,0.7126

 F1-mic 0.7127,  F1-mac 0.4790
ogbn-arxiv,dgl,1,889,14.5144,0.7127

epoch:891/50, Iteration 32/32:training loss 1.0155705213546753
Train F1-mic 0.7004, Train F1-mac 0.4941
 F1-mic 0.7127,  F1-mac 0.4790
new best val f1: 0.7127132070036829
ogbn-arxiv,dgl,1,890,14.5305,0.7127

 F1-mic 0.7127,  F1-mac 0.4794
ogbn-arxiv,dgl,1,891,14.5466,0.7127

 F1-mic 0.7127,  F1-mac 0.4794
new best val f1: 0.712733781865317
ogbn-arxiv,dgl,1,892,14.5627,0.7127

 F1-mic 0.7128,  F1-mac 0.4795
new best val f1: 0.712754356726951
ogbn-arxiv,dgl,1,893,14.5787,0.7128

 F1-mic 0.7127,  F1-mac 0.4794
ogbn-arxiv,dgl,1,894,14.5947,0.7127

 F1-mic 0.7128,  F1-mac 0.4795
new best val f1: 0.7127749315885851
ogbn-arxiv,dgl,1,895,14.6108,0.7128

 F1-mic 0.7128,  F1-mac 0.4798
new best val f1: 0.7128160813118533
ogbn-arxiv,dgl,1,896,14.6268,0.7128

 F1-mic 0.7128,  F1-mac 0.4801
new best val f1: 0.7128366561734873
ogbn-arxiv,dgl,1,897,14.6428,0.7128

 F1-mic 0.7128,  F1-mac 0.4800
ogbn-arxiv,dgl,1,898,14.6588,0.7128

 F1-mic 0.7129,  F1-mac 0.4801
new best val f1: 0.7128572310351213
ogbn-arxiv,dgl,1,899,14.6749,0.7129

epoch:901/50, Iteration 32/32:training loss 1.014281153678894
Train F1-mic 0.7007, Train F1-mac 0.4947
 F1-mic 0.7131,  F1-mac 0.4802
new best val f1: 0.7130629796514618
ogbn-arxiv,dgl,1,900,14.6910,0.7131

 F1-mic 0.7129,  F1-mac 0.4802
ogbn-arxiv,dgl,1,901,14.7071,0.7129

 F1-mic 0.7130,  F1-mac 0.4803
ogbn-arxiv,dgl,1,902,14.7232,0.7130

 F1-mic 0.7130,  F1-mac 0.4805
ogbn-arxiv,dgl,1,903,14.7392,0.7130

 F1-mic 0.7129,  F1-mac 0.4804
ogbn-arxiv,dgl,1,904,14.7552,0.7129

 F1-mic 0.7131,  F1-mac 0.4803
ogbn-arxiv,dgl,1,905,14.7712,0.7131

 F1-mic 0.7129,  F1-mac 0.4806
ogbn-arxiv,dgl,1,906,14.7872,0.7129

 F1-mic 0.7130,  F1-mac 0.4806
ogbn-arxiv,dgl,1,907,14.8033,0.7130

 F1-mic 0.7130,  F1-mac 0.4804
ogbn-arxiv,dgl,1,908,14.8193,0.7130

 F1-mic 0.7131,  F1-mac 0.4805
new best val f1: 0.71310412937473
ogbn-arxiv,dgl,1,909,14.8354,0.7131

epoch:911/50, Iteration 32/32:training loss 1.0130152702331543
Train F1-mic 0.7011, Train F1-mac 0.4954
 F1-mic 0.7131,  F1-mac 0.4804
ogbn-arxiv,dgl,1,910,14.8514,0.7131

 F1-mic 0.7131,  F1-mac 0.4806
ogbn-arxiv,dgl,1,911,14.8676,0.7131

 F1-mic 0.7134,  F1-mac 0.4808
new best val f1: 0.7133510277143387
ogbn-arxiv,dgl,1,912,14.8836,0.7134

 F1-mic 0.7133,  F1-mac 0.4807
ogbn-arxiv,dgl,1,913,14.8996,0.7133

 F1-mic 0.7133,  F1-mac 0.4808
ogbn-arxiv,dgl,1,914,14.9157,0.7133

 F1-mic 0.7133,  F1-mac 0.4809
ogbn-arxiv,dgl,1,915,14.9317,0.7133

 F1-mic 0.7134,  F1-mac 0.4811
new best val f1: 0.7133921774376066
ogbn-arxiv,dgl,1,916,14.9478,0.7134

 F1-mic 0.7134,  F1-mac 0.4811
ogbn-arxiv,dgl,1,917,14.9639,0.7134

 F1-mic 0.7135,  F1-mac 0.4812
new best val f1: 0.713474476884143
ogbn-arxiv,dgl,1,918,14.9799,0.7135

 F1-mic 0.7135,  F1-mac 0.4814
new best val f1: 0.7135156266074111
ogbn-arxiv,dgl,1,919,14.9960,0.7135

epoch:921/50, Iteration 32/32:training loss 1.0117695331573486
Train F1-mic 0.7013, Train F1-mac 0.4960
 F1-mic 0.7134,  F1-mac 0.4813
ogbn-arxiv,dgl,1,920,15.0120,0.7134

 F1-mic 0.7135,  F1-mac 0.4812
ogbn-arxiv,dgl,1,921,15.0282,0.7135

 F1-mic 0.7136,  F1-mac 0.4822
new best val f1: 0.7136185009155813
ogbn-arxiv,dgl,1,922,15.0443,0.7136

 F1-mic 0.7135,  F1-mac 0.4817
ogbn-arxiv,dgl,1,923,15.0603,0.7135

 F1-mic 0.7136,  F1-mac 0.4817
ogbn-arxiv,dgl,1,924,15.0763,0.7136

 F1-mic 0.7135,  F1-mac 0.4816
ogbn-arxiv,dgl,1,925,15.0923,0.7135

 F1-mic 0.7136,  F1-mac 0.4817
ogbn-arxiv,dgl,1,926,15.1084,0.7136

 F1-mic 0.7136,  F1-mac 0.4817
ogbn-arxiv,dgl,1,927,15.1245,0.7136

 F1-mic 0.7137,  F1-mac 0.4818
new best val f1: 0.7136802255004835
ogbn-arxiv,dgl,1,928,15.1405,0.7137

 F1-mic 0.7137,  F1-mac 0.4818
ogbn-arxiv,dgl,1,929,15.1565,0.7137

epoch:931/50, Iteration 32/32:training loss 1.0105438232421875
Train F1-mic 0.7017, Train F1-mac 0.4964
 F1-mic 0.7137,  F1-mac 0.4818
ogbn-arxiv,dgl,1,930,15.1726,0.7137

 F1-mic 0.7137,  F1-mac 0.4818
new best val f1: 0.7137419500853857
ogbn-arxiv,dgl,1,931,15.1887,0.7137

 F1-mic 0.7138,  F1-mac 0.4818
new best val f1: 0.7137625249470197
ogbn-arxiv,dgl,1,932,15.2047,0.7138

 F1-mic 0.7136,  F1-mac 0.4821
ogbn-arxiv,dgl,1,933,15.2208,0.7136

 F1-mic 0.7139,  F1-mac 0.4823
new best val f1: 0.713927123840092
ogbn-arxiv,dgl,1,934,15.2368,0.7139

 F1-mic 0.7138,  F1-mac 0.4820
ogbn-arxiv,dgl,1,935,15.2528,0.7138

 F1-mic 0.7139,  F1-mac 0.4823
ogbn-arxiv,dgl,1,936,15.2689,0.7139

 F1-mic 0.7138,  F1-mac 0.4824
ogbn-arxiv,dgl,1,937,15.2850,0.7138

 F1-mic 0.7138,  F1-mac 0.4818
ogbn-arxiv,dgl,1,938,15.3010,0.7138

 F1-mic 0.7139,  F1-mac 0.4819
ogbn-arxiv,dgl,1,939,15.3170,0.7139

epoch:941/50, Iteration 32/32:training loss 1.0093426704406738
Train F1-mic 0.7019, Train F1-mac 0.4968
 F1-mic 0.7139,  F1-mac 0.4822
ogbn-arxiv,dgl,1,940,15.3331,0.7139

 F1-mic 0.7139,  F1-mac 0.4823
ogbn-arxiv,dgl,1,941,15.3492,0.7139

 F1-mic 0.7142,  F1-mac 0.4824
new best val f1: 0.7141945970413349
ogbn-arxiv,dgl,1,942,15.3653,0.7142

 F1-mic 0.7142,  F1-mac 0.4824
ogbn-arxiv,dgl,1,943,15.3813,0.7142

 F1-mic 0.7141,  F1-mac 0.4822
ogbn-arxiv,dgl,1,944,15.3973,0.7141

 F1-mic 0.7141,  F1-mac 0.4824
ogbn-arxiv,dgl,1,945,15.4134,0.7141

 F1-mic 0.7141,  F1-mac 0.4826
ogbn-arxiv,dgl,1,946,15.4295,0.7141

 F1-mic 0.7143,  F1-mac 0.4824
new best val f1: 0.7142974713495053
ogbn-arxiv,dgl,1,947,15.4456,0.7143

 F1-mic 0.7142,  F1-mac 0.4824
ogbn-arxiv,dgl,1,948,15.4616,0.7142

 F1-mic 0.7143,  F1-mac 0.4824
ogbn-arxiv,dgl,1,949,15.4777,0.7143

epoch:951/50, Iteration 32/32:training loss 1.0081617832183838
Train F1-mic 0.7021, Train F1-mac 0.4971
 F1-mic 0.7143,  F1-mac 0.4826
ogbn-arxiv,dgl,1,950,15.4937,0.7143

 F1-mic 0.7143,  F1-mac 0.4826
ogbn-arxiv,dgl,1,951,15.5099,0.7143

 F1-mic 0.7143,  F1-mac 0.4825
ogbn-arxiv,dgl,1,952,15.5260,0.7143

 F1-mic 0.7144,  F1-mac 0.4827
new best val f1: 0.7143591959344073
ogbn-arxiv,dgl,1,953,15.5420,0.7144

 F1-mic 0.7144,  F1-mac 0.4827
ogbn-arxiv,dgl,1,954,15.5580,0.7144

 F1-mic 0.7143,  F1-mac 0.4823
ogbn-arxiv,dgl,1,955,15.5741,0.7143

 F1-mic 0.7142,  F1-mac 0.4821
ogbn-arxiv,dgl,1,956,15.5902,0.7142

 F1-mic 0.7144,  F1-mac 0.4821
new best val f1: 0.7144003456576754
ogbn-arxiv,dgl,1,957,15.6062,0.7144

 F1-mic 0.7143,  F1-mac 0.4822
ogbn-arxiv,dgl,1,958,15.6222,0.7143

 F1-mic 0.7143,  F1-mac 0.4820
ogbn-arxiv,dgl,1,959,15.6383,0.7143

epoch:961/50, Iteration 32/32:training loss 1.0070031881332397
Train F1-mic 0.7024, Train F1-mac 0.4975
 F1-mic 0.7144,  F1-mac 0.4823
new best val f1: 0.7144209205193095
ogbn-arxiv,dgl,1,960,15.6543,0.7144

 F1-mic 0.7145,  F1-mac 0.4823
new best val f1: 0.7145032199658456
ogbn-arxiv,dgl,1,961,15.6704,0.7145

 F1-mic 0.7143,  F1-mac 0.4821
ogbn-arxiv,dgl,1,962,15.6865,0.7143

 F1-mic 0.7144,  F1-mac 0.4823
ogbn-arxiv,dgl,1,963,15.7025,0.7144

 F1-mic 0.7145,  F1-mac 0.4824
new best val f1: 0.7145443696891138
ogbn-arxiv,dgl,1,964,15.7185,0.7145

 F1-mic 0.7145,  F1-mac 0.4826
ogbn-arxiv,dgl,1,965,15.7346,0.7145

 F1-mic 0.7145,  F1-mac 0.4824
ogbn-arxiv,dgl,1,966,15.7506,0.7145

 F1-mic 0.7146,  F1-mac 0.4827
new best val f1: 0.7146472439972841
ogbn-arxiv,dgl,1,967,15.7667,0.7146

 F1-mic 0.7147,  F1-mac 0.4828
new best val f1: 0.7147295434438203
ogbn-arxiv,dgl,1,968,15.7827,0.7147

 F1-mic 0.7147,  F1-mac 0.4827
ogbn-arxiv,dgl,1,969,15.7987,0.7147

epoch:971/50, Iteration 32/32:training loss 1.0058600902557373
Train F1-mic 0.7026, Train F1-mac 0.4979
 F1-mic 0.7146,  F1-mac 0.4825
ogbn-arxiv,dgl,1,970,15.8148,0.7146

 F1-mic 0.7146,  F1-mac 0.4826
ogbn-arxiv,dgl,1,971,15.8309,0.7146

 F1-mic 0.7148,  F1-mac 0.4830
new best val f1: 0.7148118428903566
ogbn-arxiv,dgl,1,972,15.8470,0.7148

 F1-mic 0.7149,  F1-mac 0.4832
new best val f1: 0.7148529926136247
ogbn-arxiv,dgl,1,973,15.8631,0.7149

 F1-mic 0.7149,  F1-mac 0.4831
new best val f1: 0.7148735674752588
ogbn-arxiv,dgl,1,974,15.8791,0.7149

 F1-mic 0.7150,  F1-mac 0.4832
new best val f1: 0.7149558669217949
ogbn-arxiv,dgl,1,975,15.8951,0.7150

 F1-mic 0.7149,  F1-mac 0.4832
ogbn-arxiv,dgl,1,976,15.9112,0.7149

 F1-mic 0.7148,  F1-mac 0.4832
ogbn-arxiv,dgl,1,977,15.9273,0.7148

 F1-mic 0.7149,  F1-mac 0.4835
ogbn-arxiv,dgl,1,978,15.9433,0.7149

 F1-mic 0.7150,  F1-mac 0.4832
new best val f1: 0.714976441783429
ogbn-arxiv,dgl,1,979,15.9593,0.7150

epoch:981/50, Iteration 32/32:training loss 1.0047404766082764
Train F1-mic 0.7029, Train F1-mac 0.4983
 F1-mic 0.7150,  F1-mac 0.4834
ogbn-arxiv,dgl,1,980,15.9754,0.7150

 F1-mic 0.7150,  F1-mac 0.4834
new best val f1: 0.7150381663683311
ogbn-arxiv,dgl,1,981,15.9915,0.7150

 F1-mic 0.7151,  F1-mac 0.4834
new best val f1: 0.7151204658148674
ogbn-arxiv,dgl,1,982,16.0076,0.7151

 F1-mic 0.7150,  F1-mac 0.4834
ogbn-arxiv,dgl,1,983,16.0236,0.7150

 F1-mic 0.7151,  F1-mac 0.4835
new best val f1: 0.7151410406765014
ogbn-arxiv,dgl,1,984,16.0397,0.7151

 F1-mic 0.7153,  F1-mac 0.4836
new best val f1: 0.7153262144312079
ogbn-arxiv,dgl,1,985,16.0557,0.7153

 F1-mic 0.7151,  F1-mac 0.4836
ogbn-arxiv,dgl,1,986,16.0718,0.7151

 F1-mic 0.7152,  F1-mac 0.4837
ogbn-arxiv,dgl,1,987,16.0878,0.7152

 F1-mic 0.7156,  F1-mac 0.4839
new best val f1: 0.7155525379091826
ogbn-arxiv,dgl,1,988,16.1038,0.7156

 F1-mic 0.7152,  F1-mac 0.4839
ogbn-arxiv,dgl,1,989,16.1199,0.7152

epoch:991/50, Iteration 32/32:training loss 1.0036375522613525
Train F1-mic 0.7032, Train F1-mac 0.4987
 F1-mic 0.7152,  F1-mac 0.4837
ogbn-arxiv,dgl,1,990,16.1359,0.7152

 F1-mic 0.7156,  F1-mac 0.4840
new best val f1: 0.7155936876324507
ogbn-arxiv,dgl,1,991,16.1521,0.7156

 F1-mic 0.7154,  F1-mac 0.4840
ogbn-arxiv,dgl,1,992,16.1682,0.7154

 F1-mic 0.7151,  F1-mac 0.4839
ogbn-arxiv,dgl,1,993,16.1842,0.7151

 F1-mic 0.7154,  F1-mac 0.4840
ogbn-arxiv,dgl,1,994,16.2002,0.7154

 F1-mic 0.7154,  F1-mac 0.4836
ogbn-arxiv,dgl,1,995,16.2162,0.7154

 F1-mic 0.7153,  F1-mac 0.4840
ogbn-arxiv,dgl,1,996,16.2323,0.7153

 F1-mic 0.7153,  F1-mac 0.4840
ogbn-arxiv,dgl,1,997,16.2484,0.7153

 F1-mic 0.7155,  F1-mac 0.4839
ogbn-arxiv,dgl,1,998,16.2644,0.7155

 F1-mic 0.7154,  F1-mac 0.4839
ogbn-arxiv,dgl,1,999,16.2805,0.7154

epoch:1001/50, Iteration 32/32:training loss 1.0025525093078613
Train F1-mic 0.7034, Train F1-mac 0.4991
 F1-mic 0.7153,  F1-mac 0.4839
ogbn-arxiv,dgl,1,1000,16.2966,0.7153

 F1-mic 0.7155,  F1-mac 0.4838
ogbn-arxiv,dgl,1,1001,16.3127,0.7155

 F1-mic 0.7156,  F1-mac 0.4839
ogbn-arxiv,dgl,1,1002,16.3288,0.7156

 F1-mic 0.7154,  F1-mac 0.4843
ogbn-arxiv,dgl,1,1003,16.3448,0.7154

 F1-mic 0.7157,  F1-mac 0.4844
new best val f1: 0.715655412217353
ogbn-arxiv,dgl,1,1004,16.3608,0.7157

 F1-mic 0.7158,  F1-mac 0.4844
new best val f1: 0.7157582865255231
ogbn-arxiv,dgl,1,1005,16.3768,0.7158

 F1-mic 0.7156,  F1-mac 0.4844
ogbn-arxiv,dgl,1,1006,16.3929,0.7156

 F1-mic 0.7156,  F1-mac 0.4845
ogbn-arxiv,dgl,1,1007,16.4089,0.7156

 F1-mic 0.7159,  F1-mac 0.4846
new best val f1: 0.7158611608336933
ogbn-arxiv,dgl,1,1008,16.4250,0.7159

 F1-mic 0.7157,  F1-mac 0.4846
ogbn-arxiv,dgl,1,1009,16.4410,0.7157

epoch:1011/50, Iteration 32/32:training loss 1.0014840364456177
Train F1-mic 0.7037, Train F1-mac 0.4996
 F1-mic 0.7157,  F1-mac 0.4850
ogbn-arxiv,dgl,1,1010,16.4571,0.7157

 F1-mic 0.7159,  F1-mac 0.4851
ogbn-arxiv,dgl,1,1011,16.4732,0.7159

 F1-mic 0.7160,  F1-mac 0.4852
new best val f1: 0.7159846100034978
ogbn-arxiv,dgl,1,1012,16.4893,0.7160

 F1-mic 0.7158,  F1-mac 0.4852
ogbn-arxiv,dgl,1,1013,16.5053,0.7158

 F1-mic 0.7159,  F1-mac 0.4852
ogbn-arxiv,dgl,1,1014,16.5213,0.7159

 F1-mic 0.7160,  F1-mac 0.4853
ogbn-arxiv,dgl,1,1015,16.5374,0.7160

 F1-mic 0.7159,  F1-mac 0.4853
ogbn-arxiv,dgl,1,1016,16.5534,0.7159

 F1-mic 0.7161,  F1-mac 0.4855
new best val f1: 0.7160669094500339
ogbn-arxiv,dgl,1,1017,16.5695,0.7161

 F1-mic 0.7162,  F1-mac 0.4855
new best val f1: 0.7161697837582043
ogbn-arxiv,dgl,1,1018,16.5855,0.7162

 F1-mic 0.7161,  F1-mac 0.4856
ogbn-arxiv,dgl,1,1019,16.6015,0.7161

epoch:1021/50, Iteration 32/32:training loss 1.0004326105117798
Train F1-mic 0.7040, Train F1-mac 0.5005
 F1-mic 0.7161,  F1-mac 0.4855
ogbn-arxiv,dgl,1,1020,16.6176,0.7161

 F1-mic 0.7161,  F1-mac 0.4854
ogbn-arxiv,dgl,1,1021,16.6338,0.7161

 F1-mic 0.7162,  F1-mac 0.4856
ogbn-arxiv,dgl,1,1022,16.6498,0.7162

 F1-mic 0.7162,  F1-mac 0.4855
new best val f1: 0.7161903586198383
ogbn-arxiv,dgl,1,1023,16.6659,0.7162

 F1-mic 0.7161,  F1-mac 0.4855
ogbn-arxiv,dgl,1,1024,16.6819,0.7161

 F1-mic 0.7162,  F1-mac 0.4856
new best val f1: 0.7162109334814724
ogbn-arxiv,dgl,1,1025,16.6979,0.7162

 F1-mic 0.7163,  F1-mac 0.4857
new best val f1: 0.7162726580663745
ogbn-arxiv,dgl,1,1026,16.7139,0.7163

 F1-mic 0.7162,  F1-mac 0.4855
ogbn-arxiv,dgl,1,1027,16.7301,0.7162

 F1-mic 0.7163,  F1-mac 0.4856
new best val f1: 0.7163343826512766
ogbn-arxiv,dgl,1,1028,16.7461,0.7163

 F1-mic 0.7163,  F1-mac 0.4855
ogbn-arxiv,dgl,1,1029,16.7622,0.7163

epoch:1031/50, Iteration 32/32:training loss 0.9993981122970581
Train F1-mic 0.7042, Train F1-mac 0.5008
 F1-mic 0.7163,  F1-mac 0.4856
ogbn-arxiv,dgl,1,1030,16.7782,0.7163

 F1-mic 0.7163,  F1-mac 0.4857
ogbn-arxiv,dgl,1,1031,16.7943,0.7163

 F1-mic 0.7163,  F1-mac 0.4856
ogbn-arxiv,dgl,1,1032,16.8104,0.7163

 F1-mic 0.7164,  F1-mac 0.4857
new best val f1: 0.7163549575129107
ogbn-arxiv,dgl,1,1033,16.8264,0.7164

 F1-mic 0.7164,  F1-mac 0.4858
new best val f1: 0.7164372569594468
ogbn-arxiv,dgl,1,1034,16.8424,0.7164

 F1-mic 0.7165,  F1-mac 0.4857
new best val f1: 0.7165195564059832
ogbn-arxiv,dgl,1,1035,16.8585,0.7165

 F1-mic 0.7165,  F1-mac 0.4858
ogbn-arxiv,dgl,1,1036,16.8745,0.7165

 F1-mic 0.7165,  F1-mac 0.4858
ogbn-arxiv,dgl,1,1037,16.8906,0.7165

 F1-mic 0.7164,  F1-mac 0.4859
ogbn-arxiv,dgl,1,1038,16.9067,0.7164

 F1-mic 0.7164,  F1-mac 0.4859
ogbn-arxiv,dgl,1,1039,16.9227,0.7164

epoch:1041/50, Iteration 32/32:training loss 0.9983804225921631
Train F1-mic 0.7045, Train F1-mac 0.5016
 F1-mic 0.7166,  F1-mac 0.4859
new best val f1: 0.7165812809908854
ogbn-arxiv,dgl,1,1040,16.9388,0.7166

 F1-mic 0.7166,  F1-mac 0.4860
ogbn-arxiv,dgl,1,1041,16.9549,0.7166

 F1-mic 0.7167,  F1-mac 0.4861
new best val f1: 0.7167047301606897
ogbn-arxiv,dgl,1,1042,16.9711,0.7167

 F1-mic 0.7166,  F1-mac 0.4861
ogbn-arxiv,dgl,1,1043,16.9871,0.7166

 F1-mic 0.7169,  F1-mac 0.4866
new best val f1: 0.7169310536386644
ogbn-arxiv,dgl,1,1044,17.0031,0.7169

 F1-mic 0.7168,  F1-mac 0.4863
ogbn-arxiv,dgl,1,1045,17.0191,0.7168

 F1-mic 0.7167,  F1-mac 0.4862
ogbn-arxiv,dgl,1,1046,17.0352,0.7167

 F1-mic 0.7168,  F1-mac 0.4864
ogbn-arxiv,dgl,1,1047,17.0513,0.7168

 F1-mic 0.7169,  F1-mac 0.4864
ogbn-arxiv,dgl,1,1048,17.0673,0.7169

 F1-mic 0.7169,  F1-mac 0.4865
ogbn-arxiv,dgl,1,1049,17.0834,0.7169

epoch:1051/50, Iteration 32/32:training loss 0.9973734617233276
Train F1-mic 0.7047, Train F1-mac 0.5022
 F1-mic 0.7169,  F1-mac 0.4865
ogbn-arxiv,dgl,1,1050,17.0994,0.7169

 F1-mic 0.7170,  F1-mac 0.4866
new best val f1: 0.7169516285002984
ogbn-arxiv,dgl,1,1051,17.1155,0.7170

 F1-mic 0.7170,  F1-mac 0.4866
ogbn-arxiv,dgl,1,1052,17.1316,0.7170

 F1-mic 0.7169,  F1-mac 0.4865
ogbn-arxiv,dgl,1,1053,17.1477,0.7169

 F1-mic 0.7171,  F1-mac 0.4867
new best val f1: 0.7170750776701028
ogbn-arxiv,dgl,1,1054,17.1637,0.7171

 F1-mic 0.7170,  F1-mac 0.4870
ogbn-arxiv,dgl,1,1055,17.1797,0.7170

 F1-mic 0.7172,  F1-mac 0.4867
new best val f1: 0.7171573771166389
ogbn-arxiv,dgl,1,1056,17.1958,0.7172

 F1-mic 0.7172,  F1-mac 0.4871
new best val f1: 0.7171779519782728
ogbn-arxiv,dgl,1,1057,17.2118,0.7172

 F1-mic 0.7171,  F1-mac 0.4870
ogbn-arxiv,dgl,1,1058,17.2278,0.7171

 F1-mic 0.7171,  F1-mac 0.4871
ogbn-arxiv,dgl,1,1059,17.2439,0.7171

epoch:1061/50, Iteration 32/32:training loss 0.9963824152946472
Train F1-mic 0.7049, Train F1-mac 0.5026
 F1-mic 0.7172,  F1-mac 0.4870
ogbn-arxiv,dgl,1,1060,17.2600,0.7172

 F1-mic 0.7171,  F1-mac 0.4870
ogbn-arxiv,dgl,1,1061,17.2760,0.7171

 F1-mic 0.7171,  F1-mac 0.4870
ogbn-arxiv,dgl,1,1062,17.2921,0.7171

 F1-mic 0.7174,  F1-mac 0.4871
new best val f1: 0.7173631257329794
ogbn-arxiv,dgl,1,1063,17.3081,0.7174

 F1-mic 0.7172,  F1-mac 0.4870
ogbn-arxiv,dgl,1,1064,17.3241,0.7172

 F1-mic 0.7172,  F1-mac 0.4872
ogbn-arxiv,dgl,1,1065,17.3402,0.7172

 F1-mic 0.7174,  F1-mac 0.4877
new best val f1: 0.7174454251795156
ogbn-arxiv,dgl,1,1066,17.3562,0.7174

 F1-mic 0.7172,  F1-mac 0.4876
ogbn-arxiv,dgl,1,1067,17.3723,0.7172

 F1-mic 0.7173,  F1-mac 0.4875
ogbn-arxiv,dgl,1,1068,17.3883,0.7173

 F1-mic 0.7174,  F1-mac 0.4878
ogbn-arxiv,dgl,1,1069,17.4044,0.7174

epoch:1071/50, Iteration 32/32:training loss 0.9954039454460144
Train F1-mic 0.7051, Train F1-mac 0.5035
 F1-mic 0.7174,  F1-mac 0.4880
ogbn-arxiv,dgl,1,1070,17.4204,0.7174

 F1-mic 0.7173,  F1-mac 0.4876
ogbn-arxiv,dgl,1,1071,17.4366,0.7173

 F1-mic 0.7174,  F1-mac 0.4877
ogbn-arxiv,dgl,1,1072,17.4527,0.7174

 F1-mic 0.7174,  F1-mac 0.4877
ogbn-arxiv,dgl,1,1073,17.4688,0.7174

 F1-mic 0.7174,  F1-mac 0.4878
ogbn-arxiv,dgl,1,1074,17.4848,0.7174

 F1-mic 0.7175,  F1-mac 0.4879
new best val f1: 0.717527724626052
ogbn-arxiv,dgl,1,1075,17.5008,0.7175

 F1-mic 0.7175,  F1-mac 0.4879
ogbn-arxiv,dgl,1,1076,17.5168,0.7175

 F1-mic 0.7174,  F1-mac 0.4883
ogbn-arxiv,dgl,1,1077,17.5329,0.7174

 F1-mic 0.7174,  F1-mac 0.4878
ogbn-arxiv,dgl,1,1078,17.5489,0.7174

 F1-mic 0.7175,  F1-mac 0.4882
ogbn-arxiv,dgl,1,1079,17.5650,0.7175

epoch:1081/50, Iteration 32/32:training loss 0.9944347143173218
Train F1-mic 0.7053, Train F1-mac 0.5040
 F1-mic 0.7175,  F1-mac 0.4882
ogbn-arxiv,dgl,1,1080,17.5810,0.7175

 F1-mic 0.7176,  F1-mac 0.4886
new best val f1: 0.71756887434932
ogbn-arxiv,dgl,1,1081,17.5971,0.7176

 F1-mic 0.7177,  F1-mac 0.4890
new best val f1: 0.7177334732423925
ogbn-arxiv,dgl,1,1082,17.6133,0.7177

 F1-mic 0.7177,  F1-mac 0.4890
ogbn-arxiv,dgl,1,1083,17.6293,0.7177

 F1-mic 0.7177,  F1-mac 0.4885
ogbn-arxiv,dgl,1,1084,17.6454,0.7177

 F1-mic 0.7178,  F1-mac 0.4893
new best val f1: 0.7177746229656605
ogbn-arxiv,dgl,1,1085,17.6614,0.7178

 F1-mic 0.7178,  F1-mac 0.4893
ogbn-arxiv,dgl,1,1086,17.6775,0.7178

 F1-mic 0.7178,  F1-mac 0.4896
new best val f1: 0.7177951978272946
ogbn-arxiv,dgl,1,1087,17.6936,0.7178

 F1-mic 0.7177,  F1-mac 0.4893
ogbn-arxiv,dgl,1,1088,17.7096,0.7177

 F1-mic 0.7178,  F1-mac 0.4893
ogbn-arxiv,dgl,1,1089,17.7257,0.7178

epoch:1091/50, Iteration 32/32:training loss 0.9934791922569275
Train F1-mic 0.7055, Train F1-mac 0.5046
 F1-mic 0.7179,  F1-mac 0.4897
new best val f1: 0.7178774972738309
ogbn-arxiv,dgl,1,1090,17.7417,0.7179

 F1-mic 0.7177,  F1-mac 0.4894
ogbn-arxiv,dgl,1,1091,17.7578,0.7177

 F1-mic 0.7178,  F1-mac 0.4896
ogbn-arxiv,dgl,1,1092,17.7740,0.7178

 F1-mic 0.7180,  F1-mac 0.4898
new best val f1: 0.7180420961669033
ogbn-arxiv,dgl,1,1093,17.7900,0.7180

 F1-mic 0.7178,  F1-mac 0.4896
ogbn-arxiv,dgl,1,1094,17.8060,0.7178

 F1-mic 0.7179,  F1-mac 0.4898
ogbn-arxiv,dgl,1,1095,17.8221,0.7179

 F1-mic 0.7180,  F1-mac 0.4896
ogbn-arxiv,dgl,1,1096,17.8381,0.7180

 F1-mic 0.7179,  F1-mac 0.4898
ogbn-arxiv,dgl,1,1097,17.8542,0.7179

 F1-mic 0.7178,  F1-mac 0.4894
ogbn-arxiv,dgl,1,1098,17.8703,0.7178

 F1-mic 0.7180,  F1-mac 0.4898
ogbn-arxiv,dgl,1,1099,17.8864,0.7180

epoch:1101/50, Iteration 32/32:training loss 0.9925367832183838
Train F1-mic 0.7058, Train F1-mac 0.5050
 F1-mic 0.7178,  F1-mac 0.4900
ogbn-arxiv,dgl,1,1100,17.9024,0.7178

 F1-mic 0.7180,  F1-mac 0.4898
ogbn-arxiv,dgl,1,1101,17.9185,0.7180

 F1-mic 0.7180,  F1-mac 0.4895
ogbn-arxiv,dgl,1,1102,17.9346,0.7180

 F1-mic 0.7179,  F1-mac 0.4897
ogbn-arxiv,dgl,1,1103,17.9507,0.7179

 F1-mic 0.7179,  F1-mac 0.4895
ogbn-arxiv,dgl,1,1104,17.9667,0.7179

 F1-mic 0.7179,  F1-mac 0.4895
ogbn-arxiv,dgl,1,1105,17.9828,0.7179

 F1-mic 0.7179,  F1-mac 0.4899
ogbn-arxiv,dgl,1,1106,17.9988,0.7179

 F1-mic 0.7179,  F1-mac 0.4898
ogbn-arxiv,dgl,1,1107,18.0149,0.7179

 F1-mic 0.7179,  F1-mac 0.4896
ogbn-arxiv,dgl,1,1108,18.0309,0.7179

 F1-mic 0.7181,  F1-mac 0.4897
new best val f1: 0.7180832458901713
ogbn-arxiv,dgl,1,1109,18.0470,0.7181

epoch:1111/50, Iteration 32/32:training loss 0.9916027784347534
Train F1-mic 0.7060, Train F1-mac 0.5055
 F1-mic 0.7180,  F1-mac 0.4899
ogbn-arxiv,dgl,1,1110,18.0630,0.7180

 F1-mic 0.7180,  F1-mac 0.4899
ogbn-arxiv,dgl,1,1111,18.0791,0.7180

 F1-mic 0.7180,  F1-mac 0.4895
ogbn-arxiv,dgl,1,1112,18.0952,0.7180

 F1-mic 0.7180,  F1-mac 0.4898
ogbn-arxiv,dgl,1,1113,18.1112,0.7180

 F1-mic 0.7179,  F1-mac 0.4897
ogbn-arxiv,dgl,1,1114,18.1273,0.7179

 F1-mic 0.7180,  F1-mac 0.4896
ogbn-arxiv,dgl,1,1115,18.1433,0.7180

 F1-mic 0.7180,  F1-mac 0.4898
ogbn-arxiv,dgl,1,1116,18.1594,0.7180

 F1-mic 0.7180,  F1-mac 0.4900
ogbn-arxiv,dgl,1,1117,18.1754,0.7180

 F1-mic 0.7180,  F1-mac 0.4898
ogbn-arxiv,dgl,1,1118,18.1915,0.7180

 F1-mic 0.7180,  F1-mac 0.4901
ogbn-arxiv,dgl,1,1119,18.2075,0.7180

epoch:1121/50, Iteration 32/32:training loss 0.990680456161499
Train F1-mic 0.7062, Train F1-mac 0.5065
 F1-mic 0.7180,  F1-mac 0.4901
ogbn-arxiv,dgl,1,1120,18.2236,0.7180

 F1-mic 0.7179,  F1-mac 0.4898
ogbn-arxiv,dgl,1,1121,18.2398,0.7179

 F1-mic 0.7180,  F1-mac 0.4900
ogbn-arxiv,dgl,1,1122,18.2559,0.7180

 F1-mic 0.7179,  F1-mac 0.4897
ogbn-arxiv,dgl,1,1123,18.2719,0.7179

 F1-mic 0.7180,  F1-mac 0.4898
ogbn-arxiv,dgl,1,1124,18.2879,0.7180

 F1-mic 0.7179,  F1-mac 0.4898
ogbn-arxiv,dgl,1,1125,18.3039,0.7179

 F1-mic 0.7179,  F1-mac 0.4899
ogbn-arxiv,dgl,1,1126,18.3200,0.7179

 F1-mic 0.7180,  F1-mac 0.4899
ogbn-arxiv,dgl,1,1127,18.3361,0.7180

 F1-mic 0.7180,  F1-mac 0.4903
ogbn-arxiv,dgl,1,1128,18.3521,0.7180

 F1-mic 0.7180,  F1-mac 0.4903
ogbn-arxiv,dgl,1,1129,18.3682,0.7180

epoch:1131/50, Iteration 32/32:training loss 0.9897704720497131
Train F1-mic 0.7063, Train F1-mac 0.5070
 F1-mic 0.7181,  F1-mac 0.4904
new best val f1: 0.7181449704750736
ogbn-arxiv,dgl,1,1130,18.3842,0.7181

 F1-mic 0.7180,  F1-mac 0.4901
ogbn-arxiv,dgl,1,1131,18.4003,0.7180

 F1-mic 0.7182,  F1-mac 0.4906
new best val f1: 0.7181655453367075
ogbn-arxiv,dgl,1,1132,18.4164,0.7182

 F1-mic 0.7181,  F1-mac 0.4903
ogbn-arxiv,dgl,1,1133,18.4324,0.7181

 F1-mic 0.7181,  F1-mac 0.4905
ogbn-arxiv,dgl,1,1134,18.4484,0.7181

 F1-mic 0.7181,  F1-mac 0.4904
ogbn-arxiv,dgl,1,1135,18.4645,0.7181

 F1-mic 0.7181,  F1-mac 0.4902
ogbn-arxiv,dgl,1,1136,18.4805,0.7181

 F1-mic 0.7183,  F1-mac 0.4905
new best val f1: 0.718288994506512
ogbn-arxiv,dgl,1,1137,18.4966,0.7183

 F1-mic 0.7182,  F1-mac 0.4906
ogbn-arxiv,dgl,1,1138,18.5126,0.7182

 F1-mic 0.7182,  F1-mac 0.4905
ogbn-arxiv,dgl,1,1139,18.5287,0.7182

epoch:1141/50, Iteration 32/32:training loss 0.9888662695884705
Train F1-mic 0.7063, Train F1-mac 0.5070
 F1-mic 0.7182,  F1-mac 0.4905
ogbn-arxiv,dgl,1,1140,18.5447,0.7182

 F1-mic 0.7183,  F1-mac 0.4906
new best val f1: 0.718309569368146
ogbn-arxiv,dgl,1,1141,18.5608,0.7183

 F1-mic 0.7183,  F1-mac 0.4906
ogbn-arxiv,dgl,1,1142,18.5770,0.7183

 F1-mic 0.7184,  F1-mac 0.4908
new best val f1: 0.7184330185379504
ogbn-arxiv,dgl,1,1143,18.5930,0.7184

 F1-mic 0.7184,  F1-mac 0.4907
ogbn-arxiv,dgl,1,1144,18.6090,0.7184

 F1-mic 0.7184,  F1-mac 0.4910
ogbn-arxiv,dgl,1,1145,18.6250,0.7184

 F1-mic 0.7185,  F1-mac 0.4911
new best val f1: 0.7184535933995844
ogbn-arxiv,dgl,1,1146,18.6410,0.7185

 F1-mic 0.7184,  F1-mac 0.4915
ogbn-arxiv,dgl,1,1147,18.6571,0.7184

 F1-mic 0.7183,  F1-mac 0.4910
ogbn-arxiv,dgl,1,1148,18.6731,0.7183

 F1-mic 0.7184,  F1-mac 0.4913
ogbn-arxiv,dgl,1,1149,18.6891,0.7184

epoch:1151/50, Iteration 32/32:training loss 0.9879762530326843
Train F1-mic 0.7065, Train F1-mac 0.5077
 F1-mic 0.7185,  F1-mac 0.4917
new best val f1: 0.7185358928461205
ogbn-arxiv,dgl,1,1150,18.7052,0.7185

 F1-mic 0.7185,  F1-mac 0.4912
ogbn-arxiv,dgl,1,1151,18.7213,0.7185

 F1-mic 0.7185,  F1-mac 0.4910
ogbn-arxiv,dgl,1,1152,18.7374,0.7185

 F1-mic 0.7185,  F1-mac 0.4915
ogbn-arxiv,dgl,1,1153,18.7534,0.7185

 F1-mic 0.7185,  F1-mac 0.4915
ogbn-arxiv,dgl,1,1154,18.7694,0.7185

 F1-mic 0.7186,  F1-mac 0.4915
new best val f1: 0.7185770425693887
ogbn-arxiv,dgl,1,1155,18.7855,0.7186

 F1-mic 0.7186,  F1-mac 0.4916
new best val f1: 0.7186181922926568
ogbn-arxiv,dgl,1,1156,18.8015,0.7186

 F1-mic 0.7187,  F1-mac 0.4914
new best val f1: 0.7186799168775589
ogbn-arxiv,dgl,1,1157,18.8176,0.7187

 F1-mic 0.7188,  F1-mac 0.4917
new best val f1: 0.7188239409089973
ogbn-arxiv,dgl,1,1158,18.8336,0.7188

 F1-mic 0.7187,  F1-mac 0.4921
ogbn-arxiv,dgl,1,1159,18.8497,0.7187

epoch:1161/50, Iteration 32/32:training loss 0.9870925545692444
Train F1-mic 0.7068, Train F1-mac 0.5089
 F1-mic 0.7188,  F1-mac 0.4921
ogbn-arxiv,dgl,1,1160,18.8657,0.7188

 F1-mic 0.7188,  F1-mac 0.4926
ogbn-arxiv,dgl,1,1161,18.8819,0.7188

 F1-mic 0.7187,  F1-mac 0.4923
ogbn-arxiv,dgl,1,1162,18.8980,0.7187

 F1-mic 0.7189,  F1-mac 0.4921
new best val f1: 0.7188856654938995
ogbn-arxiv,dgl,1,1163,18.9140,0.7189

 F1-mic 0.7189,  F1-mac 0.4925
new best val f1: 0.7189268152171676
ogbn-arxiv,dgl,1,1164,18.9300,0.7189

 F1-mic 0.7189,  F1-mac 0.4923
ogbn-arxiv,dgl,1,1165,18.9461,0.7189

 F1-mic 0.7189,  F1-mac 0.4923
ogbn-arxiv,dgl,1,1166,18.9621,0.7189

 F1-mic 0.7188,  F1-mac 0.4925
ogbn-arxiv,dgl,1,1167,18.9782,0.7188

 F1-mic 0.7188,  F1-mac 0.4925
ogbn-arxiv,dgl,1,1168,18.9942,0.7188

 F1-mic 0.7189,  F1-mac 0.4927
ogbn-arxiv,dgl,1,1169,19.0102,0.7189

epoch:1171/50, Iteration 32/32:training loss 0.9862228631973267
Train F1-mic 0.7071, Train F1-mac 0.5093
 F1-mic 0.7188,  F1-mac 0.4924
ogbn-arxiv,dgl,1,1170,19.0263,0.7188

 F1-mic 0.7190,  F1-mac 0.4925
new best val f1: 0.719009114663704
ogbn-arxiv,dgl,1,1171,19.0424,0.7190

 F1-mic 0.7190,  F1-mac 0.4926
ogbn-arxiv,dgl,1,1172,19.0585,0.7190

 F1-mic 0.7190,  F1-mac 0.4927
new best val f1: 0.719029689525338
ogbn-arxiv,dgl,1,1173,19.0745,0.7190

 F1-mic 0.7189,  F1-mac 0.4927
ogbn-arxiv,dgl,1,1174,19.0905,0.7189

 F1-mic 0.7191,  F1-mac 0.4928
new best val f1: 0.719050264386972
ogbn-arxiv,dgl,1,1175,19.1065,0.7191

 F1-mic 0.7191,  F1-mac 0.4930
new best val f1: 0.71909141411024
ogbn-arxiv,dgl,1,1176,19.1226,0.7191

 F1-mic 0.7191,  F1-mac 0.4929
ogbn-arxiv,dgl,1,1177,19.1386,0.7191

 F1-mic 0.7191,  F1-mac 0.4929
ogbn-arxiv,dgl,1,1178,19.1546,0.7191

 F1-mic 0.7191,  F1-mac 0.4931
new best val f1: 0.7191325638335082
ogbn-arxiv,dgl,1,1179,19.1706,0.7191

epoch:1181/50, Iteration 32/32:training loss 0.9853554368019104
Train F1-mic 0.7071, Train F1-mac 0.5097
 F1-mic 0.7192,  F1-mac 0.4932
new best val f1: 0.7191531386951423
ogbn-arxiv,dgl,1,1180,19.1867,0.7192

 F1-mic 0.7192,  F1-mac 0.4933
ogbn-arxiv,dgl,1,1181,19.2028,0.7192

 F1-mic 0.7192,  F1-mac 0.4931
new best val f1: 0.7191942884184105
ogbn-arxiv,dgl,1,1182,19.2189,0.7192

 F1-mic 0.7192,  F1-mac 0.4932
new best val f1: 0.7192354381416785
ogbn-arxiv,dgl,1,1183,19.2350,0.7192

 F1-mic 0.7193,  F1-mac 0.4932
new best val f1: 0.7192560130033124
ogbn-arxiv,dgl,1,1184,19.2510,0.7193

 F1-mic 0.7194,  F1-mac 0.4935
new best val f1: 0.7193588873114828
ogbn-arxiv,dgl,1,1185,19.2670,0.7194

 F1-mic 0.7194,  F1-mac 0.4937
new best val f1: 0.719420611896385
ogbn-arxiv,dgl,1,1186,19.2830,0.7194

 F1-mic 0.7194,  F1-mac 0.4934
ogbn-arxiv,dgl,1,1187,19.2991,0.7194

 F1-mic 0.7194,  F1-mac 0.4933
ogbn-arxiv,dgl,1,1188,19.3151,0.7194

 F1-mic 0.7194,  F1-mac 0.4935
ogbn-arxiv,dgl,1,1189,19.3312,0.7194

epoch:1191/50, Iteration 32/32:training loss 0.9844980835914612
Train F1-mic 0.7073, Train F1-mac 0.5098
 F1-mic 0.7193,  F1-mac 0.4936
ogbn-arxiv,dgl,1,1190,19.3473,0.7193

 F1-mic 0.7195,  F1-mac 0.4937
new best val f1: 0.7194823364812871
ogbn-arxiv,dgl,1,1191,19.3634,0.7195

 F1-mic 0.7194,  F1-mac 0.4938
ogbn-arxiv,dgl,1,1192,19.3795,0.7194

 F1-mic 0.7194,  F1-mac 0.4936
ogbn-arxiv,dgl,1,1193,19.3955,0.7194

 F1-mic 0.7194,  F1-mac 0.4940
ogbn-arxiv,dgl,1,1194,19.4115,0.7194

 F1-mic 0.7196,  F1-mac 0.4942
new best val f1: 0.7195646359278234
ogbn-arxiv,dgl,1,1195,19.4275,0.7196

 F1-mic 0.7195,  F1-mac 0.4943
ogbn-arxiv,dgl,1,1196,19.4436,0.7195

 F1-mic 0.7195,  F1-mac 0.4941
ogbn-arxiv,dgl,1,1197,19.4597,0.7195

 F1-mic 0.7194,  F1-mac 0.4941
ogbn-arxiv,dgl,1,1198,19.4757,0.7194

 F1-mic 0.7195,  F1-mac 0.4943
ogbn-arxiv,dgl,1,1199,19.4918,0.7195

epoch:1201/50, Iteration 32/32:training loss 0.9836499691009521
Train F1-mic 0.7075, Train F1-mac 0.5103
 F1-mic 0.7196,  F1-mac 0.4943
new best val f1: 0.7196263605127255
ogbn-arxiv,dgl,1,1200,19.5079,0.7196

 F1-mic 0.7195,  F1-mac 0.4943
ogbn-arxiv,dgl,1,1201,19.5240,0.7195

 F1-mic 0.7195,  F1-mac 0.4943
ogbn-arxiv,dgl,1,1202,19.5401,0.7195

 F1-mic 0.7196,  F1-mac 0.4944
new best val f1: 0.7196469353743596
ogbn-arxiv,dgl,1,1203,19.5562,0.7196

 F1-mic 0.7197,  F1-mac 0.4946
new best val f1: 0.7197292348208958
ogbn-arxiv,dgl,1,1204,19.5722,0.7197

 F1-mic 0.7197,  F1-mac 0.4949
ogbn-arxiv,dgl,1,1205,19.5886,0.7197

 F1-mic 0.7197,  F1-mac 0.4950
ogbn-arxiv,dgl,1,1206,19.6047,0.7197

 F1-mic 0.7197,  F1-mac 0.4946
new best val f1: 0.7197498096825299
ogbn-arxiv,dgl,1,1207,19.6208,0.7197

 F1-mic 0.7197,  F1-mac 0.4948
ogbn-arxiv,dgl,1,1208,19.6368,0.7197

 F1-mic 0.7198,  F1-mac 0.4949
new best val f1: 0.7198115342674322
ogbn-arxiv,dgl,1,1209,19.6529,0.7198

epoch:1211/50, Iteration 32/32:training loss 0.9828118681907654
Train F1-mic 0.7078, Train F1-mac 0.5110
 F1-mic 0.7197,  F1-mac 0.4949
ogbn-arxiv,dgl,1,1210,19.6689,0.7197

 F1-mic 0.7197,  F1-mac 0.4949
ogbn-arxiv,dgl,1,1211,19.6851,0.7197

 F1-mic 0.7198,  F1-mac 0.4951
ogbn-arxiv,dgl,1,1212,19.7012,0.7198

 F1-mic 0.7198,  F1-mac 0.4950
ogbn-arxiv,dgl,1,1213,19.7172,0.7198

 F1-mic 0.7198,  F1-mac 0.4950
ogbn-arxiv,dgl,1,1214,19.7333,0.7198

 F1-mic 0.7199,  F1-mac 0.4952
new best val f1: 0.7198938337139683
ogbn-arxiv,dgl,1,1215,19.7493,0.7199

 F1-mic 0.7198,  F1-mac 0.4952
ogbn-arxiv,dgl,1,1216,19.7654,0.7198

 F1-mic 0.7198,  F1-mac 0.4949
ogbn-arxiv,dgl,1,1217,19.7814,0.7198

 F1-mic 0.7197,  F1-mac 0.4949
ogbn-arxiv,dgl,1,1218,19.7974,0.7197

 F1-mic 0.7198,  F1-mac 0.4952
ogbn-arxiv,dgl,1,1219,19.8135,0.7198

epoch:1221/50, Iteration 32/32:training loss 0.9819818139076233
Train F1-mic 0.7081, Train F1-mac 0.5116
 F1-mic 0.7198,  F1-mac 0.4950
ogbn-arxiv,dgl,1,1220,19.8296,0.7198

 F1-mic 0.7199,  F1-mac 0.4954
new best val f1: 0.7199349834372363
ogbn-arxiv,dgl,1,1221,19.8457,0.7199

 F1-mic 0.7197,  F1-mac 0.4949
ogbn-arxiv,dgl,1,1222,19.8618,0.7197

 F1-mic 0.7199,  F1-mac 0.4954
ogbn-arxiv,dgl,1,1223,19.8779,0.7199

 F1-mic 0.7199,  F1-mac 0.4951
ogbn-arxiv,dgl,1,1224,19.8938,0.7199

 F1-mic 0.7197,  F1-mac 0.4949
ogbn-arxiv,dgl,1,1225,19.9099,0.7197

 F1-mic 0.7199,  F1-mac 0.4953
ogbn-arxiv,dgl,1,1226,19.9259,0.7199

 F1-mic 0.7198,  F1-mac 0.4950
ogbn-arxiv,dgl,1,1227,19.9419,0.7198

 F1-mic 0.7197,  F1-mac 0.4949
ogbn-arxiv,dgl,1,1228,19.9579,0.7197

 F1-mic 0.7199,  F1-mac 0.4953
ogbn-arxiv,dgl,1,1229,19.9739,0.7199

epoch:1231/50, Iteration 32/32:training loss 0.9811602830886841
Train F1-mic 0.7083, Train F1-mac 0.5118
 F1-mic 0.7199,  F1-mac 0.4951
ogbn-arxiv,dgl,1,1230,19.9900,0.7199

 F1-mic 0.7200,  F1-mac 0.4954
new best val f1: 0.7200172828837726
ogbn-arxiv,dgl,1,1231,20.0061,0.7200

 F1-mic 0.7201,  F1-mac 0.4956
new best val f1: 0.7200584326070408
ogbn-arxiv,dgl,1,1232,20.0222,0.7201

 F1-mic 0.7200,  F1-mac 0.4953
ogbn-arxiv,dgl,1,1233,20.0382,0.7200

 F1-mic 0.7198,  F1-mac 0.4952
ogbn-arxiv,dgl,1,1234,20.0542,0.7198

 F1-mic 0.7200,  F1-mac 0.4958
ogbn-arxiv,dgl,1,1235,20.0703,0.7200

 F1-mic 0.7200,  F1-mac 0.4955
ogbn-arxiv,dgl,1,1236,20.0865,0.7200

 F1-mic 0.7200,  F1-mac 0.4955
ogbn-arxiv,dgl,1,1237,20.1026,0.7200

 F1-mic 0.7201,  F1-mac 0.4958
new best val f1: 0.7201201571919429
ogbn-arxiv,dgl,1,1238,20.1186,0.7201

 F1-mic 0.7200,  F1-mac 0.4955
ogbn-arxiv,dgl,1,1239,20.1346,0.7200

epoch:1241/50, Iteration 32/32:training loss 0.9803443551063538
Train F1-mic 0.7083, Train F1-mac 0.5119
 F1-mic 0.7201,  F1-mac 0.4955
ogbn-arxiv,dgl,1,1240,20.1507,0.7201

 F1-mic 0.7201,  F1-mac 0.4957
ogbn-arxiv,dgl,1,1241,20.1669,0.7201

 F1-mic 0.7201,  F1-mac 0.4960
ogbn-arxiv,dgl,1,1242,20.1829,0.7201

 F1-mic 0.7201,  F1-mac 0.4956
ogbn-arxiv,dgl,1,1243,20.1989,0.7201

 F1-mic 0.7201,  F1-mac 0.4961
ogbn-arxiv,dgl,1,1244,20.2149,0.7201

 F1-mic 0.7202,  F1-mac 0.4962
new best val f1: 0.7201818817768451
ogbn-arxiv,dgl,1,1245,20.2310,0.7202

 F1-mic 0.7200,  F1-mac 0.4955
ogbn-arxiv,dgl,1,1246,20.2470,0.7200

 F1-mic 0.7202,  F1-mac 0.4961
new best val f1: 0.7202024566384791
ogbn-arxiv,dgl,1,1247,20.2631,0.7202

 F1-mic 0.7202,  F1-mac 0.4963
new best val f1: 0.7202436063617471
ogbn-arxiv,dgl,1,1248,20.2791,0.7202

 F1-mic 0.7202,  F1-mac 0.4961
ogbn-arxiv,dgl,1,1249,20.2952,0.7202

epoch:1251/50, Iteration 32/32:training loss 0.9795368313789368
Train F1-mic 0.7085, Train F1-mac 0.5123
 F1-mic 0.7202,  F1-mac 0.4961
ogbn-arxiv,dgl,1,1250,20.3112,0.7202

 F1-mic 0.7203,  F1-mac 0.4963
new best val f1: 0.7202847560850153
ogbn-arxiv,dgl,1,1251,20.3274,0.7203

 F1-mic 0.7202,  F1-mac 0.4960
ogbn-arxiv,dgl,1,1252,20.3434,0.7202

 F1-mic 0.7200,  F1-mac 0.4958
ogbn-arxiv,dgl,1,1253,20.3595,0.7200

 F1-mic 0.7202,  F1-mac 0.4962
ogbn-arxiv,dgl,1,1254,20.3755,0.7202

 F1-mic 0.7202,  F1-mac 0.4962
ogbn-arxiv,dgl,1,1255,20.3915,0.7202

 F1-mic 0.7202,  F1-mac 0.4965
ogbn-arxiv,dgl,1,1256,20.4075,0.7202

 F1-mic 0.7202,  F1-mac 0.4964
ogbn-arxiv,dgl,1,1257,20.4235,0.7202

 F1-mic 0.7203,  F1-mac 0.4965
new best val f1: 0.7203053309466494
ogbn-arxiv,dgl,1,1258,20.4395,0.7203

 F1-mic 0.7202,  F1-mac 0.4962
ogbn-arxiv,dgl,1,1259,20.4556,0.7202

epoch:1261/50, Iteration 32/32:training loss 0.9787350296974182
Train F1-mic 0.7087, Train F1-mac 0.5127
 F1-mic 0.7201,  F1-mac 0.4961
ogbn-arxiv,dgl,1,1260,20.4717,0.7201

 F1-mic 0.7202,  F1-mac 0.4964
ogbn-arxiv,dgl,1,1261,20.4878,0.7202

 F1-mic 0.7202,  F1-mac 0.4963
ogbn-arxiv,dgl,1,1262,20.5039,0.7202

 F1-mic 0.7202,  F1-mac 0.4964
ogbn-arxiv,dgl,1,1263,20.5199,0.7202

 F1-mic 0.7203,  F1-mac 0.4965
ogbn-arxiv,dgl,1,1264,20.5360,0.7203

 F1-mic 0.7202,  F1-mac 0.4967
ogbn-arxiv,dgl,1,1265,20.5520,0.7202

 F1-mic 0.7202,  F1-mac 0.4967
ogbn-arxiv,dgl,1,1266,20.5681,0.7202

 F1-mic 0.7203,  F1-mac 0.4966
ogbn-arxiv,dgl,1,1267,20.5841,0.7203

 F1-mic 0.7203,  F1-mac 0.4965
ogbn-arxiv,dgl,1,1268,20.6002,0.7203

 F1-mic 0.7203,  F1-mac 0.4970
ogbn-arxiv,dgl,1,1269,20.6162,0.7203

epoch:1271/50, Iteration 32/32:training loss 0.977944016456604
Train F1-mic 0.7088, Train F1-mac 0.5132
 F1-mic 0.7203,  F1-mac 0.4970
new best val f1: 0.7203464806699176
ogbn-arxiv,dgl,1,1270,20.6323,0.7203

 F1-mic 0.7203,  F1-mac 0.4970
ogbn-arxiv,dgl,1,1271,20.6484,0.7203

 F1-mic 0.7204,  F1-mac 0.4969
new best val f1: 0.7203876303931858
ogbn-arxiv,dgl,1,1272,20.6645,0.7204

 F1-mic 0.7203,  F1-mac 0.4968
ogbn-arxiv,dgl,1,1273,20.6806,0.7203

 F1-mic 0.7204,  F1-mac 0.4970
new best val f1: 0.7204493549780878
ogbn-arxiv,dgl,1,1274,20.6966,0.7204

 F1-mic 0.7205,  F1-mac 0.4971
new best val f1: 0.7204699298397218
ogbn-arxiv,dgl,1,1275,20.7126,0.7205

 F1-mic 0.7204,  F1-mac 0.4973
ogbn-arxiv,dgl,1,1276,20.7287,0.7204

 F1-mic 0.7204,  F1-mac 0.4975
ogbn-arxiv,dgl,1,1277,20.7448,0.7204

 F1-mic 0.7205,  F1-mac 0.4975
ogbn-arxiv,dgl,1,1278,20.7608,0.7205

 F1-mic 0.7205,  F1-mac 0.4975
new best val f1: 0.720531654424624
ogbn-arxiv,dgl,1,1279,20.7769,0.7205

epoch:1281/50, Iteration 32/32:training loss 0.9771618247032166
Train F1-mic 0.7091, Train F1-mac 0.5136
 F1-mic 0.7203,  F1-mac 0.4986
ogbn-arxiv,dgl,1,1280,20.7929,0.7203

 F1-mic 0.7204,  F1-mac 0.4986
ogbn-arxiv,dgl,1,1281,20.8091,0.7204

 F1-mic 0.7206,  F1-mac 0.4987
new best val f1: 0.7206139538711602
ogbn-arxiv,dgl,1,1282,20.8252,0.7206

 F1-mic 0.7204,  F1-mac 0.4992
ogbn-arxiv,dgl,1,1283,20.8412,0.7204

 F1-mic 0.7206,  F1-mac 0.4995
ogbn-arxiv,dgl,1,1284,20.8572,0.7206

 F1-mic 0.7206,  F1-mac 0.4990
new best val f1: 0.7206345287327943
ogbn-arxiv,dgl,1,1285,20.8733,0.7206

 F1-mic 0.7203,  F1-mac 0.4992
ogbn-arxiv,dgl,1,1286,20.8894,0.7203

 F1-mic 0.7205,  F1-mac 0.4993
ogbn-arxiv,dgl,1,1287,20.9055,0.7205

 F1-mic 0.7208,  F1-mac 0.4995
new best val f1: 0.7208197024875008
ogbn-arxiv,dgl,1,1288,20.9220,0.7208

 F1-mic 0.7206,  F1-mac 0.4995
ogbn-arxiv,dgl,1,1289,20.9381,0.7206

epoch:1291/50, Iteration 32/32:training loss 0.9763821363449097
Train F1-mic 0.7092, Train F1-mac 0.5144
 F1-mic 0.7206,  F1-mac 0.4995
ogbn-arxiv,dgl,1,1290,20.9541,0.7206

 F1-mic 0.7207,  F1-mac 0.4996
ogbn-arxiv,dgl,1,1291,20.9703,0.7207

 F1-mic 0.7206,  F1-mac 0.4994
ogbn-arxiv,dgl,1,1292,20.9863,0.7206

 F1-mic 0.7206,  F1-mac 0.4994
ogbn-arxiv,dgl,1,1293,21.0024,0.7206

 F1-mic 0.7208,  F1-mac 0.4997
ogbn-arxiv,dgl,1,1294,21.0184,0.7208

 F1-mic 0.7206,  F1-mac 0.4994
ogbn-arxiv,dgl,1,1295,21.0344,0.7206

 F1-mic 0.7207,  F1-mac 0.4992
ogbn-arxiv,dgl,1,1296,21.0505,0.7207

 F1-mic 0.7207,  F1-mac 0.4992
ogbn-arxiv,dgl,1,1297,21.0666,0.7207

 F1-mic 0.7206,  F1-mac 0.4993
ogbn-arxiv,dgl,1,1298,21.0826,0.7206

 F1-mic 0.7207,  F1-mac 0.4995
ogbn-arxiv,dgl,1,1299,21.0987,0.7207

epoch:1301/50, Iteration 32/32:training loss 0.9756151437759399
Train F1-mic 0.7094, Train F1-mac 0.5151
 F1-mic 0.7208,  F1-mac 0.4993
ogbn-arxiv,dgl,1,1300,21.1148,0.7208

 F1-mic 0.7206,  F1-mac 0.4992
ogbn-arxiv,dgl,1,1301,21.1309,0.7206

 F1-mic 0.7207,  F1-mac 0.4992
ogbn-arxiv,dgl,1,1302,21.1470,0.7207

 F1-mic 0.7208,  F1-mac 0.4994
ogbn-arxiv,dgl,1,1303,21.1630,0.7208

 F1-mic 0.7207,  F1-mac 0.4993
ogbn-arxiv,dgl,1,1304,21.1790,0.7207

 F1-mic 0.7206,  F1-mac 0.4989
ogbn-arxiv,dgl,1,1305,21.1950,0.7206

 F1-mic 0.7208,  F1-mac 0.4992
ogbn-arxiv,dgl,1,1306,21.2111,0.7208

 F1-mic 0.7209,  F1-mac 0.4997
new best val f1: 0.720902001934037
ogbn-arxiv,dgl,1,1307,21.2272,0.7209

 F1-mic 0.7208,  F1-mac 0.4995
ogbn-arxiv,dgl,1,1308,21.2432,0.7208

 F1-mic 0.7208,  F1-mac 0.4994
ogbn-arxiv,dgl,1,1309,21.2593,0.7208

epoch:1311/50, Iteration 32/32:training loss 0.9748534560203552
Train F1-mic 0.7095, Train F1-mac 0.5155
 F1-mic 0.7209,  F1-mac 0.4995
ogbn-arxiv,dgl,1,1310,21.2753,0.7209

 F1-mic 0.7208,  F1-mac 0.4996
ogbn-arxiv,dgl,1,1311,21.2914,0.7208

 F1-mic 0.7207,  F1-mac 0.4993
ogbn-arxiv,dgl,1,1312,21.3075,0.7207

 F1-mic 0.7207,  F1-mac 0.4996
ogbn-arxiv,dgl,1,1313,21.3236,0.7207

 F1-mic 0.7207,  F1-mac 0.4995
ogbn-arxiv,dgl,1,1314,21.3396,0.7207

 F1-mic 0.7209,  F1-mac 0.4999
ogbn-arxiv,dgl,1,1315,21.3556,0.7209

 F1-mic 0.7207,  F1-mac 0.4996
ogbn-arxiv,dgl,1,1316,21.3717,0.7207

 F1-mic 0.7207,  F1-mac 0.4997
ogbn-arxiv,dgl,1,1317,21.3877,0.7207

 F1-mic 0.7210,  F1-mac 0.5000
new best val f1: 0.7210048762422073
ogbn-arxiv,dgl,1,1318,21.4038,0.7210

 F1-mic 0.7210,  F1-mac 0.5001
ogbn-arxiv,dgl,1,1319,21.4198,0.7210

epoch:1321/50, Iteration 32/32:training loss 0.9740927219390869
Train F1-mic 0.7097, Train F1-mac 0.5161
 F1-mic 0.7208,  F1-mac 0.4997
ogbn-arxiv,dgl,1,1320,21.4359,0.7208

 F1-mic 0.7209,  F1-mac 0.5000
ogbn-arxiv,dgl,1,1321,21.4521,0.7209

 F1-mic 0.7211,  F1-mac 0.5000
new best val f1: 0.7210666008271095
ogbn-arxiv,dgl,1,1322,21.4682,0.7211

 F1-mic 0.7209,  F1-mac 0.5000
ogbn-arxiv,dgl,1,1323,21.4842,0.7209

 F1-mic 0.7210,  F1-mac 0.5000
ogbn-arxiv,dgl,1,1324,21.5002,0.7210

 F1-mic 0.7210,  F1-mac 0.5000
ogbn-arxiv,dgl,1,1325,21.5163,0.7210

 F1-mic 0.7208,  F1-mac 0.4997
ogbn-arxiv,dgl,1,1326,21.5324,0.7208

 F1-mic 0.7210,  F1-mac 0.5001
ogbn-arxiv,dgl,1,1327,21.5484,0.7210

 F1-mic 0.7210,  F1-mac 0.5000
ogbn-arxiv,dgl,1,1328,21.5645,0.7210

 F1-mic 0.7210,  F1-mac 0.5001
ogbn-arxiv,dgl,1,1329,21.5806,0.7210

epoch:1331/50, Iteration 32/32:training loss 0.9733458757400513
Train F1-mic 0.7097, Train F1-mac 0.5163
 F1-mic 0.7211,  F1-mac 0.5003
new best val f1: 0.7211283254120116
ogbn-arxiv,dgl,1,1330,21.5966,0.7211

 F1-mic 0.7211,  F1-mac 0.5002
ogbn-arxiv,dgl,1,1331,21.6127,0.7211

 F1-mic 0.7209,  F1-mac 0.5001
ogbn-arxiv,dgl,1,1332,21.6288,0.7209

 F1-mic 0.7211,  F1-mac 0.5002
ogbn-arxiv,dgl,1,1333,21.6449,0.7211

 F1-mic 0.7212,  F1-mac 0.5006
new best val f1: 0.7212106248585478
ogbn-arxiv,dgl,1,1334,21.6609,0.7212

 F1-mic 0.7209,  F1-mac 0.5002
ogbn-arxiv,dgl,1,1335,21.6769,0.7209

 F1-mic 0.7211,  F1-mac 0.5002
ogbn-arxiv,dgl,1,1336,21.6930,0.7211

 F1-mic 0.7211,  F1-mac 0.5005
ogbn-arxiv,dgl,1,1337,21.7090,0.7211

 F1-mic 0.7211,  F1-mac 0.5004
ogbn-arxiv,dgl,1,1338,21.7251,0.7211

 F1-mic 0.7211,  F1-mac 0.5002
ogbn-arxiv,dgl,1,1339,21.7411,0.7211

epoch:1341/50, Iteration 32/32:training loss 0.9725945591926575
Train F1-mic 0.7099, Train F1-mac 0.5166
 F1-mic 0.7211,  F1-mac 0.5005
ogbn-arxiv,dgl,1,1340,21.7574,0.7211

 F1-mic 0.7211,  F1-mac 0.5002
ogbn-arxiv,dgl,1,1341,21.7735,0.7211

 F1-mic 0.7211,  F1-mac 0.5004
ogbn-arxiv,dgl,1,1342,21.7896,0.7211

 F1-mic 0.7211,  F1-mac 0.5006
ogbn-arxiv,dgl,1,1343,21.8057,0.7211

 F1-mic 0.7212,  F1-mac 0.5004
ogbn-arxiv,dgl,1,1344,21.8217,0.7212

 F1-mic 0.7211,  F1-mac 0.5002
ogbn-arxiv,dgl,1,1345,21.8377,0.7211

 F1-mic 0.7214,  F1-mac 0.5008
new best val f1: 0.7214369483365224
ogbn-arxiv,dgl,1,1346,21.8538,0.7214

 F1-mic 0.7214,  F1-mac 0.5007
ogbn-arxiv,dgl,1,1347,21.8699,0.7214

 F1-mic 0.7212,  F1-mac 0.5004
ogbn-arxiv,dgl,1,1348,21.8859,0.7212

 F1-mic 0.7213,  F1-mac 0.5003
ogbn-arxiv,dgl,1,1349,21.9019,0.7213

epoch:1351/50, Iteration 32/32:training loss 0.9718544483184814
Train F1-mic 0.7101, Train F1-mac 0.5171
 F1-mic 0.7214,  F1-mac 0.5004
ogbn-arxiv,dgl,1,1350,21.9180,0.7214

 F1-mic 0.7212,  F1-mac 0.5005
ogbn-arxiv,dgl,1,1351,21.9341,0.7212

 F1-mic 0.7214,  F1-mac 0.5006
ogbn-arxiv,dgl,1,1352,21.9502,0.7214

 F1-mic 0.7213,  F1-mac 0.5006
ogbn-arxiv,dgl,1,1353,21.9662,0.7213

 F1-mic 0.7212,  F1-mac 0.5004
ogbn-arxiv,dgl,1,1354,21.9822,0.7212

 F1-mic 0.7211,  F1-mac 0.5003
ogbn-arxiv,dgl,1,1355,21.9983,0.7211

 F1-mic 0.7212,  F1-mac 0.5009
ogbn-arxiv,dgl,1,1356,22.0144,0.7212

 F1-mic 0.7213,  F1-mac 0.5009
ogbn-arxiv,dgl,1,1357,22.0305,0.7213

 F1-mic 0.7215,  F1-mac 0.5011
new best val f1: 0.7214575231981564
ogbn-arxiv,dgl,1,1358,22.0465,0.7215

 F1-mic 0.7212,  F1-mac 0.5004
ogbn-arxiv,dgl,1,1359,22.0626,0.7212

epoch:1361/50, Iteration 32/32:training loss 0.9711189270019531
Train F1-mic 0.7103, Train F1-mac 0.5174
 F1-mic 0.7214,  F1-mac 0.5009
ogbn-arxiv,dgl,1,1360,22.0786,0.7214

 F1-mic 0.7213,  F1-mac 0.5006
ogbn-arxiv,dgl,1,1361,22.0947,0.7213

 F1-mic 0.7215,  F1-mac 0.5007
ogbn-arxiv,dgl,1,1362,22.1108,0.7215

 F1-mic 0.7215,  F1-mac 0.5008
ogbn-arxiv,dgl,1,1363,22.1269,0.7215

 F1-mic 0.7213,  F1-mac 0.5005
ogbn-arxiv,dgl,1,1364,22.1429,0.7213

 F1-mic 0.7212,  F1-mac 0.5006
ogbn-arxiv,dgl,1,1365,22.1590,0.7212

 F1-mic 0.7214,  F1-mac 0.5007
ogbn-arxiv,dgl,1,1366,22.1750,0.7214

 F1-mic 0.7214,  F1-mac 0.5005
ogbn-arxiv,dgl,1,1367,22.1911,0.7214

 F1-mic 0.7215,  F1-mac 0.5008
new best val f1: 0.7214986729214246
ogbn-arxiv,dgl,1,1368,22.2072,0.7215

 F1-mic 0.7213,  F1-mac 0.5005
ogbn-arxiv,dgl,1,1369,22.2232,0.7213

epoch:1371/50, Iteration 32/32:training loss 0.970395028591156
Train F1-mic 0.7105, Train F1-mac 0.5178
 F1-mic 0.7214,  F1-mac 0.5008
ogbn-arxiv,dgl,1,1370,22.2393,0.7214

 F1-mic 0.7215,  F1-mac 0.5006
ogbn-arxiv,dgl,1,1371,22.2554,0.7215

 F1-mic 0.7214,  F1-mac 0.5007
ogbn-arxiv,dgl,1,1372,22.2715,0.7214

 F1-mic 0.7216,  F1-mac 0.5010
new best val f1: 0.7215603975063268
ogbn-arxiv,dgl,1,1373,22.2875,0.7216

 F1-mic 0.7214,  F1-mac 0.5007
ogbn-arxiv,dgl,1,1374,22.3037,0.7214

 F1-mic 0.7215,  F1-mac 0.5007
ogbn-arxiv,dgl,1,1375,22.3198,0.7215

 F1-mic 0.7215,  F1-mac 0.5009
ogbn-arxiv,dgl,1,1376,22.3358,0.7215

 F1-mic 0.7214,  F1-mac 0.5007
ogbn-arxiv,dgl,1,1377,22.3519,0.7214

 F1-mic 0.7213,  F1-mac 0.5006
ogbn-arxiv,dgl,1,1378,22.3679,0.7213

 F1-mic 0.7215,  F1-mac 0.5006
ogbn-arxiv,dgl,1,1379,22.3840,0.7215

epoch:1381/50, Iteration 32/32:training loss 0.9696704745292664
Train F1-mic 0.7105, Train F1-mac 0.5180
 F1-mic 0.7215,  F1-mac 0.5008
ogbn-arxiv,dgl,1,1380,22.4001,0.7215

 F1-mic 0.7215,  F1-mac 0.5009
ogbn-arxiv,dgl,1,1381,22.4162,0.7215

 F1-mic 0.7215,  F1-mac 0.5008
ogbn-arxiv,dgl,1,1382,22.4323,0.7215

 F1-mic 0.7215,  F1-mac 0.5009
ogbn-arxiv,dgl,1,1383,22.4483,0.7215

 F1-mic 0.7215,  F1-mac 0.5010
ogbn-arxiv,dgl,1,1384,22.4643,0.7215

 F1-mic 0.7215,  F1-mac 0.5009
ogbn-arxiv,dgl,1,1385,22.4803,0.7215

 F1-mic 0.7215,  F1-mac 0.5006
ogbn-arxiv,dgl,1,1386,22.4964,0.7215

 F1-mic 0.7215,  F1-mac 0.5007
ogbn-arxiv,dgl,1,1387,22.5125,0.7215

 F1-mic 0.7214,  F1-mac 0.5007
ogbn-arxiv,dgl,1,1388,22.5285,0.7214

 F1-mic 0.7214,  F1-mac 0.5006
ogbn-arxiv,dgl,1,1389,22.5446,0.7214

epoch:1391/50, Iteration 32/32:training loss 0.9689582586288452
Train F1-mic 0.7105, Train F1-mac 0.5181
 F1-mic 0.7213,  F1-mac 0.5006
ogbn-arxiv,dgl,1,1390,22.5607,0.7213

 F1-mic 0.7213,  F1-mac 0.5006
ogbn-arxiv,dgl,1,1391,22.5768,0.7213

 F1-mic 0.7214,  F1-mac 0.5007
ogbn-arxiv,dgl,1,1392,22.5929,0.7214

 F1-mic 0.7214,  F1-mac 0.5005
ogbn-arxiv,dgl,1,1393,22.6089,0.7214

 F1-mic 0.7213,  F1-mac 0.5003
ogbn-arxiv,dgl,1,1394,22.6249,0.7213

 F1-mic 0.7215,  F1-mac 0.5009
ogbn-arxiv,dgl,1,1395,22.6410,0.7215

 F1-mic 0.7214,  F1-mac 0.5005
ogbn-arxiv,dgl,1,1396,22.6570,0.7214

 F1-mic 0.7215,  F1-mac 0.5010
ogbn-arxiv,dgl,1,1397,22.6731,0.7215

 F1-mic 0.7216,  F1-mac 0.5012
new best val f1: 0.7216221220912289
ogbn-arxiv,dgl,1,1398,22.6892,0.7216

 F1-mic 0.7216,  F1-mac 0.5008
ogbn-arxiv,dgl,1,1399,22.7053,0.7216

epoch:1401/50, Iteration 32/32:training loss 0.968243420124054
Train F1-mic 0.7107, Train F1-mac 0.5184
 F1-mic 0.7215,  F1-mac 0.5006
ogbn-arxiv,dgl,1,1400,22.7214,0.7215

 F1-mic 0.7215,  F1-mac 0.5008
ogbn-arxiv,dgl,1,1401,22.7375,0.7215

 F1-mic 0.7216,  F1-mac 0.5009
ogbn-arxiv,dgl,1,1402,22.7537,0.7216

 F1-mic 0.7215,  F1-mac 0.5008
ogbn-arxiv,dgl,1,1403,22.7697,0.7215

 F1-mic 0.7216,  F1-mac 0.5015
ogbn-arxiv,dgl,1,1404,22.7857,0.7216

 F1-mic 0.7216,  F1-mac 0.5012
ogbn-arxiv,dgl,1,1405,22.8017,0.7216

 F1-mic 0.7216,  F1-mac 0.5015
ogbn-arxiv,dgl,1,1406,22.8178,0.7216

 F1-mic 0.7217,  F1-mac 0.5015
new best val f1: 0.7216632718144972
ogbn-arxiv,dgl,1,1407,22.8339,0.7217

 F1-mic 0.7217,  F1-mac 0.5012
ogbn-arxiv,dgl,1,1408,22.8499,0.7217

 F1-mic 0.7217,  F1-mac 0.5016
ogbn-arxiv,dgl,1,1409,22.8660,0.7217

epoch:1411/50, Iteration 32/32:training loss 0.9675338268280029
Train F1-mic 0.7110, Train F1-mac 0.5189
 F1-mic 0.7215,  F1-mac 0.5014
ogbn-arxiv,dgl,1,1410,22.8820,0.7215

 F1-mic 0.7216,  F1-mac 0.5019
ogbn-arxiv,dgl,1,1411,22.8982,0.7216

 F1-mic 0.7216,  F1-mac 0.5019
ogbn-arxiv,dgl,1,1412,22.9143,0.7216

 F1-mic 0.7216,  F1-mac 0.5020
ogbn-arxiv,dgl,1,1413,22.9303,0.7216

 F1-mic 0.7217,  F1-mac 0.5017
new best val f1: 0.7217455712610333
ogbn-arxiv,dgl,1,1414,22.9464,0.7217

 F1-mic 0.7217,  F1-mac 0.5021
ogbn-arxiv,dgl,1,1415,22.9624,0.7217

 F1-mic 0.7217,  F1-mac 0.5024
ogbn-arxiv,dgl,1,1416,22.9785,0.7217

 F1-mic 0.7216,  F1-mac 0.5019
ogbn-arxiv,dgl,1,1417,22.9945,0.7216

 F1-mic 0.7217,  F1-mac 0.5024
ogbn-arxiv,dgl,1,1418,23.0106,0.7217

 F1-mic 0.7217,  F1-mac 0.5022
ogbn-arxiv,dgl,1,1419,23.0266,0.7217

epoch:1421/50, Iteration 32/32:training loss 0.9668346643447876
Train F1-mic 0.7111, Train F1-mac 0.5195
 F1-mic 0.7219,  F1-mac 0.5025
new best val f1: 0.7218895952924717
ogbn-arxiv,dgl,1,1420,23.0427,0.7219

 F1-mic 0.7219,  F1-mac 0.5022
ogbn-arxiv,dgl,1,1421,23.0588,0.7219

 F1-mic 0.7218,  F1-mac 0.5025
ogbn-arxiv,dgl,1,1422,23.0749,0.7218

 F1-mic 0.7218,  F1-mac 0.5022
ogbn-arxiv,dgl,1,1423,23.0909,0.7218

 F1-mic 0.7219,  F1-mac 0.5023
new best val f1: 0.7219101701541057
ogbn-arxiv,dgl,1,1424,23.1070,0.7219

 F1-mic 0.7216,  F1-mac 0.5024
ogbn-arxiv,dgl,1,1425,23.1230,0.7216

 F1-mic 0.7219,  F1-mac 0.5023
ogbn-arxiv,dgl,1,1426,23.1391,0.7219

 F1-mic 0.7218,  F1-mac 0.5021
ogbn-arxiv,dgl,1,1427,23.1551,0.7218

 F1-mic 0.7216,  F1-mac 0.5021
ogbn-arxiv,dgl,1,1428,23.1712,0.7216

 F1-mic 0.7218,  F1-mac 0.5023
ogbn-arxiv,dgl,1,1429,23.1872,0.7218

epoch:1431/50, Iteration 32/32:training loss 0.9661370515823364
Train F1-mic 0.7113, Train F1-mac 0.5203
 F1-mic 0.7218,  F1-mac 0.5023
ogbn-arxiv,dgl,1,1430,23.2033,0.7218

 F1-mic 0.7218,  F1-mac 0.5021
ogbn-arxiv,dgl,1,1431,23.2194,0.7218

 F1-mic 0.7217,  F1-mac 0.5020
ogbn-arxiv,dgl,1,1432,23.2355,0.7217

 F1-mic 0.7218,  F1-mac 0.5019
ogbn-arxiv,dgl,1,1433,23.2515,0.7218

 F1-mic 0.7219,  F1-mac 0.5021
new best val f1: 0.7219307450157396
ogbn-arxiv,dgl,1,1434,23.2675,0.7219

 F1-mic 0.7218,  F1-mac 0.5019
ogbn-arxiv,dgl,1,1435,23.2836,0.7218

 F1-mic 0.7218,  F1-mac 0.5020
ogbn-arxiv,dgl,1,1436,23.2996,0.7218

 F1-mic 0.7219,  F1-mac 0.5020
ogbn-arxiv,dgl,1,1437,23.3157,0.7219

 F1-mic 0.7218,  F1-mac 0.5021
ogbn-arxiv,dgl,1,1438,23.3317,0.7218

 F1-mic 0.7217,  F1-mac 0.5017
ogbn-arxiv,dgl,1,1439,23.3478,0.7217

epoch:1441/50, Iteration 32/32:training loss 0.9654474258422852
Train F1-mic 0.7113, Train F1-mac 0.5204
 F1-mic 0.7218,  F1-mac 0.5019
ogbn-arxiv,dgl,1,1440,23.3639,0.7218

 F1-mic 0.7218,  F1-mac 0.5020
ogbn-arxiv,dgl,1,1441,23.3800,0.7218

 F1-mic 0.7218,  F1-mac 0.5019
ogbn-arxiv,dgl,1,1442,23.3961,0.7218

 F1-mic 0.7218,  F1-mac 0.5019
ogbn-arxiv,dgl,1,1443,23.4121,0.7218

 F1-mic 0.7219,  F1-mac 0.5020
ogbn-arxiv,dgl,1,1444,23.4282,0.7219

 F1-mic 0.7219,  F1-mac 0.5020
ogbn-arxiv,dgl,1,1445,23.4442,0.7219

 F1-mic 0.7218,  F1-mac 0.5021
ogbn-arxiv,dgl,1,1446,23.4603,0.7218

 F1-mic 0.7218,  F1-mac 0.5020
ogbn-arxiv,dgl,1,1447,23.4763,0.7218

 F1-mic 0.7218,  F1-mac 0.5022
ogbn-arxiv,dgl,1,1448,23.4924,0.7218

 F1-mic 0.7220,  F1-mac 0.5023
new best val f1: 0.7219924696006419
ogbn-arxiv,dgl,1,1449,23.5085,0.7220

epoch:1451/50, Iteration 32/32:training loss 0.9647599458694458
Train F1-mic 0.7115, Train F1-mac 0.5209
 F1-mic 0.7219,  F1-mac 0.5023
ogbn-arxiv,dgl,1,1450,23.5245,0.7219

 F1-mic 0.7220,  F1-mac 0.5022
ogbn-arxiv,dgl,1,1451,23.5406,0.7220

 F1-mic 0.7219,  F1-mac 0.5022
ogbn-arxiv,dgl,1,1452,23.5567,0.7219

 F1-mic 0.7220,  F1-mac 0.5021
ogbn-arxiv,dgl,1,1453,23.5728,0.7220

 F1-mic 0.7219,  F1-mac 0.5021
ogbn-arxiv,dgl,1,1454,23.5888,0.7219

 F1-mic 0.7219,  F1-mac 0.5023
ogbn-arxiv,dgl,1,1455,23.6048,0.7219

 F1-mic 0.7218,  F1-mac 0.5022
ogbn-arxiv,dgl,1,1456,23.6209,0.7218

 F1-mic 0.7218,  F1-mac 0.5021
ogbn-arxiv,dgl,1,1457,23.6369,0.7218

 F1-mic 0.7218,  F1-mac 0.5020
ogbn-arxiv,dgl,1,1458,23.6529,0.7218

 F1-mic 0.7220,  F1-mac 0.5023
ogbn-arxiv,dgl,1,1459,23.6690,0.7220

epoch:1461/50, Iteration 32/32:training loss 0.9640800356864929
Train F1-mic 0.7115, Train F1-mac 0.5208
 F1-mic 0.7219,  F1-mac 0.5025
ogbn-arxiv,dgl,1,1460,23.6851,0.7219

 F1-mic 0.7220,  F1-mac 0.5026
ogbn-arxiv,dgl,1,1461,23.7012,0.7220

 F1-mic 0.7220,  F1-mac 0.5027
ogbn-arxiv,dgl,1,1462,23.7172,0.7220

 F1-mic 0.7219,  F1-mac 0.5025
ogbn-arxiv,dgl,1,1463,23.7333,0.7219

 F1-mic 0.7219,  F1-mac 0.5025
ogbn-arxiv,dgl,1,1464,23.7493,0.7219

 F1-mic 0.7220,  F1-mac 0.5027
ogbn-arxiv,dgl,1,1465,23.7653,0.7220

 F1-mic 0.7220,  F1-mac 0.5028
ogbn-arxiv,dgl,1,1466,23.7814,0.7220

 F1-mic 0.7221,  F1-mac 0.5040
new best val f1: 0.7221159187704462
ogbn-arxiv,dgl,1,1467,23.7974,0.7221

 F1-mic 0.7218,  F1-mac 0.5027
ogbn-arxiv,dgl,1,1468,23.8135,0.7218

 F1-mic 0.7221,  F1-mac 0.5030
ogbn-arxiv,dgl,1,1469,23.8296,0.7221

epoch:1471/50, Iteration 32/32:training loss 0.9633998870849609
Train F1-mic 0.7116, Train F1-mac 0.5211
 F1-mic 0.7221,  F1-mac 0.5028
ogbn-arxiv,dgl,1,1470,23.8456,0.7221

 F1-mic 0.7220,  F1-mac 0.5027
ogbn-arxiv,dgl,1,1471,23.8618,0.7220

 F1-mic 0.7220,  F1-mac 0.5037
ogbn-arxiv,dgl,1,1472,23.8779,0.7220

 F1-mic 0.7222,  F1-mac 0.5041
new best val f1: 0.7221776433553484
ogbn-arxiv,dgl,1,1473,23.8939,0.7222

 F1-mic 0.7221,  F1-mac 0.5041
ogbn-arxiv,dgl,1,1474,23.9099,0.7221

 F1-mic 0.7220,  F1-mac 0.5039
ogbn-arxiv,dgl,1,1475,23.9260,0.7220

 F1-mic 0.7222,  F1-mac 0.5041
ogbn-arxiv,dgl,1,1476,23.9421,0.7222

 F1-mic 0.7220,  F1-mac 0.5041
ogbn-arxiv,dgl,1,1477,23.9582,0.7220

 F1-mic 0.7222,  F1-mac 0.5040
new best val f1: 0.7221982182169825
ogbn-arxiv,dgl,1,1478,23.9742,0.7222

 F1-mic 0.7221,  F1-mac 0.5041
ogbn-arxiv,dgl,1,1479,23.9903,0.7221

epoch:1481/50, Iteration 32/32:training loss 0.9627279043197632
Train F1-mic 0.7117, Train F1-mac 0.5216
 F1-mic 0.7221,  F1-mac 0.5042
ogbn-arxiv,dgl,1,1480,24.0063,0.7221

 F1-mic 0.7222,  F1-mac 0.5041
new best val f1: 0.7222393679402506
ogbn-arxiv,dgl,1,1481,24.0225,0.7222

 F1-mic 0.7223,  F1-mac 0.5043
new best val f1: 0.7222599428018847
ogbn-arxiv,dgl,1,1482,24.0386,0.7223

 F1-mic 0.7220,  F1-mac 0.5041
ogbn-arxiv,dgl,1,1483,24.0546,0.7220

 F1-mic 0.7222,  F1-mac 0.5041
ogbn-arxiv,dgl,1,1484,24.0706,0.7222

 F1-mic 0.7222,  F1-mac 0.5045
ogbn-arxiv,dgl,1,1485,24.0867,0.7222

 F1-mic 0.7223,  F1-mac 0.5041
ogbn-arxiv,dgl,1,1486,24.1027,0.7223

 F1-mic 0.7223,  F1-mac 0.5045
new best val f1: 0.7223010925251527
ogbn-arxiv,dgl,1,1487,24.1187,0.7223

 F1-mic 0.7223,  F1-mac 0.5041
new best val f1: 0.7223216673867868
ogbn-arxiv,dgl,1,1488,24.1348,0.7223

 F1-mic 0.7223,  F1-mac 0.5041
ogbn-arxiv,dgl,1,1489,24.1508,0.7223

epoch:1491/50, Iteration 32/32:training loss 0.9620599746704102
Train F1-mic 0.7119, Train F1-mac 0.5217
 F1-mic 0.7223,  F1-mac 0.5037
ogbn-arxiv,dgl,1,1490,24.1668,0.7223

 F1-mic 0.7222,  F1-mac 0.5042
ogbn-arxiv,dgl,1,1491,24.1829,0.7222

 F1-mic 0.7224,  F1-mac 0.5043
new best val f1: 0.722424541694957
ogbn-arxiv,dgl,1,1492,24.1990,0.7224

 F1-mic 0.7223,  F1-mac 0.5041
ogbn-arxiv,dgl,1,1493,24.2150,0.7223

 F1-mic 0.7223,  F1-mac 0.5041
ogbn-arxiv,dgl,1,1494,24.2311,0.7223

 F1-mic 0.7223,  F1-mac 0.5042
ogbn-arxiv,dgl,1,1495,24.2471,0.7223

 F1-mic 0.7225,  F1-mac 0.5043
new best val f1: 0.7224656914182254
ogbn-arxiv,dgl,1,1496,24.2631,0.7225

 F1-mic 0.7224,  F1-mac 0.5043
ogbn-arxiv,dgl,1,1497,24.2792,0.7224

 F1-mic 0.7224,  F1-mac 0.5043
ogbn-arxiv,dgl,1,1498,24.2952,0.7224

 F1-mic 0.7226,  F1-mac 0.5045
new best val f1: 0.7225685657263954
ogbn-arxiv,dgl,1,1499,24.3113,0.7226

epoch:1501/50, Iteration 32/32:training loss 0.9613950252532959
Train F1-mic 0.7120, Train F1-mac 0.5220
 F1-mic 0.7224,  F1-mac 0.5043
ogbn-arxiv,dgl,1,1500,24.3274,0.7224

 F1-mic 0.7224,  F1-mac 0.5043
ogbn-arxiv,dgl,1,1501,24.3435,0.7224

 F1-mic 0.7225,  F1-mac 0.5044
ogbn-arxiv,dgl,1,1502,24.3596,0.7225

 F1-mic 0.7224,  F1-mac 0.5044
ogbn-arxiv,dgl,1,1503,24.3757,0.7224

 F1-mic 0.7225,  F1-mac 0.5044
ogbn-arxiv,dgl,1,1504,24.3917,0.7225

 F1-mic 0.7225,  F1-mac 0.5043
ogbn-arxiv,dgl,1,1505,24.4077,0.7225

 F1-mic 0.7224,  F1-mac 0.5045
ogbn-arxiv,dgl,1,1506,24.4237,0.7224

 F1-mic 0.7225,  F1-mac 0.5045
ogbn-arxiv,dgl,1,1507,24.4398,0.7225

 F1-mic 0.7224,  F1-mac 0.5042
ogbn-arxiv,dgl,1,1508,24.4558,0.7224

 F1-mic 0.7225,  F1-mac 0.5044
ogbn-arxiv,dgl,1,1509,24.4719,0.7225

epoch:1511/50, Iteration 32/32:training loss 0.9607367515563965
Train F1-mic 0.7120, Train F1-mac 0.5221
 F1-mic 0.7224,  F1-mac 0.5044
ogbn-arxiv,dgl,1,1510,24.4879,0.7224

 F1-mic 0.7224,  F1-mac 0.5045
ogbn-arxiv,dgl,1,1511,24.5040,0.7224

 F1-mic 0.7225,  F1-mac 0.5046
ogbn-arxiv,dgl,1,1512,24.5201,0.7225

 F1-mic 0.7224,  F1-mac 0.5043
ogbn-arxiv,dgl,1,1513,24.5361,0.7224

 F1-mic 0.7225,  F1-mac 0.5046
ogbn-arxiv,dgl,1,1514,24.5521,0.7225

 F1-mic 0.7225,  F1-mac 0.5044
ogbn-arxiv,dgl,1,1515,24.5682,0.7225

 F1-mic 0.7225,  F1-mac 0.5045
ogbn-arxiv,dgl,1,1516,24.5842,0.7225

 F1-mic 0.7224,  F1-mac 0.5044
ogbn-arxiv,dgl,1,1517,24.6003,0.7224

 F1-mic 0.7225,  F1-mac 0.5045
ogbn-arxiv,dgl,1,1518,24.6163,0.7225

 F1-mic 0.7225,  F1-mac 0.5045
ogbn-arxiv,dgl,1,1519,24.6324,0.7225

epoch:1521/50, Iteration 32/32:training loss 0.9600847363471985
Train F1-mic 0.7121, Train F1-mac 0.5222
 F1-mic 0.7226,  F1-mac 0.5046
ogbn-arxiv,dgl,1,1520,24.6485,0.7226

 F1-mic 0.7225,  F1-mac 0.5049
ogbn-arxiv,dgl,1,1521,24.6646,0.7225

 F1-mic 0.7225,  F1-mac 0.5049
ogbn-arxiv,dgl,1,1522,24.6807,0.7225

 F1-mic 0.7226,  F1-mac 0.5048
new best val f1: 0.7226302903112977
ogbn-arxiv,dgl,1,1523,24.6967,0.7226

 F1-mic 0.7226,  F1-mac 0.5052
ogbn-arxiv,dgl,1,1524,24.7127,0.7226

 F1-mic 0.7227,  F1-mac 0.5063
new best val f1: 0.7226920148961998
ogbn-arxiv,dgl,1,1525,24.7288,0.7227

 F1-mic 0.7228,  F1-mac 0.5065
new best val f1: 0.722753739481102
ogbn-arxiv,dgl,1,1526,24.7448,0.7228

 F1-mic 0.7226,  F1-mac 0.5060
ogbn-arxiv,dgl,1,1527,24.7609,0.7226

 F1-mic 0.7226,  F1-mac 0.5058
ogbn-arxiv,dgl,1,1528,24.7769,0.7226

 F1-mic 0.7227,  F1-mac 0.5060
ogbn-arxiv,dgl,1,1529,24.7930,0.7227

epoch:1531/50, Iteration 32/32:training loss 0.9594364166259766
Train F1-mic 0.7123, Train F1-mac 0.5231
 F1-mic 0.7228,  F1-mac 0.5060
new best val f1: 0.7227743143427362
ogbn-arxiv,dgl,1,1530,24.8090,0.7228

 F1-mic 0.7228,  F1-mac 0.5064
ogbn-arxiv,dgl,1,1531,24.8252,0.7228

 F1-mic 0.7227,  F1-mac 0.5063
ogbn-arxiv,dgl,1,1532,24.8413,0.7227

 F1-mic 0.7228,  F1-mac 0.5061
new best val f1: 0.7228154640660042
ogbn-arxiv,dgl,1,1533,24.8574,0.7228

 F1-mic 0.7228,  F1-mac 0.5064
new best val f1: 0.7228360389276383
ogbn-arxiv,dgl,1,1534,24.8734,0.7228

 F1-mic 0.7229,  F1-mac 0.5065
new best val f1: 0.7228566137892722
ogbn-arxiv,dgl,1,1535,24.8894,0.7229

 F1-mic 0.7229,  F1-mac 0.5062
new best val f1: 0.7228771886509063
ogbn-arxiv,dgl,1,1536,24.9055,0.7229

 F1-mic 0.7228,  F1-mac 0.5063
ogbn-arxiv,dgl,1,1537,24.9215,0.7228

 F1-mic 0.7228,  F1-mac 0.5064
ogbn-arxiv,dgl,1,1538,24.9375,0.7228

 F1-mic 0.7229,  F1-mac 0.5065
new best val f1: 0.7229183383741743
ogbn-arxiv,dgl,1,1539,24.9536,0.7229

epoch:1541/50, Iteration 32/32:training loss 0.9587829113006592
Train F1-mic 0.7124, Train F1-mac 0.5235
 F1-mic 0.7230,  F1-mac 0.5069
new best val f1: 0.7229800629590766
ogbn-arxiv,dgl,1,1540,24.9696,0.7230

 F1-mic 0.7228,  F1-mac 0.5064
ogbn-arxiv,dgl,1,1541,24.9857,0.7228

 F1-mic 0.7228,  F1-mac 0.5065
ogbn-arxiv,dgl,1,1542,25.0018,0.7228

 F1-mic 0.7229,  F1-mac 0.5064
ogbn-arxiv,dgl,1,1543,25.0179,0.7229

 F1-mic 0.7229,  F1-mac 0.5065
ogbn-arxiv,dgl,1,1544,25.0339,0.7229

 F1-mic 0.7230,  F1-mac 0.5065
ogbn-arxiv,dgl,1,1545,25.0499,0.7230

 F1-mic 0.7229,  F1-mac 0.5065
ogbn-arxiv,dgl,1,1546,25.0660,0.7229

 F1-mic 0.7229,  F1-mac 0.5069
ogbn-arxiv,dgl,1,1547,25.0823,0.7229

 F1-mic 0.7229,  F1-mac 0.5069
ogbn-arxiv,dgl,1,1548,25.0984,0.7229

 F1-mic 0.7229,  F1-mac 0.5066
ogbn-arxiv,dgl,1,1549,25.1145,0.7229

epoch:1551/50, Iteration 32/32:training loss 0.9581372141838074
Train F1-mic 0.7124, Train F1-mac 0.5236
 F1-mic 0.7230,  F1-mac 0.5070
new best val f1: 0.7230212126823448
ogbn-arxiv,dgl,1,1550,25.1305,0.7230

 F1-mic 0.7229,  F1-mac 0.5066
ogbn-arxiv,dgl,1,1551,25.1466,0.7229

 F1-mic 0.7229,  F1-mac 0.5062
ogbn-arxiv,dgl,1,1552,25.1627,0.7229

 F1-mic 0.7230,  F1-mac 0.5064
ogbn-arxiv,dgl,1,1553,25.1787,0.7230

 F1-mic 0.7230,  F1-mac 0.5068
ogbn-arxiv,dgl,1,1554,25.1947,0.7230

 F1-mic 0.7228,  F1-mac 0.5066
ogbn-arxiv,dgl,1,1555,25.2107,0.7228

 F1-mic 0.7229,  F1-mac 0.5066
ogbn-arxiv,dgl,1,1556,25.2267,0.7229

 F1-mic 0.7229,  F1-mac 0.5066
ogbn-arxiv,dgl,1,1557,25.2428,0.7229

 F1-mic 0.7228,  F1-mac 0.5067
ogbn-arxiv,dgl,1,1558,25.2588,0.7228

 F1-mic 0.7230,  F1-mac 0.5078
ogbn-arxiv,dgl,1,1559,25.2749,0.7230

epoch:1561/50, Iteration 32/32:training loss 0.9574927091598511
Train F1-mic 0.7125, Train F1-mac 0.5241
 F1-mic 0.7230,  F1-mac 0.5077
ogbn-arxiv,dgl,1,1560,25.2909,0.7230

 F1-mic 0.7230,  F1-mac 0.5077
ogbn-arxiv,dgl,1,1561,25.3071,0.7230

 F1-mic 0.7230,  F1-mac 0.5078
new best val f1: 0.7230417875439787
ogbn-arxiv,dgl,1,1562,25.3231,0.7230

 F1-mic 0.7230,  F1-mac 0.5078
ogbn-arxiv,dgl,1,1563,25.3392,0.7230

 F1-mic 0.7229,  F1-mac 0.5077
ogbn-arxiv,dgl,1,1564,25.3552,0.7229

 F1-mic 0.7230,  F1-mac 0.5076
ogbn-arxiv,dgl,1,1565,25.3712,0.7230

 F1-mic 0.7230,  F1-mac 0.5077
ogbn-arxiv,dgl,1,1566,25.3873,0.7230

 F1-mic 0.7230,  F1-mac 0.5079
ogbn-arxiv,dgl,1,1567,25.4034,0.7230

 F1-mic 0.7231,  F1-mac 0.5078
new best val f1: 0.7230623624056127
ogbn-arxiv,dgl,1,1568,25.4194,0.7231

 F1-mic 0.7230,  F1-mac 0.5079
ogbn-arxiv,dgl,1,1569,25.4355,0.7230

epoch:1571/50, Iteration 32/32:training loss 0.956851065158844
Train F1-mic 0.7126, Train F1-mac 0.5243
 F1-mic 0.7231,  F1-mac 0.5080
new best val f1: 0.7231446618521491
ogbn-arxiv,dgl,1,1570,25.4515,0.7231

 F1-mic 0.7232,  F1-mac 0.5079
new best val f1: 0.7231858115754172
ogbn-arxiv,dgl,1,1571,25.4677,0.7232

 F1-mic 0.7231,  F1-mac 0.5080
ogbn-arxiv,dgl,1,1572,25.4838,0.7231

 F1-mic 0.7232,  F1-mac 0.5081
new best val f1: 0.7232063864370513
ogbn-arxiv,dgl,1,1573,25.4998,0.7232

 F1-mic 0.7232,  F1-mac 0.5079
ogbn-arxiv,dgl,1,1574,25.5158,0.7232

 F1-mic 0.7232,  F1-mac 0.5079
new best val f1: 0.7232269612986852
ogbn-arxiv,dgl,1,1575,25.5319,0.7232

 F1-mic 0.7232,  F1-mac 0.5081
ogbn-arxiv,dgl,1,1576,25.5479,0.7232

 F1-mic 0.7232,  F1-mac 0.5083
new best val f1: 0.7232475361603192
ogbn-arxiv,dgl,1,1577,25.5640,0.7232

 F1-mic 0.7233,  F1-mac 0.5083
new best val f1: 0.7232681110219534
ogbn-arxiv,dgl,1,1578,25.5800,0.7233

 F1-mic 0.7233,  F1-mac 0.5084
new best val f1: 0.7233298356068556
ogbn-arxiv,dgl,1,1579,25.5960,0.7233

epoch:1581/50, Iteration 32/32:training loss 0.9562128782272339
Train F1-mic 0.7128, Train F1-mac 0.5247
 F1-mic 0.7231,  F1-mac 0.5078
ogbn-arxiv,dgl,1,1580,25.6121,0.7231

 F1-mic 0.7232,  F1-mac 0.5081
ogbn-arxiv,dgl,1,1581,25.6282,0.7232

 F1-mic 0.7234,  F1-mac 0.5083
new best val f1: 0.7234121350533917
ogbn-arxiv,dgl,1,1582,25.6443,0.7234

 F1-mic 0.7233,  F1-mac 0.5083
ogbn-arxiv,dgl,1,1583,25.6603,0.7233

 F1-mic 0.7235,  F1-mac 0.5086
new best val f1: 0.7234738596382939
ogbn-arxiv,dgl,1,1584,25.6763,0.7235

 F1-mic 0.7232,  F1-mac 0.5084
ogbn-arxiv,dgl,1,1585,25.6924,0.7232

 F1-mic 0.7233,  F1-mac 0.5082
ogbn-arxiv,dgl,1,1586,25.7084,0.7233

 F1-mic 0.7234,  F1-mac 0.5086
ogbn-arxiv,dgl,1,1587,25.7245,0.7234

 F1-mic 0.7236,  F1-mac 0.5085
new best val f1: 0.7235561590848301
ogbn-arxiv,dgl,1,1588,25.7405,0.7236

 F1-mic 0.7234,  F1-mac 0.5084
ogbn-arxiv,dgl,1,1589,25.7566,0.7234

epoch:1591/50, Iteration 32/32:training loss 0.9555737376213074
Train F1-mic 0.7130, Train F1-mac 0.5253
 F1-mic 0.7235,  F1-mac 0.5086
ogbn-arxiv,dgl,1,1590,25.7726,0.7235

 F1-mic 0.7235,  F1-mac 0.5090
ogbn-arxiv,dgl,1,1591,25.7887,0.7235

 F1-mic 0.7235,  F1-mac 0.5086
ogbn-arxiv,dgl,1,1592,25.8048,0.7235

 F1-mic 0.7235,  F1-mac 0.5085
ogbn-arxiv,dgl,1,1593,25.8208,0.7235

 F1-mic 0.7235,  F1-mac 0.5084
ogbn-arxiv,dgl,1,1594,25.8368,0.7235

 F1-mic 0.7236,  F1-mac 0.5088
new best val f1: 0.7236178836697323
ogbn-arxiv,dgl,1,1595,25.8529,0.7236

 F1-mic 0.7236,  F1-mac 0.5086
ogbn-arxiv,dgl,1,1596,25.8689,0.7236

 F1-mic 0.7235,  F1-mac 0.5085
ogbn-arxiv,dgl,1,1597,25.8850,0.7235

 F1-mic 0.7235,  F1-mac 0.5085
ogbn-arxiv,dgl,1,1598,25.9010,0.7235

 F1-mic 0.7235,  F1-mac 0.5086
ogbn-arxiv,dgl,1,1599,25.9171,0.7235

epoch:1601/50, Iteration 32/32:training loss 0.9549416899681091
Train F1-mic 0.7130, Train F1-mac 0.5254
 F1-mic 0.7236,  F1-mac 0.5087
ogbn-arxiv,dgl,1,1600,25.9332,0.7236

 F1-mic 0.7237,  F1-mac 0.5087
new best val f1: 0.7237001831162685
ogbn-arxiv,dgl,1,1601,25.9493,0.7237

 F1-mic 0.7237,  F1-mac 0.5090
new best val f1: 0.7237413328395367
ogbn-arxiv,dgl,1,1602,25.9654,0.7237

 F1-mic 0.7237,  F1-mac 0.5090
ogbn-arxiv,dgl,1,1603,25.9814,0.7237

 F1-mic 0.7236,  F1-mac 0.5088
ogbn-arxiv,dgl,1,1604,25.9975,0.7236

 F1-mic 0.7236,  F1-mac 0.5087
ogbn-arxiv,dgl,1,1605,26.0135,0.7236

 F1-mic 0.7236,  F1-mac 0.5084
ogbn-arxiv,dgl,1,1606,26.0296,0.7236

 F1-mic 0.7235,  F1-mac 0.5086
ogbn-arxiv,dgl,1,1607,26.0456,0.7235

 F1-mic 0.7237,  F1-mac 0.5089
ogbn-arxiv,dgl,1,1608,26.0616,0.7237

 F1-mic 0.7238,  F1-mac 0.5091
new best val f1: 0.7237619077011707
ogbn-arxiv,dgl,1,1609,26.0777,0.7238

epoch:1611/50, Iteration 32/32:training loss 0.9543106555938721
Train F1-mic 0.7133, Train F1-mac 0.5259
 F1-mic 0.7236,  F1-mac 0.5089
ogbn-arxiv,dgl,1,1610,26.0938,0.7236

 F1-mic 0.7237,  F1-mac 0.5091
ogbn-arxiv,dgl,1,1611,26.1099,0.7237

 F1-mic 0.7238,  F1-mac 0.5091
ogbn-arxiv,dgl,1,1612,26.1259,0.7238

 F1-mic 0.7238,  F1-mac 0.5086
ogbn-arxiv,dgl,1,1613,26.1420,0.7238

 F1-mic 0.7238,  F1-mac 0.5091
ogbn-arxiv,dgl,1,1614,26.1580,0.7238

 F1-mic 0.7238,  F1-mac 0.5093
new best val f1: 0.7238236322860728
ogbn-arxiv,dgl,1,1615,26.1740,0.7238

 F1-mic 0.7237,  F1-mac 0.5092
ogbn-arxiv,dgl,1,1616,26.1901,0.7237

 F1-mic 0.7238,  F1-mac 0.5092
ogbn-arxiv,dgl,1,1617,26.2061,0.7238

 F1-mic 0.7238,  F1-mac 0.5093
ogbn-arxiv,dgl,1,1618,26.2221,0.7238

 F1-mic 0.7237,  F1-mac 0.5092
ogbn-arxiv,dgl,1,1619,26.2382,0.7237

epoch:1621/50, Iteration 32/32:training loss 0.9536813497543335
Train F1-mic 0.7134, Train F1-mac 0.5262
 F1-mic 0.7239,  F1-mac 0.5091
new best val f1: 0.723864782009341
ogbn-arxiv,dgl,1,1620,26.2542,0.7239

 F1-mic 0.7238,  F1-mac 0.5095
ogbn-arxiv,dgl,1,1621,26.2703,0.7238

 F1-mic 0.7238,  F1-mac 0.5098
ogbn-arxiv,dgl,1,1622,26.2864,0.7238

 F1-mic 0.7239,  F1-mac 0.5099
new best val f1: 0.7239265065942432
ogbn-arxiv,dgl,1,1623,26.3024,0.7239

 F1-mic 0.7240,  F1-mac 0.5095
new best val f1: 0.7240293809024134
ogbn-arxiv,dgl,1,1624,26.3184,0.7240

 F1-mic 0.7239,  F1-mac 0.5093
ogbn-arxiv,dgl,1,1625,26.3344,0.7239

 F1-mic 0.7239,  F1-mac 0.5095
ogbn-arxiv,dgl,1,1626,26.3505,0.7239

 F1-mic 0.7239,  F1-mac 0.5097
ogbn-arxiv,dgl,1,1627,26.3666,0.7239

 F1-mic 0.7239,  F1-mac 0.5096
ogbn-arxiv,dgl,1,1628,26.3826,0.7239

 F1-mic 0.7241,  F1-mac 0.5099
new best val f1: 0.7240705306256815
ogbn-arxiv,dgl,1,1629,26.3987,0.7241

epoch:1631/50, Iteration 32/32:training loss 0.9530547857284546
Train F1-mic 0.7136, Train F1-mac 0.5266
 F1-mic 0.7240,  F1-mac 0.5099
ogbn-arxiv,dgl,1,1630,26.4147,0.7240

 F1-mic 0.7239,  F1-mac 0.5097
ogbn-arxiv,dgl,1,1631,26.4308,0.7239

 F1-mic 0.7239,  F1-mac 0.5099
ogbn-arxiv,dgl,1,1632,26.4469,0.7239

 F1-mic 0.7239,  F1-mac 0.5100
ogbn-arxiv,dgl,1,1633,26.4630,0.7239

 F1-mic 0.7240,  F1-mac 0.5100
ogbn-arxiv,dgl,1,1634,26.4790,0.7240

 F1-mic 0.7241,  F1-mac 0.5102
new best val f1: 0.7241322552105838
ogbn-arxiv,dgl,1,1635,26.4950,0.7241

 F1-mic 0.7239,  F1-mac 0.5098
ogbn-arxiv,dgl,1,1636,26.5110,0.7239

 F1-mic 0.7239,  F1-mac 0.5097
ogbn-arxiv,dgl,1,1637,26.5271,0.7239

 F1-mic 0.7240,  F1-mac 0.5097
ogbn-arxiv,dgl,1,1638,26.5431,0.7240

 F1-mic 0.7240,  F1-mac 0.5097
ogbn-arxiv,dgl,1,1639,26.5592,0.7240

epoch:1641/50, Iteration 32/32:training loss 0.9524295926094055
Train F1-mic 0.7136, Train F1-mac 0.5266
 F1-mic 0.7240,  F1-mac 0.5099
ogbn-arxiv,dgl,1,1640,26.5752,0.7240

 F1-mic 0.7241,  F1-mac 0.5099
ogbn-arxiv,dgl,1,1641,26.5914,0.7241

 F1-mic 0.7242,  F1-mac 0.5099
new best val f1: 0.7241528300722178
ogbn-arxiv,dgl,1,1642,26.6075,0.7242

 F1-mic 0.7240,  F1-mac 0.5098
ogbn-arxiv,dgl,1,1643,26.6235,0.7240

 F1-mic 0.7241,  F1-mac 0.5097
ogbn-arxiv,dgl,1,1644,26.6395,0.7241

 F1-mic 0.7242,  F1-mac 0.5099
ogbn-arxiv,dgl,1,1645,26.6556,0.7242

 F1-mic 0.7239,  F1-mac 0.5097
ogbn-arxiv,dgl,1,1646,26.6716,0.7239

 F1-mic 0.7241,  F1-mac 0.5101
ogbn-arxiv,dgl,1,1647,26.6877,0.7241

 F1-mic 0.7239,  F1-mac 0.5098
ogbn-arxiv,dgl,1,1648,26.7037,0.7239

 F1-mic 0.7241,  F1-mac 0.5099
ogbn-arxiv,dgl,1,1649,26.7198,0.7241

epoch:1651/50, Iteration 32/32:training loss 0.9518088102340698
Train F1-mic 0.7137, Train F1-mac 0.5270
 F1-mic 0.7241,  F1-mac 0.5100
ogbn-arxiv,dgl,1,1650,26.7359,0.7241

 F1-mic 0.7241,  F1-mac 0.5099
ogbn-arxiv,dgl,1,1651,26.7520,0.7241

 F1-mic 0.7240,  F1-mac 0.5099
ogbn-arxiv,dgl,1,1652,26.7681,0.7240

 F1-mic 0.7242,  F1-mac 0.5102
new best val f1: 0.7242145546571199
ogbn-arxiv,dgl,1,1653,26.7842,0.7242

 F1-mic 0.7242,  F1-mac 0.5099
new best val f1: 0.724235129518754
ogbn-arxiv,dgl,1,1654,26.8002,0.7242

 F1-mic 0.7243,  F1-mac 0.5102
new best val f1: 0.7242762792420221
ogbn-arxiv,dgl,1,1655,26.8162,0.7243

 F1-mic 0.7243,  F1-mac 0.5100
ogbn-arxiv,dgl,1,1656,26.8323,0.7243

 F1-mic 0.7242,  F1-mac 0.5100
ogbn-arxiv,dgl,1,1657,26.8484,0.7242

 F1-mic 0.7243,  F1-mac 0.5100
new best val f1: 0.7242968541036562
ogbn-arxiv,dgl,1,1658,26.8643,0.7243

 F1-mic 0.7243,  F1-mac 0.5102
new best val f1: 0.7243174289652902
ogbn-arxiv,dgl,1,1659,26.8804,0.7243

epoch:1661/50, Iteration 32/32:training loss 0.9511895775794983
Train F1-mic 0.7139, Train F1-mac 0.5273
 F1-mic 0.7243,  F1-mac 0.5100
new best val f1: 0.7243380038269243
ogbn-arxiv,dgl,1,1660,26.8965,0.7243

 F1-mic 0.7242,  F1-mac 0.5102
ogbn-arxiv,dgl,1,1661,26.9126,0.7242

 F1-mic 0.7242,  F1-mac 0.5102
ogbn-arxiv,dgl,1,1662,26.9287,0.7242

 F1-mic 0.7243,  F1-mac 0.5100
ogbn-arxiv,dgl,1,1663,26.9447,0.7243

 F1-mic 0.7243,  F1-mac 0.5112
ogbn-arxiv,dgl,1,1664,26.9608,0.7243

 F1-mic 0.7244,  F1-mac 0.5115
new best val f1: 0.7244408781350946
ogbn-arxiv,dgl,1,1665,26.9768,0.7244

 F1-mic 0.7244,  F1-mac 0.5113
ogbn-arxiv,dgl,1,1666,26.9928,0.7244

 F1-mic 0.7244,  F1-mac 0.5116
ogbn-arxiv,dgl,1,1667,27.0089,0.7244

 F1-mic 0.7244,  F1-mac 0.5119
ogbn-arxiv,dgl,1,1668,27.0249,0.7244

 F1-mic 0.7244,  F1-mac 0.5118
ogbn-arxiv,dgl,1,1669,27.0410,0.7244

epoch:1671/50, Iteration 32/32:training loss 0.9505706429481506
Train F1-mic 0.7141, Train F1-mac 0.5280
 F1-mic 0.7245,  F1-mac 0.5116
new best val f1: 0.7244614529967286
ogbn-arxiv,dgl,1,1670,27.0570,0.7245

 F1-mic 0.7244,  F1-mac 0.5116
ogbn-arxiv,dgl,1,1671,27.0731,0.7244

 F1-mic 0.7245,  F1-mac 0.5121
ogbn-arxiv,dgl,1,1672,27.0892,0.7245

 F1-mic 0.7244,  F1-mac 0.5119
ogbn-arxiv,dgl,1,1673,27.1053,0.7244

 F1-mic 0.7245,  F1-mac 0.5119
new best val f1: 0.7244820278583627
ogbn-arxiv,dgl,1,1674,27.1213,0.7245

 F1-mic 0.7245,  F1-mac 0.5119
new best val f1: 0.7245026027199968
ogbn-arxiv,dgl,1,1675,27.1373,0.7245

 F1-mic 0.7243,  F1-mac 0.5118
ogbn-arxiv,dgl,1,1676,27.1534,0.7243

 F1-mic 0.7245,  F1-mac 0.5123
new best val f1: 0.7245437524432649
ogbn-arxiv,dgl,1,1677,27.1694,0.7245

 F1-mic 0.7245,  F1-mac 0.5121
ogbn-arxiv,dgl,1,1678,27.1855,0.7245

 F1-mic 0.7244,  F1-mac 0.5116
ogbn-arxiv,dgl,1,1679,27.2015,0.7244

epoch:1681/50, Iteration 32/32:training loss 0.9499594569206238
Train F1-mic 0.7142, Train F1-mac 0.5282
 F1-mic 0.7244,  F1-mac 0.5116
ogbn-arxiv,dgl,1,1680,27.2175,0.7244

 F1-mic 0.7245,  F1-mac 0.5117
ogbn-arxiv,dgl,1,1681,27.2337,0.7245

 F1-mic 0.7244,  F1-mac 0.5116
ogbn-arxiv,dgl,1,1682,27.2497,0.7244

 F1-mic 0.7244,  F1-mac 0.5114
ogbn-arxiv,dgl,1,1683,27.2658,0.7244

 F1-mic 0.7243,  F1-mac 0.5119
ogbn-arxiv,dgl,1,1684,27.2818,0.7243

 F1-mic 0.7244,  F1-mac 0.5116
ogbn-arxiv,dgl,1,1685,27.2978,0.7244

 F1-mic 0.7244,  F1-mac 0.5117
ogbn-arxiv,dgl,1,1686,27.3139,0.7244

 F1-mic 0.7243,  F1-mac 0.5117
ogbn-arxiv,dgl,1,1687,27.3300,0.7243

 F1-mic 0.7243,  F1-mac 0.5115
ogbn-arxiv,dgl,1,1688,27.3460,0.7243

 F1-mic 0.7244,  F1-mac 0.5116
ogbn-arxiv,dgl,1,1689,27.3620,0.7244

epoch:1691/50, Iteration 32/32:training loss 0.9493455290794373
Train F1-mic 0.7143, Train F1-mac 0.5283
 F1-mic 0.7243,  F1-mac 0.5116
ogbn-arxiv,dgl,1,1690,27.3781,0.7243

 F1-mic 0.7243,  F1-mac 0.5112
ogbn-arxiv,dgl,1,1691,27.3942,0.7243

 F1-mic 0.7246,  F1-mac 0.5121
new best val f1: 0.7245849021665329
ogbn-arxiv,dgl,1,1692,27.4103,0.7246

 F1-mic 0.7244,  F1-mac 0.5118
ogbn-arxiv,dgl,1,1693,27.4263,0.7244

 F1-mic 0.7243,  F1-mac 0.5116
ogbn-arxiv,dgl,1,1694,27.4423,0.7243

 F1-mic 0.7244,  F1-mac 0.5115
ogbn-arxiv,dgl,1,1695,27.4583,0.7244

 F1-mic 0.7243,  F1-mac 0.5115
ogbn-arxiv,dgl,1,1696,27.4744,0.7243

 F1-mic 0.7244,  F1-mac 0.5116
ogbn-arxiv,dgl,1,1697,27.4905,0.7244

 F1-mic 0.7246,  F1-mac 0.5121
ogbn-arxiv,dgl,1,1698,27.5065,0.7246

 F1-mic 0.7244,  F1-mac 0.5117
ogbn-arxiv,dgl,1,1699,27.5226,0.7244

epoch:1701/50, Iteration 32/32:training loss 0.9487335085868835
Train F1-mic 0.7144, Train F1-mac 0.5286
 F1-mic 0.7244,  F1-mac 0.5119
ogbn-arxiv,dgl,1,1700,27.5387,0.7244

 F1-mic 0.7244,  F1-mac 0.5119
ogbn-arxiv,dgl,1,1701,27.5548,0.7244

 F1-mic 0.7244,  F1-mac 0.5119
ogbn-arxiv,dgl,1,1702,27.5709,0.7244

 F1-mic 0.7243,  F1-mac 0.5117
ogbn-arxiv,dgl,1,1703,27.5869,0.7243

 F1-mic 0.7246,  F1-mac 0.5120
new best val f1: 0.724605477028167
ogbn-arxiv,dgl,1,1704,27.6029,0.7246

 F1-mic 0.7244,  F1-mac 0.5119
ogbn-arxiv,dgl,1,1705,27.6190,0.7244

 F1-mic 0.7244,  F1-mac 0.5114
ogbn-arxiv,dgl,1,1706,27.6350,0.7244

 F1-mic 0.7245,  F1-mac 0.5119
ogbn-arxiv,dgl,1,1707,27.6511,0.7245

 F1-mic 0.7245,  F1-mac 0.5120
ogbn-arxiv,dgl,1,1708,27.6671,0.7245

 F1-mic 0.7245,  F1-mac 0.5119
ogbn-arxiv,dgl,1,1709,27.6832,0.7245

epoch:1711/50, Iteration 32/32:training loss 0.9481233358383179
Train F1-mic 0.7145, Train F1-mac 0.5288
 F1-mic 0.7245,  F1-mac 0.5119
ogbn-arxiv,dgl,1,1710,27.6992,0.7245

 F1-mic 0.7244,  F1-mac 0.5118
ogbn-arxiv,dgl,1,1711,27.7154,0.7244

 F1-mic 0.7244,  F1-mac 0.5118
ogbn-arxiv,dgl,1,1712,27.7314,0.7244

 F1-mic 0.7245,  F1-mac 0.5119
ogbn-arxiv,dgl,1,1713,27.7475,0.7245

 F1-mic 0.7244,  F1-mac 0.5118
ogbn-arxiv,dgl,1,1714,27.7635,0.7244

 F1-mic 0.7244,  F1-mac 0.5119
ogbn-arxiv,dgl,1,1715,27.7795,0.7244

 F1-mic 0.7245,  F1-mac 0.5117
ogbn-arxiv,dgl,1,1716,27.7956,0.7245

 F1-mic 0.7244,  F1-mac 0.5117
ogbn-arxiv,dgl,1,1717,27.8117,0.7244

 F1-mic 0.7244,  F1-mac 0.5117
ogbn-arxiv,dgl,1,1718,27.8277,0.7244

 F1-mic 0.7244,  F1-mac 0.5116
ogbn-arxiv,dgl,1,1719,27.8437,0.7244

epoch:1721/50, Iteration 32/32:training loss 0.9475133419036865
Train F1-mic 0.7145, Train F1-mac 0.5290
 F1-mic 0.7245,  F1-mac 0.5119
ogbn-arxiv,dgl,1,1720,27.8598,0.7245

 F1-mic 0.7245,  F1-mac 0.5117
ogbn-arxiv,dgl,1,1721,27.8759,0.7245

 F1-mic 0.7244,  F1-mac 0.5115
ogbn-arxiv,dgl,1,1722,27.8921,0.7244

 F1-mic 0.7244,  F1-mac 0.5116
ogbn-arxiv,dgl,1,1723,27.9081,0.7244

 F1-mic 0.7245,  F1-mac 0.5118
ogbn-arxiv,dgl,1,1724,27.9242,0.7245

 F1-mic 0.7245,  F1-mac 0.5118
ogbn-arxiv,dgl,1,1725,27.9402,0.7245

 F1-mic 0.7245,  F1-mac 0.5119
ogbn-arxiv,dgl,1,1726,27.9562,0.7245

 F1-mic 0.7245,  F1-mac 0.5117
ogbn-arxiv,dgl,1,1727,27.9723,0.7245

 F1-mic 0.7245,  F1-mac 0.5117
ogbn-arxiv,dgl,1,1728,27.9883,0.7245

 F1-mic 0.7245,  F1-mac 0.5118
ogbn-arxiv,dgl,1,1729,28.0044,0.7245

epoch:1731/50, Iteration 32/32:training loss 0.9469068646430969
Train F1-mic 0.7147, Train F1-mac 0.5292
 F1-mic 0.7245,  F1-mac 0.5115
ogbn-arxiv,dgl,1,1730,28.0205,0.7245

 F1-mic 0.7244,  F1-mac 0.5115
ogbn-arxiv,dgl,1,1731,28.0366,0.7244

 F1-mic 0.7245,  F1-mac 0.5115
ogbn-arxiv,dgl,1,1732,28.0527,0.7245

 F1-mic 0.7245,  F1-mac 0.5117
ogbn-arxiv,dgl,1,1733,28.0688,0.7245

 F1-mic 0.7246,  F1-mac 0.5118
ogbn-arxiv,dgl,1,1734,28.0848,0.7246

 F1-mic 0.7246,  F1-mac 0.5120
ogbn-arxiv,dgl,1,1735,28.1008,0.7246

 F1-mic 0.7245,  F1-mac 0.5120
ogbn-arxiv,dgl,1,1736,28.1169,0.7245

 F1-mic 0.7244,  F1-mac 0.5112
ogbn-arxiv,dgl,1,1737,28.1330,0.7244

 F1-mic 0.7244,  F1-mac 0.5113
ogbn-arxiv,dgl,1,1738,28.1490,0.7244

 F1-mic 0.7246,  F1-mac 0.5118
ogbn-arxiv,dgl,1,1739,28.1651,0.7246

epoch:1741/50, Iteration 32/32:training loss 0.946302056312561
Train F1-mic 0.7148, Train F1-mac 0.5293
 F1-mic 0.7245,  F1-mac 0.5118
ogbn-arxiv,dgl,1,1740,28.1811,0.7245

 F1-mic 0.7245,  F1-mac 0.5118
ogbn-arxiv,dgl,1,1741,28.1972,0.7245

 F1-mic 0.7246,  F1-mac 0.5118
ogbn-arxiv,dgl,1,1742,28.2134,0.7246

 F1-mic 0.7246,  F1-mac 0.5119
new best val f1: 0.724626051889801
ogbn-arxiv,dgl,1,1743,28.2294,0.7246

 F1-mic 0.7245,  F1-mac 0.5117
ogbn-arxiv,dgl,1,1744,28.2454,0.7245

 F1-mic 0.7245,  F1-mac 0.5120
ogbn-arxiv,dgl,1,1745,28.2615,0.7245

 F1-mic 0.7245,  F1-mac 0.5118
ogbn-arxiv,dgl,1,1746,28.2776,0.7245

 F1-mic 0.7247,  F1-mac 0.5120
new best val f1: 0.7247083513363373
ogbn-arxiv,dgl,1,1747,28.2937,0.7247

 F1-mic 0.7246,  F1-mac 0.5119
ogbn-arxiv,dgl,1,1748,28.3097,0.7246

 F1-mic 0.7247,  F1-mac 0.5120
ogbn-arxiv,dgl,1,1749,28.3257,0.7247

epoch:1751/50, Iteration 32/32:training loss 0.9456989765167236
Train F1-mic 0.7149, Train F1-mac 0.5296
 F1-mic 0.7246,  F1-mac 0.5120
ogbn-arxiv,dgl,1,1750,28.3418,0.7246

 F1-mic 0.7246,  F1-mac 0.5119
ogbn-arxiv,dgl,1,1751,28.3579,0.7246

 F1-mic 0.7245,  F1-mac 0.5118
ogbn-arxiv,dgl,1,1752,28.3741,0.7245

 F1-mic 0.7247,  F1-mac 0.5123
ogbn-arxiv,dgl,1,1753,28.3901,0.7247

 F1-mic 0.7247,  F1-mac 0.5122
ogbn-arxiv,dgl,1,1754,28.4062,0.7247

 F1-mic 0.7247,  F1-mac 0.5120
new best val f1: 0.7247495010596053
ogbn-arxiv,dgl,1,1755,28.4222,0.7247

 F1-mic 0.7246,  F1-mac 0.5119
ogbn-arxiv,dgl,1,1756,28.4382,0.7246

 F1-mic 0.7246,  F1-mac 0.5121
ogbn-arxiv,dgl,1,1757,28.4543,0.7246

 F1-mic 0.7247,  F1-mac 0.5122
ogbn-arxiv,dgl,1,1758,28.4704,0.7247

 F1-mic 0.7247,  F1-mac 0.5119
ogbn-arxiv,dgl,1,1759,28.4865,0.7247

epoch:1761/50, Iteration 32/32:training loss 0.9450989365577698
Train F1-mic 0.7150, Train F1-mac 0.5298
 F1-mic 0.7248,  F1-mac 0.5126
new best val f1: 0.7248318005061416
ogbn-arxiv,dgl,1,1760,28.5025,0.7248

 F1-mic 0.7248,  F1-mac 0.5122
ogbn-arxiv,dgl,1,1761,28.5186,0.7248

 F1-mic 0.7249,  F1-mac 0.5125
new best val f1: 0.7248729502294097
ogbn-arxiv,dgl,1,1762,28.5347,0.7249

 F1-mic 0.7247,  F1-mac 0.5123
ogbn-arxiv,dgl,1,1763,28.5508,0.7247

 F1-mic 0.7248,  F1-mac 0.5127
ogbn-arxiv,dgl,1,1764,28.5668,0.7248

 F1-mic 0.7249,  F1-mac 0.5125
ogbn-arxiv,dgl,1,1765,28.5829,0.7249

 F1-mic 0.7249,  F1-mac 0.5121
ogbn-arxiv,dgl,1,1766,28.5989,0.7249

 F1-mic 0.7248,  F1-mac 0.5123
ogbn-arxiv,dgl,1,1767,28.6150,0.7248

 F1-mic 0.7249,  F1-mac 0.5122
ogbn-arxiv,dgl,1,1768,28.6310,0.7249

 F1-mic 0.7250,  F1-mac 0.5123
new best val f1: 0.72497582453758
ogbn-arxiv,dgl,1,1769,28.6470,0.7250

epoch:1771/50, Iteration 32/32:training loss 0.944495439529419
Train F1-mic 0.7152, Train F1-mac 0.5301
 F1-mic 0.7249,  F1-mac 0.5127
ogbn-arxiv,dgl,1,1770,28.6631,0.7249

 F1-mic 0.7250,  F1-mac 0.5123
new best val f1: 0.7250169742608481
ogbn-arxiv,dgl,1,1771,28.6793,0.7250

 F1-mic 0.7249,  F1-mac 0.5126
ogbn-arxiv,dgl,1,1772,28.6953,0.7249

 F1-mic 0.7249,  F1-mac 0.5129
ogbn-arxiv,dgl,1,1773,28.7114,0.7249

 F1-mic 0.7251,  F1-mac 0.5132
new best val f1: 0.7250992737073845
ogbn-arxiv,dgl,1,1774,28.7275,0.7251

 F1-mic 0.7249,  F1-mac 0.5132
ogbn-arxiv,dgl,1,1775,28.7435,0.7249

 F1-mic 0.7250,  F1-mac 0.5134
ogbn-arxiv,dgl,1,1776,28.7595,0.7250

 F1-mic 0.7252,  F1-mac 0.5134
new best val f1: 0.7251815731539205
ogbn-arxiv,dgl,1,1777,28.7756,0.7252

 F1-mic 0.7251,  F1-mac 0.5137
ogbn-arxiv,dgl,1,1778,28.7917,0.7251

 F1-mic 0.7251,  F1-mac 0.5138
ogbn-arxiv,dgl,1,1779,28.8077,0.7251

epoch:1781/50, Iteration 32/32:training loss 0.9438961148262024
Train F1-mic 0.7153, Train F1-mac 0.5306
 F1-mic 0.7253,  F1-mac 0.5136
new best val f1: 0.7253050223237247
ogbn-arxiv,dgl,1,1780,28.8238,0.7253

 F1-mic 0.7253,  F1-mac 0.5142
ogbn-arxiv,dgl,1,1781,28.8400,0.7253

 F1-mic 0.7252,  F1-mac 0.5139
ogbn-arxiv,dgl,1,1782,28.8561,0.7252

 F1-mic 0.7252,  F1-mac 0.5137
ogbn-arxiv,dgl,1,1783,28.8721,0.7252

 F1-mic 0.7254,  F1-mac 0.5141
new best val f1: 0.725387321770261
ogbn-arxiv,dgl,1,1784,28.8881,0.7254

 F1-mic 0.7252,  F1-mac 0.5136
ogbn-arxiv,dgl,1,1785,28.9041,0.7252

 F1-mic 0.7252,  F1-mac 0.5138
ogbn-arxiv,dgl,1,1786,28.9202,0.7252

 F1-mic 0.7254,  F1-mac 0.5142
new best val f1: 0.7254078966318952
ogbn-arxiv,dgl,1,1787,28.9362,0.7254

 F1-mic 0.7252,  F1-mac 0.5137
ogbn-arxiv,dgl,1,1788,28.9522,0.7252

 F1-mic 0.7253,  F1-mac 0.5142
ogbn-arxiv,dgl,1,1789,28.9683,0.7253

epoch:1791/50, Iteration 32/32:training loss 0.9433040618896484
Train F1-mic 0.7155, Train F1-mac 0.5311
 F1-mic 0.7253,  F1-mac 0.5145
ogbn-arxiv,dgl,1,1790,28.9843,0.7253

 F1-mic 0.7252,  F1-mac 0.5142
ogbn-arxiv,dgl,1,1791,29.0005,0.7252

 F1-mic 0.7254,  F1-mac 0.5144
ogbn-arxiv,dgl,1,1792,29.0166,0.7254

 F1-mic 0.7254,  F1-mac 0.5145
new best val f1: 0.7254284714935292
ogbn-arxiv,dgl,1,1793,29.0326,0.7254

 F1-mic 0.7254,  F1-mac 0.5144
new best val f1: 0.7254490463551633
ogbn-arxiv,dgl,1,1794,29.0487,0.7254

 F1-mic 0.7254,  F1-mac 0.5143
ogbn-arxiv,dgl,1,1795,29.0647,0.7254

 F1-mic 0.7255,  F1-mac 0.5146
new best val f1: 0.7254696212167974
ogbn-arxiv,dgl,1,1796,29.0808,0.7255

 F1-mic 0.7253,  F1-mac 0.5142
ogbn-arxiv,dgl,1,1797,29.0969,0.7253

 F1-mic 0.7254,  F1-mac 0.5143
ogbn-arxiv,dgl,1,1798,29.1129,0.7254

 F1-mic 0.7257,  F1-mac 0.5146
new best val f1: 0.7256547949715039
ogbn-arxiv,dgl,1,1799,29.1289,0.7257

epoch:1801/50, Iteration 32/32:training loss 0.9427090883255005
Train F1-mic 0.7156, Train F1-mac 0.5315
 F1-mic 0.7254,  F1-mac 0.5143
ogbn-arxiv,dgl,1,1800,29.1450,0.7254

 F1-mic 0.7254,  F1-mac 0.5143
ogbn-arxiv,dgl,1,1801,29.1611,0.7254

 F1-mic 0.7255,  F1-mac 0.5142
ogbn-arxiv,dgl,1,1802,29.1772,0.7255

 F1-mic 0.7256,  F1-mac 0.5142
ogbn-arxiv,dgl,1,1803,29.1933,0.7256

 F1-mic 0.7256,  F1-mac 0.5144
ogbn-arxiv,dgl,1,1804,29.2093,0.7256

 F1-mic 0.7255,  F1-mac 0.5142
ogbn-arxiv,dgl,1,1805,29.2253,0.7255

 F1-mic 0.7255,  F1-mac 0.5142
ogbn-arxiv,dgl,1,1806,29.2414,0.7255

 F1-mic 0.7256,  F1-mac 0.5142
ogbn-arxiv,dgl,1,1807,29.2575,0.7256

 F1-mic 0.7257,  F1-mac 0.5145
ogbn-arxiv,dgl,1,1808,29.2735,0.7257

 F1-mic 0.7256,  F1-mac 0.5142
ogbn-arxiv,dgl,1,1809,29.2896,0.7256

epoch:1811/50, Iteration 32/32:training loss 0.9421076774597168
Train F1-mic 0.7158, Train F1-mac 0.5321
 F1-mic 0.7255,  F1-mac 0.5141
ogbn-arxiv,dgl,1,1810,29.3057,0.7255

 F1-mic 0.7256,  F1-mac 0.5142
ogbn-arxiv,dgl,1,1811,29.3218,0.7256

 F1-mic 0.7256,  F1-mac 0.5142
ogbn-arxiv,dgl,1,1812,29.3379,0.7256

 F1-mic 0.7257,  F1-mac 0.5143
new best val f1: 0.7257370944180399
ogbn-arxiv,dgl,1,1813,29.3539,0.7257

 F1-mic 0.7257,  F1-mac 0.5142
ogbn-arxiv,dgl,1,1814,29.3699,0.7257

 F1-mic 0.7257,  F1-mac 0.5144
ogbn-arxiv,dgl,1,1815,29.3859,0.7257

 F1-mic 0.7257,  F1-mac 0.5144
ogbn-arxiv,dgl,1,1816,29.4020,0.7257

 F1-mic 0.7256,  F1-mac 0.5143
ogbn-arxiv,dgl,1,1817,29.4181,0.7256

 F1-mic 0.7258,  F1-mac 0.5144
new best val f1: 0.7257988190029421
ogbn-arxiv,dgl,1,1818,29.4341,0.7258

 F1-mic 0.7257,  F1-mac 0.5145
ogbn-arxiv,dgl,1,1819,29.4501,0.7257

epoch:1821/50, Iteration 32/32:training loss 0.9415200352668762
Train F1-mic 0.7159, Train F1-mac 0.5325
 F1-mic 0.7256,  F1-mac 0.5143
ogbn-arxiv,dgl,1,1820,29.4663,0.7256

 F1-mic 0.7257,  F1-mac 0.5142
ogbn-arxiv,dgl,1,1821,29.4824,0.7257

 F1-mic 0.7257,  F1-mac 0.5144
ogbn-arxiv,dgl,1,1822,29.4985,0.7257

 F1-mic 0.7258,  F1-mac 0.5144
ogbn-arxiv,dgl,1,1823,29.5145,0.7258

 F1-mic 0.7258,  F1-mac 0.5144
new best val f1: 0.7258399687262104
ogbn-arxiv,dgl,1,1824,29.5305,0.7258

 F1-mic 0.7258,  F1-mac 0.5143
ogbn-arxiv,dgl,1,1825,29.5466,0.7258

 F1-mic 0.7257,  F1-mac 0.5144
ogbn-arxiv,dgl,1,1826,29.5626,0.7257

 F1-mic 0.7258,  F1-mac 0.5143
ogbn-arxiv,dgl,1,1827,29.5787,0.7258

 F1-mic 0.7260,  F1-mac 0.5145
new best val f1: 0.7260045676192828
ogbn-arxiv,dgl,1,1828,29.5947,0.7260

 F1-mic 0.7257,  F1-mac 0.5143
ogbn-arxiv,dgl,1,1829,29.6108,0.7257

epoch:1831/50, Iteration 32/32:training loss 0.9409245252609253
Train F1-mic 0.7159, Train F1-mac 0.5325
 F1-mic 0.7258,  F1-mac 0.5143
ogbn-arxiv,dgl,1,1830,29.6269,0.7258

 F1-mic 0.7260,  F1-mac 0.5149
new best val f1: 0.7260251424809168
ogbn-arxiv,dgl,1,1831,29.6430,0.7260

 F1-mic 0.7259,  F1-mac 0.5146
ogbn-arxiv,dgl,1,1832,29.6591,0.7259

 F1-mic 0.7258,  F1-mac 0.5143
ogbn-arxiv,dgl,1,1833,29.6752,0.7258

 F1-mic 0.7261,  F1-mac 0.5151
new best val f1: 0.7261485916507211
ogbn-arxiv,dgl,1,1834,29.6912,0.7261

 F1-mic 0.7259,  F1-mac 0.5148
ogbn-arxiv,dgl,1,1835,29.7073,0.7259

 F1-mic 0.7258,  F1-mac 0.5144
ogbn-arxiv,dgl,1,1836,29.7233,0.7258

 F1-mic 0.7261,  F1-mac 0.5146
ogbn-arxiv,dgl,1,1837,29.7394,0.7261

 F1-mic 0.7259,  F1-mac 0.5144
ogbn-arxiv,dgl,1,1838,29.7554,0.7259

 F1-mic 0.7260,  F1-mac 0.5147
ogbn-arxiv,dgl,1,1839,29.7715,0.7260

epoch:1841/50, Iteration 32/32:training loss 0.9403296113014221
Train F1-mic 0.7162, Train F1-mac 0.5326
 F1-mic 0.7260,  F1-mac 0.5145
ogbn-arxiv,dgl,1,1840,29.7875,0.7260

 F1-mic 0.7258,  F1-mac 0.5144
ogbn-arxiv,dgl,1,1841,29.8037,0.7258

 F1-mic 0.7259,  F1-mac 0.5146
ogbn-arxiv,dgl,1,1842,29.8198,0.7259

 F1-mic 0.7261,  F1-mac 0.5147
ogbn-arxiv,dgl,1,1843,29.8358,0.7261

 F1-mic 0.7260,  F1-mac 0.5146
ogbn-arxiv,dgl,1,1844,29.8518,0.7260

 F1-mic 0.7259,  F1-mac 0.5146
ogbn-arxiv,dgl,1,1845,29.8679,0.7259

 F1-mic 0.7261,  F1-mac 0.5148
ogbn-arxiv,dgl,1,1846,29.8839,0.7261

 F1-mic 0.7259,  F1-mac 0.5146
ogbn-arxiv,dgl,1,1847,29.9000,0.7259

 F1-mic 0.7261,  F1-mac 0.5147
ogbn-arxiv,dgl,1,1848,29.9159,0.7261

 F1-mic 0.7261,  F1-mac 0.5146
ogbn-arxiv,dgl,1,1849,29.9320,0.7261

epoch:1851/50, Iteration 32/32:training loss 0.9397464394569397
Train F1-mic 0.7162, Train F1-mac 0.5325
 F1-mic 0.7259,  F1-mac 0.5144
ogbn-arxiv,dgl,1,1850,29.9480,0.7259

 F1-mic 0.7260,  F1-mac 0.5148
ogbn-arxiv,dgl,1,1851,29.9641,0.7260

 F1-mic 0.7261,  F1-mac 0.5143
ogbn-arxiv,dgl,1,1852,29.9802,0.7261

 F1-mic 0.7260,  F1-mac 0.5148
ogbn-arxiv,dgl,1,1853,29.9963,0.7260

 F1-mic 0.7260,  F1-mac 0.5148
ogbn-arxiv,dgl,1,1854,30.0123,0.7260

 F1-mic 0.7260,  F1-mac 0.5147
ogbn-arxiv,dgl,1,1855,30.0284,0.7260

 F1-mic 0.7261,  F1-mac 0.5149
ogbn-arxiv,dgl,1,1856,30.0444,0.7261

 F1-mic 0.7261,  F1-mac 0.5145
ogbn-arxiv,dgl,1,1857,30.0605,0.7261

 F1-mic 0.7261,  F1-mac 0.5146
ogbn-arxiv,dgl,1,1858,30.0765,0.7261

 F1-mic 0.7262,  F1-mac 0.5150
new best val f1: 0.7261897413739893
ogbn-arxiv,dgl,1,1859,30.0926,0.7262

epoch:1861/50, Iteration 32/32:training loss 0.9391553997993469
Train F1-mic 0.7163, Train F1-mac 0.5328
 F1-mic 0.7261,  F1-mac 0.5146
ogbn-arxiv,dgl,1,1860,30.1086,0.7261

 F1-mic 0.7262,  F1-mac 0.5147
ogbn-arxiv,dgl,1,1861,30.1247,0.7262

 F1-mic 0.7260,  F1-mac 0.5149
ogbn-arxiv,dgl,1,1862,30.1408,0.7260

 F1-mic 0.7260,  F1-mac 0.5147
ogbn-arxiv,dgl,1,1863,30.1568,0.7260

 F1-mic 0.7262,  F1-mac 0.5147
ogbn-arxiv,dgl,1,1864,30.1728,0.7262

 F1-mic 0.7260,  F1-mac 0.5148
ogbn-arxiv,dgl,1,1865,30.1889,0.7260

 F1-mic 0.7261,  F1-mac 0.5148
ogbn-arxiv,dgl,1,1866,30.2049,0.7261

 F1-mic 0.7262,  F1-mac 0.5148
new best val f1: 0.7262103162356233
ogbn-arxiv,dgl,1,1867,30.2210,0.7262

 F1-mic 0.7260,  F1-mac 0.5146
ogbn-arxiv,dgl,1,1868,30.2370,0.7260

 F1-mic 0.7260,  F1-mac 0.5148
ogbn-arxiv,dgl,1,1869,30.2530,0.7260

epoch:1871/50, Iteration 32/32:training loss 0.9385702013969421
Train F1-mic 0.7163, Train F1-mac 0.5329
 F1-mic 0.7261,  F1-mac 0.5146
ogbn-arxiv,dgl,1,1870,30.2691,0.7261

 F1-mic 0.7259,  F1-mac 0.5145
ogbn-arxiv,dgl,1,1871,30.2852,0.7259

 F1-mic 0.7262,  F1-mac 0.5148
ogbn-arxiv,dgl,1,1872,30.3013,0.7262

 F1-mic 0.7263,  F1-mac 0.5148
new best val f1: 0.7262514659588915
ogbn-arxiv,dgl,1,1873,30.3173,0.7263

 F1-mic 0.7261,  F1-mac 0.5148
ogbn-arxiv,dgl,1,1874,30.3334,0.7261

 F1-mic 0.7261,  F1-mac 0.5146
ogbn-arxiv,dgl,1,1875,30.3494,0.7261

 F1-mic 0.7262,  F1-mac 0.5148
ogbn-arxiv,dgl,1,1876,30.3654,0.7262

 F1-mic 0.7263,  F1-mac 0.5151
new best val f1: 0.7262926156821595
ogbn-arxiv,dgl,1,1877,30.3815,0.7263

 F1-mic 0.7263,  F1-mac 0.5151
new best val f1: 0.7263337654054277
ogbn-arxiv,dgl,1,1878,30.3975,0.7263

 F1-mic 0.7264,  F1-mac 0.5148
new best val f1: 0.7264160648519639
ogbn-arxiv,dgl,1,1879,30.4136,0.7264

epoch:1881/50, Iteration 32/32:training loss 0.9379872679710388
Train F1-mic 0.7165, Train F1-mac 0.5329
 F1-mic 0.7261,  F1-mac 0.5148
ogbn-arxiv,dgl,1,1880,30.4297,0.7261

 F1-mic 0.7262,  F1-mac 0.5149
ogbn-arxiv,dgl,1,1881,30.4458,0.7262

 F1-mic 0.7262,  F1-mac 0.5147
ogbn-arxiv,dgl,1,1882,30.4621,0.7262

 F1-mic 0.7263,  F1-mac 0.5154
ogbn-arxiv,dgl,1,1883,30.4781,0.7263

 F1-mic 0.7263,  F1-mac 0.5149
ogbn-arxiv,dgl,1,1884,30.4941,0.7263

 F1-mic 0.7264,  F1-mac 0.5146
new best val f1: 0.726436639713598
ogbn-arxiv,dgl,1,1885,30.5102,0.7264

 F1-mic 0.7262,  F1-mac 0.5147
ogbn-arxiv,dgl,1,1886,30.5262,0.7262

 F1-mic 0.7263,  F1-mac 0.5152
ogbn-arxiv,dgl,1,1887,30.5423,0.7263

 F1-mic 0.7265,  F1-mac 0.5151
new best val f1: 0.7264983642985001
ogbn-arxiv,dgl,1,1888,30.5583,0.7265

 F1-mic 0.7263,  F1-mac 0.5150
ogbn-arxiv,dgl,1,1889,30.5743,0.7263

epoch:1891/50, Iteration 32/32:training loss 0.9374005198478699
Train F1-mic 0.7166, Train F1-mac 0.5332
 F1-mic 0.7262,  F1-mac 0.5151
ogbn-arxiv,dgl,1,1890,30.5904,0.7262

 F1-mic 0.7264,  F1-mac 0.5150
ogbn-arxiv,dgl,1,1891,30.6065,0.7264

 F1-mic 0.7264,  F1-mac 0.5151
ogbn-arxiv,dgl,1,1892,30.6226,0.7264

 F1-mic 0.7263,  F1-mac 0.5151
ogbn-arxiv,dgl,1,1893,30.6386,0.7263

 F1-mic 0.7263,  F1-mac 0.5150
ogbn-arxiv,dgl,1,1894,30.6546,0.7263

 F1-mic 0.7265,  F1-mac 0.5151
ogbn-arxiv,dgl,1,1895,30.6707,0.7265

 F1-mic 0.7264,  F1-mac 0.5154
ogbn-arxiv,dgl,1,1896,30.6867,0.7264

 F1-mic 0.7264,  F1-mac 0.5152
ogbn-arxiv,dgl,1,1897,30.7028,0.7264

 F1-mic 0.7264,  F1-mac 0.5152
ogbn-arxiv,dgl,1,1898,30.7188,0.7264

 F1-mic 0.7263,  F1-mac 0.5151
ogbn-arxiv,dgl,1,1899,30.7348,0.7263

epoch:1901/50, Iteration 32/32:training loss 0.9368183016777039
Train F1-mic 0.7166, Train F1-mac 0.5335
 F1-mic 0.7264,  F1-mac 0.5151
ogbn-arxiv,dgl,1,1900,30.7509,0.7264

 F1-mic 0.7265,  F1-mac 0.5153
ogbn-arxiv,dgl,1,1901,30.7670,0.7265

 F1-mic 0.7265,  F1-mac 0.5156
ogbn-arxiv,dgl,1,1902,30.7831,0.7265

 F1-mic 0.7263,  F1-mac 0.5154
ogbn-arxiv,dgl,1,1903,30.7991,0.7263

 F1-mic 0.7266,  F1-mac 0.5152
new best val f1: 0.7265600888834022
ogbn-arxiv,dgl,1,1904,30.8151,0.7266

 F1-mic 0.7264,  F1-mac 0.5150
ogbn-arxiv,dgl,1,1905,30.8312,0.7264

 F1-mic 0.7264,  F1-mac 0.5153
ogbn-arxiv,dgl,1,1906,30.8472,0.7264

 F1-mic 0.7265,  F1-mac 0.5153
ogbn-arxiv,dgl,1,1907,30.8633,0.7265

 F1-mic 0.7265,  F1-mac 0.5156
ogbn-arxiv,dgl,1,1908,30.8793,0.7265

 F1-mic 0.7265,  F1-mac 0.5156
ogbn-arxiv,dgl,1,1909,30.8954,0.7265

epoch:1911/50, Iteration 32/32:training loss 0.9362392425537109
Train F1-mic 0.7168, Train F1-mac 0.5340
 F1-mic 0.7266,  F1-mac 0.5157
new best val f1: 0.7266012386066705
ogbn-arxiv,dgl,1,1910,30.9115,0.7266

 F1-mic 0.7266,  F1-mac 0.5157
ogbn-arxiv,dgl,1,1911,30.9276,0.7266

 F1-mic 0.7267,  F1-mac 0.5157
new best val f1: 0.7266835380532066
ogbn-arxiv,dgl,1,1912,30.9437,0.7267

 F1-mic 0.7267,  F1-mac 0.5156
ogbn-arxiv,dgl,1,1913,30.9597,0.7267

 F1-mic 0.7265,  F1-mac 0.5156
ogbn-arxiv,dgl,1,1914,30.9758,0.7265

 F1-mic 0.7266,  F1-mac 0.5154
ogbn-arxiv,dgl,1,1915,30.9918,0.7266

 F1-mic 0.7267,  F1-mac 0.5159
new best val f1: 0.7267452626381088
ogbn-arxiv,dgl,1,1916,31.0079,0.7267

 F1-mic 0.7266,  F1-mac 0.5156
ogbn-arxiv,dgl,1,1917,31.0240,0.7266

 F1-mic 0.7266,  F1-mac 0.5155
ogbn-arxiv,dgl,1,1918,31.0400,0.7266

 F1-mic 0.7267,  F1-mac 0.5157
ogbn-arxiv,dgl,1,1919,31.0561,0.7267

epoch:1921/50, Iteration 32/32:training loss 0.9356620907783508
Train F1-mic 0.7170, Train F1-mac 0.5340
 F1-mic 0.7266,  F1-mac 0.5156
ogbn-arxiv,dgl,1,1920,31.0721,0.7266

 F1-mic 0.7267,  F1-mac 0.5156
ogbn-arxiv,dgl,1,1921,31.0882,0.7267

 F1-mic 0.7268,  F1-mac 0.5159
new best val f1: 0.726827562084645
ogbn-arxiv,dgl,1,1922,31.1043,0.7268

 F1-mic 0.7266,  F1-mac 0.5155
ogbn-arxiv,dgl,1,1923,31.1203,0.7266

 F1-mic 0.7266,  F1-mac 0.5156
ogbn-arxiv,dgl,1,1924,31.1363,0.7266

 F1-mic 0.7266,  F1-mac 0.5159
ogbn-arxiv,dgl,1,1925,31.1524,0.7266

 F1-mic 0.7267,  F1-mac 0.5157
ogbn-arxiv,dgl,1,1926,31.1684,0.7267

 F1-mic 0.7267,  F1-mac 0.5156
ogbn-arxiv,dgl,1,1927,31.1845,0.7267

 F1-mic 0.7268,  F1-mac 0.5163
ogbn-arxiv,dgl,1,1928,31.2005,0.7268

 F1-mic 0.7267,  F1-mac 0.5157
ogbn-arxiv,dgl,1,1929,31.2166,0.7267

epoch:1931/50, Iteration 32/32:training loss 0.9350874423980713
Train F1-mic 0.7169, Train F1-mac 0.5344
 F1-mic 0.7267,  F1-mac 0.5157
ogbn-arxiv,dgl,1,1930,31.2327,0.7267

 F1-mic 0.7267,  F1-mac 0.5159
ogbn-arxiv,dgl,1,1931,31.2488,0.7267

 F1-mic 0.7268,  F1-mac 0.5159
ogbn-arxiv,dgl,1,1932,31.2649,0.7268

 F1-mic 0.7268,  F1-mac 0.5159
ogbn-arxiv,dgl,1,1933,31.2809,0.7268

 F1-mic 0.7268,  F1-mac 0.5158
ogbn-arxiv,dgl,1,1934,31.2969,0.7268

 F1-mic 0.7267,  F1-mac 0.5159
ogbn-arxiv,dgl,1,1935,31.3130,0.7267

 F1-mic 0.7268,  F1-mac 0.5159
ogbn-arxiv,dgl,1,1936,31.3290,0.7268

 F1-mic 0.7269,  F1-mac 0.5162
new best val f1: 0.726889286669547
ogbn-arxiv,dgl,1,1937,31.3450,0.7269

 F1-mic 0.7269,  F1-mac 0.5162
ogbn-arxiv,dgl,1,1938,31.3611,0.7269

 F1-mic 0.7268,  F1-mac 0.5163
ogbn-arxiv,dgl,1,1939,31.3772,0.7268

epoch:1941/50, Iteration 32/32:training loss 0.9345108866691589
Train F1-mic 0.7172, Train F1-mac 0.5346
 F1-mic 0.7268,  F1-mac 0.5166
ogbn-arxiv,dgl,1,1940,31.3932,0.7268

 F1-mic 0.7270,  F1-mac 0.5162
new best val f1: 0.7269510112544493
ogbn-arxiv,dgl,1,1941,31.4094,0.7270

 F1-mic 0.7268,  F1-mac 0.5162
ogbn-arxiv,dgl,1,1942,31.4255,0.7268

 F1-mic 0.7268,  F1-mac 0.5163
ogbn-arxiv,dgl,1,1943,31.4415,0.7268

 F1-mic 0.7269,  F1-mac 0.5166
ogbn-arxiv,dgl,1,1944,31.4575,0.7269

 F1-mic 0.7269,  F1-mac 0.5165
ogbn-arxiv,dgl,1,1945,31.4735,0.7269

 F1-mic 0.7269,  F1-mac 0.5164
ogbn-arxiv,dgl,1,1946,31.4896,0.7269

 F1-mic 0.7268,  F1-mac 0.5163
ogbn-arxiv,dgl,1,1947,31.5057,0.7268

 F1-mic 0.7269,  F1-mac 0.5164
ogbn-arxiv,dgl,1,1948,31.5217,0.7269

 F1-mic 0.7269,  F1-mac 0.5163
ogbn-arxiv,dgl,1,1949,31.5378,0.7269

epoch:1951/50, Iteration 32/32:training loss 0.9339354038238525
Train F1-mic 0.7173, Train F1-mac 0.5350
 F1-mic 0.7269,  F1-mac 0.5166
ogbn-arxiv,dgl,1,1950,31.5538,0.7269

 F1-mic 0.7268,  F1-mac 0.5166
ogbn-arxiv,dgl,1,1951,31.5699,0.7268

 F1-mic 0.7270,  F1-mac 0.5169
new best val f1: 0.7270127358393514
ogbn-arxiv,dgl,1,1952,31.5860,0.7270

 F1-mic 0.7270,  F1-mac 0.5166
ogbn-arxiv,dgl,1,1953,31.6021,0.7270

 F1-mic 0.7268,  F1-mac 0.5167
ogbn-arxiv,dgl,1,1954,31.6181,0.7268

 F1-mic 0.7270,  F1-mac 0.5171
ogbn-arxiv,dgl,1,1955,31.6341,0.7270

 F1-mic 0.7270,  F1-mac 0.5169
ogbn-arxiv,dgl,1,1956,31.6502,0.7270

 F1-mic 0.7268,  F1-mac 0.5165
ogbn-arxiv,dgl,1,1957,31.6663,0.7268

 F1-mic 0.7270,  F1-mac 0.5168
ogbn-arxiv,dgl,1,1958,31.6823,0.7270

 F1-mic 0.7269,  F1-mac 0.5166
ogbn-arxiv,dgl,1,1959,31.6984,0.7269

epoch:1961/50, Iteration 32/32:training loss 0.9333639144897461
Train F1-mic 0.7173, Train F1-mac 0.5351
 F1-mic 0.7269,  F1-mac 0.5168
ogbn-arxiv,dgl,1,1960,31.7144,0.7269

 F1-mic 0.7269,  F1-mac 0.5163
ogbn-arxiv,dgl,1,1961,31.7306,0.7269

 F1-mic 0.7268,  F1-mac 0.5166
ogbn-arxiv,dgl,1,1962,31.7467,0.7268

 F1-mic 0.7270,  F1-mac 0.5169
ogbn-arxiv,dgl,1,1963,31.7627,0.7270

 F1-mic 0.7271,  F1-mac 0.5171
new best val f1: 0.7270538855626196
ogbn-arxiv,dgl,1,1964,31.7787,0.7271

 F1-mic 0.7270,  F1-mac 0.5168
ogbn-arxiv,dgl,1,1965,31.7948,0.7270

 F1-mic 0.7270,  F1-mac 0.5166
ogbn-arxiv,dgl,1,1966,31.8109,0.7270

 F1-mic 0.7269,  F1-mac 0.5169
ogbn-arxiv,dgl,1,1967,31.8269,0.7269

 F1-mic 0.7271,  F1-mac 0.5169
new best val f1: 0.7270744604242535
ogbn-arxiv,dgl,1,1968,31.8430,0.7271

 F1-mic 0.7271,  F1-mac 0.5168
new best val f1: 0.7270950352858877
ogbn-arxiv,dgl,1,1969,31.8590,0.7271

epoch:1971/50, Iteration 32/32:training loss 0.9327928423881531
Train F1-mic 0.7175, Train F1-mac 0.5354
 F1-mic 0.7271,  F1-mac 0.5171
ogbn-arxiv,dgl,1,1970,31.8751,0.7271

 F1-mic 0.7272,  F1-mac 0.5172
new best val f1: 0.727197909594058
ogbn-arxiv,dgl,1,1971,31.8912,0.7272

 F1-mic 0.7271,  F1-mac 0.5172
ogbn-arxiv,dgl,1,1972,31.9073,0.7271

 F1-mic 0.7269,  F1-mac 0.5169
ogbn-arxiv,dgl,1,1973,31.9234,0.7269

 F1-mic 0.7270,  F1-mac 0.5169
ogbn-arxiv,dgl,1,1974,31.9394,0.7270

 F1-mic 0.7270,  F1-mac 0.5172
ogbn-arxiv,dgl,1,1975,31.9555,0.7270

 F1-mic 0.7272,  F1-mac 0.5173
ogbn-arxiv,dgl,1,1976,31.9715,0.7272

 F1-mic 0.7271,  F1-mac 0.5172
ogbn-arxiv,dgl,1,1977,31.9876,0.7271

 F1-mic 0.7272,  F1-mac 0.5175
ogbn-arxiv,dgl,1,1978,32.0036,0.7272

 F1-mic 0.7272,  F1-mac 0.5174
ogbn-arxiv,dgl,1,1979,32.0197,0.7272

epoch:1981/50, Iteration 32/32:training loss 0.932225227355957
Train F1-mic 0.7176, Train F1-mac 0.5354
 F1-mic 0.7271,  F1-mac 0.5173
ogbn-arxiv,dgl,1,1980,32.0357,0.7271

 F1-mic 0.7272,  F1-mac 0.5173
ogbn-arxiv,dgl,1,1981,32.0519,0.7272

 F1-mic 0.7273,  F1-mac 0.5177
new best val f1: 0.7272596341789601
ogbn-arxiv,dgl,1,1982,32.0679,0.7273

 F1-mic 0.7270,  F1-mac 0.5170
ogbn-arxiv,dgl,1,1983,32.0839,0.7270

 F1-mic 0.7271,  F1-mac 0.5167
ogbn-arxiv,dgl,1,1984,32.1002,0.7271

 F1-mic 0.7272,  F1-mac 0.5172
ogbn-arxiv,dgl,1,1985,32.1162,0.7272

 F1-mic 0.7270,  F1-mac 0.5167
ogbn-arxiv,dgl,1,1986,32.1323,0.7270

 F1-mic 0.7272,  F1-mac 0.5171
ogbn-arxiv,dgl,1,1987,32.1484,0.7272

 F1-mic 0.7272,  F1-mac 0.5171
ogbn-arxiv,dgl,1,1988,32.1644,0.7272

 F1-mic 0.7271,  F1-mac 0.5170
ogbn-arxiv,dgl,1,1989,32.1804,0.7271

epoch:1991/50, Iteration 32/32:training loss 0.9316585659980774
Train F1-mic 0.7176, Train F1-mac 0.5357
 F1-mic 0.7272,  F1-mac 0.5169
ogbn-arxiv,dgl,1,1990,32.1965,0.7272

 F1-mic 0.7272,  F1-mac 0.5169
ogbn-arxiv,dgl,1,1991,32.2126,0.7272

 F1-mic 0.7272,  F1-mac 0.5173
ogbn-arxiv,dgl,1,1992,32.2287,0.7272

 F1-mic 0.7273,  F1-mac 0.5173
new best val f1: 0.7273213587638623
ogbn-arxiv,dgl,1,1993,32.2448,0.7273

 F1-mic 0.7272,  F1-mac 0.5171
ogbn-arxiv,dgl,1,1994,32.2608,0.7272

 F1-mic 0.7271,  F1-mac 0.5172
ogbn-arxiv,dgl,1,1995,32.2768,0.7271

 F1-mic 0.7273,  F1-mac 0.5173
ogbn-arxiv,dgl,1,1996,32.2929,0.7273

 F1-mic 0.7273,  F1-mac 0.5174
new best val f1: 0.7273419336254963
ogbn-arxiv,dgl,1,1997,32.3090,0.7273

 F1-mic 0.7273,  F1-mac 0.5173
ogbn-arxiv,dgl,1,1998,32.3250,0.7273

 F1-mic 0.7273,  F1-mac 0.5172
ogbn-arxiv,dgl,1,1999,32.3411,0.7273

training using time 203.60693764686584
Test F1-mic 0.7273, Test F1-mac 0.5172
Namespace(csv='full.csv', dataset='reddit', gpu=0, log_dir='test', lr=0.001, n_epochs=50, n_hidden=128, online=False)
Inited proc group
Namespace(csv='full.csv', dataset='meta', gpu=0, log_dir='test', lr=0.001, n_epochs=50, n_hidden=128, online=False)
Inited proc group
15359
torch.Size([15360, 64])
15317
torch.Size([15318, 64])
15321
torch.Size([15322, 64])
Max label: tensor(24.)
----Data statistics------'
    #Nodes 500036
    #Edges 53859150
    #Classes/Labels (multi binary labels) 25
    #Train samples 166678
    #Val samples 166678
    #Test samples 166680
Running on: 0
GCN(
  (layers): ModuleList(
    (0): GraphConv(in=64, out=128, normalization=both, activation=<function relu at 0x14f267febc20>)
    (1): GraphConv(in=128, out=25, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0.1, inplace=False)
)
Namespace(csv='full.csv', dataset='meta', gpu=0, log_dir='test', lr=0.001, n_epochs=50, n_hidden=128, online=False)
epoch:1/50, Iteration 32/32:training loss 3.2065980434417725
Train F1-mic 0.0160, Train F1-mac 0.0026
 F1-mic 0.0334,  F1-mac 0.0119
new best val f1: 0.033363330933525316
meta,dgl,1,0,0.3326,0.0334

 F1-mic 0.1734,  F1-mac 0.0484
new best val f1: 0.17335013198944085
meta,dgl,1,1,0.3832,0.1734

 F1-mic 0.2737,  F1-mac 0.0638
new best val f1: 0.27374610031197505
meta,dgl,1,2,0.4344,0.2737

 F1-mic 0.3107,  F1-mac 0.0623
new best val f1: 0.31067314614830815
meta,dgl,1,3,0.4847,0.3107

 F1-mic 0.3106,  F1-mac 0.0630
meta,dgl,1,4,0.5353,0.3106

 F1-mic 0.3178,  F1-mac 0.0704
new best val f1: 0.3177645788336933
meta,dgl,1,5,0.5856,0.3178

 F1-mic 0.3334,  F1-mac 0.0786
new best val f1: 0.3333753299736021
meta,dgl,1,6,0.6361,0.3334

 F1-mic 0.3374,  F1-mac 0.0781
new best val f1: 0.33738300935925125
meta,dgl,1,7,0.6867,0.3374

 F1-mic 0.3259,  F1-mac 0.0705
meta,dgl,1,8,0.7372,0.3259

 F1-mic 0.3171,  F1-mac 0.0634
meta,dgl,1,9,0.7878,0.3171

epoch:11/50, Iteration 32/32:training loss 3.077000379562378
Train F1-mic 0.3159, Train F1-mac 0.0632
 F1-mic 0.3162,  F1-mac 0.0628
meta,dgl,1,10,0.8385,0.3162

 F1-mic 0.3158,  F1-mac 0.0627
meta,dgl,1,11,0.8888,0.3158

 F1-mic 0.3154,  F1-mac 0.0627
meta,dgl,1,12,0.9392,0.3154

 F1-mic 0.3150,  F1-mac 0.0627
meta,dgl,1,13,0.9895,0.3150

 F1-mic 0.3146,  F1-mac 0.0626
meta,dgl,1,14,1.0399,0.3146

 F1-mic 0.3143,  F1-mac 0.0626
meta,dgl,1,15,1.0904,0.3143

 F1-mic 0.3140,  F1-mac 0.0626
meta,dgl,1,16,1.1412,0.3140

 F1-mic 0.3137,  F1-mac 0.0625
meta,dgl,1,17,1.1918,0.3137

 F1-mic 0.3135,  F1-mac 0.0625
meta,dgl,1,18,1.2425,0.3135

 F1-mic 0.3135,  F1-mac 0.0626
meta,dgl,1,19,1.2929,0.3135

epoch:21/50, Iteration 32/32:training loss 2.941657304763794
Train F1-mic 0.3123, Train F1-mac 0.0625
 F1-mic 0.3135,  F1-mac 0.0628
meta,dgl,1,20,1.3435,0.3135

 F1-mic 0.3136,  F1-mac 0.0630
meta,dgl,1,21,1.3941,0.3136

 F1-mic 0.3139,  F1-mac 0.0634
meta,dgl,1,22,1.4446,0.3139

 F1-mic 0.3142,  F1-mac 0.0638
meta,dgl,1,23,1.4952,0.3142

 F1-mic 0.3145,  F1-mac 0.0643
meta,dgl,1,24,1.5462,0.3145

 F1-mic 0.3146,  F1-mac 0.0647
meta,dgl,1,25,1.5967,0.3146

 F1-mic 0.3147,  F1-mac 0.0654
meta,dgl,1,26,1.6473,0.3147

 F1-mic 0.3149,  F1-mac 0.0662
meta,dgl,1,27,1.6979,0.3149

 F1-mic 0.3149,  F1-mac 0.0668
meta,dgl,1,28,1.7483,0.3149

 F1-mic 0.3146,  F1-mac 0.0673
meta,dgl,1,29,1.7988,0.3146

epoch:31/50, Iteration 32/32:training loss 2.7976059913635254
Train F1-mic 0.3140, Train F1-mac 0.0674
 F1-mic 0.3140,  F1-mac 0.0677
meta,dgl,1,30,1.8493,0.3140

 F1-mic 0.3127,  F1-mac 0.0679
meta,dgl,1,31,1.8998,0.3127

 F1-mic 0.3113,  F1-mac 0.0681
meta,dgl,1,32,1.9503,0.3113

 F1-mic 0.3100,  F1-mac 0.0682
meta,dgl,1,33,2.0009,0.3100

 F1-mic 0.3091,  F1-mac 0.0683
meta,dgl,1,34,2.0515,0.3091

 F1-mic 0.3076,  F1-mac 0.0683
meta,dgl,1,35,2.1026,0.3076

 F1-mic 0.3051,  F1-mac 0.0681
meta,dgl,1,36,2.1531,0.3051

 F1-mic 0.3031,  F1-mac 0.0678
meta,dgl,1,37,2.2037,0.3031

 F1-mic 0.3013,  F1-mac 0.0676
meta,dgl,1,38,2.2542,0.3013

 F1-mic 0.2994,  F1-mac 0.0673
meta,dgl,1,39,2.3048,0.2994

epoch:41/50, Iteration 32/32:training loss 2.6637542247772217
Train F1-mic 0.2987, Train F1-mac 0.0672
 F1-mic 0.2974,  F1-mac 0.0670
meta,dgl,1,40,2.3553,0.2974

 F1-mic 0.2959,  F1-mac 0.0666
meta,dgl,1,41,2.4061,0.2959

 F1-mic 0.2949,  F1-mac 0.0663
meta,dgl,1,42,2.4565,0.2949

 F1-mic 0.2939,  F1-mac 0.0658
meta,dgl,1,43,2.5072,0.2939

 F1-mic 0.2948,  F1-mac 0.0657
meta,dgl,1,44,2.5576,0.2948

 F1-mic 0.2970,  F1-mac 0.0657
meta,dgl,1,45,2.6082,0.2970

 F1-mic 0.3019,  F1-mac 0.0659
meta,dgl,1,46,2.6586,0.3019

 F1-mic 0.3076,  F1-mac 0.0662
meta,dgl,1,47,2.7093,0.3076

 F1-mic 0.3150,  F1-mac 0.0667
meta,dgl,1,48,2.7598,0.3150

 F1-mic 0.3216,  F1-mac 0.0672
meta,dgl,1,49,2.8104,0.3216

epoch:51/50, Iteration 32/32:training loss 2.5507049560546875
Train F1-mic 0.3211, Train F1-mac 0.0671
 F1-mic 0.3280,  F1-mac 0.0678
meta,dgl,1,50,2.8609,0.3280

 F1-mic 0.3326,  F1-mac 0.0681
meta,dgl,1,51,2.9114,0.3326

 F1-mic 0.3362,  F1-mac 0.0685
meta,dgl,1,52,2.9622,0.3362

 F1-mic 0.3393,  F1-mac 0.0688
new best val f1: 0.3392908567314615
meta,dgl,1,53,3.0128,0.3393

 F1-mic 0.3416,  F1-mac 0.0689
new best val f1: 0.3416126709863211
meta,dgl,1,54,3.0633,0.3416

 F1-mic 0.3434,  F1-mac 0.0691
new best val f1: 0.3433765298776098
meta,dgl,1,55,3.1138,0.3434

 F1-mic 0.3446,  F1-mac 0.0691
new best val f1: 0.34460643148548115
meta,dgl,1,56,3.1643,0.3446

 F1-mic 0.3460,  F1-mac 0.0692
new best val f1: 0.34602831773458126
meta,dgl,1,57,3.2151,0.3460

 F1-mic 0.3468,  F1-mac 0.0691
new best val f1: 0.34676625869930405
meta,dgl,1,58,3.2654,0.3468

 F1-mic 0.3473,  F1-mac 0.0691
new best val f1: 0.34734221262299014
meta,dgl,1,59,3.3158,0.3473

epoch:61/50, Iteration 32/32:training loss 2.456237316131592
Train F1-mic 0.3462, Train F1-mac 0.0689
 F1-mic 0.3477,  F1-mac 0.0691
new best val f1: 0.3476841852651788
meta,dgl,1,60,3.3662,0.3477

 F1-mic 0.3480,  F1-mac 0.0690
new best val f1: 0.34800215982721383
meta,dgl,1,61,3.4166,0.3480

 F1-mic 0.3484,  F1-mac 0.0690
new best val f1: 0.34839212862970964
meta,dgl,1,62,3.4675,0.3484

 F1-mic 0.3488,  F1-mac 0.0690
new best val f1: 0.34878809695224383
meta,dgl,1,63,3.5180,0.3488

 F1-mic 0.3489,  F1-mac 0.0690
new best val f1: 0.34891408687305014
meta,dgl,1,64,3.5685,0.3489

 F1-mic 0.3490,  F1-mac 0.0689
new best val f1: 0.3490220782337413
meta,dgl,1,65,3.6189,0.3490

 F1-mic 0.3491,  F1-mac 0.0689
new best val f1: 0.3490820734341253
meta,dgl,1,66,3.6694,0.3491

 F1-mic 0.3492,  F1-mac 0.0688
new best val f1: 0.3492020638348932
meta,dgl,1,67,3.7200,0.3492

 F1-mic 0.3497,  F1-mac 0.0692
new best val f1: 0.34970002399808015
meta,dgl,1,68,3.7708,0.3497

 F1-mic 0.3512,  F1-mac 0.0706
new best val f1: 0.3512419006479482
meta,dgl,1,69,3.8214,0.3512

epoch:71/50, Iteration 32/32:training loss 2.3761212825775146
Train F1-mic 0.3501, Train F1-mac 0.0703
 F1-mic 0.3536,  F1-mac 0.0727
new best val f1: 0.35363570914326853
meta,dgl,1,70,3.8720,0.3536

 F1-mic 0.3569,  F1-mac 0.0752
new best val f1: 0.3568634509239261
meta,dgl,1,71,3.9226,0.3569

 F1-mic 0.3603,  F1-mac 0.0776
new best val f1: 0.3603071754259659
meta,dgl,1,72,3.9732,0.3603

 F1-mic 0.3647,  F1-mac 0.0804
new best val f1: 0.3646688264938805
meta,dgl,1,73,4.0237,0.3647

 F1-mic 0.3686,  F1-mac 0.0826
new best val f1: 0.3686405087592992
meta,dgl,1,74,4.0743,0.3686

 F1-mic 0.3733,  F1-mac 0.0853
new best val f1: 0.3733201343892489
meta,dgl,1,75,4.1246,0.3733

 F1-mic 0.3790,  F1-mac 0.0885
new best val f1: 0.3789716822654188
meta,dgl,1,76,4.1752,0.3790

 F1-mic 0.3839,  F1-mac 0.0914
new best val f1: 0.38389128869690425
meta,dgl,1,77,4.2257,0.3839

 F1-mic 0.3894,  F1-mac 0.0945
new best val f1: 0.3894468442524598
meta,dgl,1,78,4.2762,0.3894

 F1-mic 0.3946,  F1-mac 0.0974
new best val f1: 0.3945644348452124
meta,dgl,1,79,4.3266,0.3946

epoch:81/50, Iteration 32/32:training loss 2.306480646133423
Train F1-mic 0.3937, Train F1-mac 0.0973
 F1-mic 0.3994,  F1-mac 0.1000
new best val f1: 0.39937005039596835
meta,dgl,1,80,4.3770,0.3994

 F1-mic 0.4044,  F1-mac 0.1027
new best val f1: 0.4044036477081833
meta,dgl,1,81,4.4275,0.4044

 F1-mic 0.4083,  F1-mac 0.1048
new best val f1: 0.4083333333333333
meta,dgl,1,82,4.4781,0.4083

 F1-mic 0.4113,  F1-mac 0.1063
new best val f1: 0.4113030957523398
meta,dgl,1,83,4.5284,0.4113

 F1-mic 0.4139,  F1-mac 0.1076
new best val f1: 0.41392488600911925
meta,dgl,1,84,4.5789,0.4139

 F1-mic 0.4163,  F1-mac 0.1088
new best val f1: 0.41629469642428607
meta,dgl,1,85,4.6292,0.4163

 F1-mic 0.4178,  F1-mac 0.1094
new best val f1: 0.4177945764338853
meta,dgl,1,86,4.6798,0.4178

 F1-mic 0.4194,  F1-mac 0.1100
new best val f1: 0.41943244540436764
meta,dgl,1,87,4.7303,0.4194

 F1-mic 0.4208,  F1-mac 0.1106
new best val f1: 0.42081833453323736
meta,dgl,1,88,4.7807,0.4208

 F1-mic 0.4223,  F1-mac 0.1111
new best val f1: 0.4223002159827214
meta,dgl,1,89,4.8313,0.4223

epoch:91/50, Iteration 32/32:training loss 2.245327949523926
Train F1-mic 0.4214, Train F1-mac 0.1110
 F1-mic 0.4235,  F1-mac 0.1115
new best val f1: 0.42350011999040077
meta,dgl,1,90,4.8817,0.4235

 F1-mic 0.4248,  F1-mac 0.1119
new best val f1: 0.4248380129589633
meta,dgl,1,91,4.9322,0.4248

 F1-mic 0.4262,  F1-mac 0.1123
new best val f1: 0.4262479001679866
meta,dgl,1,92,4.9826,0.4262

 F1-mic 0.4275,  F1-mac 0.1126
new best val f1: 0.42747780177585787
meta,dgl,1,93,5.0332,0.4275

 F1-mic 0.4287,  F1-mac 0.1129
new best val f1: 0.4286957043436525
meta,dgl,1,94,5.0837,0.4287

 F1-mic 0.4300,  F1-mac 0.1131
new best val f1: 0.42997960163186943
meta,dgl,1,95,5.1342,0.4300

 F1-mic 0.4310,  F1-mac 0.1133
new best val f1: 0.4310415166786657
meta,dgl,1,96,5.1849,0.4310

 F1-mic 0.4321,  F1-mac 0.1134
new best val f1: 0.4320794336453084
meta,dgl,1,97,5.2356,0.4321

 F1-mic 0.4330,  F1-mac 0.1136
new best val f1: 0.4330093592512599
meta,dgl,1,98,5.2862,0.4330

 F1-mic 0.4341,  F1-mac 0.1138
new best val f1: 0.43406527477801776
meta,dgl,1,99,5.3367,0.4341

epoch:101/50, Iteration 32/32:training loss 2.190894842147827
Train F1-mic 0.4329, Train F1-mac 0.1135
 F1-mic 0.4350,  F1-mac 0.1140
new best val f1: 0.4349832013438925
meta,dgl,1,100,5.3872,0.4350

 F1-mic 0.4356,  F1-mac 0.1141
new best val f1: 0.43561315094792424
meta,dgl,1,101,5.4378,0.4356

 F1-mic 0.4363,  F1-mac 0.1143
new best val f1: 0.43630309575233983
meta,dgl,1,102,5.4885,0.4363

 F1-mic 0.4369,  F1-mac 0.1145
new best val f1: 0.4368970482361411
meta,dgl,1,103,5.5390,0.4369

 F1-mic 0.4373,  F1-mac 0.1147
new best val f1: 0.4373230141588673
meta,dgl,1,104,5.5895,0.4373

 F1-mic 0.4376,  F1-mac 0.1148
new best val f1: 0.4375629949604032
meta,dgl,1,105,5.6399,0.4376

 F1-mic 0.4378,  F1-mac 0.1151
new best val f1: 0.43781497480201587
meta,dgl,1,106,5.6905,0.4378

 F1-mic 0.4380,  F1-mac 0.1153
new best val f1: 0.43801295896328296
meta,dgl,1,107,5.7410,0.4380

 F1-mic 0.4380,  F1-mac 0.1155
meta,dgl,1,108,5.7916,0.4380

 F1-mic 0.4378,  F1-mac 0.1156
meta,dgl,1,109,5.8423,0.4378

epoch:111/50, Iteration 32/32:training loss 2.1417813301086426
Train F1-mic 0.4365, Train F1-mac 0.1152
 F1-mic 0.4374,  F1-mac 0.1156
meta,dgl,1,110,5.8932,0.4374

 F1-mic 0.4371,  F1-mac 0.1157
meta,dgl,1,111,5.9436,0.4371

 F1-mic 0.4365,  F1-mac 0.1157
meta,dgl,1,112,5.9942,0.4365

 F1-mic 0.4359,  F1-mac 0.1155
meta,dgl,1,113,6.0451,0.4359

 F1-mic 0.4352,  F1-mac 0.1154
meta,dgl,1,114,6.0955,0.4352

 F1-mic 0.4346,  F1-mac 0.1152
meta,dgl,1,115,6.1460,0.4346

 F1-mic 0.4340,  F1-mac 0.1150
meta,dgl,1,116,6.1964,0.4340

 F1-mic 0.4335,  F1-mac 0.1148
meta,dgl,1,117,6.2470,0.4335

 F1-mic 0.4329,  F1-mac 0.1146
meta,dgl,1,118,6.2975,0.4329

 F1-mic 0.4325,  F1-mac 0.1144
meta,dgl,1,119,6.3486,0.4325

epoch:121/50, Iteration 32/32:training loss 2.0968613624572754
Train F1-mic 0.4314, Train F1-mac 0.1142
 F1-mic 0.4322,  F1-mac 0.1143
meta,dgl,1,120,6.3990,0.4322

 F1-mic 0.4317,  F1-mac 0.1140
meta,dgl,1,121,6.4493,0.4317

 F1-mic 0.4316,  F1-mac 0.1140
meta,dgl,1,122,6.4997,0.4316

 F1-mic 0.4314,  F1-mac 0.1139
meta,dgl,1,123,6.5500,0.4314

 F1-mic 0.4314,  F1-mac 0.1138
meta,dgl,1,124,6.6014,0.4314

 F1-mic 0.4314,  F1-mac 0.1138
meta,dgl,1,125,6.6518,0.4314

 F1-mic 0.4314,  F1-mac 0.1138
meta,dgl,1,126,6.7024,0.4314

 F1-mic 0.4316,  F1-mac 0.1138
meta,dgl,1,127,6.7529,0.4316

 F1-mic 0.4316,  F1-mac 0.1138
meta,dgl,1,128,6.8038,0.4316

 F1-mic 0.4316,  F1-mac 0.1138
meta,dgl,1,129,6.8543,0.4316

epoch:131/50, Iteration 32/32:training loss 2.0555758476257324
Train F1-mic 0.4303, Train F1-mac 0.1135
 F1-mic 0.4316,  F1-mac 0.1137
meta,dgl,1,130,6.9047,0.4316

 F1-mic 0.4317,  F1-mac 0.1138
meta,dgl,1,131,6.9553,0.4317

 F1-mic 0.4318,  F1-mac 0.1138
meta,dgl,1,132,7.0058,0.4318

 F1-mic 0.4319,  F1-mac 0.1138
meta,dgl,1,133,7.0566,0.4319

 F1-mic 0.4321,  F1-mac 0.1139
meta,dgl,1,134,7.1074,0.4321

 F1-mic 0.4322,  F1-mac 0.1139
meta,dgl,1,135,7.1579,0.4322

 F1-mic 0.4323,  F1-mac 0.1139
meta,dgl,1,136,7.2084,0.4323

 F1-mic 0.4325,  F1-mac 0.1140
meta,dgl,1,137,7.2590,0.4325

 F1-mic 0.4326,  F1-mac 0.1140
meta,dgl,1,138,7.3100,0.4326

 F1-mic 0.4328,  F1-mac 0.1141
meta,dgl,1,139,7.3606,0.4328

epoch:141/50, Iteration 32/32:training loss 2.0175185203552246
Train F1-mic 0.4316, Train F1-mac 0.1138
 F1-mic 0.4329,  F1-mac 0.1141
meta,dgl,1,140,7.4111,0.4329

 F1-mic 0.4331,  F1-mac 0.1142
meta,dgl,1,141,7.4615,0.4331

 F1-mic 0.4333,  F1-mac 0.1142
meta,dgl,1,142,7.5120,0.4333

 F1-mic 0.4336,  F1-mac 0.1143
meta,dgl,1,143,7.5628,0.4336

 F1-mic 0.4339,  F1-mac 0.1144
meta,dgl,1,144,7.6134,0.4339

 F1-mic 0.4342,  F1-mac 0.1146
meta,dgl,1,145,7.6639,0.4342

 F1-mic 0.4344,  F1-mac 0.1146
meta,dgl,1,146,7.7144,0.4344

 F1-mic 0.4347,  F1-mac 0.1147
meta,dgl,1,147,7.7648,0.4347

 F1-mic 0.4350,  F1-mac 0.1148
meta,dgl,1,148,7.8154,0.4350

 F1-mic 0.4353,  F1-mac 0.1150
meta,dgl,1,149,7.8659,0.4353

epoch:151/50, Iteration 32/32:training loss 1.9823167324066162
Train F1-mic 0.4345, Train F1-mac 0.1149
 F1-mic 0.4358,  F1-mac 0.1152
meta,dgl,1,150,7.9163,0.4358

 F1-mic 0.4363,  F1-mac 0.1153
meta,dgl,1,151,7.9667,0.4363

 F1-mic 0.4367,  F1-mac 0.1155
meta,dgl,1,152,8.0173,0.4367

 F1-mic 0.4371,  F1-mac 0.1157
meta,dgl,1,153,8.0678,0.4371

 F1-mic 0.4377,  F1-mac 0.1159
meta,dgl,1,154,8.1183,0.4377

 F1-mic 0.4382,  F1-mac 0.1161
new best val f1: 0.4381929445644348
meta,dgl,1,155,8.1689,0.4382

 F1-mic 0.4388,  F1-mac 0.1163
new best val f1: 0.43880489560835134
meta,dgl,1,156,8.2195,0.4388

 F1-mic 0.4393,  F1-mac 0.1165
new best val f1: 0.43932085433165347
meta,dgl,1,157,8.2699,0.4393

 F1-mic 0.4401,  F1-mac 0.1167
new best val f1: 0.44007679385649145
meta,dgl,1,158,8.3204,0.4401

 F1-mic 0.4406,  F1-mac 0.1169
new best val f1: 0.440598752099832
meta,dgl,1,159,8.3709,0.4406

epoch:161/50, Iteration 32/32:training loss 1.9497466087341309
Train F1-mic 0.4396, Train F1-mac 0.1168
 F1-mic 0.4413,  F1-mac 0.1172
new best val f1: 0.4413126949844012
meta,dgl,1,160,8.4213,0.4413

 F1-mic 0.4419,  F1-mac 0.1174
new best val f1: 0.44193064554835615
meta,dgl,1,161,8.4718,0.4419

 F1-mic 0.4424,  F1-mac 0.1175
new best val f1: 0.4424406047516199
meta,dgl,1,162,8.5223,0.4424

 F1-mic 0.4429,  F1-mac 0.1177
new best val f1: 0.4429205663546916
meta,dgl,1,163,8.5732,0.4429

 F1-mic 0.4433,  F1-mac 0.1178
new best val f1: 0.4433225341972642
meta,dgl,1,164,8.6237,0.4433

 F1-mic 0.4438,  F1-mac 0.1179
new best val f1: 0.4437964962802976
meta,dgl,1,165,8.6743,0.4438

 F1-mic 0.4441,  F1-mac 0.1180
new best val f1: 0.44407847372210224
meta,dgl,1,166,8.7248,0.4441

 F1-mic 0.4446,  F1-mac 0.1182
new best val f1: 0.44458243340532755
meta,dgl,1,167,8.7753,0.4446

 F1-mic 0.4447,  F1-mac 0.1182
new best val f1: 0.4447324214062875
meta,dgl,1,168,8.8258,0.4447

 F1-mic 0.4449,  F1-mac 0.1182
new best val f1: 0.44492440604751615
meta,dgl,1,169,8.8765,0.4449

epoch:171/50, Iteration 32/32:training loss 1.9195916652679443
Train F1-mic 0.4439, Train F1-mac 0.1181
 F1-mic 0.4449,  F1-mac 0.1182
meta,dgl,1,170,8.9275,0.4449

 F1-mic 0.4452,  F1-mac 0.1182
new best val f1: 0.4451643868490521
meta,dgl,1,171,8.9780,0.4452

 F1-mic 0.4452,  F1-mac 0.1182
new best val f1: 0.44520038396928246
meta,dgl,1,172,9.0285,0.4452

 F1-mic 0.4453,  F1-mac 0.1183
new best val f1: 0.4453383729301656
meta,dgl,1,173,9.0790,0.4453

 F1-mic 0.4454,  F1-mac 0.1184
new best val f1: 0.44542236621070314
meta,dgl,1,174,9.1295,0.4454

 F1-mic 0.4456,  F1-mac 0.1184
new best val f1: 0.4455723542116631
meta,dgl,1,175,9.1800,0.4456

 F1-mic 0.4456,  F1-mac 0.1185
new best val f1: 0.44559635229181666
meta,dgl,1,176,9.2310,0.4456

 F1-mic 0.4456,  F1-mac 0.1185
meta,dgl,1,177,9.2814,0.4456

 F1-mic 0.4457,  F1-mac 0.1186
new best val f1: 0.4457103431725462
meta,dgl,1,178,9.3319,0.4457

 F1-mic 0.4458,  F1-mac 0.1188
new best val f1: 0.44584833213342934
meta,dgl,1,179,9.3825,0.4458

epoch:181/50, Iteration 32/32:training loss 1.8916417360305786
Train F1-mic 0.4447, Train F1-mac 0.1185
 F1-mic 0.4460,  F1-mac 0.1189
new best val f1: 0.4459623230141589
meta,dgl,1,180,9.4330,0.4460

 F1-mic 0.4463,  F1-mac 0.1191
new best val f1: 0.4462742980561555
meta,dgl,1,181,9.4835,0.4463

 F1-mic 0.4465,  F1-mac 0.1194
new best val f1: 0.4465142788576914
meta,dgl,1,182,9.5340,0.4465

 F1-mic 0.4468,  F1-mac 0.1196
new best val f1: 0.446826253899688
meta,dgl,1,183,9.5846,0.4468

 F1-mic 0.4472,  F1-mac 0.1199
new best val f1: 0.44715622750179984
meta,dgl,1,184,9.6351,0.4472

 F1-mic 0.4475,  F1-mac 0.1202
new best val f1: 0.44753419726421884
meta,dgl,1,185,9.6855,0.4475

 F1-mic 0.4479,  F1-mac 0.1205
new best val f1: 0.44788816894648426
meta,dgl,1,186,9.7364,0.4479

 F1-mic 0.4482,  F1-mac 0.1208
new best val f1: 0.4482181425485961
meta,dgl,1,187,9.7869,0.4482

 F1-mic 0.4487,  F1-mac 0.1211
new best val f1: 0.44865610751139906
meta,dgl,1,188,9.8373,0.4487

 F1-mic 0.4488,  F1-mac 0.1212
new best val f1: 0.448836093112551
meta,dgl,1,189,9.8877,0.4488

epoch:191/50, Iteration 32/32:training loss 1.865664005279541
Train F1-mic 0.4473, Train F1-mac 0.1208
 F1-mic 0.4491,  F1-mac 0.1214
new best val f1: 0.4490520758339333
meta,dgl,1,190,9.9381,0.4491

 F1-mic 0.4494,  F1-mac 0.1217
new best val f1: 0.44935205183585314
meta,dgl,1,191,9.9886,0.4494

 F1-mic 0.4499,  F1-mac 0.1221
new best val f1: 0.4498980081593473
meta,dgl,1,192,10.0391,0.4499

 F1-mic 0.4503,  F1-mac 0.1224
new best val f1: 0.4502519798416127
meta,dgl,1,193,10.0895,0.4503

 F1-mic 0.4506,  F1-mac 0.1227
new best val f1: 0.4505879529637629
meta,dgl,1,194,10.1400,0.4506

 F1-mic 0.4510,  F1-mac 0.1229
new best val f1: 0.4509659227261819
meta,dgl,1,195,10.1903,0.4510

 F1-mic 0.4513,  F1-mac 0.1232
new best val f1: 0.45131989440844733
meta,dgl,1,196,10.2435,0.4513

 F1-mic 0.4518,  F1-mac 0.1236
new best val f1: 0.45178185745140387
meta,dgl,1,197,10.2938,0.4518

 F1-mic 0.4522,  F1-mac 0.1239
new best val f1: 0.4522198224142069
meta,dgl,1,198,10.3444,0.4522

 F1-mic 0.4527,  F1-mac 0.1242
new best val f1: 0.452705783537317
meta,dgl,1,199,10.3949,0.4527

epoch:201/50, Iteration 32/32:training loss 1.8414335250854492
Train F1-mic 0.4512, Train F1-mac 0.1238
 F1-mic 0.4532,  F1-mac 0.1246
new best val f1: 0.45323374130069594
meta,dgl,1,200,10.4454,0.4532

 F1-mic 0.4538,  F1-mac 0.1250
new best val f1: 0.4538276937844972
meta,dgl,1,201,10.4959,0.4538

 F1-mic 0.4544,  F1-mac 0.1254
new best val f1: 0.45442764578833694
meta,dgl,1,202,10.5464,0.4544

 F1-mic 0.4550,  F1-mac 0.1258
new best val f1: 0.4549916006719462
meta,dgl,1,203,10.5970,0.4550

 F1-mic 0.4555,  F1-mac 0.1261
new best val f1: 0.455471562275018
meta,dgl,1,204,10.6474,0.4555

 F1-mic 0.4560,  F1-mac 0.1264
new best val f1: 0.4559575233981282
meta,dgl,1,205,10.6980,0.4560

 F1-mic 0.4563,  F1-mac 0.1266
new best val f1: 0.4563114950803936
meta,dgl,1,206,10.7486,0.4563

 F1-mic 0.4568,  F1-mac 0.1269
new best val f1: 0.45677345812335013
meta,dgl,1,207,10.7990,0.4568

 F1-mic 0.4571,  F1-mac 0.1271
new best val f1: 0.45713342932565393
meta,dgl,1,208,10.8496,0.4571

 F1-mic 0.4574,  F1-mac 0.1273
new best val f1: 0.4574334053275738
meta,dgl,1,209,10.9002,0.4574

epoch:211/50, Iteration 32/32:training loss 1.8187565803527832
Train F1-mic 0.4559, Train F1-mac 0.1270
 F1-mic 0.4578,  F1-mac 0.1276
new best val f1: 0.4578113750899928
meta,dgl,1,210,10.9507,0.4578

 F1-mic 0.4582,  F1-mac 0.1278
new best val f1: 0.4582133429325654
meta,dgl,1,211,11.0012,0.4582

 F1-mic 0.4587,  F1-mac 0.1282
new best val f1: 0.4587293016558675
meta,dgl,1,212,11.0518,0.4587

 F1-mic 0.4591,  F1-mac 0.1284
new best val f1: 0.4591372690184785
meta,dgl,1,213,11.1025,0.4591

 F1-mic 0.4596,  F1-mac 0.1286
new best val f1: 0.4595512359011279
meta,dgl,1,214,11.1530,0.4596

 F1-mic 0.4600,  F1-mac 0.1289
new best val f1: 0.46004319654427644
meta,dgl,1,215,11.2036,0.4600

 F1-mic 0.4605,  F1-mac 0.1292
new best val f1: 0.4604991600671946
meta,dgl,1,216,11.2544,0.4605

 F1-mic 0.4608,  F1-mac 0.1294
new best val f1: 0.46084713222942164
meta,dgl,1,217,11.3049,0.4608

 F1-mic 0.4613,  F1-mac 0.1296
new best val f1: 0.461261099112071
meta,dgl,1,218,11.3554,0.4613

 F1-mic 0.4617,  F1-mac 0.1298
new best val f1: 0.46166306695464365
meta,dgl,1,219,11.4059,0.4617

epoch:221/50, Iteration 32/32:training loss 1.7974451780319214
Train F1-mic 0.4603, Train F1-mac 0.1296
 F1-mic 0.4620,  F1-mac 0.1300
new best val f1: 0.46204103671706265
meta,dgl,1,220,11.4565,0.4620

 F1-mic 0.4624,  F1-mac 0.1303
new best val f1: 0.4624070074394048
meta,dgl,1,221,11.5070,0.4624

 F1-mic 0.4628,  F1-mac 0.1305
new best val f1: 0.46276097912167025
meta,dgl,1,222,11.5575,0.4628

 F1-mic 0.4631,  F1-mac 0.1307
new best val f1: 0.46309695224382047
meta,dgl,1,223,11.6081,0.4631

 F1-mic 0.4636,  F1-mac 0.1310
new best val f1: 0.4635529157667387
meta,dgl,1,224,11.6584,0.4636

 F1-mic 0.4639,  F1-mac 0.1312
new best val f1: 0.4638588912886969
meta,dgl,1,225,11.7091,0.4639

 F1-mic 0.4644,  F1-mac 0.1315
new best val f1: 0.4643928485721142
meta,dgl,1,226,11.7596,0.4644

 F1-mic 0.4648,  F1-mac 0.1318
new best val f1: 0.4648068154547636
meta,dgl,1,227,11.8101,0.4648

 F1-mic 0.4651,  F1-mac 0.1320
new best val f1: 0.46511279097672187
meta,dgl,1,228,11.8605,0.4651

 F1-mic 0.4656,  F1-mac 0.1322
new best val f1: 0.46559875209983204
meta,dgl,1,229,11.9117,0.4656

epoch:231/50, Iteration 32/32:training loss 1.7773593664169312
Train F1-mic 0.4642, Train F1-mac 0.1320
 F1-mic 0.4661,  F1-mac 0.1325
new best val f1: 0.46607871370290377
meta,dgl,1,230,11.9621,0.4661

 F1-mic 0.4665,  F1-mac 0.1328
new best val f1: 0.46647468202543796
meta,dgl,1,231,12.0126,0.4665

 F1-mic 0.4669,  F1-mac 0.1331
new best val f1: 0.4668946484281257
meta,dgl,1,232,12.0631,0.4669

 F1-mic 0.4673,  F1-mac 0.1334
new best val f1: 0.46729661627069835
meta,dgl,1,233,12.1137,0.4673

 F1-mic 0.4676,  F1-mac 0.1336
new best val f1: 0.467608591312695
meta,dgl,1,234,12.1642,0.4676

 F1-mic 0.4681,  F1-mac 0.1339
new best val f1: 0.46808855291576673
meta,dgl,1,235,12.2150,0.4681

 F1-mic 0.4684,  F1-mac 0.1342
new best val f1: 0.46843652507799377
meta,dgl,1,236,12.2655,0.4684

 F1-mic 0.4688,  F1-mac 0.1343
new best val f1: 0.4687904967602592
meta,dgl,1,237,12.3157,0.4688

 F1-mic 0.4691,  F1-mac 0.1346
new best val f1: 0.4691144708423326
meta,dgl,1,238,12.3670,0.4691

 F1-mic 0.4695,  F1-mac 0.1349
new best val f1: 0.4695044396448284
meta,dgl,1,239,12.4176,0.4695

epoch:241/50, Iteration 32/32:training loss 1.7583662271499634
Train F1-mic 0.4679, Train F1-mac 0.1345
 F1-mic 0.4699,  F1-mac 0.1351
new best val f1: 0.4699304055675546
meta,dgl,1,240,12.4681,0.4699

 F1-mic 0.4703,  F1-mac 0.1354
new best val f1: 0.47033837293016556
meta,dgl,1,241,12.5194,0.4703

 F1-mic 0.4709,  F1-mac 0.1357
new best val f1: 0.4708663306935445
meta,dgl,1,242,12.5700,0.4709

 F1-mic 0.4712,  F1-mac 0.1359
new best val f1: 0.4712323014158867
meta,dgl,1,243,12.6205,0.4712

 F1-mic 0.4717,  F1-mac 0.1362
new best val f1: 0.4716762658987281
meta,dgl,1,244,12.6712,0.4717

 F1-mic 0.4721,  F1-mac 0.1365
new best val f1: 0.4720782337413007
meta,dgl,1,245,12.7217,0.4721

 F1-mic 0.4723,  F1-mac 0.1367
new best val f1: 0.4723122150227982
meta,dgl,1,246,12.7723,0.4723

 F1-mic 0.4726,  F1-mac 0.1369
new best val f1: 0.47262419006479484
meta,dgl,1,247,12.8235,0.4726

 F1-mic 0.4730,  F1-mac 0.1371
new best val f1: 0.47296016318694506
meta,dgl,1,248,12.8738,0.4730

 F1-mic 0.4733,  F1-mac 0.1374
new best val f1: 0.4733321334293257
meta,dgl,1,249,12.9243,0.4733

epoch:251/50, Iteration 32/32:training loss 1.740364909172058
Train F1-mic 0.4718, Train F1-mac 0.1372
 F1-mic 0.4737,  F1-mac 0.1377
new best val f1: 0.4736861051115911
meta,dgl,1,250,12.9749,0.4737

 F1-mic 0.4740,  F1-mac 0.1379
new best val f1: 0.4740160787137029
meta,dgl,1,251,13.0252,0.4740

 F1-mic 0.4744,  F1-mac 0.1382
new best val f1: 0.4743520518358531
meta,dgl,1,252,13.0758,0.4744

 F1-mic 0.4746,  F1-mac 0.1384
new best val f1: 0.4746400287976961
meta,dgl,1,253,13.1263,0.4746

 F1-mic 0.4749,  F1-mac 0.1386
new best val f1: 0.4749220062395008
meta,dgl,1,254,13.1768,0.4749

 F1-mic 0.4752,  F1-mac 0.1389
new best val f1: 0.4752459803215743
meta,dgl,1,255,13.2274,0.4752

 F1-mic 0.4756,  F1-mac 0.1391
new best val f1: 0.4755639548836093
meta,dgl,1,256,13.2779,0.4756

 F1-mic 0.4758,  F1-mac 0.1394
new best val f1: 0.475815934725222
meta,dgl,1,257,13.3284,0.4758

 F1-mic 0.4762,  F1-mac 0.1397
new best val f1: 0.4761759059275258
meta,dgl,1,258,13.3788,0.4762

 F1-mic 0.4764,  F1-mac 0.1399
new best val f1: 0.4764398848092153
meta,dgl,1,259,13.4292,0.4764

epoch:261/50, Iteration 32/32:training loss 1.7232686281204224
Train F1-mic 0.4750, Train F1-mac 0.1398
 F1-mic 0.4767,  F1-mac 0.1402
new best val f1: 0.47673386129109674
meta,dgl,1,260,13.4797,0.4767

 F1-mic 0.4770,  F1-mac 0.1405
new best val f1: 0.47702183825293976
meta,dgl,1,261,13.5301,0.4770

 F1-mic 0.4773,  F1-mac 0.1407
new best val f1: 0.47728581713462925
meta,dgl,1,262,13.5807,0.4773

 F1-mic 0.4776,  F1-mac 0.1410
new best val f1: 0.47762778977681786
meta,dgl,1,263,13.6312,0.4776

 F1-mic 0.4778,  F1-mac 0.1413
new best val f1: 0.47783177345812333
meta,dgl,1,264,13.6817,0.4778

 F1-mic 0.4782,  F1-mac 0.1415
new best val f1: 0.4781617470602352
meta,dgl,1,265,13.7323,0.4782

 F1-mic 0.4784,  F1-mac 0.1417
new best val f1: 0.47837772978161747
meta,dgl,1,266,13.7831,0.4784

 F1-mic 0.4786,  F1-mac 0.1420
new best val f1: 0.47864770818334534
meta,dgl,1,267,13.8336,0.4786

 F1-mic 0.4789,  F1-mac 0.1424
new best val f1: 0.47893568514518836
meta,dgl,1,268,13.8839,0.4789

 F1-mic 0.4792,  F1-mac 0.1426
new best val f1: 0.47915166786657065
meta,dgl,1,269,13.9345,0.4792

epoch:271/50, Iteration 32/32:training loss 1.7069976329803467
Train F1-mic 0.4777, Train F1-mac 0.1424
 F1-mic 0.4794,  F1-mac 0.1428
new best val f1: 0.47937964962802976
meta,dgl,1,270,13.9850,0.4794

 F1-mic 0.4796,  F1-mac 0.1430
new best val f1: 0.47959563234941205
meta,dgl,1,271,14.0355,0.4796

 F1-mic 0.4799,  F1-mac 0.1432
new best val f1: 0.47987760979121674
meta,dgl,1,272,14.0867,0.4799

 F1-mic 0.4801,  F1-mac 0.1435
new best val f1: 0.4800815934725222
meta,dgl,1,273,14.1371,0.4801

 F1-mic 0.4804,  F1-mac 0.1438
new best val f1: 0.4803515718742501
meta,dgl,1,274,14.1876,0.4804

 F1-mic 0.4805,  F1-mac 0.1440
new best val f1: 0.4805135589152868
meta,dgl,1,275,14.2378,0.4805

 F1-mic 0.4807,  F1-mac 0.1442
new best val f1: 0.4807175425965923
meta,dgl,1,276,14.2891,0.4807

 F1-mic 0.4810,  F1-mac 0.1445
new best val f1: 0.4809635229181665
meta,dgl,1,277,14.3397,0.4810

 F1-mic 0.4812,  F1-mac 0.1447
new best val f1: 0.481197504199664
meta,dgl,1,278,14.3902,0.4812

 F1-mic 0.4814,  F1-mac 0.1449
new best val f1: 0.4814074874010079
meta,dgl,1,279,14.4408,0.4814

epoch:281/50, Iteration 32/32:training loss 1.6914875507354736
Train F1-mic 0.4801, Train F1-mac 0.1450
 F1-mic 0.4816,  F1-mac 0.1451
new best val f1: 0.48156347492200624
meta,dgl,1,280,14.4915,0.4816

 F1-mic 0.4818,  F1-mac 0.1454
new best val f1: 0.48179145668346535
meta,dgl,1,281,14.5421,0.4818

 F1-mic 0.4819,  F1-mac 0.1456
new best val f1: 0.48193544516438686
meta,dgl,1,282,14.5926,0.4819

 F1-mic 0.4822,  F1-mac 0.1458
new best val f1: 0.4821574274058075
meta,dgl,1,283,14.6431,0.4822

 F1-mic 0.4823,  F1-mac 0.1460
new best val f1: 0.48231941444684423
meta,dgl,1,284,14.6936,0.4823

 F1-mic 0.4825,  F1-mac 0.1463
new best val f1: 0.48252339812814976
meta,dgl,1,285,14.7442,0.4825

 F1-mic 0.4828,  F1-mac 0.1465
new best val f1: 0.482769378449724
meta,dgl,1,286,14.7951,0.4828

 F1-mic 0.4830,  F1-mac 0.1466
new best val f1: 0.4829613630909527
meta,dgl,1,287,14.8456,0.4830

 F1-mic 0.4831,  F1-mac 0.1468
new best val f1: 0.48309935205183585
meta,dgl,1,288,14.8961,0.4831

 F1-mic 0.4833,  F1-mac 0.1471
new best val f1: 0.48330933525317976
meta,dgl,1,289,14.9467,0.4833

epoch:291/50, Iteration 32/32:training loss 1.6766624450683594
Train F1-mic 0.4821, Train F1-mac 0.1472
 F1-mic 0.4835,  F1-mac 0.1472
new best val f1: 0.48345332373410127
meta,dgl,1,290,14.9972,0.4835

 F1-mic 0.4836,  F1-mac 0.1475
new best val f1: 0.4836093112550996
meta,dgl,1,291,15.0477,0.4836

 F1-mic 0.4838,  F1-mac 0.1477
new best val f1: 0.48384929205663546
meta,dgl,1,292,15.0982,0.4838

 F1-mic 0.4841,  F1-mac 0.1480
new best val f1: 0.48407727381809457
meta,dgl,1,293,15.1487,0.4841

 F1-mic 0.4843,  F1-mac 0.1483
new best val f1: 0.48425725941924647
meta,dgl,1,294,15.1993,0.4843

 F1-mic 0.4845,  F1-mac 0.1486
new best val f1: 0.48452723782097434
meta,dgl,1,295,15.2498,0.4845

 F1-mic 0.4848,  F1-mac 0.1489
new best val f1: 0.4848212143028558
meta,dgl,1,296,15.3003,0.4848

 F1-mic 0.4850,  F1-mac 0.1491
new best val f1: 0.4850071994240461
meta,dgl,1,297,15.3508,0.4850

 F1-mic 0.4852,  F1-mac 0.1493
new best val f1: 0.4851811855051596
meta,dgl,1,298,15.4018,0.4852

 F1-mic 0.4854,  F1-mac 0.1496
new best val f1: 0.48540316774658027
meta,dgl,1,299,15.4521,0.4854

epoch:301/50, Iteration 32/32:training loss 1.6624699831008911
Train F1-mic 0.4843, Train F1-mac 0.1498
 F1-mic 0.4856,  F1-mac 0.1499
new best val f1: 0.48562514998800094
meta,dgl,1,300,15.5026,0.4856

 F1-mic 0.4858,  F1-mac 0.1501
new best val f1: 0.48584713222942166
meta,dgl,1,301,15.5530,0.4858

 F1-mic 0.4860,  F1-mac 0.1503
new best val f1: 0.4860211183105352
meta,dgl,1,302,15.6035,0.4860

 F1-mic 0.4862,  F1-mac 0.1505
new best val f1: 0.48619510439164865
meta,dgl,1,303,15.6541,0.4862

 F1-mic 0.4863,  F1-mac 0.1507
new best val f1: 0.4862730981521478
meta,dgl,1,304,15.7046,0.4863

 F1-mic 0.4865,  F1-mac 0.1509
new best val f1: 0.4865010799136069
meta,dgl,1,305,15.7551,0.4865

 F1-mic 0.4866,  F1-mac 0.1511
new best val f1: 0.4866450683945284
meta,dgl,1,306,15.8056,0.4866

 F1-mic 0.4869,  F1-mac 0.1515
new best val f1: 0.48687305015598753
meta,dgl,1,307,15.8560,0.4869

 F1-mic 0.4871,  F1-mac 0.1517
new best val f1: 0.4870710343172546
meta,dgl,1,308,15.9065,0.4871

 F1-mic 0.4872,  F1-mac 0.1519
new best val f1: 0.48723302135829133
meta,dgl,1,309,15.9570,0.4872

epoch:311/50, Iteration 32/32:training loss 1.6488595008850098
Train F1-mic 0.4865, Train F1-mac 0.1526
 F1-mic 0.4874,  F1-mac 0.1522
new best val f1: 0.48742500599952004
meta,dgl,1,310,16.0075,0.4874

 F1-mic 0.4877,  F1-mac 0.1525
new best val f1: 0.4876709863210943
meta,dgl,1,311,16.0580,0.4877

 F1-mic 0.4878,  F1-mac 0.1527
new best val f1: 0.4878089752819774
meta,dgl,1,312,16.1086,0.4878

 F1-mic 0.4881,  F1-mac 0.1530
new best val f1: 0.4880609551235901
meta,dgl,1,313,16.1591,0.4881

 F1-mic 0.4883,  F1-mac 0.1533
new best val f1: 0.48826493880489563
meta,dgl,1,314,16.2096,0.4883

 F1-mic 0.4884,  F1-mac 0.1535
new best val f1: 0.48840892728581714
meta,dgl,1,315,16.2601,0.4884

 F1-mic 0.4886,  F1-mac 0.1538
new best val f1: 0.48860691144708424
meta,dgl,1,316,16.3108,0.4886

 F1-mic 0.4888,  F1-mac 0.1541
new best val f1: 0.4888228941684665
meta,dgl,1,317,16.3618,0.4888

 F1-mic 0.4891,  F1-mac 0.1545
new best val f1: 0.48908687305015597
meta,dgl,1,318,16.4122,0.4891

 F1-mic 0.4892,  F1-mac 0.1548
new best val f1: 0.4892428605711543
meta,dgl,1,319,16.4627,0.4892

epoch:321/50, Iteration 32/32:training loss 1.6357835531234741
Train F1-mic 0.4886, Train F1-mac 0.1554
 F1-mic 0.4894,  F1-mac 0.1550
new best val f1: 0.48940484761219105
meta,dgl,1,320,16.5131,0.4894

 F1-mic 0.4895,  F1-mac 0.1552
new best val f1: 0.48954883609311256
meta,dgl,1,321,16.5636,0.4895

 F1-mic 0.4897,  F1-mac 0.1554
new best val f1: 0.4896748260139189
meta,dgl,1,322,16.6145,0.4897

 F1-mic 0.4899,  F1-mac 0.1557
new best val f1: 0.4899208063354932
meta,dgl,1,323,16.6650,0.4899

 F1-mic 0.4901,  F1-mac 0.1561
new best val f1: 0.4901487880969522
meta,dgl,1,324,16.7156,0.4901

 F1-mic 0.4904,  F1-mac 0.1564
new best val f1: 0.4904067674586033
meta,dgl,1,325,16.7661,0.4904

 F1-mic 0.4906,  F1-mac 0.1568
new best val f1: 0.4906467482601392
meta,dgl,1,326,16.8166,0.4906

 F1-mic 0.4908,  F1-mac 0.1570
new best val f1: 0.4908447324214063
meta,dgl,1,327,16.8671,0.4908

 F1-mic 0.4910,  F1-mac 0.1573
new best val f1: 0.49103671706263496
meta,dgl,1,328,16.9175,0.4910

 F1-mic 0.4912,  F1-mac 0.1576
new best val f1: 0.4912167026637869
meta,dgl,1,329,16.9680,0.4912

epoch:331/50, Iteration 32/32:training loss 1.623203158378601
Train F1-mic 0.4907, Train F1-mac 0.1584
 F1-mic 0.4914,  F1-mac 0.1579
new best val f1: 0.491384689224862
meta,dgl,1,330,17.0184,0.4914

 F1-mic 0.4916,  F1-mac 0.1582
new best val f1: 0.4916486681065515
meta,dgl,1,331,17.0690,0.4916

 F1-mic 0.4919,  F1-mac 0.1585
new best val f1: 0.49187065034797217
meta,dgl,1,332,17.1195,0.4919

 F1-mic 0.4920,  F1-mac 0.1588
new best val f1: 0.49202063834893206
meta,dgl,1,333,17.1701,0.4920

 F1-mic 0.4922,  F1-mac 0.1591
new best val f1: 0.49223662107031435
meta,dgl,1,334,17.2205,0.4922

 F1-mic 0.4924,  F1-mac 0.1594
new best val f1: 0.49241060715142787
meta,dgl,1,335,17.2711,0.4924

 F1-mic 0.4927,  F1-mac 0.1597
new best val f1: 0.49267458603311737
meta,dgl,1,336,17.3216,0.4927

 F1-mic 0.4929,  F1-mac 0.1601
new best val f1: 0.49287856971442284
meta,dgl,1,337,17.3721,0.4929

 F1-mic 0.4931,  F1-mac 0.1604
new best val f1: 0.49311255099592033
meta,dgl,1,338,17.4226,0.4931

 F1-mic 0.4933,  F1-mac 0.1607
new best val f1: 0.4933105351571874
meta,dgl,1,339,17.4731,0.4933

epoch:341/50, Iteration 32/32:training loss 1.611088752746582
Train F1-mic 0.4930, Train F1-mac 0.1616
 F1-mic 0.4935,  F1-mac 0.1610
new best val f1: 0.4935145188384929
meta,dgl,1,340,17.5236,0.4935

 F1-mic 0.4937,  F1-mac 0.1612
new best val f1: 0.493742500599952
meta,dgl,1,341,17.5742,0.4937

 F1-mic 0.4939,  F1-mac 0.1615
new best val f1: 0.4939224862011039
meta,dgl,1,342,17.6247,0.4939

 F1-mic 0.4941,  F1-mac 0.1618
new best val f1: 0.4941024718022558
meta,dgl,1,343,17.6752,0.4941

 F1-mic 0.4943,  F1-mac 0.1620
new best val f1: 0.4942644588432925
meta,dgl,1,344,17.7258,0.4943

 F1-mic 0.4945,  F1-mac 0.1623
new best val f1: 0.49446244300455966
meta,dgl,1,345,17.7769,0.4945

 F1-mic 0.4948,  F1-mac 0.1627
new best val f1: 0.4947624190064795
meta,dgl,1,346,17.8274,0.4948

 F1-mic 0.4951,  F1-mac 0.1630
new best val f1: 0.49507439404847614
meta,dgl,1,347,17.8779,0.4951

 F1-mic 0.4953,  F1-mac 0.1633
new best val f1: 0.49528437724982
meta,dgl,1,348,17.9284,0.4953

 F1-mic 0.4956,  F1-mac 0.1637
new best val f1: 0.49559635229181664
meta,dgl,1,349,17.9790,0.4956

epoch:351/50, Iteration 32/32:training loss 1.5994070768356323
Train F1-mic 0.4955, Train F1-mac 0.1648
 F1-mic 0.4957,  F1-mac 0.1639
new best val f1: 0.4957403407727382
meta,dgl,1,350,18.0293,0.4957

 F1-mic 0.4961,  F1-mac 0.1643
new best val f1: 0.49607631389488843
meta,dgl,1,351,18.0803,0.4961

 F1-mic 0.4963,  F1-mac 0.1647
new best val f1: 0.49632829373650106
meta,dgl,1,352,18.1307,0.4963

 F1-mic 0.4966,  F1-mac 0.1651
new best val f1: 0.49659827213822894
meta,dgl,1,353,18.1810,0.4966

 F1-mic 0.4968,  F1-mac 0.1654
new best val f1: 0.4968382529397648
meta,dgl,1,354,18.2313,0.4968

 F1-mic 0.4971,  F1-mac 0.1657
new best val f1: 0.4970842332613391
meta,dgl,1,355,18.2816,0.4971

 F1-mic 0.4974,  F1-mac 0.1661
new best val f1: 0.49738420926325894
meta,dgl,1,356,18.3322,0.4974

 F1-mic 0.4976,  F1-mac 0.1664
new best val f1: 0.4976181905447564
meta,dgl,1,357,18.3828,0.4976

 F1-mic 0.4978,  F1-mac 0.1667
new best val f1: 0.49781017518598514
meta,dgl,1,358,18.4333,0.4978

 F1-mic 0.4981,  F1-mac 0.1670
new best val f1: 0.4980561555075594
meta,dgl,1,359,18.4838,0.4981

epoch:361/50, Iteration 32/32:training loss 1.588141918182373
Train F1-mic 0.4978, Train F1-mac 0.1680
 F1-mic 0.4982,  F1-mac 0.1673
new best val f1: 0.4982421406287497
meta,dgl,1,360,18.5349,0.4982

 F1-mic 0.4985,  F1-mac 0.1676
new best val f1: 0.4984521238300936
meta,dgl,1,361,18.5854,0.4985

 F1-mic 0.4986,  F1-mac 0.1679
new best val f1: 0.4986321094312455
meta,dgl,1,362,18.6359,0.4986

 F1-mic 0.4989,  F1-mac 0.1684
new best val f1: 0.4988720902327814
meta,dgl,1,363,18.6865,0.4989

 F1-mic 0.4990,  F1-mac 0.1686
new best val f1: 0.4990220782337413
meta,dgl,1,364,18.7370,0.4990

 F1-mic 0.4993,  F1-mac 0.1690
new best val f1: 0.49925605951523877
meta,dgl,1,365,18.7878,0.4993

 F1-mic 0.4994,  F1-mac 0.1693
new best val f1: 0.4993760499160067
meta,dgl,1,366,18.8383,0.4994

 F1-mic 0.4996,  F1-mac 0.1697
new best val f1: 0.4996400287976962
meta,dgl,1,367,18.8888,0.4996

 F1-mic 0.4999,  F1-mac 0.1701
new best val f1: 0.49988000959923207
meta,dgl,1,368,18.9393,0.4999

 F1-mic 0.5000,  F1-mac 0.1703
new best val f1: 0.499970002399808
meta,dgl,1,369,18.9898,0.5000

epoch:371/50, Iteration 32/32:training loss 1.577271819114685
Train F1-mic 0.4999, Train F1-mac 0.1712
 F1-mic 0.5001,  F1-mac 0.1705
new best val f1: 0.5001259899208064
meta,dgl,1,370,19.0403,0.5001

 F1-mic 0.5003,  F1-mac 0.1708
new best val f1: 0.5002579793616511
meta,dgl,1,371,19.0907,0.5003

 F1-mic 0.5004,  F1-mac 0.1712
new best val f1: 0.5004439644828413
meta,dgl,1,372,19.1411,0.5004

 F1-mic 0.5006,  F1-mac 0.1714
new best val f1: 0.5005639548836093
meta,dgl,1,373,19.1916,0.5006

 F1-mic 0.5007,  F1-mac 0.1717
new best val f1: 0.5007379409647228
meta,dgl,1,374,19.2421,0.5007

 F1-mic 0.5009,  F1-mac 0.1720
new best val f1: 0.5009239260859131
meta,dgl,1,375,19.2925,0.5009

 F1-mic 0.5012,  F1-mac 0.1723
new best val f1: 0.5011579073674106
meta,dgl,1,376,19.3433,0.5012

 F1-mic 0.5013,  F1-mac 0.1726
new best val f1: 0.5013498920086393
meta,dgl,1,377,19.3939,0.5013

 F1-mic 0.5015,  F1-mac 0.1729
new best val f1: 0.5015298776097912
meta,dgl,1,378,19.4442,0.5015

 F1-mic 0.5017,  F1-mac 0.1731
new best val f1: 0.501661867050636
meta,dgl,1,379,19.4947,0.5017

epoch:381/50, Iteration 32/32:training loss 1.566776156425476
Train F1-mic 0.5015, Train F1-mac 0.1742
 F1-mic 0.5018,  F1-mac 0.1733
new best val f1: 0.5018358531317495
meta,dgl,1,380,19.5452,0.5018

 F1-mic 0.5021,  F1-mac 0.1737
new best val f1: 0.5020518358531317
meta,dgl,1,381,19.5964,0.5021

 F1-mic 0.5022,  F1-mac 0.1740
new best val f1: 0.5021778257739381
meta,dgl,1,382,19.6472,0.5022

 F1-mic 0.5023,  F1-mac 0.1742
new best val f1: 0.5023458123350132
meta,dgl,1,383,19.6977,0.5023

 F1-mic 0.5025,  F1-mac 0.1746
new best val f1: 0.5025377969762419
meta,dgl,1,384,19.7484,0.5025

 F1-mic 0.5027,  F1-mac 0.1749
new best val f1: 0.502705783537317
meta,dgl,1,385,19.7989,0.5027

 F1-mic 0.5030,  F1-mac 0.1753
new best val f1: 0.5029517638588913
meta,dgl,1,386,19.8494,0.5030

 F1-mic 0.5031,  F1-mac 0.1757
new best val f1: 0.5031377489800816
meta,dgl,1,387,19.8999,0.5031

 F1-mic 0.5033,  F1-mac 0.1761
new best val f1: 0.503341732661387
meta,dgl,1,388,19.9504,0.5033

 F1-mic 0.5035,  F1-mac 0.1766
new best val f1: 0.5035037197024238
meta,dgl,1,389,20.0010,0.5035

epoch:391/50, Iteration 32/32:training loss 1.5566394329071045
Train F1-mic 0.5034, Train F1-mac 0.1779
 F1-mic 0.5036,  F1-mac 0.1768
new best val f1: 0.503611711063115
meta,dgl,1,390,20.0515,0.5036

 F1-mic 0.5039,  F1-mac 0.1772
new best val f1: 0.5038636909047276
meta,dgl,1,391,20.1020,0.5039

 F1-mic 0.5040,  F1-mac 0.1776
new best val f1: 0.5040436765058796
meta,dgl,1,392,20.1526,0.5040

 F1-mic 0.5041,  F1-mac 0.1778
new best val f1: 0.5041336693064555
meta,dgl,1,393,20.2031,0.5041

 F1-mic 0.5043,  F1-mac 0.1783
new best val f1: 0.5042896568274539
meta,dgl,1,394,20.2535,0.5043

 F1-mic 0.5044,  F1-mac 0.1786
new best val f1: 0.5043976481881449
meta,dgl,1,395,20.3047,0.5044

 F1-mic 0.5046,  F1-mac 0.1792
new best val f1: 0.5046196304295656
meta,dgl,1,396,20.3552,0.5046

 F1-mic 0.5048,  F1-mac 0.1797
new best val f1: 0.5047936165106791
meta,dgl,1,397,20.4057,0.5048

 F1-mic 0.5050,  F1-mac 0.1803
new best val f1: 0.5049856011519078
meta,dgl,1,398,20.4562,0.5050

 F1-mic 0.5051,  F1-mac 0.1806
new best val f1: 0.5051475881929446
meta,dgl,1,399,20.5066,0.5051

epoch:401/50, Iteration 32/32:training loss 1.5468416213989258
Train F1-mic 0.5051, Train F1-mac 0.1817
 F1-mic 0.5054,  F1-mac 0.1812
new best val f1: 0.5053515718742501
meta,dgl,1,400,20.5572,0.5054

 F1-mic 0.5056,  F1-mac 0.1817
new best val f1: 0.5055855531557475
meta,dgl,1,401,20.6077,0.5056

 F1-mic 0.5058,  F1-mac 0.1821
new best val f1: 0.5058075353971683
meta,dgl,1,402,20.6582,0.5058

 F1-mic 0.5060,  F1-mac 0.1825
new best val f1: 0.5059875209983201
meta,dgl,1,403,20.7088,0.5060

 F1-mic 0.5061,  F1-mac 0.1828
new best val f1: 0.5061255099592032
meta,dgl,1,404,20.7594,0.5061

 F1-mic 0.5063,  F1-mac 0.1833
new best val f1: 0.5062634989200864
meta,dgl,1,405,20.8098,0.5063

 F1-mic 0.5065,  F1-mac 0.1837
new best val f1: 0.5064734821214303
meta,dgl,1,406,20.8601,0.5065

 F1-mic 0.5066,  F1-mac 0.1840
new best val f1: 0.506635469162467
meta,dgl,1,407,20.9107,0.5066

 F1-mic 0.5068,  F1-mac 0.1844
new best val f1: 0.5068274538036956
meta,dgl,1,408,20.9612,0.5068

 F1-mic 0.5070,  F1-mac 0.1849
new best val f1: 0.5070374370050396
meta,dgl,1,409,21.0117,0.5070

epoch:411/50, Iteration 32/32:training loss 1.5373705625534058
Train F1-mic 0.5067, Train F1-mac 0.1855
 F1-mic 0.5072,  F1-mac 0.1852
new best val f1: 0.5072114230861531
meta,dgl,1,410,21.0623,0.5072

 F1-mic 0.5073,  F1-mac 0.1855
new best val f1: 0.5073494120470362
meta,dgl,1,411,21.1128,0.5073

 F1-mic 0.5075,  F1-mac 0.1859
new best val f1: 0.5075353971682265
meta,dgl,1,412,21.1634,0.5075

 F1-mic 0.5078,  F1-mac 0.1865
new best val f1: 0.5078173746100312
meta,dgl,1,413,21.2138,0.5078

 F1-mic 0.5081,  F1-mac 0.1870
new best val f1: 0.5080873530117591
meta,dgl,1,414,21.2643,0.5081

 F1-mic 0.5083,  F1-mac 0.1876
new best val f1: 0.508267338612911
meta,dgl,1,415,21.3148,0.5083

 F1-mic 0.5084,  F1-mac 0.1880
new best val f1: 0.5084173266138708
meta,dgl,1,416,21.3656,0.5084

 F1-mic 0.5086,  F1-mac 0.1885
new best val f1: 0.5085673146148308
meta,dgl,1,417,21.4161,0.5086

 F1-mic 0.5087,  F1-mac 0.1889
new best val f1: 0.5086873050155988
meta,dgl,1,418,21.4666,0.5087

 F1-mic 0.5090,  F1-mac 0.1895
new best val f1: 0.5089812814974802
meta,dgl,1,419,21.5172,0.5090

epoch:421/50, Iteration 32/32:training loss 1.5282156467437744
Train F1-mic 0.5086, Train F1-mac 0.1901
 F1-mic 0.5091,  F1-mac 0.1898
new best val f1: 0.5091072714182865
meta,dgl,1,420,21.5677,0.5091

 F1-mic 0.5093,  F1-mac 0.1906
new best val f1: 0.5093172546196304
meta,dgl,1,421,21.6182,0.5093

 F1-mic 0.5094,  F1-mac 0.1910
new best val f1: 0.50943124550036
meta,dgl,1,422,21.6688,0.5094

 F1-mic 0.5097,  F1-mac 0.1916
new best val f1: 0.5096712263018959
meta,dgl,1,423,21.7194,0.5097

 F1-mic 0.5099,  F1-mac 0.1924
new best val f1: 0.5098572114230862
meta,dgl,1,424,21.7698,0.5099

 F1-mic 0.5101,  F1-mac 0.1929
new best val f1: 0.5100551955843533
meta,dgl,1,425,21.8203,0.5101

 F1-mic 0.5103,  F1-mac 0.1932
new best val f1: 0.5102591792656588
meta,dgl,1,426,21.8708,0.5103

 F1-mic 0.5104,  F1-mac 0.1936
new best val f1: 0.5104271658267339
meta,dgl,1,427,21.9212,0.5104

 F1-mic 0.5106,  F1-mac 0.1940
new best val f1: 0.5105831533477322
meta,dgl,1,428,21.9716,0.5106

 F1-mic 0.5107,  F1-mac 0.1944
new best val f1: 0.5106611471082313
meta,dgl,1,429,22.0221,0.5107

epoch:431/50, Iteration 32/32:training loss 1.5193620920181274
Train F1-mic 0.5102, Train F1-mac 0.1948
 F1-mic 0.5109,  F1-mac 0.1948
new best val f1: 0.5108951283897288
meta,dgl,1,430,22.0726,0.5109

 F1-mic 0.5109,  F1-mac 0.1949
new best val f1: 0.5109371250299976
meta,dgl,1,431,22.1231,0.5109

 F1-mic 0.5110,  F1-mac 0.1952
new best val f1: 0.511033117350612
meta,dgl,1,432,22.1736,0.5110

 F1-mic 0.5111,  F1-mac 0.1955
new best val f1: 0.5111231101511879
meta,dgl,1,433,22.2241,0.5111

 F1-mic 0.5113,  F1-mac 0.1960
new best val f1: 0.511291096712263
meta,dgl,1,434,22.2746,0.5113

 F1-mic 0.5115,  F1-mac 0.1963
new best val f1: 0.5114590832733381
meta,dgl,1,435,22.3255,0.5115

 F1-mic 0.5116,  F1-mac 0.1968
new best val f1: 0.5116030717542597
meta,dgl,1,436,22.3762,0.5116

 F1-mic 0.5118,  F1-mac 0.1972
new best val f1: 0.5118250539956803
meta,dgl,1,437,22.4269,0.5118

 F1-mic 0.5120,  F1-mac 0.1976
new best val f1: 0.5119930405567554
meta,dgl,1,438,22.4774,0.5120

 F1-mic 0.5121,  F1-mac 0.1980
new best val f1: 0.512107031437485
meta,dgl,1,439,22.5279,0.5121

epoch:441/50, Iteration 32/32:training loss 1.510805368423462
Train F1-mic 0.5117, Train F1-mac 0.1988
 F1-mic 0.5123,  F1-mac 0.1984
new best val f1: 0.5122630189584834
meta,dgl,1,440,22.5784,0.5123

 F1-mic 0.5123,  F1-mac 0.1986
new best val f1: 0.5123470122390209
meta,dgl,1,441,22.6290,0.5123

 F1-mic 0.5125,  F1-mac 0.1990
new best val f1: 0.5125269978401727
meta,dgl,1,442,22.6795,0.5125

 F1-mic 0.5126,  F1-mac 0.1992
new best val f1: 0.512604991600672
meta,dgl,1,443,22.7301,0.5126

 F1-mic 0.5127,  F1-mac 0.1995
new best val f1: 0.5127369810415167
meta,dgl,1,444,22.7805,0.5127

 F1-mic 0.5129,  F1-mac 0.1998
new best val f1: 0.5128809695224382
meta,dgl,1,445,22.8309,0.5129

 F1-mic 0.5130,  F1-mac 0.2001
new best val f1: 0.5130129589632829
meta,dgl,1,446,22.8814,0.5130

 F1-mic 0.5132,  F1-mac 0.2005
new best val f1: 0.5131929445644349
meta,dgl,1,447,22.9319,0.5132

 F1-mic 0.5134,  F1-mac 0.2007
new best val f1: 0.51336093112551
meta,dgl,1,448,22.9825,0.5134

 F1-mic 0.5136,  F1-mac 0.2011
new best val f1: 0.5135529157667387
meta,dgl,1,449,23.0328,0.5136

epoch:451/50, Iteration 32/32:training loss 1.5025315284729004
Train F1-mic 0.5132, Train F1-mac 0.2022
 F1-mic 0.5137,  F1-mac 0.2015
new best val f1: 0.5137209023278138
meta,dgl,1,450,23.0834,0.5137

 F1-mic 0.5139,  F1-mac 0.2019
new best val f1: 0.5138588912886969
meta,dgl,1,451,23.1336,0.5139

 F1-mic 0.5140,  F1-mac 0.2023
new best val f1: 0.5140028797696184
meta,dgl,1,452,23.1843,0.5140

 F1-mic 0.5142,  F1-mac 0.2027
new best val f1: 0.5141588672906168
meta,dgl,1,453,23.2348,0.5142

 F1-mic 0.5143,  F1-mac 0.2030
new best val f1: 0.5142548596112311
meta,dgl,1,454,23.2852,0.5143

 F1-mic 0.5145,  F1-mac 0.2036
new best val f1: 0.5145068394528438
meta,dgl,1,455,23.3360,0.5145

 F1-mic 0.5147,  F1-mac 0.2039
new best val f1: 0.5146628269738421
meta,dgl,1,456,23.3865,0.5147

 F1-mic 0.5148,  F1-mac 0.2042
new best val f1: 0.5148008159347253
meta,dgl,1,457,23.4370,0.5148

 F1-mic 0.5149,  F1-mac 0.2046
new best val f1: 0.5149448044156467
meta,dgl,1,458,23.4875,0.5149

 F1-mic 0.5151,  F1-mac 0.2049
new best val f1: 0.5151427885769139
meta,dgl,1,459,23.5384,0.5151

epoch:461/50, Iteration 32/32:training loss 1.4945337772369385
Train F1-mic 0.5148, Train F1-mac 0.2056
 F1-mic 0.5152,  F1-mac 0.2051
new best val f1: 0.5151787856971443
meta,dgl,1,460,23.5889,0.5152

 F1-mic 0.5153,  F1-mac 0.2053
new best val f1: 0.5152987760979122
meta,dgl,1,461,23.6397,0.5153

 F1-mic 0.5155,  F1-mac 0.2056
new best val f1: 0.5154607631389488
meta,dgl,1,462,23.6901,0.5155

 F1-mic 0.5156,  F1-mac 0.2060
new best val f1: 0.5156047516198704
meta,dgl,1,463,23.7404,0.5156

 F1-mic 0.5157,  F1-mac 0.2063
new best val f1: 0.5157007439404847
meta,dgl,1,464,23.7915,0.5157

 F1-mic 0.5158,  F1-mac 0.2068
new best val f1: 0.5158327333813295
meta,dgl,1,465,23.8420,0.5158

 F1-mic 0.5160,  F1-mac 0.2071
new best val f1: 0.5160007199424046
meta,dgl,1,466,23.8925,0.5160

 F1-mic 0.5162,  F1-mac 0.2074
new best val f1: 0.5162047036237101
meta,dgl,1,467,23.9430,0.5162

 F1-mic 0.5164,  F1-mac 0.2077
new best val f1: 0.5163546916246701
meta,dgl,1,468,23.9938,0.5164

 F1-mic 0.5166,  F1-mac 0.2080
new best val f1: 0.5165646748260139
meta,dgl,1,469,24.0441,0.5166

epoch:471/50, Iteration 32/32:training loss 1.4867991209030151
Train F1-mic 0.5164, Train F1-mac 0.2088
 F1-mic 0.5167,  F1-mac 0.2083
new best val f1: 0.5167086633069354
meta,dgl,1,470,24.0944,0.5167

 F1-mic 0.5169,  F1-mac 0.2086
new best val f1: 0.516852651787857
meta,dgl,1,471,24.1447,0.5169

 F1-mic 0.5169,  F1-mac 0.2087
new best val f1: 0.5169366450683945
meta,dgl,1,472,24.1953,0.5169

 F1-mic 0.5171,  F1-mac 0.2089
new best val f1: 0.5170626349892009
meta,dgl,1,473,24.2456,0.5171

 F1-mic 0.5172,  F1-mac 0.2092
new best val f1: 0.517230621550276
meta,dgl,1,474,24.2960,0.5172

 F1-mic 0.5174,  F1-mac 0.2095
new best val f1: 0.5174166066714663
meta,dgl,1,475,24.3466,0.5174

 F1-mic 0.5175,  F1-mac 0.2098
new best val f1: 0.517518598512119
meta,dgl,1,476,24.3971,0.5175

 F1-mic 0.5177,  F1-mac 0.2100
new best val f1: 0.5176505879529638
meta,dgl,1,477,24.4480,0.5177

 F1-mic 0.5179,  F1-mac 0.2103
new best val f1: 0.5178605711543076
meta,dgl,1,478,24.4986,0.5179

 F1-mic 0.5180,  F1-mac 0.2105
new best val f1: 0.5179805615550755
meta,dgl,1,479,24.5491,0.5180

epoch:481/50, Iteration 32/32:training loss 1.4793195724487305
Train F1-mic 0.5179, Train F1-mac 0.2116
 F1-mic 0.5181,  F1-mac 0.2108
new best val f1: 0.5181425485961123
meta,dgl,1,480,24.5996,0.5181

 F1-mic 0.5183,  F1-mac 0.2111
new best val f1: 0.5182985361171106
meta,dgl,1,481,24.6501,0.5183

 F1-mic 0.5184,  F1-mac 0.2113
new best val f1: 0.5184305255579553
meta,dgl,1,482,24.7005,0.5184

 F1-mic 0.5185,  F1-mac 0.2114
new best val f1: 0.5184905207583393
meta,dgl,1,483,24.7509,0.5185

 F1-mic 0.5186,  F1-mac 0.2117
new best val f1: 0.5186285097192225
meta,dgl,1,484,24.8013,0.5186

 F1-mic 0.5188,  F1-mac 0.2120
new best val f1: 0.5188204943604512
meta,dgl,1,485,24.8519,0.5188

 F1-mic 0.5190,  F1-mac 0.2123
new best val f1: 0.5189824814014878
meta,dgl,1,486,24.9024,0.5190

 F1-mic 0.5192,  F1-mac 0.2126
new best val f1: 0.5191564674826014
meta,dgl,1,487,24.9529,0.5192

 F1-mic 0.5193,  F1-mac 0.2129
new best val f1: 0.5192884569234462
meta,dgl,1,488,25.0035,0.5193

 F1-mic 0.5195,  F1-mac 0.2130
new best val f1: 0.5194504439644828
meta,dgl,1,489,25.0538,0.5195

epoch:491/50, Iteration 32/32:training loss 1.4720807075500488
Train F1-mic 0.5194, Train F1-mac 0.2141
 F1-mic 0.5196,  F1-mac 0.2133
new best val f1: 0.5196244300455963
meta,dgl,1,490,25.1051,0.5196

 F1-mic 0.5198,  F1-mac 0.2136
new best val f1: 0.5197984161267099
meta,dgl,1,491,25.1554,0.5198

 F1-mic 0.5200,  F1-mac 0.2138
new best val f1: 0.519996400287977
meta,dgl,1,492,25.2058,0.5200

 F1-mic 0.5202,  F1-mac 0.2141
new best val f1: 0.5201763858891288
meta,dgl,1,493,25.2563,0.5202

 F1-mic 0.5203,  F1-mac 0.2143
new best val f1: 0.52028437724982
meta,dgl,1,494,25.3067,0.5203

 F1-mic 0.5205,  F1-mac 0.2147
new best val f1: 0.5204523638108951
meta,dgl,1,495,25.3572,0.5205

 F1-mic 0.5207,  F1-mac 0.2150
new best val f1: 0.5206743460523158
meta,dgl,1,496,25.4074,0.5207

 F1-mic 0.5209,  F1-mac 0.2152
new best val f1: 0.5208843292536597
meta,dgl,1,497,25.4577,0.5209

 F1-mic 0.5210,  F1-mac 0.2154
new best val f1: 0.5210043196544276
meta,dgl,1,498,25.5082,0.5210

 F1-mic 0.5212,  F1-mac 0.2157
new best val f1: 0.5212143028557715
meta,dgl,1,499,25.5585,0.5212

epoch:501/50, Iteration 32/32:training loss 1.4650765657424927
Train F1-mic 0.5210, Train F1-mac 0.2168
 F1-mic 0.5213,  F1-mac 0.2159
new best val f1: 0.5212922966162707
meta,dgl,1,500,25.6088,0.5213

 F1-mic 0.5214,  F1-mac 0.2161
new best val f1: 0.5214362850971922
meta,dgl,1,501,25.6601,0.5214

 F1-mic 0.5216,  F1-mac 0.2163
new best val f1: 0.5215862730981522
meta,dgl,1,502,25.7106,0.5216

 F1-mic 0.5218,  F1-mac 0.2167
new best val f1: 0.5218022558195344
meta,dgl,1,503,25.7612,0.5218

 F1-mic 0.5219,  F1-mac 0.2168
new best val f1: 0.5218982481401487
meta,dgl,1,504,25.8117,0.5219

 F1-mic 0.5220,  F1-mac 0.2171
new best val f1: 0.5220302375809935
meta,dgl,1,505,25.8625,0.5220

 F1-mic 0.5222,  F1-mac 0.2174
new best val f1: 0.5221682265418767
meta,dgl,1,506,25.9128,0.5222

 F1-mic 0.5223,  F1-mac 0.2178
new best val f1: 0.5223362131029518
meta,dgl,1,507,25.9634,0.5223

 F1-mic 0.5225,  F1-mac 0.2181
new best val f1: 0.5224742020638349
meta,dgl,1,508,26.0139,0.5225

 F1-mic 0.5227,  F1-mac 0.2183
new best val f1: 0.5226841852651788
meta,dgl,1,509,26.0645,0.5227

epoch:511/50, Iteration 32/32:training loss 1.4582940340042114
Train F1-mic 0.5225, Train F1-mac 0.2191
 F1-mic 0.5228,  F1-mac 0.2184
new best val f1: 0.5227501799856011
meta,dgl,1,510,26.1150,0.5228

 F1-mic 0.5230,  F1-mac 0.2187
new best val f1: 0.5229541636669066
meta,dgl,1,511,26.1662,0.5230

 F1-mic 0.5232,  F1-mac 0.2190
new best val f1: 0.5231521478281738
meta,dgl,1,512,26.2166,0.5232

 F1-mic 0.5232,  F1-mac 0.2192
new best val f1: 0.5232421406287497
meta,dgl,1,513,26.2669,0.5232

 F1-mic 0.5234,  F1-mac 0.2194
new best val f1: 0.5234041276697864
meta,dgl,1,514,26.3173,0.5234

 F1-mic 0.5236,  F1-mac 0.2197
new best val f1: 0.5235601151907847
meta,dgl,1,515,26.3676,0.5236

 F1-mic 0.5237,  F1-mac 0.2199
new best val f1: 0.5237401007919367
meta,dgl,1,516,26.4179,0.5237

 F1-mic 0.5239,  F1-mac 0.2201
new best val f1: 0.5238840892728581
meta,dgl,1,517,26.4691,0.5239

 F1-mic 0.5241,  F1-mac 0.2204
new best val f1: 0.5241240700743941
meta,dgl,1,518,26.5196,0.5241

 F1-mic 0.5243,  F1-mac 0.2206
new best val f1: 0.5242500599952004
meta,dgl,1,519,26.5702,0.5243

epoch:521/50, Iteration 32/32:training loss 1.4517215490341187
Train F1-mic 0.5240, Train F1-mac 0.2211
 F1-mic 0.5244,  F1-mac 0.2208
new best val f1: 0.5244120470362371
meta,dgl,1,520,26.6205,0.5244

 F1-mic 0.5245,  F1-mac 0.2210
new best val f1: 0.5245140388768899
meta,dgl,1,521,26.6716,0.5245

 F1-mic 0.5247,  F1-mac 0.2212
new best val f1: 0.5246760259179266
meta,dgl,1,522,26.7220,0.5247

 F1-mic 0.5248,  F1-mac 0.2215
new best val f1: 0.5248260139188865
meta,dgl,1,523,26.7726,0.5248

 F1-mic 0.5250,  F1-mac 0.2217
new best val f1: 0.5249940004799616
meta,dgl,1,524,26.8231,0.5250

 F1-mic 0.5252,  F1-mac 0.2220
new best val f1: 0.5252219822414207
meta,dgl,1,525,26.8736,0.5252

 F1-mic 0.5254,  F1-mac 0.2223
new best val f1: 0.5254019678425726
meta,dgl,1,526,26.9242,0.5254

 F1-mic 0.5255,  F1-mac 0.2225
new best val f1: 0.5255459563234941
meta,dgl,1,527,26.9751,0.5255

 F1-mic 0.5257,  F1-mac 0.2227
new best val f1: 0.525695944324454
meta,dgl,1,528,27.0256,0.5257

 F1-mic 0.5258,  F1-mac 0.2230
new best val f1: 0.5258399328053756
meta,dgl,1,529,27.0761,0.5258

epoch:531/50, Iteration 32/32:training loss 1.4453479051589966
Train F1-mic 0.5255, Train F1-mac 0.2233
 F1-mic 0.5260,  F1-mac 0.2232
new best val f1: 0.5259539236861052
meta,dgl,1,530,27.1266,0.5260

 F1-mic 0.5261,  F1-mac 0.2234
new best val f1: 0.5260919126469883
meta,dgl,1,531,27.1770,0.5261

 F1-mic 0.5262,  F1-mac 0.2237
new best val f1: 0.526193904487641
meta,dgl,1,532,27.2282,0.5262

 F1-mic 0.5264,  F1-mac 0.2240
new best val f1: 0.5263918886489081
meta,dgl,1,533,27.2787,0.5264

 F1-mic 0.5266,  F1-mac 0.2243
new best val f1: 0.5266318694504439
meta,dgl,1,534,27.3292,0.5266

 F1-mic 0.5267,  F1-mac 0.2245
new best val f1: 0.5267458603311735
meta,dgl,1,535,27.3797,0.5267

 F1-mic 0.5269,  F1-mac 0.2247
new best val f1: 0.526889848812095
meta,dgl,1,536,27.4302,0.5269

 F1-mic 0.5270,  F1-mac 0.2248
new best val f1: 0.5270098392128629
meta,dgl,1,537,27.4807,0.5270

 F1-mic 0.5271,  F1-mac 0.2249
new best val f1: 0.5271058315334773
meta,dgl,1,538,27.5316,0.5271

 F1-mic 0.5273,  F1-mac 0.2252
new best val f1: 0.5272978161747061
meta,dgl,1,539,27.5821,0.5273

epoch:541/50, Iteration 32/32:training loss 1.4391611814498901
Train F1-mic 0.5271, Train F1-mac 0.2256
 F1-mic 0.5274,  F1-mac 0.2254
new best val f1: 0.527447804175666
meta,dgl,1,540,27.6324,0.5274

 F1-mic 0.5276,  F1-mac 0.2256
new best val f1: 0.5275617950563954
meta,dgl,1,541,27.6828,0.5276

 F1-mic 0.5277,  F1-mac 0.2258
new best val f1: 0.527735781137509
meta,dgl,1,542,27.7331,0.5277

 F1-mic 0.5279,  F1-mac 0.2260
new best val f1: 0.5279037676985842
meta,dgl,1,543,27.7836,0.5279

 F1-mic 0.5280,  F1-mac 0.2262
new best val f1: 0.5280117590592752
meta,dgl,1,544,27.8339,0.5280

 F1-mic 0.5281,  F1-mac 0.2262
new best val f1: 0.5281197504199664
meta,dgl,1,545,27.8844,0.5281

 F1-mic 0.5283,  F1-mac 0.2264
new best val f1: 0.5282817374610032
meta,dgl,1,546,27.9347,0.5283

 F1-mic 0.5285,  F1-mac 0.2268
new best val f1: 0.5285277177825773
meta,dgl,1,547,27.9860,0.5285

 F1-mic 0.5286,  F1-mac 0.2269
new best val f1: 0.5286297096232302
meta,dgl,1,548,28.0363,0.5286

 F1-mic 0.5288,  F1-mac 0.2271
new best val f1: 0.5287856971442285
meta,dgl,1,549,28.0868,0.5288

epoch:551/50, Iteration 32/32:training loss 1.4331510066986084
Train F1-mic 0.5287, Train F1-mac 0.2276
 F1-mic 0.5290,  F1-mac 0.2274
new best val f1: 0.5289656827453804
meta,dgl,1,550,28.1376,0.5290

 F1-mic 0.5291,  F1-mac 0.2276
new best val f1: 0.5291156707463402
meta,dgl,1,551,28.1880,0.5291

 F1-mic 0.5294,  F1-mac 0.2279
new best val f1: 0.5293556515478761
meta,dgl,1,552,28.2385,0.5294

 F1-mic 0.5296,  F1-mac 0.2282
new best val f1: 0.5295776337892969
meta,dgl,1,553,28.2890,0.5296

 F1-mic 0.5297,  F1-mac 0.2285
new best val f1: 0.529745620350372
meta,dgl,1,554,28.3395,0.5297

 F1-mic 0.5298,  F1-mac 0.2286
new best val f1: 0.5298476121910247
meta,dgl,1,555,28.3903,0.5298

 F1-mic 0.5300,  F1-mac 0.2287
new best val f1: 0.5300215982721382
meta,dgl,1,556,28.4408,0.5300

 F1-mic 0.5302,  F1-mac 0.2289
new best val f1: 0.5302195824334053
meta,dgl,1,557,28.4913,0.5302

 F1-mic 0.5304,  F1-mac 0.2291
new best val f1: 0.5303935685145188
meta,dgl,1,558,28.5418,0.5304

 F1-mic 0.5306,  F1-mac 0.2293
new best val f1: 0.5305735541156708
meta,dgl,1,559,28.5923,0.5306

epoch:561/50, Iteration 32/32:training loss 1.4273113012313843
Train F1-mic 0.5305, Train F1-mac 0.2297
 F1-mic 0.5308,  F1-mac 0.2295
new best val f1: 0.5308015358771299
meta,dgl,1,560,28.6428,0.5308

 F1-mic 0.5309,  F1-mac 0.2296
new best val f1: 0.5309155267578594
meta,dgl,1,561,28.6933,0.5309

 F1-mic 0.5310,  F1-mac 0.2297
new best val f1: 0.531029517638589
meta,dgl,1,562,28.7439,0.5310

 F1-mic 0.5313,  F1-mac 0.2299
new best val f1: 0.5312514998800096
meta,dgl,1,563,28.7944,0.5313

 F1-mic 0.5315,  F1-mac 0.2302
new best val f1: 0.5314914806815455
meta,dgl,1,564,28.8449,0.5315

 F1-mic 0.5317,  F1-mac 0.2304
new best val f1: 0.5317014638828894
meta,dgl,1,565,28.8953,0.5317

 F1-mic 0.5319,  F1-mac 0.2307
new best val f1: 0.5319114470842332
meta,dgl,1,566,28.9459,0.5319

 F1-mic 0.5321,  F1-mac 0.2308
new best val f1: 0.5320674346052315
meta,dgl,1,567,28.9963,0.5321

 F1-mic 0.5322,  F1-mac 0.2309
new best val f1: 0.5322174226061915
meta,dgl,1,568,29.0469,0.5322

 F1-mic 0.5324,  F1-mac 0.2311
new best val f1: 0.5323734101271899
meta,dgl,1,569,29.0972,0.5324

epoch:571/50, Iteration 32/32:training loss 1.4216251373291016
Train F1-mic 0.5323, Train F1-mac 0.2318
 F1-mic 0.5325,  F1-mac 0.2313
new best val f1: 0.5324994000479961
meta,dgl,1,570,29.1487,0.5325

 F1-mic 0.5328,  F1-mac 0.2315
new best val f1: 0.5327513798896089
meta,dgl,1,571,29.1991,0.5328

 F1-mic 0.5328,  F1-mac 0.2317
new best val f1: 0.5328413726901848
meta,dgl,1,572,29.2496,0.5328

 F1-mic 0.5329,  F1-mac 0.2319
new best val f1: 0.5329373650107991
meta,dgl,1,573,29.3004,0.5329

 F1-mic 0.5332,  F1-mac 0.2321
new best val f1: 0.5331653467722582
meta,dgl,1,574,29.3509,0.5332

 F1-mic 0.5334,  F1-mac 0.2324
new best val f1: 0.5333513318934485
meta,dgl,1,575,29.4014,0.5334

 F1-mic 0.5335,  F1-mac 0.2325
new best val f1: 0.5334893208543317
meta,dgl,1,576,29.4519,0.5335

 F1-mic 0.5335,  F1-mac 0.2326
new best val f1: 0.5335313174946005
meta,dgl,1,577,29.5025,0.5335

 F1-mic 0.5338,  F1-mac 0.2329
new best val f1: 0.5337532997360211
meta,dgl,1,578,29.5530,0.5338

 F1-mic 0.5340,  F1-mac 0.2332
new best val f1: 0.5340412766978642
meta,dgl,1,579,29.6038,0.5340

epoch:581/50, Iteration 32/32:training loss 1.416089415550232
Train F1-mic 0.5341, Train F1-mac 0.2339
 F1-mic 0.5343,  F1-mac 0.2335
new best val f1: 0.5342512598992081
meta,dgl,1,580,29.6541,0.5343

 F1-mic 0.5344,  F1-mac 0.2337
new best val f1: 0.5344312455003599
meta,dgl,1,581,29.7045,0.5344

 F1-mic 0.5346,  F1-mac 0.2339
new best val f1: 0.5346232301415886
meta,dgl,1,582,29.7549,0.5346

 F1-mic 0.5348,  F1-mac 0.2340
new best val f1: 0.534809215262779
meta,dgl,1,583,29.8055,0.5348

 F1-mic 0.5350,  F1-mac 0.2342
new best val f1: 0.5350011999040076
meta,dgl,1,584,29.8559,0.5350

 F1-mic 0.5352,  F1-mac 0.2345
new best val f1: 0.53521718262539
meta,dgl,1,585,29.9066,0.5352

 F1-mic 0.5355,  F1-mac 0.2347
new best val f1: 0.535475161987041
meta,dgl,1,586,29.9570,0.5355

 F1-mic 0.5357,  F1-mac 0.2350
new best val f1: 0.5356971442284617
meta,dgl,1,587,30.0074,0.5357

 F1-mic 0.5359,  F1-mac 0.2353
new best val f1: 0.5359311255099592
meta,dgl,1,588,30.0577,0.5359

 F1-mic 0.5361,  F1-mac 0.2355
new best val f1: 0.5360811135109191
meta,dgl,1,589,30.1081,0.5361

epoch:591/50, Iteration 32/32:training loss 1.4106827974319458
Train F1-mic 0.5360, Train F1-mac 0.2360
 F1-mic 0.5364,  F1-mac 0.2357
new best val f1: 0.5363570914326854
meta,dgl,1,590,30.1585,0.5364

 F1-mic 0.5365,  F1-mac 0.2360
new best val f1: 0.5365190784737222
meta,dgl,1,591,30.2090,0.5365

 F1-mic 0.5367,  F1-mac 0.2362
new best val f1: 0.5367050635949124
meta,dgl,1,592,30.2594,0.5367

 F1-mic 0.5369,  F1-mac 0.2364
new best val f1: 0.5368970482361412
meta,dgl,1,593,30.3098,0.5369

 F1-mic 0.5372,  F1-mac 0.2368
new best val f1: 0.5372390208783298
meta,dgl,1,594,30.3603,0.5372

 F1-mic 0.5374,  F1-mac 0.2369
new best val f1: 0.5373950083993281
meta,dgl,1,595,30.4111,0.5374

 F1-mic 0.5376,  F1-mac 0.2371
new best val f1: 0.5375689944804416
meta,dgl,1,596,30.4617,0.5376

 F1-mic 0.5377,  F1-mac 0.2373
new best val f1: 0.5377429805615551
meta,dgl,1,597,30.5123,0.5377

 F1-mic 0.5379,  F1-mac 0.2375
new best val f1: 0.5379409647228222
meta,dgl,1,598,30.5628,0.5379

 F1-mic 0.5381,  F1-mac 0.2376
new best val f1: 0.5380969522438205
meta,dgl,1,599,30.6134,0.5381

epoch:601/50, Iteration 32/32:training loss 1.4054043292999268
Train F1-mic 0.5379, Train F1-mac 0.2381
 F1-mic 0.5383,  F1-mac 0.2379
new best val f1: 0.5383129349652028
meta,dgl,1,600,30.6640,0.5383

 F1-mic 0.5385,  F1-mac 0.2381
new best val f1: 0.5385409167266618
meta,dgl,1,601,30.7144,0.5385

 F1-mic 0.5388,  F1-mac 0.2383
new best val f1: 0.5388168946484281
meta,dgl,1,602,30.7648,0.5388

 F1-mic 0.5390,  F1-mac 0.2385
new best val f1: 0.53899688024958
meta,dgl,1,603,30.8161,0.5390

 F1-mic 0.5392,  F1-mac 0.2387
new best val f1: 0.5391648668106551
meta,dgl,1,604,30.8664,0.5392

 F1-mic 0.5393,  F1-mac 0.2388
new best val f1: 0.5393448524118071
meta,dgl,1,605,30.9168,0.5393

 F1-mic 0.5395,  F1-mac 0.2390
new best val f1: 0.5395128389728822
meta,dgl,1,606,30.9673,0.5395

 F1-mic 0.5397,  F1-mac 0.2392
new best val f1: 0.5397348212143028
meta,dgl,1,607,31.0178,0.5397

 F1-mic 0.5400,  F1-mac 0.2394
new best val f1: 0.5399568034557235
meta,dgl,1,608,31.0685,0.5400

 F1-mic 0.5402,  F1-mac 0.2396
new best val f1: 0.5401667866570674
meta,dgl,1,609,31.1246,0.5402

epoch:611/50, Iteration 32/32:training loss 1.4002426862716675
Train F1-mic 0.5400, Train F1-mac 0.2400
 F1-mic 0.5404,  F1-mac 0.2399
new best val f1: 0.5404247660187185
meta,dgl,1,610,31.1749,0.5404

 F1-mic 0.5405,  F1-mac 0.2399
new best val f1: 0.5404967602591793
meta,dgl,1,611,31.2253,0.5405

 F1-mic 0.5406,  F1-mac 0.2401
new best val f1: 0.5405747540196785
meta,dgl,1,612,31.2767,0.5406

 F1-mic 0.5407,  F1-mac 0.2403
new best val f1: 0.5407127429805616
meta,dgl,1,613,31.3272,0.5407

 F1-mic 0.5410,  F1-mac 0.2405
new best val f1: 0.5409527237820975
meta,dgl,1,614,31.3775,0.5410

 F1-mic 0.5412,  F1-mac 0.2407
new best val f1: 0.5411927045836333
meta,dgl,1,615,31.4287,0.5412

 F1-mic 0.5415,  F1-mac 0.2409
new best val f1: 0.5414686825053996
meta,dgl,1,616,31.4791,0.5415

 F1-mic 0.5416,  F1-mac 0.2410
new best val f1: 0.541594672426206
meta,dgl,1,617,31.5299,0.5416

 F1-mic 0.5418,  F1-mac 0.2412
new best val f1: 0.5418106551475882
meta,dgl,1,618,31.5805,0.5418

 F1-mic 0.5421,  F1-mac 0.2414
new best val f1: 0.5420506359491241
meta,dgl,1,619,31.6311,0.5421

epoch:621/50, Iteration 32/32:training loss 1.3951870203018188
Train F1-mic 0.5421, Train F1-mac 0.2422
 F1-mic 0.5423,  F1-mac 0.2417
new best val f1: 0.5422906167506599
meta,dgl,1,620,31.6816,0.5423

 F1-mic 0.5425,  F1-mac 0.2419
new best val f1: 0.5425365970722342
meta,dgl,1,621,31.7320,0.5425

 F1-mic 0.5428,  F1-mac 0.2421
new best val f1: 0.5427525797936165
meta,dgl,1,622,31.7826,0.5428

 F1-mic 0.5430,  F1-mac 0.2423
new best val f1: 0.543016558675306
meta,dgl,1,623,31.8331,0.5430

 F1-mic 0.5433,  F1-mac 0.2426
new best val f1: 0.5433225341972642
meta,dgl,1,624,31.8837,0.5433

 F1-mic 0.5436,  F1-mac 0.2429
new best val f1: 0.5435805135589152
meta,dgl,1,625,31.9343,0.5436

 F1-mic 0.5438,  F1-mac 0.2432
new best val f1: 0.543802495800336
meta,dgl,1,626,31.9850,0.5438

 F1-mic 0.5441,  F1-mac 0.2435
new best val f1: 0.5440724742020638
meta,dgl,1,627,32.0355,0.5441

 F1-mic 0.5444,  F1-mac 0.2437
new best val f1: 0.5443724502039837
meta,dgl,1,628,32.0861,0.5444

 F1-mic 0.5446,  F1-mac 0.2439
new best val f1: 0.544558435325174
meta,dgl,1,629,32.1368,0.5446

epoch:631/50, Iteration 32/32:training loss 1.3902324438095093
Train F1-mic 0.5445, Train F1-mac 0.2446
 F1-mic 0.5449,  F1-mac 0.2442
new best val f1: 0.5449004079673626
meta,dgl,1,630,32.1875,0.5449

 F1-mic 0.5452,  F1-mac 0.2446
new best val f1: 0.5451583873290137
meta,dgl,1,631,32.2380,0.5452

 F1-mic 0.5453,  F1-mac 0.2448
new best val f1: 0.5453323734101272
meta,dgl,1,632,32.2885,0.5453

 F1-mic 0.5456,  F1-mac 0.2449
new best val f1: 0.5455723542116631
meta,dgl,1,633,32.3391,0.5456

 F1-mic 0.5458,  F1-mac 0.2451
new best val f1: 0.5458363330933526
meta,dgl,1,634,32.3897,0.5458

 F1-mic 0.5461,  F1-mac 0.2453
new best val f1: 0.54607031437485
meta,dgl,1,635,32.4404,0.5461

 F1-mic 0.5462,  F1-mac 0.2455
new best val f1: 0.5462443004559635
meta,dgl,1,636,32.4909,0.5462

 F1-mic 0.5465,  F1-mac 0.2457
new best val f1: 0.546478281737461
meta,dgl,1,637,32.5416,0.5465

 F1-mic 0.5467,  F1-mac 0.2458
new best val f1: 0.5466822654187665
meta,dgl,1,638,32.5922,0.5467

 F1-mic 0.5469,  F1-mac 0.2460
new best val f1: 0.5469042476601872
meta,dgl,1,639,32.6428,0.5469

epoch:641/50, Iteration 32/32:training loss 1.3853695392608643
Train F1-mic 0.5469, Train F1-mac 0.2468
 F1-mic 0.5472,  F1-mac 0.2463
new best val f1: 0.5471982241420686
meta,dgl,1,640,32.6934,0.5472

 F1-mic 0.5475,  F1-mac 0.2467
new best val f1: 0.5475341972642188
meta,dgl,1,641,32.7437,0.5475

 F1-mic 0.5477,  F1-mac 0.2468
new best val f1: 0.5476781857451404
meta,dgl,1,642,32.7944,0.5477

 F1-mic 0.5480,  F1-mac 0.2471
new best val f1: 0.5480321574274059
meta,dgl,1,643,32.8450,0.5480

 F1-mic 0.5484,  F1-mac 0.2474
new best val f1: 0.5483801295896328
meta,dgl,1,644,32.8953,0.5484

 F1-mic 0.5487,  F1-mac 0.2477
new best val f1: 0.5486981041516679
meta,dgl,1,645,32.9458,0.5487

 F1-mic 0.5489,  F1-mac 0.2478
new best val f1: 0.5488540916726662
meta,dgl,1,646,32.9967,0.5489

 F1-mic 0.5491,  F1-mac 0.2480
new best val f1: 0.5491120710343173
meta,dgl,1,647,33.0472,0.5491

 F1-mic 0.5494,  F1-mac 0.2482
new best val f1: 0.5493520518358531
meta,dgl,1,648,33.0978,0.5494

 F1-mic 0.5496,  F1-mac 0.2485
new best val f1: 0.5496460283177346
meta,dgl,1,649,33.1483,0.5496

epoch:651/50, Iteration 32/32:training loss 1.3805949687957764
Train F1-mic 0.5497, Train F1-mac 0.2493
 F1-mic 0.5499,  F1-mac 0.2487
new best val f1: 0.5498920086393089
meta,dgl,1,650,33.1988,0.5499

 F1-mic 0.5501,  F1-mac 0.2489
new best val f1: 0.5501019918406528
meta,dgl,1,651,33.2493,0.5501

 F1-mic 0.5504,  F1-mac 0.2492
new best val f1: 0.5504019678425726
meta,dgl,1,652,33.3001,0.5504

 F1-mic 0.5507,  F1-mac 0.2495
new best val f1: 0.5506839452843773
meta,dgl,1,653,33.3506,0.5507

 F1-mic 0.5510,  F1-mac 0.2497
new best val f1: 0.5510139188864891
meta,dgl,1,654,33.4010,0.5510

 F1-mic 0.5513,  F1-mac 0.2500
new best val f1: 0.5513258939284857
meta,dgl,1,655,33.4515,0.5513

 F1-mic 0.5516,  F1-mac 0.2502
new best val f1: 0.5515958723302136
meta,dgl,1,656,33.5020,0.5516

 F1-mic 0.5518,  F1-mac 0.2504
new best val f1: 0.5517638588912886
meta,dgl,1,657,33.5526,0.5518

 F1-mic 0.5520,  F1-mac 0.2506
new best val f1: 0.5520038396928246
meta,dgl,1,658,33.6038,0.5520

 F1-mic 0.5522,  F1-mac 0.2509
new best val f1: 0.5522498200143988
meta,dgl,1,659,33.6543,0.5522

epoch:661/50, Iteration 32/32:training loss 1.3758952617645264
Train F1-mic 0.5525, Train F1-mac 0.2517
 F1-mic 0.5524,  F1-mac 0.2510
new best val f1: 0.5524358051355891
meta,dgl,1,660,33.7048,0.5524

 F1-mic 0.5528,  F1-mac 0.2513
new best val f1: 0.5527597792176626
meta,dgl,1,661,33.7553,0.5528

 F1-mic 0.5530,  F1-mac 0.2516
new best val f1: 0.5529817614590833
meta,dgl,1,662,33.8059,0.5530

 F1-mic 0.5532,  F1-mac 0.2518
new best val f1: 0.5532337413006959
meta,dgl,1,663,33.8565,0.5532

 F1-mic 0.5535,  F1-mac 0.2521
new best val f1: 0.5535157187425006
meta,dgl,1,664,33.9069,0.5535

 F1-mic 0.5538,  F1-mac 0.2524
new best val f1: 0.5537856971442284
meta,dgl,1,665,33.9580,0.5538

 F1-mic 0.5541,  F1-mac 0.2527
new best val f1: 0.5541456683465322
meta,dgl,1,666,34.0085,0.5541

 F1-mic 0.5543,  F1-mac 0.2528
new best val f1: 0.554307655387569
meta,dgl,1,667,34.0589,0.5543

 F1-mic 0.5545,  F1-mac 0.2530
new best val f1: 0.5544816414686825
meta,dgl,1,668,34.1095,0.5545

 F1-mic 0.5548,  F1-mac 0.2533
new best val f1: 0.5548236141108711
meta,dgl,1,669,34.1599,0.5548

epoch:671/50, Iteration 32/32:training loss 1.3712708950042725
Train F1-mic 0.5550, Train F1-mac 0.2541
 F1-mic 0.5550,  F1-mac 0.2535
new best val f1: 0.5549856011519079
meta,dgl,1,670,34.2104,0.5550

 F1-mic 0.5553,  F1-mac 0.2538
new best val f1: 0.5553455723542117
meta,dgl,1,671,34.2608,0.5553

 F1-mic 0.5556,  F1-mac 0.2540
new best val f1: 0.5555975521958243
meta,dgl,1,672,34.3113,0.5556

 F1-mic 0.5558,  F1-mac 0.2542
new best val f1: 0.555789536837053
meta,dgl,1,673,34.3618,0.5558

 F1-mic 0.5561,  F1-mac 0.2545
new best val f1: 0.5560835133189345
meta,dgl,1,674,34.4121,0.5561

 F1-mic 0.5564,  F1-mac 0.2548
new best val f1: 0.5563594912407007
meta,dgl,1,675,34.4625,0.5564

 F1-mic 0.5566,  F1-mac 0.2550
new best val f1: 0.5566174706023518
meta,dgl,1,676,34.5129,0.5566

 F1-mic 0.5568,  F1-mac 0.2551
new best val f1: 0.5568334533237341
meta,dgl,1,677,34.5634,0.5568

 F1-mic 0.5572,  F1-mac 0.2554
new best val f1: 0.5571874250059995
meta,dgl,1,678,34.6139,0.5572

 F1-mic 0.5572,  F1-mac 0.2555
new best val f1: 0.5572114230861531
meta,dgl,1,679,34.6642,0.5572

epoch:681/50, Iteration 32/32:training loss 1.3667185306549072
Train F1-mic 0.5573, Train F1-mac 0.2562
 F1-mic 0.5575,  F1-mac 0.2557
new best val f1: 0.5575113990880729
meta,dgl,1,680,34.7147,0.5575

 F1-mic 0.5578,  F1-mac 0.2560
new best val f1: 0.5577753779697624
meta,dgl,1,681,34.7651,0.5578

 F1-mic 0.5580,  F1-mac 0.2562
new best val f1: 0.5580273578113751
meta,dgl,1,682,34.8155,0.5580

 F1-mic 0.5582,  F1-mac 0.2564
new best val f1: 0.558177345812335
meta,dgl,1,683,34.8660,0.5582

 F1-mic 0.5584,  F1-mac 0.2565
new best val f1: 0.5583873290136789
meta,dgl,1,684,34.9165,0.5584

 F1-mic 0.5585,  F1-mac 0.2567
new best val f1: 0.5584593232541397
meta,dgl,1,685,34.9676,0.5585

 F1-mic 0.5588,  F1-mac 0.2569
new best val f1: 0.5587592992560595
meta,dgl,1,686,35.0180,0.5588

 F1-mic 0.5591,  F1-mac 0.2573
new best val f1: 0.5590712742980561
meta,dgl,1,687,35.0686,0.5591

 F1-mic 0.5593,  F1-mac 0.2575
new best val f1: 0.5593172546196304
meta,dgl,1,688,35.1191,0.5593

 F1-mic 0.5595,  F1-mac 0.2578
new best val f1: 0.5595452363810896
meta,dgl,1,689,35.1696,0.5595

epoch:691/50, Iteration 32/32:training loss 1.3622256517410278
Train F1-mic 0.5597, Train F1-mac 0.2584
 F1-mic 0.5597,  F1-mac 0.2580
new best val f1: 0.5596652267818575
meta,dgl,1,690,35.2201,0.5597

 F1-mic 0.5598,  F1-mac 0.2581
new best val f1: 0.5598032157427406
meta,dgl,1,691,35.2704,0.5598

 F1-mic 0.5600,  F1-mac 0.2583
new best val f1: 0.5599772018238541
meta,dgl,1,692,35.3210,0.5600

 F1-mic 0.5603,  F1-mac 0.2586
new best val f1: 0.5603011759059275
meta,dgl,1,693,35.3716,0.5603

 F1-mic 0.5606,  F1-mac 0.2589
new best val f1: 0.5606011519078473
meta,dgl,1,694,35.4218,0.5606

 F1-mic 0.5608,  F1-mac 0.2591
new best val f1: 0.5607871370290377
meta,dgl,1,695,35.4726,0.5608

 F1-mic 0.5610,  F1-mac 0.2593
new best val f1: 0.5610151187904968
meta,dgl,1,696,35.5229,0.5610

 F1-mic 0.5611,  F1-mac 0.2594
new best val f1: 0.5610811135109192
meta,dgl,1,697,35.5734,0.5611

 F1-mic 0.5614,  F1-mac 0.2597
new best val f1: 0.561351091912647
meta,dgl,1,698,35.6238,0.5614

 F1-mic 0.5615,  F1-mac 0.2599
new best val f1: 0.5615370770338373
meta,dgl,1,699,35.6744,0.5615

epoch:701/50, Iteration 32/32:training loss 1.3577955961227417
Train F1-mic 0.5617, Train F1-mac 0.2604
 F1-mic 0.5618,  F1-mac 0.2600
new best val f1: 0.5617650587952964
meta,dgl,1,700,35.7252,0.5618

 F1-mic 0.5620,  F1-mac 0.2602
new best val f1: 0.5619930405567555
meta,dgl,1,701,35.7756,0.5620

 F1-mic 0.5622,  F1-mac 0.2603
new best val f1: 0.5621610271178306
meta,dgl,1,702,35.8261,0.5622

 F1-mic 0.5623,  F1-mac 0.2605
new best val f1: 0.5622810175185985
meta,dgl,1,703,35.8766,0.5623

 F1-mic 0.5625,  F1-mac 0.2606
new best val f1: 0.562455003599712
meta,dgl,1,704,35.9271,0.5625

 F1-mic 0.5627,  F1-mac 0.2609
new best val f1: 0.562742980561555
meta,dgl,1,705,35.9779,0.5627

 F1-mic 0.5630,  F1-mac 0.2611
new best val f1: 0.5629889608831293
meta,dgl,1,706,36.0282,0.5630

 F1-mic 0.5633,  F1-mac 0.2614
new best val f1: 0.5633069354451644
meta,dgl,1,707,36.0787,0.5633

 F1-mic 0.5635,  F1-mac 0.2616
new best val f1: 0.5634989200863931
meta,dgl,1,708,36.1290,0.5635

 F1-mic 0.5636,  F1-mac 0.2617
new best val f1: 0.5635769138468922
meta,dgl,1,709,36.1795,0.5636

epoch:711/50, Iteration 32/32:training loss 1.3534212112426758
Train F1-mic 0.5638, Train F1-mac 0.2623
 F1-mic 0.5637,  F1-mac 0.2619
new best val f1: 0.563738900887929
meta,dgl,1,710,36.2297,0.5637

 F1-mic 0.5640,  F1-mac 0.2621
new best val f1: 0.5639548836093112
meta,dgl,1,711,36.2808,0.5640

 F1-mic 0.5642,  F1-mac 0.2624
new best val f1: 0.5642308615310775
meta,dgl,1,712,36.3310,0.5642

 F1-mic 0.5645,  F1-mac 0.2626
new best val f1: 0.5644708423326134
meta,dgl,1,713,36.3816,0.5645

 F1-mic 0.5646,  F1-mac 0.2628
new best val f1: 0.5646268298536117
meta,dgl,1,714,36.4326,0.5646

 F1-mic 0.5648,  F1-mac 0.2629
new best val f1: 0.5647648188144948
meta,dgl,1,715,36.4832,0.5648

 F1-mic 0.5650,  F1-mac 0.2631
new best val f1: 0.5649688024958003
meta,dgl,1,716,36.5338,0.5650

 F1-mic 0.5652,  F1-mac 0.2633
new best val f1: 0.5651907847372211
meta,dgl,1,717,36.5843,0.5652

 F1-mic 0.5654,  F1-mac 0.2634
new best val f1: 0.5653827693784498
meta,dgl,1,718,36.6346,0.5654

 F1-mic 0.5656,  F1-mac 0.2637
new best val f1: 0.5656347492200624
meta,dgl,1,719,36.6850,0.5656

epoch:721/50, Iteration 32/32:training loss 1.3490984439849854
Train F1-mic 0.5659, Train F1-mac 0.2644
 F1-mic 0.5658,  F1-mac 0.2638
new best val f1: 0.5658147348212142
meta,dgl,1,720,36.7358,0.5658

 F1-mic 0.5660,  F1-mac 0.2640
new best val f1: 0.5660247180225582
meta,dgl,1,721,36.7864,0.5660

 F1-mic 0.5662,  F1-mac 0.2642
new best val f1: 0.5662107031437486
meta,dgl,1,722,36.8369,0.5662

 F1-mic 0.5663,  F1-mac 0.2643
new best val f1: 0.5663426925845932
meta,dgl,1,723,36.8873,0.5663

 F1-mic 0.5665,  F1-mac 0.2644
new best val f1: 0.5665106791456683
meta,dgl,1,724,36.9377,0.5665

 F1-mic 0.5667,  F1-mac 0.2646
new best val f1: 0.5667086633069355
meta,dgl,1,725,36.9888,0.5667

 F1-mic 0.5669,  F1-mac 0.2647
new best val f1: 0.5669426445884329
meta,dgl,1,726,37.0393,0.5669

 F1-mic 0.5671,  F1-mac 0.2649
new best val f1: 0.5671166306695464
meta,dgl,1,727,37.0898,0.5671

 F1-mic 0.5673,  F1-mac 0.2651
new best val f1: 0.5672846172306215
meta,dgl,1,728,37.1404,0.5673

 F1-mic 0.5676,  F1-mac 0.2653
new best val f1: 0.5676025917926566
meta,dgl,1,729,37.1910,0.5676

epoch:731/50, Iteration 32/32:training loss 1.344819188117981
Train F1-mic 0.5679, Train F1-mac 0.2663
 F1-mic 0.5678,  F1-mac 0.2654
new best val f1: 0.5677945764338853
meta,dgl,1,730,37.2415,0.5678

 F1-mic 0.5680,  F1-mac 0.2656
new best val f1: 0.5679685625149988
meta,dgl,1,731,37.2919,0.5680

 F1-mic 0.5680,  F1-mac 0.2657
new best val f1: 0.5680345572354212
meta,dgl,1,732,37.3425,0.5680

 F1-mic 0.5682,  F1-mac 0.2659
new best val f1: 0.5682445404367651
meta,dgl,1,733,37.3931,0.5682

 F1-mic 0.5684,  F1-mac 0.2660
new best val f1: 0.5683705303575713
meta,dgl,1,734,37.4436,0.5684

 F1-mic 0.5686,  F1-mac 0.2663
new best val f1: 0.5686165106791456
meta,dgl,1,735,37.4945,0.5686

 F1-mic 0.5690,  F1-mac 0.2666
new best val f1: 0.5689524838012959
meta,dgl,1,736,37.5457,0.5690

 F1-mic 0.5692,  F1-mac 0.2668
new best val f1: 0.5691564674826014
meta,dgl,1,737,37.5963,0.5692

 F1-mic 0.5693,  F1-mac 0.2669
new best val f1: 0.5692584593232541
meta,dgl,1,738,37.6469,0.5693

 F1-mic 0.5695,  F1-mac 0.2671
new best val f1: 0.569468442524598
meta,dgl,1,739,37.6973,0.5695

epoch:741/50, Iteration 32/32:training loss 1.3405824899673462
Train F1-mic 0.5698, Train F1-mac 0.2682
 F1-mic 0.5696,  F1-mac 0.2673
new best val f1: 0.5696484281257499
meta,dgl,1,740,37.7479,0.5696

 F1-mic 0.5699,  F1-mac 0.2675
new best val f1: 0.5698884089272859
meta,dgl,1,741,37.7983,0.5699

 F1-mic 0.5700,  F1-mac 0.2676
new best val f1: 0.5700443964482841
meta,dgl,1,742,37.8488,0.5700

 F1-mic 0.5702,  F1-mac 0.2678
new best val f1: 0.5701643868490521
meta,dgl,1,743,37.8992,0.5702

 F1-mic 0.5703,  F1-mac 0.2679
new best val f1: 0.5702903767698584
meta,dgl,1,744,37.9498,0.5703

 F1-mic 0.5706,  F1-mac 0.2681
new best val f1: 0.5705903527717783
meta,dgl,1,745,38.0004,0.5706

 F1-mic 0.5708,  F1-mac 0.2683
new best val f1: 0.5707943364530838
meta,dgl,1,746,38.0508,0.5708

 F1-mic 0.5710,  F1-mac 0.2685
new best val f1: 0.5709503239740821
meta,dgl,1,747,38.1012,0.5710

 F1-mic 0.5712,  F1-mac 0.2686
new best val f1: 0.5711903047756179
meta,dgl,1,748,38.1516,0.5712

 F1-mic 0.5713,  F1-mac 0.2687
new best val f1: 0.5712922966162707
meta,dgl,1,749,38.2020,0.5713

epoch:751/50, Iteration 32/32:training loss 1.3363850116729736
Train F1-mic 0.5717, Train F1-mac 0.2700
 F1-mic 0.5715,  F1-mac 0.2689
new best val f1: 0.571538276937845
meta,dgl,1,750,38.2524,0.5715

 F1-mic 0.5717,  F1-mac 0.2691
new best val f1: 0.5717122630189585
meta,dgl,1,751,38.3028,0.5717

 F1-mic 0.5719,  F1-mac 0.2693
new best val f1: 0.5719342452603792
meta,dgl,1,752,38.3533,0.5719

 F1-mic 0.5721,  F1-mac 0.2695
new best val f1: 0.5721202303815695
meta,dgl,1,753,38.4042,0.5721

 F1-mic 0.5723,  F1-mac 0.2697
new best val f1: 0.5723062155027597
meta,dgl,1,754,38.4546,0.5723

 F1-mic 0.5725,  F1-mac 0.2700
new best val f1: 0.5725461963042957
meta,dgl,1,755,38.5051,0.5725

 F1-mic 0.5727,  F1-mac 0.2701
new best val f1: 0.5726781857451404
meta,dgl,1,756,38.5558,0.5727

 F1-mic 0.5729,  F1-mac 0.2703
new best val f1: 0.5729001679865611
meta,dgl,1,757,38.6062,0.5729

 F1-mic 0.5731,  F1-mac 0.2705
new best val f1: 0.5731161507079434
meta,dgl,1,758,38.6567,0.5731

 F1-mic 0.5731,  F1-mac 0.2706
new best val f1: 0.5731401487880969
meta,dgl,1,759,38.7072,0.5731

epoch:761/50, Iteration 32/32:training loss 1.3322194814682007
Train F1-mic 0.5735, Train F1-mac 0.2720
 F1-mic 0.5734,  F1-mac 0.2708
new best val f1: 0.5733801295896328
meta,dgl,1,760,38.7577,0.5734

 F1-mic 0.5735,  F1-mac 0.2710
new best val f1: 0.5735241180705544
meta,dgl,1,761,38.8083,0.5735

 F1-mic 0.5738,  F1-mac 0.2712
new best val f1: 0.5737640988720902
meta,dgl,1,762,38.8589,0.5738

 F1-mic 0.5739,  F1-mac 0.2714
new best val f1: 0.573926085913127
meta,dgl,1,763,38.9101,0.5739

 F1-mic 0.5741,  F1-mac 0.2715
new best val f1: 0.5740580753539717
meta,dgl,1,764,38.9605,0.5741

 F1-mic 0.5743,  F1-mac 0.2717
new best val f1: 0.5742620590352772
meta,dgl,1,765,39.0109,0.5743

 F1-mic 0.5744,  F1-mac 0.2718
new best val f1: 0.5743760499160068
meta,dgl,1,766,39.0621,0.5744

 F1-mic 0.5746,  F1-mac 0.2720
new best val f1: 0.5746100311975042
meta,dgl,1,767,39.1124,0.5746

 F1-mic 0.5749,  F1-mac 0.2722
new best val f1: 0.5748740100791937
meta,dgl,1,768,39.1630,0.5749

 F1-mic 0.5751,  F1-mac 0.2724
new best val f1: 0.5750659947204224
meta,dgl,1,769,39.2137,0.5751

epoch:771/50, Iteration 32/32:training loss 1.3280797004699707
Train F1-mic 0.5755, Train F1-mac 0.2740
 F1-mic 0.5753,  F1-mac 0.2726
new best val f1: 0.5752759779217662
meta,dgl,1,770,39.2641,0.5753

 F1-mic 0.5754,  F1-mac 0.2727
new best val f1: 0.5754139668826493
meta,dgl,1,771,39.3147,0.5754

 F1-mic 0.5755,  F1-mac 0.2729
new best val f1: 0.575527957763379
meta,dgl,1,772,39.3652,0.5755

 F1-mic 0.5758,  F1-mac 0.2730
new best val f1: 0.5757619390448764
meta,dgl,1,773,39.4157,0.5758

 F1-mic 0.5760,  F1-mac 0.2733
new best val f1: 0.5759959203263739
meta,dgl,1,774,39.4662,0.5760

 F1-mic 0.5762,  F1-mac 0.2735
new best val f1: 0.5761519078473722
meta,dgl,1,775,39.5167,0.5762

 F1-mic 0.5763,  F1-mac 0.2737
new best val f1: 0.5763018958483321
meta,dgl,1,776,39.5672,0.5763

 F1-mic 0.5764,  F1-mac 0.2738
new best val f1: 0.5764038876889849
meta,dgl,1,777,39.6177,0.5764

 F1-mic 0.5766,  F1-mac 0.2740
new best val f1: 0.5765838732901368
meta,dgl,1,778,39.6682,0.5766

 F1-mic 0.5767,  F1-mac 0.2741
new best val f1: 0.5767338612910967
meta,dgl,1,779,39.7193,0.5767

epoch:781/50, Iteration 32/32:training loss 1.3239669799804688
Train F1-mic 0.5772, Train F1-mac 0.2756
 F1-mic 0.5769,  F1-mac 0.2742
new best val f1: 0.5768538516918646
meta,dgl,1,780,39.7698,0.5769

 F1-mic 0.5770,  F1-mac 0.2744
new best val f1: 0.5769858411327093
meta,dgl,1,781,39.8203,0.5770

 F1-mic 0.5772,  F1-mac 0.2746
new best val f1: 0.5771718262538997
meta,dgl,1,782,39.8709,0.5772

 F1-mic 0.5774,  F1-mac 0.2748
new best val f1: 0.5774238060955124
meta,dgl,1,783,39.9215,0.5774

 F1-mic 0.5776,  F1-mac 0.2749
new best val f1: 0.5775737940964722
meta,dgl,1,784,39.9719,0.5776

 F1-mic 0.5778,  F1-mac 0.2751
new best val f1: 0.5777597792176626
meta,dgl,1,785,40.0223,0.5778

 F1-mic 0.5779,  F1-mac 0.2753
new best val f1: 0.5779157667386609
meta,dgl,1,786,40.0727,0.5779

 F1-mic 0.5781,  F1-mac 0.2755
new best val f1: 0.5780717542596592
meta,dgl,1,787,40.1231,0.5781

 F1-mic 0.5783,  F1-mac 0.2757
new best val f1: 0.5782637389008879
meta,dgl,1,788,40.1737,0.5783

 F1-mic 0.5784,  F1-mac 0.2758
new best val f1: 0.578401727861771
meta,dgl,1,789,40.2242,0.5784

epoch:791/50, Iteration 32/32:training loss 1.3198771476745605
Train F1-mic 0.5788, Train F1-mac 0.2772
 F1-mic 0.5785,  F1-mac 0.2759
new best val f1: 0.5785277177825774
meta,dgl,1,790,40.2747,0.5785

 F1-mic 0.5787,  F1-mac 0.2761
new best val f1: 0.5787317014638829
meta,dgl,1,791,40.3252,0.5787

 F1-mic 0.5788,  F1-mac 0.2762
new best val f1: 0.5788336933045356
meta,dgl,1,792,40.3757,0.5788

 F1-mic 0.5790,  F1-mac 0.2764
new best val f1: 0.5790436765058795
meta,dgl,1,793,40.4263,0.5790

 F1-mic 0.5792,  F1-mac 0.2766
new best val f1: 0.5791756659467243
meta,dgl,1,794,40.4768,0.5792

 F1-mic 0.5793,  F1-mac 0.2768
new best val f1: 0.5793316534677225
meta,dgl,1,795,40.5272,0.5793

 F1-mic 0.5795,  F1-mac 0.2770
new best val f1: 0.5795476361891049
meta,dgl,1,796,40.5776,0.5795

 F1-mic 0.5797,  F1-mac 0.2771
new best val f1: 0.5796736261099112
meta,dgl,1,797,40.6283,0.5797

 F1-mic 0.5798,  F1-mac 0.2772
new best val f1: 0.5798056155507559
meta,dgl,1,798,40.6788,0.5798

 F1-mic 0.5799,  F1-mac 0.2773
new best val f1: 0.5799256059515239
meta,dgl,1,799,40.7292,0.5799

epoch:801/50, Iteration 32/32:training loss 1.3158092498779297
Train F1-mic 0.5803, Train F1-mac 0.2787
 F1-mic 0.5802,  F1-mac 0.2775
new best val f1: 0.580153587712983
meta,dgl,1,800,40.7797,0.5802

 F1-mic 0.5803,  F1-mac 0.2777
new best val f1: 0.5802915766738661
meta,dgl,1,801,40.8303,0.5803

 F1-mic 0.5805,  F1-mac 0.2779
new best val f1: 0.5804895608351331
meta,dgl,1,802,40.8808,0.5805

 F1-mic 0.5807,  F1-mac 0.2781
new best val f1: 0.5806635469162467
meta,dgl,1,803,40.9315,0.5807

 F1-mic 0.5807,  F1-mac 0.2782
new best val f1: 0.5807415406767459
meta,dgl,1,804,40.9820,0.5807

 F1-mic 0.5809,  F1-mac 0.2784
new best val f1: 0.580909527237821
meta,dgl,1,805,41.0325,0.5809

 F1-mic 0.5811,  F1-mac 0.2785
new best val f1: 0.5810655147588193
meta,dgl,1,806,41.0831,0.5811

 F1-mic 0.5813,  F1-mac 0.2788
new best val f1: 0.5812514998800096
meta,dgl,1,807,41.1334,0.5813

 F1-mic 0.5814,  F1-mac 0.2789
new best val f1: 0.5814494840412767
meta,dgl,1,808,41.1840,0.5814

 F1-mic 0.5815,  F1-mac 0.2791
new best val f1: 0.5815394768418527
meta,dgl,1,809,41.2343,0.5815

epoch:811/50, Iteration 32/32:training loss 1.311755895614624
Train F1-mic 0.5819, Train F1-mac 0.2806
 F1-mic 0.5817,  F1-mac 0.2792
new best val f1: 0.5817074634029278
meta,dgl,1,810,41.2848,0.5817

 F1-mic 0.5818,  F1-mac 0.2794
new best val f1: 0.5818334533237342
meta,dgl,1,811,41.3354,0.5818

 F1-mic 0.5820,  F1-mac 0.2795
new best val f1: 0.5819774418046556
meta,dgl,1,812,41.3857,0.5820

 F1-mic 0.5821,  F1-mac 0.2797
new best val f1: 0.5821094312455004
meta,dgl,1,813,41.4362,0.5821

 F1-mic 0.5822,  F1-mac 0.2798
new best val f1: 0.5822294216462683
meta,dgl,1,814,41.4866,0.5822

 F1-mic 0.5823,  F1-mac 0.2800
new best val f1: 0.5822954163666907
meta,dgl,1,815,41.5372,0.5823

 F1-mic 0.5824,  F1-mac 0.2801
new best val f1: 0.5824034077273819
meta,dgl,1,816,41.5877,0.5824

 F1-mic 0.5825,  F1-mac 0.2802
new best val f1: 0.5825113990880729
meta,dgl,1,817,41.6380,0.5825

 F1-mic 0.5827,  F1-mac 0.2805
new best val f1: 0.5827453803695705
meta,dgl,1,818,41.6893,0.5827

 F1-mic 0.5829,  F1-mac 0.2806
new best val f1: 0.5828833693304536
meta,dgl,1,819,41.7399,0.5829

epoch:821/50, Iteration 32/32:training loss 1.3077154159545898
Train F1-mic 0.5834, Train F1-mac 0.2822
 F1-mic 0.5831,  F1-mac 0.2808
new best val f1: 0.5830933525317975
meta,dgl,1,820,41.7902,0.5831

 F1-mic 0.5832,  F1-mac 0.2810
new best val f1: 0.5832433405327574
meta,dgl,1,821,41.8408,0.5832

 F1-mic 0.5833,  F1-mac 0.2811
new best val f1: 0.583297336213103
meta,dgl,1,822,41.8913,0.5833

 F1-mic 0.5834,  F1-mac 0.2812
new best val f1: 0.5833933285337173
meta,dgl,1,823,41.9418,0.5834

 F1-mic 0.5836,  F1-mac 0.2814
new best val f1: 0.5835913126949844
meta,dgl,1,824,41.9924,0.5836

 F1-mic 0.5837,  F1-mac 0.2815
new best val f1: 0.5837173026157907
meta,dgl,1,825,42.0428,0.5837

 F1-mic 0.5839,  F1-mac 0.2816
new best val f1: 0.583873290136789
meta,dgl,1,826,42.0934,0.5839

 F1-mic 0.5839,  F1-mac 0.2818
new best val f1: 0.5839452843772498
meta,dgl,1,827,42.1440,0.5839

 F1-mic 0.5841,  F1-mac 0.2820
new best val f1: 0.5840952723782098
meta,dgl,1,828,42.1945,0.5841

 F1-mic 0.5844,  F1-mac 0.2823
new best val f1: 0.584371250299976
meta,dgl,1,829,42.2450,0.5844

epoch:831/50, Iteration 32/32:training loss 1.3036913871765137
Train F1-mic 0.5848, Train F1-mac 0.2838
 F1-mic 0.5846,  F1-mac 0.2825
new best val f1: 0.5846112311015119
meta,dgl,1,830,42.2955,0.5846

 F1-mic 0.5847,  F1-mac 0.2825
new best val f1: 0.5847312215022799
meta,dgl,1,831,42.3464,0.5847

 F1-mic 0.5848,  F1-mac 0.2827
new best val f1: 0.5848212143028557
meta,dgl,1,832,42.3969,0.5848

 F1-mic 0.5849,  F1-mac 0.2829
new best val f1: 0.5849052075833934
meta,dgl,1,833,42.4474,0.5849

 F1-mic 0.5851,  F1-mac 0.2831
new best val f1: 0.5851331893448524
meta,dgl,1,834,42.4978,0.5851

 F1-mic 0.5853,  F1-mac 0.2833
new best val f1: 0.5853491720662347
meta,dgl,1,835,42.5483,0.5853

 F1-mic 0.5855,  F1-mac 0.2835
new best val f1: 0.5854691624670026
meta,dgl,1,836,42.5989,0.5855

 F1-mic 0.5855,  F1-mac 0.2836
new best val f1: 0.5855231581473482
meta,dgl,1,837,42.6502,0.5855

 F1-mic 0.5857,  F1-mac 0.2837
new best val f1: 0.5856551475881929
meta,dgl,1,838,42.7009,0.5857

 F1-mic 0.5859,  F1-mac 0.2840
new best val f1: 0.5858891288696905
meta,dgl,1,839,42.7514,0.5859

epoch:841/50, Iteration 32/32:training loss 1.299678921699524
Train F1-mic 0.5862, Train F1-mac 0.2853
 F1-mic 0.5861,  F1-mac 0.2842
new best val f1: 0.5861051115910727
meta,dgl,1,840,42.8019,0.5861

 F1-mic 0.5863,  F1-mac 0.2844
new best val f1: 0.5862970962323014
meta,dgl,1,841,42.8523,0.5863

 F1-mic 0.5865,  F1-mac 0.2846
new best val f1: 0.5864530837532997
meta,dgl,1,842,42.9029,0.5865

 F1-mic 0.5865,  F1-mac 0.2847
new best val f1: 0.5864710823134149
meta,dgl,1,843,42.9534,0.5865

 F1-mic 0.5866,  F1-mac 0.2849
new best val f1: 0.5866450683945285
meta,dgl,1,844,43.0039,0.5866

 F1-mic 0.5868,  F1-mac 0.2850
new best val f1: 0.5868370530357572
meta,dgl,1,845,43.0544,0.5868

 F1-mic 0.5869,  F1-mac 0.2851
new best val f1: 0.5869210463162947
meta,dgl,1,846,43.1048,0.5869

 F1-mic 0.5870,  F1-mac 0.2853
new best val f1: 0.5870410367170626
meta,dgl,1,847,43.1553,0.5870

 F1-mic 0.5871,  F1-mac 0.2854
new best val f1: 0.5871190304775618
meta,dgl,1,848,43.2058,0.5871

 F1-mic 0.5871,  F1-mac 0.2855
new best val f1: 0.5871490280777538
meta,dgl,1,849,43.2564,0.5871

epoch:851/50, Iteration 32/32:training loss 1.2956773042678833
Train F1-mic 0.5876, Train F1-mac 0.2868
 F1-mic 0.5873,  F1-mac 0.2857
new best val f1: 0.5873410127189825
meta,dgl,1,850,43.3067,0.5873

 F1-mic 0.5875,  F1-mac 0.2859
new best val f1: 0.587544996400288
meta,dgl,1,851,43.3572,0.5875

 F1-mic 0.5877,  F1-mac 0.2860
new best val f1: 0.5876529877609791
meta,dgl,1,852,43.4077,0.5877

 F1-mic 0.5878,  F1-mac 0.2861
new best val f1: 0.5877609791216702
meta,dgl,1,853,43.4589,0.5878

 F1-mic 0.5879,  F1-mac 0.2862
new best val f1: 0.5878509719222462
meta,dgl,1,854,43.5093,0.5879

 F1-mic 0.5879,  F1-mac 0.2863
new best val f1: 0.587922966162707
meta,dgl,1,855,43.5597,0.5879

 F1-mic 0.5882,  F1-mac 0.2866
new best val f1: 0.5882469402447804
meta,dgl,1,856,43.6102,0.5882

 F1-mic 0.5883,  F1-mac 0.2867
new best val f1: 0.5883249340052796
meta,dgl,1,857,43.6608,0.5883

 F1-mic 0.5883,  F1-mac 0.2868
new best val f1: 0.5883489320854332
meta,dgl,1,858,43.7113,0.5883

 F1-mic 0.5886,  F1-mac 0.2871
new best val f1: 0.5885529157667386
meta,dgl,1,859,43.7619,0.5886

epoch:861/50, Iteration 32/32:training loss 1.2916842699050903
Train F1-mic 0.5890, Train F1-mac 0.2885
 F1-mic 0.5887,  F1-mac 0.2873
new best val f1: 0.5886849052075834
meta,dgl,1,860,43.8124,0.5887

 F1-mic 0.5888,  F1-mac 0.2873
new best val f1: 0.5887748980081593
meta,dgl,1,861,43.8630,0.5888

 F1-mic 0.5889,  F1-mac 0.2875
new best val f1: 0.5888888888888889
meta,dgl,1,862,43.9136,0.5889

 F1-mic 0.5891,  F1-mac 0.2877
new best val f1: 0.589056875449964
meta,dgl,1,863,43.9641,0.5891

 F1-mic 0.5892,  F1-mac 0.2879
new best val f1: 0.5892428605711543
meta,dgl,1,864,44.0145,0.5892

 F1-mic 0.5893,  F1-mac 0.2879
new best val f1: 0.5892608591312695
meta,dgl,1,865,44.0653,0.5893

 F1-mic 0.5894,  F1-mac 0.2881
new best val f1: 0.5894468442524599
meta,dgl,1,866,44.1159,0.5894

 F1-mic 0.5897,  F1-mac 0.2883
new best val f1: 0.5896748260139189
meta,dgl,1,867,44.1664,0.5897

 F1-mic 0.5898,  F1-mac 0.2884
new best val f1: 0.5897588192944564
meta,dgl,1,868,44.2168,0.5898

 F1-mic 0.5899,  F1-mac 0.2886
new best val f1: 0.5898788096952244
meta,dgl,1,869,44.2672,0.5899

epoch:871/50, Iteration 32/32:training loss 1.2877029180526733
Train F1-mic 0.5904, Train F1-mac 0.2901
 F1-mic 0.5900,  F1-mac 0.2887
new best val f1: 0.5899928005759539
meta,dgl,1,870,44.3176,0.5900

 F1-mic 0.5901,  F1-mac 0.2889
new best val f1: 0.5901187904967603
meta,dgl,1,871,44.3681,0.5901

 F1-mic 0.5903,  F1-mac 0.2890
new best val f1: 0.5903107751379889
meta,dgl,1,872,44.4187,0.5903

 F1-mic 0.5904,  F1-mac 0.2892
new best val f1: 0.5904367650587953
meta,dgl,1,873,44.4693,0.5904

 F1-mic 0.5905,  F1-mac 0.2893
new best val f1: 0.5904787616990641
meta,dgl,1,874,44.5198,0.5905

 F1-mic 0.5906,  F1-mac 0.2894
new best val f1: 0.590598752099832
meta,dgl,1,875,44.5704,0.5906

 F1-mic 0.5908,  F1-mac 0.2896
new best val f1: 0.5907607391408687
meta,dgl,1,876,44.6209,0.5908

 F1-mic 0.5908,  F1-mac 0.2897
new best val f1: 0.5908267338612911
meta,dgl,1,877,44.6715,0.5908

 F1-mic 0.5911,  F1-mac 0.2899
new best val f1: 0.591096712263019
meta,dgl,1,878,44.7221,0.5911

 F1-mic 0.5913,  F1-mac 0.2901
new best val f1: 0.591264698824094
meta,dgl,1,879,44.7726,0.5913

epoch:881/50, Iteration 32/32:training loss 1.2837367057800293
Train F1-mic 0.5918, Train F1-mac 0.2916
 F1-mic 0.5914,  F1-mac 0.2903
new best val f1: 0.59135469162467
meta,dgl,1,880,44.8231,0.5914

 F1-mic 0.5915,  F1-mac 0.2904
new best val f1: 0.5914686825053995
meta,dgl,1,881,44.8736,0.5915

 F1-mic 0.5916,  F1-mac 0.2906
new best val f1: 0.5916306695464363
meta,dgl,1,882,44.9241,0.5916

 F1-mic 0.5918,  F1-mac 0.2908
new best val f1: 0.5917866570674346
meta,dgl,1,883,44.9747,0.5918

 F1-mic 0.5919,  F1-mac 0.2909
new best val f1: 0.5918706503479721
meta,dgl,1,884,45.0255,0.5919

 F1-mic 0.5921,  F1-mac 0.2912
new best val f1: 0.5920626349892009
meta,dgl,1,885,45.0765,0.5921

 F1-mic 0.5922,  F1-mac 0.2913
new best val f1: 0.5922066234701224
meta,dgl,1,886,45.1271,0.5922

 F1-mic 0.5924,  F1-mac 0.2914
new best val f1: 0.5923866090712743
meta,dgl,1,887,45.1776,0.5924

 F1-mic 0.5925,  F1-mac 0.2916
new best val f1: 0.5925245980321574
meta,dgl,1,888,45.2280,0.5925

 F1-mic 0.5926,  F1-mac 0.2917
new best val f1: 0.5926025917926566
meta,dgl,1,889,45.2786,0.5926

epoch:891/50, Iteration 32/32:training loss 1.2797759771347046
Train F1-mic 0.5930, Train F1-mac 0.2931
 F1-mic 0.5927,  F1-mac 0.2919
new best val f1: 0.5927345812335013
meta,dgl,1,890,45.3294,0.5927

 F1-mic 0.5929,  F1-mac 0.2921
new best val f1: 0.59292656587473
meta,dgl,1,891,45.3800,0.5929

 F1-mic 0.5930,  F1-mac 0.2922
new best val f1: 0.5930225581953443
meta,dgl,1,892,45.4305,0.5930

 F1-mic 0.5931,  F1-mac 0.2923
new best val f1: 0.5931305495560355
meta,dgl,1,893,45.4810,0.5931

 F1-mic 0.5933,  F1-mac 0.2925
new best val f1: 0.5932565394768419
meta,dgl,1,894,45.5315,0.5933

 F1-mic 0.5934,  F1-mac 0.2926
new best val f1: 0.5933825293976482
meta,dgl,1,895,45.5825,0.5934

 F1-mic 0.5935,  F1-mac 0.2927
new best val f1: 0.5935445164386849
meta,dgl,1,896,45.6332,0.5935

 F1-mic 0.5937,  F1-mac 0.2928
new best val f1: 0.5936585073194145
meta,dgl,1,897,45.6837,0.5937

 F1-mic 0.5937,  F1-mac 0.2929
new best val f1: 0.5937365010799136
meta,dgl,1,898,45.7343,0.5937

 F1-mic 0.5938,  F1-mac 0.2930
new best val f1: 0.5938264938804896
meta,dgl,1,899,45.7849,0.5938

epoch:901/50, Iteration 32/32:training loss 1.2758249044418335
Train F1-mic 0.5942, Train F1-mac 0.2943
 F1-mic 0.5939,  F1-mac 0.2931
new best val f1: 0.5939464842812575
meta,dgl,1,900,45.8354,0.5939

 F1-mic 0.5940,  F1-mac 0.2933
new best val f1: 0.5940364770818335
meta,dgl,1,901,45.8858,0.5940

 F1-mic 0.5941,  F1-mac 0.2934
new best val f1: 0.5941144708423326
meta,dgl,1,902,45.9364,0.5941

 F1-mic 0.5943,  F1-mac 0.2935
new best val f1: 0.5942884569234461
meta,dgl,1,903,45.9870,0.5943

 F1-mic 0.5944,  F1-mac 0.2936
new best val f1: 0.5943964482841373
meta,dgl,1,904,46.0375,0.5944

 F1-mic 0.5946,  F1-mac 0.2938
new best val f1: 0.5945644348452124
meta,dgl,1,905,46.0884,0.5946

 F1-mic 0.5946,  F1-mac 0.2938
new best val f1: 0.5946484281257499
meta,dgl,1,906,46.1389,0.5946

 F1-mic 0.5948,  F1-mac 0.2940
new best val f1: 0.5948104151667867
meta,dgl,1,907,46.1894,0.5948

 F1-mic 0.5950,  F1-mac 0.2942
new best val f1: 0.594996400287977
meta,dgl,1,908,46.2398,0.5950

 F1-mic 0.5951,  F1-mac 0.2944
new best val f1: 0.5951403887688985
meta,dgl,1,909,46.2903,0.5951

epoch:911/50, Iteration 32/32:training loss 1.2718801498413086
Train F1-mic 0.5956, Train F1-mac 0.2959
 F1-mic 0.5953,  F1-mac 0.2945
new best val f1: 0.5952603791696665
meta,dgl,1,910,46.3408,0.5953

 F1-mic 0.5955,  F1-mac 0.2947
new best val f1: 0.5954703623710104
meta,dgl,1,911,46.3913,0.5955

 F1-mic 0.5956,  F1-mac 0.2950
new best val f1: 0.5956443484521239
meta,dgl,1,912,46.4416,0.5956

 F1-mic 0.5958,  F1-mac 0.2952
new best val f1: 0.5958363330933525
meta,dgl,1,913,46.4922,0.5958

 F1-mic 0.5960,  F1-mac 0.2954
new best val f1: 0.5960043196544277
meta,dgl,1,914,46.5429,0.5960

 F1-mic 0.5961,  F1-mac 0.2955
new best val f1: 0.5960643148548116
meta,dgl,1,915,46.5933,0.5961

 F1-mic 0.5962,  F1-mac 0.2956
new best val f1: 0.5962263018958484
meta,dgl,1,916,46.6438,0.5962

 F1-mic 0.5964,  F1-mac 0.2958
new best val f1: 0.5964122870170386
meta,dgl,1,917,46.6945,0.5964

 F1-mic 0.5965,  F1-mac 0.2958
new best val f1: 0.5964962802975762
meta,dgl,1,918,46.7450,0.5965

 F1-mic 0.5966,  F1-mac 0.2960
new best val f1: 0.5966462682985361
meta,dgl,1,919,46.7954,0.5966

epoch:921/50, Iteration 32/32:training loss 1.2679487466812134
Train F1-mic 0.5970, Train F1-mac 0.2974
 F1-mic 0.5967,  F1-mac 0.2961
new best val f1: 0.5967302615790737
meta,dgl,1,920,46.8459,0.5967

 F1-mic 0.5968,  F1-mac 0.2962
new best val f1: 0.5968202543796496
meta,dgl,1,921,46.8962,0.5968

 F1-mic 0.5970,  F1-mac 0.2964
new best val f1: 0.5970002399808015
meta,dgl,1,922,46.9468,0.5970

 F1-mic 0.5971,  F1-mac 0.2965
new best val f1: 0.5970722342212623
meta,dgl,1,923,46.9973,0.5971

 F1-mic 0.5972,  F1-mac 0.2967
new best val f1: 0.5971862251019918
meta,dgl,1,924,47.0476,0.5972

 F1-mic 0.5973,  F1-mac 0.2968
new best val f1: 0.5972882169426446
meta,dgl,1,925,47.0981,0.5973

 F1-mic 0.5975,  F1-mac 0.2969
new best val f1: 0.597474202063835
meta,dgl,1,926,47.1487,0.5975

 F1-mic 0.5975,  F1-mac 0.2970
new best val f1: 0.5975461963042956
meta,dgl,1,927,47.1990,0.5975

 F1-mic 0.5977,  F1-mac 0.2971
new best val f1: 0.597672186225102
meta,dgl,1,928,47.2494,0.5977

 F1-mic 0.5978,  F1-mac 0.2973
new best val f1: 0.5978341732661387
meta,dgl,1,929,47.2998,0.5978

epoch:931/50, Iteration 32/32:training loss 1.264027714729309
Train F1-mic 0.5983, Train F1-mac 0.2991
 F1-mic 0.5979,  F1-mac 0.2975
new best val f1: 0.5979421646268298
meta,dgl,1,930,47.3503,0.5979

 F1-mic 0.5981,  F1-mac 0.2976
new best val f1: 0.5980561555075594
meta,dgl,1,931,47.4008,0.5981

 F1-mic 0.5982,  F1-mac 0.2978
new best val f1: 0.5981701463882889
meta,dgl,1,932,47.4513,0.5982

 F1-mic 0.5983,  F1-mac 0.2979
new best val f1: 0.5982901367890568
meta,dgl,1,933,47.5017,0.5983

 F1-mic 0.5984,  F1-mac 0.2980
new best val f1: 0.598398128149748
meta,dgl,1,934,47.5522,0.5984

 F1-mic 0.5985,  F1-mac 0.2982
new best val f1: 0.598488120950324
meta,dgl,1,935,47.6027,0.5985

 F1-mic 0.5986,  F1-mac 0.2983
new best val f1: 0.5986021118310535
meta,dgl,1,936,47.6532,0.5986

 F1-mic 0.5987,  F1-mac 0.2985
new best val f1: 0.5987461003119751
meta,dgl,1,937,47.7037,0.5987

 F1-mic 0.5989,  F1-mac 0.2987
new best val f1: 0.5989080873530117
meta,dgl,1,938,47.7543,0.5989

 F1-mic 0.5990,  F1-mac 0.2987
new best val f1: 0.5990160787137029
meta,dgl,1,939,47.8047,0.5990

epoch:941/50, Iteration 32/32:training loss 1.2601141929626465
Train F1-mic 0.5994, Train F1-mac 0.3005
 F1-mic 0.5991,  F1-mac 0.2989
new best val f1: 0.5991000719942404
meta,dgl,1,940,47.8552,0.5991

 F1-mic 0.5992,  F1-mac 0.2990
new best val f1: 0.5991960643148548
meta,dgl,1,941,47.9057,0.5992

 F1-mic 0.5993,  F1-mac 0.2990
new best val f1: 0.5992800575953924
meta,dgl,1,942,47.9563,0.5993

 F1-mic 0.5993,  F1-mac 0.2991
new best val f1: 0.5993280537556995
meta,dgl,1,943,48.0068,0.5993

 F1-mic 0.5994,  F1-mac 0.2992
new best val f1: 0.5994360451163907
meta,dgl,1,944,48.0574,0.5994

 F1-mic 0.5996,  F1-mac 0.2995
new best val f1: 0.5996040316774658
meta,dgl,1,945,48.1079,0.5996

 F1-mic 0.5997,  F1-mac 0.2996
new best val f1: 0.5997480201583874
meta,dgl,1,946,48.1583,0.5997

 F1-mic 0.5999,  F1-mac 0.2997
new best val f1: 0.5998980081593472
meta,dgl,1,947,48.2088,0.5999

 F1-mic 0.6000,  F1-mac 0.2999
new best val f1: 0.5999880009599232
meta,dgl,1,948,48.2593,0.6000

 F1-mic 0.6001,  F1-mac 0.3001
new best val f1: 0.6001439884809215
meta,dgl,1,949,48.3098,0.6001

epoch:951/50, Iteration 32/32:training loss 1.2562124729156494
Train F1-mic 0.6007, Train F1-mac 0.3019
 F1-mic 0.6003,  F1-mac 0.3003
new best val f1: 0.6003359731221503
meta,dgl,1,950,48.3604,0.6003

 F1-mic 0.6004,  F1-mac 0.3004
new best val f1: 0.6003959683225342
meta,dgl,1,951,48.4116,0.6004

 F1-mic 0.6006,  F1-mac 0.3007
new best val f1: 0.6005819534437244
meta,dgl,1,952,48.4623,0.6006

 F1-mic 0.6007,  F1-mac 0.3008
new best val f1: 0.600725941924646
meta,dgl,1,953,48.5128,0.6007

 F1-mic 0.6009,  F1-mac 0.3009
new best val f1: 0.6008639308855291
meta,dgl,1,954,48.5633,0.6009

 F1-mic 0.6009,  F1-mac 0.3010
new best val f1: 0.6008999280057595
meta,dgl,1,955,48.6137,0.6009

 F1-mic 0.6011,  F1-mac 0.3013
new best val f1: 0.6010799136069115
meta,dgl,1,956,48.6641,0.6011

 F1-mic 0.6012,  F1-mac 0.3015
new best val f1: 0.6012419006479481
meta,dgl,1,957,48.7150,0.6012

 F1-mic 0.6014,  F1-mac 0.3017
new best val f1: 0.6013858891288697
meta,dgl,1,958,48.7655,0.6014

 F1-mic 0.6015,  F1-mac 0.3018
new best val f1: 0.6015178785697144
meta,dgl,1,959,48.8161,0.6015

epoch:961/50, Iteration 32/32:training loss 1.2523185014724731
Train F1-mic 0.6021, Train F1-mac 0.3035
 F1-mic 0.6017,  F1-mac 0.3021
new best val f1: 0.6017158627309815
meta,dgl,1,960,48.8666,0.6017

 F1-mic 0.6018,  F1-mac 0.3021
new best val f1: 0.6017998560115191
meta,dgl,1,961,48.9171,0.6018

 F1-mic 0.6019,  F1-mac 0.3024
new best val f1: 0.601949844012479
meta,dgl,1,962,48.9676,0.6019

 F1-mic 0.6021,  F1-mac 0.3026
new best val f1: 0.6020698344132469
meta,dgl,1,963,49.0182,0.6021

 F1-mic 0.6023,  F1-mac 0.3028
new best val f1: 0.6022558195344373
meta,dgl,1,964,49.0686,0.6023

 F1-mic 0.6024,  F1-mac 0.3029
new best val f1: 0.602387808975282
meta,dgl,1,965,49.1192,0.6024

 F1-mic 0.6025,  F1-mac 0.3030
new best val f1: 0.6025197984161267
meta,dgl,1,966,49.1698,0.6025

 F1-mic 0.6026,  F1-mac 0.3031
new best val f1: 0.6025917926565875
meta,dgl,1,967,49.2203,0.6026

 F1-mic 0.6028,  F1-mac 0.3033
new best val f1: 0.6027537796976242
meta,dgl,1,968,49.2709,0.6028

 F1-mic 0.6028,  F1-mac 0.3034
new best val f1: 0.6027837772978162
meta,dgl,1,969,49.3215,0.6028

epoch:971/50, Iteration 32/32:training loss 1.248436450958252
Train F1-mic 0.6033, Train F1-mac 0.3049
 F1-mic 0.6030,  F1-mac 0.3037
new best val f1: 0.6030297576193905
meta,dgl,1,970,49.3723,0.6030

 F1-mic 0.6031,  F1-mac 0.3038
new best val f1: 0.6031077513798896
meta,dgl,1,971,49.4228,0.6031

 F1-mic 0.6031,  F1-mac 0.3039
meta,dgl,1,972,49.4734,0.6031

 F1-mic 0.6033,  F1-mac 0.3040
new best val f1: 0.6032817374610031
meta,dgl,1,973,49.5240,0.6033

 F1-mic 0.6034,  F1-mac 0.3041
new best val f1: 0.6033777297816175
meta,dgl,1,974,49.5744,0.6034

 F1-mic 0.6035,  F1-mac 0.3042
new best val f1: 0.6034737221022318
meta,dgl,1,975,49.6252,0.6035

 F1-mic 0.6036,  F1-mac 0.3044
new best val f1: 0.6035577153827694
meta,dgl,1,976,49.6757,0.6036

 F1-mic 0.6037,  F1-mac 0.3046
new best val f1: 0.6037197024238061
meta,dgl,1,977,49.7261,0.6037

 F1-mic 0.6038,  F1-mac 0.3048
new best val f1: 0.6038456923446124
meta,dgl,1,978,49.7766,0.6038

 F1-mic 0.6039,  F1-mac 0.3050
new best val f1: 0.6039356851451884
meta,dgl,1,979,49.8269,0.6039

epoch:981/50, Iteration 32/32:training loss 1.2445626258850098
Train F1-mic 0.6044, Train F1-mac 0.3063
 F1-mic 0.6041,  F1-mac 0.3052
new best val f1: 0.6041156707463403
meta,dgl,1,980,49.8774,0.6041

 F1-mic 0.6042,  F1-mac 0.3054
new best val f1: 0.6042416606671466
meta,dgl,1,981,49.9279,0.6042

 F1-mic 0.6043,  F1-mac 0.3055
new best val f1: 0.6043316534677226
meta,dgl,1,982,49.9784,0.6043

 F1-mic 0.6045,  F1-mac 0.3057
new best val f1: 0.6044636429085674
meta,dgl,1,983,50.0290,0.6045

 F1-mic 0.6046,  F1-mac 0.3058
new best val f1: 0.6045596352291817
meta,dgl,1,984,50.0795,0.6046

 F1-mic 0.6047,  F1-mac 0.3059
new best val f1: 0.6047036237101032
meta,dgl,1,985,50.1300,0.6047

 F1-mic 0.6048,  F1-mac 0.3060
new best val f1: 0.6047936165106792
meta,dgl,1,986,50.1806,0.6048

 F1-mic 0.6049,  F1-mac 0.3062
new best val f1: 0.6048776097912167
meta,dgl,1,987,50.2311,0.6049

 F1-mic 0.6049,  F1-mac 0.3063
new best val f1: 0.6049436045116391
meta,dgl,1,988,50.2816,0.6049

 F1-mic 0.6051,  F1-mac 0.3064
new best val f1: 0.6050815934725222
meta,dgl,1,989,50.3321,0.6051

epoch:991/50, Iteration 32/32:training loss 1.240694522857666
Train F1-mic 0.6056, Train F1-mac 0.3079
 F1-mic 0.6053,  F1-mac 0.3066
new best val f1: 0.6052555795536357
meta,dgl,1,990,50.3827,0.6053

 F1-mic 0.6053,  F1-mac 0.3068
new best val f1: 0.6053095752339813
meta,dgl,1,991,50.4332,0.6053

 F1-mic 0.6054,  F1-mac 0.3068
new best val f1: 0.6053695704343652
meta,dgl,1,992,50.4838,0.6054

 F1-mic 0.6055,  F1-mac 0.3069
new best val f1: 0.605471562275018
meta,dgl,1,993,50.5343,0.6055

 F1-mic 0.6056,  F1-mac 0.3070
new best val f1: 0.605561555075594
meta,dgl,1,994,50.5848,0.6056

 F1-mic 0.6057,  F1-mac 0.3072
new best val f1: 0.6056935445164386
meta,dgl,1,995,50.6354,0.6057

 F1-mic 0.6058,  F1-mac 0.3073
new best val f1: 0.605789536837053
meta,dgl,1,996,50.6859,0.6058

 F1-mic 0.6059,  F1-mac 0.3074
new best val f1: 0.6058915286777058
meta,dgl,1,997,50.7365,0.6059

 F1-mic 0.6060,  F1-mac 0.3076
new best val f1: 0.6060115190784737
meta,dgl,1,998,50.7870,0.6060

 F1-mic 0.6061,  F1-mac 0.3078
new best val f1: 0.6060895128389728
meta,dgl,1,999,50.8375,0.6061

epoch:1001/50, Iteration 32/32:training loss 1.2368404865264893
Train F1-mic 0.6066, Train F1-mac 0.3094
 F1-mic 0.6062,  F1-mac 0.3079
new best val f1: 0.6061855051595872
meta,dgl,1,1000,50.8881,0.6062

 F1-mic 0.6063,  F1-mac 0.3080
new best val f1: 0.60628749700024
meta,dgl,1,1001,50.9387,0.6063

 F1-mic 0.6064,  F1-mac 0.3082
new best val f1: 0.6063834893208543
meta,dgl,1,1002,50.9892,0.6064

 F1-mic 0.6065,  F1-mac 0.3083
new best val f1: 0.6064734821214303
meta,dgl,1,1003,51.0400,0.6065

 F1-mic 0.6066,  F1-mac 0.3084
new best val f1: 0.6065634749220062
meta,dgl,1,1004,51.0906,0.6066

 F1-mic 0.6067,  F1-mac 0.3085
new best val f1: 0.6067014638828894
meta,dgl,1,1005,51.1411,0.6067

 F1-mic 0.6068,  F1-mac 0.3086
new best val f1: 0.6068274538036957
meta,dgl,1,1006,51.1916,0.6068

 F1-mic 0.6070,  F1-mac 0.3088
new best val f1: 0.607013438924886
meta,dgl,1,1007,51.2421,0.6070

 F1-mic 0.6071,  F1-mac 0.3089
new best val f1: 0.6070794336453084
meta,dgl,1,1008,51.2926,0.6071

 F1-mic 0.6071,  F1-mac 0.3090
new best val f1: 0.6071394288456924
meta,dgl,1,1009,51.3433,0.6071

epoch:1011/50, Iteration 32/32:training loss 1.2330045700073242
Train F1-mic 0.6076, Train F1-mac 0.3107
 F1-mic 0.6073,  F1-mac 0.3093
new best val f1: 0.6072954163666907
meta,dgl,1,1010,51.3938,0.6073

 F1-mic 0.6075,  F1-mac 0.3094
new best val f1: 0.6074694024478042
meta,dgl,1,1011,51.4441,0.6075

 F1-mic 0.6076,  F1-mac 0.3096
new best val f1: 0.6075653947684185
meta,dgl,1,1012,51.4945,0.6076

 F1-mic 0.6077,  F1-mac 0.3097
new best val f1: 0.6076553875689945
meta,dgl,1,1013,51.5448,0.6077

 F1-mic 0.6078,  F1-mac 0.3099
new best val f1: 0.6077813774898008
meta,dgl,1,1014,51.5952,0.6078

 F1-mic 0.6079,  F1-mac 0.3101
new best val f1: 0.6079373650107991
meta,dgl,1,1015,51.6464,0.6079

 F1-mic 0.6080,  F1-mac 0.3102
new best val f1: 0.6080033597312215
meta,dgl,1,1016,51.6967,0.6080

 F1-mic 0.6081,  F1-mac 0.3103
new best val f1: 0.6080633549316055
meta,dgl,1,1017,51.7471,0.6081

 F1-mic 0.6083,  F1-mac 0.3105
new best val f1: 0.6082553395728342
meta,dgl,1,1018,51.7976,0.6083

 F1-mic 0.6083,  F1-mac 0.3106
new best val f1: 0.6083033357331413
meta,dgl,1,1019,51.8485,0.6083

epoch:1021/50, Iteration 32/32:training loss 1.2291889190673828
Train F1-mic 0.6088, Train F1-mac 0.3122
 F1-mic 0.6083,  F1-mac 0.3106
meta,dgl,1,1020,51.8991,0.6083

 F1-mic 0.6084,  F1-mac 0.3108
new best val f1: 0.6084353251739861
meta,dgl,1,1021,51.9496,0.6084

 F1-mic 0.6086,  F1-mac 0.3111
new best val f1: 0.6086453083753299
meta,dgl,1,1022,52.0002,0.6086

 F1-mic 0.6087,  F1-mac 0.3111
new best val f1: 0.6086693064554836
meta,dgl,1,1023,52.0507,0.6087

 F1-mic 0.6088,  F1-mac 0.3113
new best val f1: 0.6088132949364051
meta,dgl,1,1024,52.1011,0.6088

 F1-mic 0.6088,  F1-mac 0.3114
meta,dgl,1,1025,52.1515,0.6088

 F1-mic 0.6090,  F1-mac 0.3117
new best val f1: 0.608963282937365
meta,dgl,1,1026,52.2021,0.6090

 F1-mic 0.6092,  F1-mac 0.3120
new best val f1: 0.6091792656587472
meta,dgl,1,1027,52.2524,0.6092

 F1-mic 0.6092,  F1-mac 0.3119
new best val f1: 0.6091912646988241
meta,dgl,1,1028,52.3028,0.6092

 F1-mic 0.6093,  F1-mac 0.3121
new best val f1: 0.6093352531797456
meta,dgl,1,1029,52.3533,0.6093

epoch:1031/50, Iteration 32/32:training loss 1.225396752357483
Train F1-mic 0.6098, Train F1-mac 0.3136
 F1-mic 0.6095,  F1-mac 0.3123
new best val f1: 0.6094792416606671
meta,dgl,1,1030,52.4037,0.6095

 F1-mic 0.6096,  F1-mac 0.3126
new best val f1: 0.6095572354211664
meta,dgl,1,1031,52.4543,0.6096

 F1-mic 0.6096,  F1-mac 0.3128
new best val f1: 0.6096172306215503
meta,dgl,1,1032,52.5047,0.6096

 F1-mic 0.6098,  F1-mac 0.3129
new best val f1: 0.6097612191024718
meta,dgl,1,1033,52.5552,0.6098

 F1-mic 0.6099,  F1-mac 0.3130
new best val f1: 0.6098692104631629
meta,dgl,1,1034,52.6057,0.6099

 F1-mic 0.6100,  F1-mac 0.3132
new best val f1: 0.6099952003839693
meta,dgl,1,1035,52.6562,0.6100

 F1-mic 0.6101,  F1-mac 0.3133
new best val f1: 0.6100851931845452
meta,dgl,1,1036,52.7066,0.6101

 F1-mic 0.6101,  F1-mac 0.3134
new best val f1: 0.6101391888648908
meta,dgl,1,1037,52.7570,0.6101

 F1-mic 0.6103,  F1-mac 0.3136
new best val f1: 0.6102591792656588
meta,dgl,1,1038,52.8078,0.6103

 F1-mic 0.6104,  F1-mac 0.3137
new best val f1: 0.6103971682265419
meta,dgl,1,1039,52.8583,0.6104

epoch:1041/50, Iteration 32/32:training loss 1.221624493598938
Train F1-mic 0.6108, Train F1-mac 0.3151
 F1-mic 0.6105,  F1-mac 0.3139
new best val f1: 0.6104871610271179
meta,dgl,1,1040,52.9086,0.6105

 F1-mic 0.6106,  F1-mac 0.3141
new best val f1: 0.6105951523878089
meta,dgl,1,1041,52.9597,0.6106

 F1-mic 0.6108,  F1-mac 0.3144
new best val f1: 0.6107871370290376
meta,dgl,1,1042,53.0101,0.6108

 F1-mic 0.6109,  F1-mac 0.3145
new best val f1: 0.6108951283897288
meta,dgl,1,1043,53.0606,0.6109

 F1-mic 0.6109,  F1-mac 0.3146
new best val f1: 0.6109191264698824
meta,dgl,1,1044,53.1112,0.6109

 F1-mic 0.6111,  F1-mac 0.3147
new best val f1: 0.6110511159107271
meta,dgl,1,1045,53.1616,0.6111

 F1-mic 0.6113,  F1-mac 0.3150
new best val f1: 0.6112550995920326
meta,dgl,1,1046,53.2126,0.6113

 F1-mic 0.6113,  F1-mac 0.3151
new best val f1: 0.6113150947924166
meta,dgl,1,1047,53.2631,0.6113

 F1-mic 0.6113,  F1-mac 0.3152
new best val f1: 0.6113450923926086
meta,dgl,1,1048,53.3183,0.6113

 F1-mic 0.6115,  F1-mac 0.3154
new best val f1: 0.6115370770338373
meta,dgl,1,1049,53.3688,0.6115

epoch:1051/50, Iteration 32/32:training loss 1.2178736925125122
Train F1-mic 0.6118, Train F1-mac 0.3165
 F1-mic 0.6117,  F1-mac 0.3156
new best val f1: 0.6117110631149508
meta,dgl,1,1050,53.4193,0.6117

 F1-mic 0.6117,  F1-mac 0.3157
meta,dgl,1,1051,53.4698,0.6117

 F1-mic 0.6118,  F1-mac 0.3158
new best val f1: 0.6117770578353732
meta,dgl,1,1052,53.5203,0.6118

 F1-mic 0.6120,  F1-mac 0.3161
new best val f1: 0.6119930405567554
meta,dgl,1,1053,53.5708,0.6120

 F1-mic 0.6120,  F1-mac 0.3161
new best val f1: 0.6120350371970242
meta,dgl,1,1054,53.6211,0.6120

 F1-mic 0.6121,  F1-mac 0.3163
new best val f1: 0.6121250299976002
meta,dgl,1,1055,53.6716,0.6121

 F1-mic 0.6123,  F1-mac 0.3164
new best val f1: 0.6122570194384449
meta,dgl,1,1056,53.7221,0.6123

 F1-mic 0.6124,  F1-mac 0.3166
new best val f1: 0.6124010079193665
meta,dgl,1,1057,53.7726,0.6124

 F1-mic 0.6125,  F1-mac 0.3167
new best val f1: 0.6124610031197504
meta,dgl,1,1058,53.8230,0.6125

 F1-mic 0.6126,  F1-mac 0.3168
new best val f1: 0.6125509959203264
meta,dgl,1,1059,53.8735,0.6126

epoch:1061/50, Iteration 32/32:training loss 1.214139461517334
Train F1-mic 0.6128, Train F1-mac 0.3179
 F1-mic 0.6127,  F1-mac 0.3170
new best val f1: 0.6127429805615551
meta,dgl,1,1060,53.9241,0.6127

 F1-mic 0.6128,  F1-mac 0.3172
new best val f1: 0.6128389728821694
meta,dgl,1,1061,53.9746,0.6128

 F1-mic 0.6129,  F1-mac 0.3173
new best val f1: 0.6128869690424766
meta,dgl,1,1062,54.0254,0.6129

 F1-mic 0.6131,  F1-mac 0.3175
new best val f1: 0.6130729541636669
meta,dgl,1,1063,54.0759,0.6131

 F1-mic 0.6132,  F1-mac 0.3178
new best val f1: 0.613150947924166
meta,dgl,1,1064,54.1263,0.6132

 F1-mic 0.6133,  F1-mac 0.3179
new best val f1: 0.6132889368850492
meta,dgl,1,1065,54.1768,0.6133

 F1-mic 0.6134,  F1-mac 0.3181
new best val f1: 0.6133549316054716
meta,dgl,1,1066,54.2271,0.6134

 F1-mic 0.6135,  F1-mac 0.3183
new best val f1: 0.6134809215262779
meta,dgl,1,1067,54.2783,0.6135

 F1-mic 0.6136,  F1-mac 0.3184
new best val f1: 0.6135709143268538
meta,dgl,1,1068,54.3287,0.6136

 F1-mic 0.6136,  F1-mac 0.3186
new best val f1: 0.6136489080873531
meta,dgl,1,1069,54.3791,0.6136

epoch:1071/50, Iteration 32/32:training loss 1.2104226350784302
Train F1-mic 0.6138, Train F1-mac 0.3195
 F1-mic 0.6139,  F1-mac 0.3189
new best val f1: 0.6138528917686585
meta,dgl,1,1070,54.4328,0.6139

 F1-mic 0.6139,  F1-mac 0.3191
new best val f1: 0.6139308855291576
meta,dgl,1,1071,54.4831,0.6139

 F1-mic 0.6140,  F1-mac 0.3192
new best val f1: 0.6140028797696184
meta,dgl,1,1072,54.5336,0.6140

 F1-mic 0.6141,  F1-mac 0.3194
new best val f1: 0.6140808735301176
meta,dgl,1,1073,54.5842,0.6141

 F1-mic 0.6142,  F1-mac 0.3195
new best val f1: 0.6142428605711543
meta,dgl,1,1074,54.6347,0.6142

 F1-mic 0.6143,  F1-mac 0.3196
new best val f1: 0.6143268538516918
meta,dgl,1,1075,54.6852,0.6143

 F1-mic 0.6145,  F1-mac 0.3200
new best val f1: 0.6144708423326134
meta,dgl,1,1076,54.7358,0.6145

 F1-mic 0.6145,  F1-mac 0.3200
new best val f1: 0.6145068394528438
meta,dgl,1,1077,54.7863,0.6145

 F1-mic 0.6147,  F1-mac 0.3203
new best val f1: 0.6146508279337654
meta,dgl,1,1078,54.8369,0.6147

 F1-mic 0.6148,  F1-mac 0.3205
new best val f1: 0.6147648188144949
meta,dgl,1,1079,54.8873,0.6148

epoch:1081/50, Iteration 32/32:training loss 1.206725001335144
Train F1-mic 0.6150, Train F1-mac 0.3212
 F1-mic 0.6149,  F1-mac 0.3206
new best val f1: 0.6148608111351092
meta,dgl,1,1080,54.9377,0.6149

 F1-mic 0.6150,  F1-mac 0.3208
new best val f1: 0.6149748020158388
meta,dgl,1,1081,54.9884,0.6150

 F1-mic 0.6151,  F1-mac 0.3209
new best val f1: 0.6150767938564915
meta,dgl,1,1082,55.0387,0.6151

 F1-mic 0.6152,  F1-mac 0.3210
new best val f1: 0.6151547876169906
meta,dgl,1,1083,55.0891,0.6152

 F1-mic 0.6152,  F1-mac 0.3211
new best val f1: 0.615220782337413
meta,dgl,1,1084,55.1395,0.6152

 F1-mic 0.6153,  F1-mac 0.3212
new best val f1: 0.6153287736981041
meta,dgl,1,1085,55.1900,0.6153

 F1-mic 0.6154,  F1-mac 0.3213
new best val f1: 0.6154067674586033
meta,dgl,1,1086,55.2411,0.6154

 F1-mic 0.6156,  F1-mac 0.3217
new best val f1: 0.6155627549796017
meta,dgl,1,1087,55.2916,0.6156

 F1-mic 0.6156,  F1-mac 0.3218
new best val f1: 0.6156467482601392
meta,dgl,1,1088,55.3420,0.6156

 F1-mic 0.6157,  F1-mac 0.3219
new best val f1: 0.6157007439404848
meta,dgl,1,1089,55.3924,0.6157

epoch:1091/50, Iteration 32/32:training loss 1.2030491828918457
Train F1-mic 0.6159, Train F1-mac 0.3227
 F1-mic 0.6157,  F1-mac 0.3220
new best val f1: 0.615748740100792
meta,dgl,1,1090,55.4430,0.6157

 F1-mic 0.6159,  F1-mac 0.3222
new best val f1: 0.615946724262059
meta,dgl,1,1091,55.4935,0.6159

 F1-mic 0.6160,  F1-mac 0.3223
new best val f1: 0.6159887209023278
meta,dgl,1,1092,55.5441,0.6160

 F1-mic 0.6161,  F1-mac 0.3226
new best val f1: 0.6161327093832494
meta,dgl,1,1093,55.5945,0.6161

 F1-mic 0.6162,  F1-mac 0.3227
new best val f1: 0.6161747060235181
meta,dgl,1,1094,55.6449,0.6162

 F1-mic 0.6163,  F1-mac 0.3228
new best val f1: 0.6163426925845933
meta,dgl,1,1095,55.6962,0.6163

 F1-mic 0.6164,  F1-mac 0.3229
new best val f1: 0.6163666906647468
meta,dgl,1,1096,55.7468,0.6164

 F1-mic 0.6165,  F1-mac 0.3231
new best val f1: 0.6164866810655147
meta,dgl,1,1097,55.7972,0.6165

 F1-mic 0.6166,  F1-mac 0.3233
new best val f1: 0.6166246700263979
meta,dgl,1,1098,55.8476,0.6166

 F1-mic 0.6169,  F1-mac 0.3237
new best val f1: 0.6168886489080874
meta,dgl,1,1099,55.8980,0.6169

epoch:1101/50, Iteration 32/32:training loss 1.199389934539795
Train F1-mic 0.6171, Train F1-mac 0.3245
 F1-mic 0.6168,  F1-mac 0.3237
meta,dgl,1,1100,55.9485,0.6168

 F1-mic 0.6169,  F1-mac 0.3238
new best val f1: 0.6169366450683945
meta,dgl,1,1101,55.9989,0.6169

 F1-mic 0.6171,  F1-mac 0.3240
new best val f1: 0.6171226301895848
meta,dgl,1,1102,56.0494,0.6171

 F1-mic 0.6172,  F1-mac 0.3242
new best val f1: 0.6172066234701223
meta,dgl,1,1103,56.0998,0.6172

 F1-mic 0.6172,  F1-mac 0.3242
new best val f1: 0.6172486201103912
meta,dgl,1,1104,56.1502,0.6172

 F1-mic 0.6174,  F1-mac 0.3244
new best val f1: 0.6173806095512359
meta,dgl,1,1105,56.2007,0.6174

 F1-mic 0.6176,  F1-mac 0.3247
new best val f1: 0.6175905927525798
meta,dgl,1,1106,56.2513,0.6176

 F1-mic 0.6177,  F1-mac 0.3249
new best val f1: 0.6176625869930406
meta,dgl,1,1107,56.3016,0.6177

 F1-mic 0.6177,  F1-mac 0.3249
meta,dgl,1,1108,56.3520,0.6177

 F1-mic 0.6179,  F1-mac 0.3252
new best val f1: 0.6178605711543077
meta,dgl,1,1109,56.4026,0.6179

epoch:1111/50, Iteration 32/32:training loss 1.1957489252090454
Train F1-mic 0.6181, Train F1-mac 0.3259
 F1-mic 0.6179,  F1-mac 0.3252
new best val f1: 0.6179445644348452
meta,dgl,1,1110,56.4531,0.6179

 F1-mic 0.6180,  F1-mac 0.3253
new best val f1: 0.6179505639548836
meta,dgl,1,1111,56.5034,0.6180

 F1-mic 0.6181,  F1-mac 0.3254
new best val f1: 0.6181005519558436
meta,dgl,1,1112,56.5542,0.6181

 F1-mic 0.6183,  F1-mac 0.3258
new best val f1: 0.6182985361171106
meta,dgl,1,1113,56.6046,0.6183

 F1-mic 0.6184,  F1-mac 0.3259
new best val f1: 0.6183765298776098
meta,dgl,1,1114,56.6550,0.6184

 F1-mic 0.6184,  F1-mac 0.3260
new best val f1: 0.6184365250779937
meta,dgl,1,1115,56.7054,0.6184

 F1-mic 0.6186,  F1-mac 0.3263
new best val f1: 0.6186045116390688
meta,dgl,1,1116,56.7558,0.6186

 F1-mic 0.6187,  F1-mac 0.3266
new best val f1: 0.6187245020398369
meta,dgl,1,1117,56.8068,0.6187

 F1-mic 0.6187,  F1-mac 0.3266
new best val f1: 0.618742500599952
meta,dgl,1,1118,56.8573,0.6187

 F1-mic 0.6190,  F1-mac 0.3269
new best val f1: 0.6189764818814495
meta,dgl,1,1119,56.9077,0.6190

epoch:1121/50, Iteration 32/32:training loss 1.192123293876648
Train F1-mic 0.6192, Train F1-mac 0.3276
 F1-mic 0.6191,  F1-mac 0.3271
new best val f1: 0.6190964722822174
meta,dgl,1,1120,56.9581,0.6191

 F1-mic 0.6190,  F1-mac 0.3270
meta,dgl,1,1121,57.0085,0.6190

 F1-mic 0.6192,  F1-mac 0.3272
new best val f1: 0.6191684665226782
meta,dgl,1,1122,57.0590,0.6192

 F1-mic 0.6193,  F1-mac 0.3274
new best val f1: 0.6193184545236381
meta,dgl,1,1123,57.1099,0.6193

 F1-mic 0.6194,  F1-mac 0.3275
new best val f1: 0.6193724502039837
meta,dgl,1,1124,57.1604,0.6194

 F1-mic 0.6196,  F1-mac 0.3279
new best val f1: 0.619618430525558
meta,dgl,1,1125,57.2108,0.6196

 F1-mic 0.6197,  F1-mac 0.3280
new best val f1: 0.6196544276457884
meta,dgl,1,1126,57.2613,0.6197

 F1-mic 0.6197,  F1-mac 0.3280
new best val f1: 0.6196844252459803
meta,dgl,1,1127,57.3119,0.6197

 F1-mic 0.6198,  F1-mac 0.3283
new best val f1: 0.6198404127669787
meta,dgl,1,1128,57.3625,0.6198

 F1-mic 0.6199,  F1-mac 0.3285
new best val f1: 0.6199304055675546
meta,dgl,1,1129,57.4129,0.6199

epoch:1131/50, Iteration 32/32:training loss 1.1885173320770264
Train F1-mic 0.6202, Train F1-mac 0.3292
 F1-mic 0.6201,  F1-mac 0.3286
new best val f1: 0.6200923926085913
meta,dgl,1,1130,57.4632,0.6201

 F1-mic 0.6201,  F1-mac 0.3287
new best val f1: 0.6201223902087833
meta,dgl,1,1131,57.5136,0.6201

 F1-mic 0.6202,  F1-mac 0.3288
new best val f1: 0.6202123830093592
meta,dgl,1,1132,57.5640,0.6202

 F1-mic 0.6204,  F1-mac 0.3291
new best val f1: 0.6203863690904727
meta,dgl,1,1133,57.6144,0.6204

 F1-mic 0.6205,  F1-mac 0.3292
new best val f1: 0.6205183585313175
meta,dgl,1,1134,57.6648,0.6205

 F1-mic 0.6205,  F1-mac 0.3292
new best val f1: 0.6205243580513559
meta,dgl,1,1135,57.7183,0.6205

 F1-mic 0.6207,  F1-mac 0.3294
new best val f1: 0.6207043436525078
meta,dgl,1,1136,57.7687,0.6207

 F1-mic 0.6208,  F1-mac 0.3296
new best val f1: 0.6208063354931606
meta,dgl,1,1137,57.8190,0.6208

 F1-mic 0.6209,  F1-mac 0.3298
new best val f1: 0.6209023278137749
meta,dgl,1,1138,57.8694,0.6209

 F1-mic 0.6210,  F1-mac 0.3300
new best val f1: 0.6210163186945045
meta,dgl,1,1139,57.9198,0.6210

epoch:1141/50, Iteration 32/32:training loss 1.1849236488342285
Train F1-mic 0.6212, Train F1-mac 0.3307
 F1-mic 0.6212,  F1-mac 0.3302
new best val f1: 0.6211723062155028
meta,dgl,1,1140,57.9705,0.6212

 F1-mic 0.6213,  F1-mac 0.3305
new best val f1: 0.6213222942164627
meta,dgl,1,1141,58.0239,0.6213

 F1-mic 0.6214,  F1-mac 0.3306
new best val f1: 0.6214242860571154
meta,dgl,1,1142,58.0745,0.6214

 F1-mic 0.6215,  F1-mac 0.3307
new best val f1: 0.6214722822174226
meta,dgl,1,1143,58.1251,0.6215

 F1-mic 0.6216,  F1-mac 0.3309
new best val f1: 0.6215922726181905
meta,dgl,1,1144,58.1755,0.6216

 F1-mic 0.6218,  F1-mac 0.3312
new best val f1: 0.621766258699304
meta,dgl,1,1145,58.2259,0.6218

 F1-mic 0.6219,  F1-mac 0.3313
new best val f1: 0.6218622510199184
meta,dgl,1,1146,58.2765,0.6219

 F1-mic 0.6220,  F1-mac 0.3315
new best val f1: 0.6220002399808016
meta,dgl,1,1147,58.3268,0.6220

 F1-mic 0.6221,  F1-mac 0.3317
new best val f1: 0.622144228461723
meta,dgl,1,1148,58.3772,0.6221

 F1-mic 0.6222,  F1-mac 0.3319
new best val f1: 0.6221802255819534
meta,dgl,1,1149,58.4276,0.6222

epoch:1151/50, Iteration 32/32:training loss 1.1813472509384155
Train F1-mic 0.6224, Train F1-mac 0.3326
 F1-mic 0.6223,  F1-mac 0.3320
new best val f1: 0.6222582193424526
meta,dgl,1,1150,58.4782,0.6223

 F1-mic 0.6225,  F1-mac 0.3321
new best val f1: 0.6224802015838733
meta,dgl,1,1151,58.5285,0.6225

 F1-mic 0.6225,  F1-mac 0.3323
new best val f1: 0.6225461963042956
meta,dgl,1,1152,58.5790,0.6225

 F1-mic 0.6226,  F1-mac 0.3324
new best val f1: 0.6225641948644108
meta,dgl,1,1153,58.6296,0.6226

 F1-mic 0.6228,  F1-mac 0.3327
new best val f1: 0.6227741780657547
meta,dgl,1,1154,58.6801,0.6228

 F1-mic 0.6229,  F1-mac 0.3328
new best val f1: 0.6228581713462923
meta,dgl,1,1155,58.7309,0.6229

 F1-mic 0.6230,  F1-mac 0.3331
new best val f1: 0.623020158387329
meta,dgl,1,1156,58.7815,0.6230

 F1-mic 0.6230,  F1-mac 0.3332
new best val f1: 0.6230441564674826
meta,dgl,1,1157,58.8317,0.6230

 F1-mic 0.6231,  F1-mac 0.3334
new best val f1: 0.6231101511879049
meta,dgl,1,1158,58.8821,0.6231

 F1-mic 0.6233,  F1-mac 0.3337
new best val f1: 0.6233321334293257
meta,dgl,1,1159,58.9326,0.6233

epoch:1161/50, Iteration 32/32:training loss 1.177788496017456
Train F1-mic 0.6235, Train F1-mac 0.3345
 F1-mic 0.6233,  F1-mac 0.3338
new best val f1: 0.623338132949364
meta,dgl,1,1160,58.9831,0.6233

 F1-mic 0.6236,  F1-mac 0.3341
new best val f1: 0.6235661147108231
meta,dgl,1,1161,59.0336,0.6236

 F1-mic 0.6238,  F1-mac 0.3344
new best val f1: 0.6238300935925126
meta,dgl,1,1162,59.0842,0.6238

 F1-mic 0.6237,  F1-mac 0.3343
meta,dgl,1,1163,59.1347,0.6237

 F1-mic 0.6237,  F1-mac 0.3344
meta,dgl,1,1164,59.1852,0.6237

 F1-mic 0.6241,  F1-mac 0.3348
new best val f1: 0.6240820734341253
meta,dgl,1,1165,59.2359,0.6241

 F1-mic 0.6242,  F1-mac 0.3349
new best val f1: 0.624154067674586
meta,dgl,1,1166,59.2865,0.6242

 F1-mic 0.6241,  F1-mac 0.3349
meta,dgl,1,1167,59.3369,0.6241

 F1-mic 0.6243,  F1-mac 0.3352
new best val f1: 0.624334053275738
meta,dgl,1,1168,59.3874,0.6243

 F1-mic 0.6246,  F1-mac 0.3354
new best val f1: 0.6245740340772739
meta,dgl,1,1169,59.4380,0.6246

epoch:1171/50, Iteration 32/32:training loss 1.1742475032806396
Train F1-mic 0.6247, Train F1-mac 0.3362
 F1-mic 0.6244,  F1-mac 0.3353
meta,dgl,1,1170,59.4884,0.6244

 F1-mic 0.6247,  F1-mac 0.3356
new best val f1: 0.6246700263978882
meta,dgl,1,1171,59.5387,0.6247

 F1-mic 0.6249,  F1-mac 0.3360
new best val f1: 0.624940004799616
meta,dgl,1,1172,59.5893,0.6249

 F1-mic 0.6247,  F1-mac 0.3357
meta,dgl,1,1173,59.6396,0.6247

 F1-mic 0.6248,  F1-mac 0.3359
meta,dgl,1,1174,59.6899,0.6248

 F1-mic 0.6253,  F1-mac 0.3366
new best val f1: 0.6253419726421886
meta,dgl,1,1175,59.7405,0.6253

 F1-mic 0.6251,  F1-mac 0.3364
meta,dgl,1,1176,59.7911,0.6251

 F1-mic 0.6252,  F1-mac 0.3366
meta,dgl,1,1177,59.8415,0.6252

 F1-mic 0.6256,  F1-mac 0.3370
new best val f1: 0.6256479481641468
meta,dgl,1,1178,59.8919,0.6256

 F1-mic 0.6256,  F1-mac 0.3371
meta,dgl,1,1179,59.9424,0.6256

epoch:1181/50, Iteration 32/32:training loss 1.1707199811935425
Train F1-mic 0.6257, Train F1-mac 0.3378
 F1-mic 0.6255,  F1-mac 0.3369
meta,dgl,1,1180,59.9928,0.6255

 F1-mic 0.6258,  F1-mac 0.3373
new best val f1: 0.6258399328053755
meta,dgl,1,1181,60.0439,0.6258

 F1-mic 0.6260,  F1-mac 0.3376
new best val f1: 0.6259719222462203
meta,dgl,1,1182,60.0943,0.6260

 F1-mic 0.6260,  F1-mac 0.3377
meta,dgl,1,1183,60.1447,0.6260

 F1-mic 0.6262,  F1-mac 0.3379
new best val f1: 0.6261519078473722
meta,dgl,1,1184,60.1951,0.6262

 F1-mic 0.6263,  F1-mac 0.3380
new best val f1: 0.6263258939284857
meta,dgl,1,1185,60.2456,0.6263

 F1-mic 0.6263,  F1-mac 0.3381
meta,dgl,1,1186,60.2960,0.6263

 F1-mic 0.6264,  F1-mac 0.3385
new best val f1: 0.6264038876889849
meta,dgl,1,1187,60.3464,0.6264

 F1-mic 0.6266,  F1-mac 0.3386
new best val f1: 0.6266138708903288
meta,dgl,1,1188,60.3968,0.6266

 F1-mic 0.6267,  F1-mac 0.3386
new best val f1: 0.6266678665706743
meta,dgl,1,1189,60.4472,0.6267

epoch:1191/50, Iteration 32/32:training loss 1.1672136783599854
Train F1-mic 0.6269, Train F1-mac 0.3395
 F1-mic 0.6266,  F1-mac 0.3386
meta,dgl,1,1190,60.4976,0.6266

 F1-mic 0.6269,  F1-mac 0.3389
new best val f1: 0.6268538516918647
meta,dgl,1,1191,60.5481,0.6269

 F1-mic 0.6271,  F1-mac 0.3394
new best val f1: 0.6270878329733621
meta,dgl,1,1192,60.5987,0.6271

 F1-mic 0.6272,  F1-mac 0.3396
new best val f1: 0.6271538276937845
meta,dgl,1,1193,60.6525,0.6272

 F1-mic 0.6273,  F1-mac 0.3398
new best val f1: 0.6272798176145908
meta,dgl,1,1194,60.7028,0.6273

 F1-mic 0.6274,  F1-mac 0.3399
new best val f1: 0.6273698104151668
meta,dgl,1,1195,60.7535,0.6274

 F1-mic 0.6275,  F1-mac 0.3400
new best val f1: 0.6274958003359731
meta,dgl,1,1196,60.8038,0.6275

 F1-mic 0.6276,  F1-mac 0.3401
new best val f1: 0.627585793136549
meta,dgl,1,1197,60.8543,0.6276

 F1-mic 0.6275,  F1-mac 0.3402
meta,dgl,1,1198,60.9049,0.6275

 F1-mic 0.6277,  F1-mac 0.3404
new best val f1: 0.6276997840172787
meta,dgl,1,1199,60.9582,0.6277

epoch:1201/50, Iteration 32/32:training loss 1.163717269897461
Train F1-mic 0.6279, Train F1-mac 0.3411
 F1-mic 0.6278,  F1-mac 0.3404
new best val f1: 0.6278257739380849
meta,dgl,1,1200,61.0085,0.6278

 F1-mic 0.6279,  F1-mac 0.3405
new best val f1: 0.6278977681785457
meta,dgl,1,1201,61.0589,0.6279

 F1-mic 0.6279,  F1-mac 0.3406
meta,dgl,1,1202,61.1093,0.6279

 F1-mic 0.6283,  F1-mac 0.3412
new best val f1: 0.6282817374610031
meta,dgl,1,1203,61.1598,0.6283

 F1-mic 0.6283,  F1-mac 0.3412
new best val f1: 0.6282997360211183
meta,dgl,1,1204,61.2103,0.6283

 F1-mic 0.6282,  F1-mac 0.3412
meta,dgl,1,1205,61.2609,0.6282

 F1-mic 0.6286,  F1-mac 0.3416
new best val f1: 0.628551715862731
meta,dgl,1,1206,61.3112,0.6286

 F1-mic 0.6286,  F1-mac 0.3418
new best val f1: 0.6286357091432685
meta,dgl,1,1207,61.3618,0.6286

 F1-mic 0.6286,  F1-mac 0.3417
meta,dgl,1,1208,61.4122,0.6286

 F1-mic 0.6289,  F1-mac 0.3419
new best val f1: 0.6288636909047276
meta,dgl,1,1209,61.4628,0.6289

epoch:1211/50, Iteration 32/32:training loss 1.1602375507354736
Train F1-mic 0.6291, Train F1-mac 0.3428
 F1-mic 0.6289,  F1-mac 0.3421
new best val f1: 0.6289116870650348
meta,dgl,1,1210,61.5134,0.6289

 F1-mic 0.6289,  F1-mac 0.3420
meta,dgl,1,1211,61.5642,0.6289

 F1-mic 0.6292,  F1-mac 0.3424
new best val f1: 0.6291996640268779
meta,dgl,1,1212,61.6147,0.6292

 F1-mic 0.6292,  F1-mac 0.3425
new best val f1: 0.6292416606671466
meta,dgl,1,1213,61.6651,0.6292

 F1-mic 0.6292,  F1-mac 0.3426
meta,dgl,1,1214,61.7155,0.6292

 F1-mic 0.6296,  F1-mac 0.3429
new best val f1: 0.6295656347492201
meta,dgl,1,1215,61.7659,0.6296

 F1-mic 0.6297,  F1-mac 0.3430
new best val f1: 0.6296676265898729
meta,dgl,1,1216,61.8165,0.6297

 F1-mic 0.6297,  F1-mac 0.3431
meta,dgl,1,1217,61.8673,0.6297

 F1-mic 0.6298,  F1-mac 0.3434
new best val f1: 0.6298356131509479
meta,dgl,1,1218,61.9177,0.6298

 F1-mic 0.6300,  F1-mac 0.3436
new best val f1: 0.6300275977921767
meta,dgl,1,1219,61.9682,0.6300

epoch:1221/50, Iteration 32/32:training loss 1.156774878501892
Train F1-mic 0.6303, Train F1-mac 0.3446
 F1-mic 0.6300,  F1-mac 0.3436
meta,dgl,1,1220,62.0186,0.6300

 F1-mic 0.6302,  F1-mac 0.3438
new best val f1: 0.6302015838732902
meta,dgl,1,1221,62.0689,0.6302

 F1-mic 0.6304,  F1-mac 0.3443
new best val f1: 0.6304355651547876
meta,dgl,1,1222,62.1193,0.6304

 F1-mic 0.6304,  F1-mac 0.3441
meta,dgl,1,1223,62.1698,0.6304

 F1-mic 0.6305,  F1-mac 0.3443
new best val f1: 0.6305435565154788
meta,dgl,1,1224,62.2203,0.6305

 F1-mic 0.6307,  F1-mac 0.3446
new best val f1: 0.6306575473962083
meta,dgl,1,1225,62.2707,0.6307

 F1-mic 0.6308,  F1-mac 0.3447
new best val f1: 0.6307715382769379
meta,dgl,1,1226,62.3219,0.6308

 F1-mic 0.6307,  F1-mac 0.3447
meta,dgl,1,1227,62.3724,0.6307

 F1-mic 0.6310,  F1-mac 0.3451
new best val f1: 0.6310415166786657
meta,dgl,1,1228,62.4229,0.6310

 F1-mic 0.6311,  F1-mac 0.3452
new best val f1: 0.6311195104391649
meta,dgl,1,1229,62.4734,0.6311

epoch:1231/50, Iteration 32/32:training loss 1.153325080871582
Train F1-mic 0.6314, Train F1-mac 0.3462
 F1-mic 0.6310,  F1-mac 0.3451
meta,dgl,1,1230,62.5240,0.6310

 F1-mic 0.6313,  F1-mac 0.3454
new best val f1: 0.6313414926805856
meta,dgl,1,1231,62.5745,0.6313

 F1-mic 0.6314,  F1-mac 0.3456
new best val f1: 0.6313954883609312
meta,dgl,1,1232,62.6250,0.6314

 F1-mic 0.6315,  F1-mac 0.3458
new best val f1: 0.6314674826013918
meta,dgl,1,1233,62.6756,0.6315

 F1-mic 0.6315,  F1-mac 0.3458
new best val f1: 0.6315334773218143
meta,dgl,1,1234,62.7261,0.6315

 F1-mic 0.6319,  F1-mac 0.3462
new best val f1: 0.6318994480441564
meta,dgl,1,1235,62.7764,0.6319

 F1-mic 0.6318,  F1-mac 0.3462
meta,dgl,1,1236,62.8269,0.6318

 F1-mic 0.6320,  F1-mac 0.3465
new best val f1: 0.6319594432445405
meta,dgl,1,1237,62.8774,0.6320

 F1-mic 0.6322,  F1-mac 0.3468
new best val f1: 0.6322354211663067
meta,dgl,1,1238,62.9280,0.6322

 F1-mic 0.6322,  F1-mac 0.3468
meta,dgl,1,1239,62.9783,0.6322

epoch:1241/50, Iteration 32/32:training loss 1.1498875617980957
Train F1-mic 0.6325, Train F1-mac 0.3477
 F1-mic 0.6322,  F1-mac 0.3468
meta,dgl,1,1240,63.0295,0.6322

 F1-mic 0.6325,  F1-mac 0.3472
new best val f1: 0.6325233981281497
meta,dgl,1,1241,63.0800,0.6325

 F1-mic 0.6329,  F1-mac 0.3477
new best val f1: 0.6328653707703383
meta,dgl,1,1242,63.1305,0.6329

 F1-mic 0.6324,  F1-mac 0.3472
meta,dgl,1,1243,63.1810,0.6324

 F1-mic 0.6329,  F1-mac 0.3477
new best val f1: 0.6328773698104152
meta,dgl,1,1244,63.2316,0.6329

 F1-mic 0.6333,  F1-mac 0.3482
new best val f1: 0.633267338612911
meta,dgl,1,1245,63.2820,0.6333

 F1-mic 0.6329,  F1-mac 0.3480
meta,dgl,1,1246,63.3357,0.6329

 F1-mic 0.6330,  F1-mac 0.3482
meta,dgl,1,1247,63.3865,0.6330

 F1-mic 0.6337,  F1-mac 0.3489
new best val f1: 0.633705303575714
meta,dgl,1,1248,63.4370,0.6337

 F1-mic 0.6333,  F1-mac 0.3485
meta,dgl,1,1249,63.4876,0.6333

epoch:1251/50, Iteration 32/32:training loss 1.146462321281433
Train F1-mic 0.6336, Train F1-mac 0.3493
 F1-mic 0.6333,  F1-mac 0.3486
meta,dgl,1,1250,63.5381,0.6333

 F1-mic 0.6341,  F1-mac 0.3496
new best val f1: 0.6341132709383249
meta,dgl,1,1251,63.5889,0.6341

 F1-mic 0.6339,  F1-mac 0.3494
meta,dgl,1,1252,63.6392,0.6339

 F1-mic 0.6336,  F1-mac 0.3492
meta,dgl,1,1253,63.6895,0.6336

 F1-mic 0.6342,  F1-mac 0.3498
new best val f1: 0.6342332613390929
meta,dgl,1,1254,63.7407,0.6342

 F1-mic 0.6342,  F1-mac 0.3498
meta,dgl,1,1255,63.7911,0.6342

 F1-mic 0.6340,  F1-mac 0.3497
meta,dgl,1,1256,63.8421,0.6340

 F1-mic 0.6344,  F1-mac 0.3501
new best val f1: 0.6344072474202064
meta,dgl,1,1257,63.8926,0.6344

 F1-mic 0.6345,  F1-mac 0.3502
new best val f1: 0.6345332373410127
meta,dgl,1,1258,63.9430,0.6345

 F1-mic 0.6344,  F1-mac 0.3501
meta,dgl,1,1259,63.9935,0.6344

epoch:1261/50, Iteration 32/32:training loss 1.1430490016937256
Train F1-mic 0.6347, Train F1-mac 0.3510
 F1-mic 0.6345,  F1-mac 0.3502
meta,dgl,1,1260,64.0440,0.6345

 F1-mic 0.6349,  F1-mac 0.3507
new best val f1: 0.6348872090232781
meta,dgl,1,1261,64.0945,0.6349

 F1-mic 0.6347,  F1-mac 0.3506
meta,dgl,1,1262,64.1450,0.6347

 F1-mic 0.6348,  F1-mac 0.3506
meta,dgl,1,1263,64.1955,0.6348

 F1-mic 0.6352,  F1-mac 0.3510
new best val f1: 0.6352051835853132
meta,dgl,1,1264,64.2460,0.6352

 F1-mic 0.6350,  F1-mac 0.3510
meta,dgl,1,1265,64.2964,0.6350

 F1-mic 0.6352,  F1-mac 0.3513
new best val f1: 0.6352111831053515
meta,dgl,1,1266,64.3468,0.6352

 F1-mic 0.6353,  F1-mac 0.3514
new best val f1: 0.6353491720662346
meta,dgl,1,1267,64.3974,0.6353

 F1-mic 0.6355,  F1-mac 0.3516
new best val f1: 0.6354931605471562
meta,dgl,1,1268,64.4479,0.6355

 F1-mic 0.6356,  F1-mac 0.3517
new best val f1: 0.6355771538276938
meta,dgl,1,1269,64.4985,0.6356

epoch:1271/50, Iteration 32/32:training loss 1.1396441459655762
Train F1-mic 0.6360, Train F1-mac 0.3527
 F1-mic 0.6357,  F1-mac 0.3519
new best val f1: 0.6356611471082313
meta,dgl,1,1270,64.5550,0.6357

 F1-mic 0.6359,  F1-mac 0.3521
new best val f1: 0.63585313174946
meta,dgl,1,1271,64.6055,0.6359

 F1-mic 0.6359,  F1-mac 0.3522
new best val f1: 0.6358891288696904
meta,dgl,1,1272,64.6561,0.6359

 F1-mic 0.6360,  F1-mac 0.3523
new best val f1: 0.6359731221502279
meta,dgl,1,1273,64.7067,0.6360

 F1-mic 0.6361,  F1-mac 0.3524
new best val f1: 0.6360511159107272
meta,dgl,1,1274,64.7572,0.6361

 F1-mic 0.6362,  F1-mac 0.3526
new best val f1: 0.6362131029517638
meta,dgl,1,1275,64.8077,0.6362

 F1-mic 0.6363,  F1-mac 0.3527
new best val f1: 0.6363150947924167
meta,dgl,1,1276,64.8582,0.6363

 F1-mic 0.6362,  F1-mac 0.3527
meta,dgl,1,1277,64.9086,0.6362

 F1-mic 0.6367,  F1-mac 0.3532
new best val f1: 0.6366630669546436
meta,dgl,1,1278,64.9589,0.6367

 F1-mic 0.6367,  F1-mac 0.3533
new best val f1: 0.6367350611951044
meta,dgl,1,1279,65.0100,0.6367

epoch:1281/50, Iteration 32/32:training loss 1.136253833770752
Train F1-mic 0.6371, Train F1-mac 0.3543
 F1-mic 0.6366,  F1-mac 0.3533
meta,dgl,1,1280,65.0605,0.6366

 F1-mic 0.6369,  F1-mac 0.3536
new best val f1: 0.6368970482361411
meta,dgl,1,1281,65.1110,0.6369

 F1-mic 0.6372,  F1-mac 0.3540
new best val f1: 0.6372450203983682
meta,dgl,1,1282,65.1615,0.6372

 F1-mic 0.6369,  F1-mac 0.3537
meta,dgl,1,1283,65.2119,0.6369

 F1-mic 0.6374,  F1-mac 0.3543
new best val f1: 0.6373710103191744
meta,dgl,1,1284,65.2653,0.6374

 F1-mic 0.6378,  F1-mac 0.3547
new best val f1: 0.6377549796016319
meta,dgl,1,1285,65.3158,0.6378

 F1-mic 0.6373,  F1-mac 0.3544
meta,dgl,1,1286,65.3664,0.6373

 F1-mic 0.6377,  F1-mac 0.3547
meta,dgl,1,1287,65.4168,0.6377

 F1-mic 0.6381,  F1-mac 0.3552
new best val f1: 0.6381209503239741
meta,dgl,1,1288,65.4673,0.6381

 F1-mic 0.6378,  F1-mac 0.3550
meta,dgl,1,1289,65.5177,0.6378

epoch:1291/50, Iteration 32/32:training loss 1.132868766784668
Train F1-mic 0.6381, Train F1-mac 0.3558
 F1-mic 0.6378,  F1-mac 0.3550
meta,dgl,1,1290,65.5682,0.6378

 F1-mic 0.6384,  F1-mac 0.3556
new best val f1: 0.6383969282457403
meta,dgl,1,1291,65.6188,0.6384

 F1-mic 0.6382,  F1-mac 0.3554
meta,dgl,1,1292,65.6692,0.6382

 F1-mic 0.6383,  F1-mac 0.3556
meta,dgl,1,1293,65.7231,0.6383

 F1-mic 0.6386,  F1-mac 0.3560
new best val f1: 0.6386429085673146
meta,dgl,1,1294,65.7736,0.6386

 F1-mic 0.6386,  F1-mac 0.3560
meta,dgl,1,1295,65.8242,0.6386

 F1-mic 0.6386,  F1-mac 0.3561
meta,dgl,1,1296,65.8747,0.6386

 F1-mic 0.6390,  F1-mac 0.3566
new best val f1: 0.6390328773698104
meta,dgl,1,1297,65.9251,0.6390

 F1-mic 0.6390,  F1-mac 0.3566
meta,dgl,1,1298,65.9755,0.6390

 F1-mic 0.6389,  F1-mac 0.3565
meta,dgl,1,1299,66.0259,0.6389

epoch:1301/50, Iteration 32/32:training loss 1.1294970512390137
Train F1-mic 0.6391, Train F1-mac 0.3573
 F1-mic 0.6394,  F1-mac 0.3570
new best val f1: 0.6393568514518838
meta,dgl,1,1300,66.0764,0.6394

 F1-mic 0.6393,  F1-mac 0.3571
meta,dgl,1,1301,66.1268,0.6393

 F1-mic 0.6391,  F1-mac 0.3569
meta,dgl,1,1302,66.1773,0.6391

 F1-mic 0.6395,  F1-mac 0.3573
new best val f1: 0.6395368370530358
meta,dgl,1,1303,66.2277,0.6395

 F1-mic 0.6397,  F1-mac 0.3576
new best val f1: 0.6396808255339573
meta,dgl,1,1304,66.2781,0.6397

 F1-mic 0.6395,  F1-mac 0.3574
meta,dgl,1,1305,66.3287,0.6395

 F1-mic 0.6398,  F1-mac 0.3577
new best val f1: 0.6398008159347253
meta,dgl,1,1306,66.3792,0.6398

 F1-mic 0.6400,  F1-mac 0.3579
new best val f1: 0.6399508039356852
meta,dgl,1,1307,66.4297,0.6400

 F1-mic 0.6399,  F1-mac 0.3580
meta,dgl,1,1308,66.4802,0.6399

 F1-mic 0.6402,  F1-mac 0.3583
new best val f1: 0.6401547876169906
meta,dgl,1,1309,66.5307,0.6402

epoch:1311/50, Iteration 32/32:training loss 1.1261297464370728
Train F1-mic 0.6405, Train F1-mac 0.3591
 F1-mic 0.6403,  F1-mac 0.3584
new best val f1: 0.6403047756179505
meta,dgl,1,1310,66.5812,0.6403

 F1-mic 0.6403,  F1-mac 0.3585
meta,dgl,1,1311,66.6318,0.6403

 F1-mic 0.6405,  F1-mac 0.3587
new best val f1: 0.6404967602591792
meta,dgl,1,1312,66.6822,0.6405

 F1-mic 0.6408,  F1-mac 0.3591
new best val f1: 0.6408027357811376
meta,dgl,1,1313,66.7328,0.6408

 F1-mic 0.6406,  F1-mac 0.3591
meta,dgl,1,1314,66.7834,0.6406

 F1-mic 0.6409,  F1-mac 0.3594
new best val f1: 0.6408867290616751
meta,dgl,1,1315,66.8337,0.6409

 F1-mic 0.6412,  F1-mac 0.3596
new best val f1: 0.6411747060235181
meta,dgl,1,1316,66.8841,0.6412

 F1-mic 0.6410,  F1-mac 0.3596
meta,dgl,1,1317,66.9346,0.6410

 F1-mic 0.6412,  F1-mac 0.3599
new best val f1: 0.6412107031437485
meta,dgl,1,1318,66.9850,0.6412

 F1-mic 0.6416,  F1-mac 0.3602
new best val f1: 0.6416066714662827
meta,dgl,1,1319,67.0353,0.6416

epoch:1321/50, Iteration 32/32:training loss 1.1227731704711914
Train F1-mic 0.6419, Train F1-mac 0.3610
 F1-mic 0.6415,  F1-mac 0.3602
meta,dgl,1,1320,67.0859,0.6415

 F1-mic 0.6414,  F1-mac 0.3602
meta,dgl,1,1321,67.1365,0.6414

 F1-mic 0.6420,  F1-mac 0.3608
new best val f1: 0.6420206383489321
meta,dgl,1,1322,67.1870,0.6420

 F1-mic 0.6420,  F1-mac 0.3609
meta,dgl,1,1323,67.2376,0.6420

 F1-mic 0.6417,  F1-mac 0.3608
meta,dgl,1,1324,67.2881,0.6417

 F1-mic 0.6425,  F1-mac 0.3613
new best val f1: 0.6425065994720423
meta,dgl,1,1325,67.3386,0.6425

 F1-mic 0.6424,  F1-mac 0.3614
meta,dgl,1,1326,67.3893,0.6424

 F1-mic 0.6420,  F1-mac 0.3611
meta,dgl,1,1327,67.4400,0.6420

 F1-mic 0.6427,  F1-mac 0.3617
new best val f1: 0.6427465802735781
meta,dgl,1,1328,67.4907,0.6427

 F1-mic 0.6427,  F1-mac 0.3617
meta,dgl,1,1329,67.5414,0.6427

epoch:1331/50, Iteration 32/32:training loss 1.1194220781326294
Train F1-mic 0.6429, Train F1-mac 0.3626
 F1-mic 0.6426,  F1-mac 0.3617
meta,dgl,1,1330,67.5921,0.6426

 F1-mic 0.6429,  F1-mac 0.3619
new best val f1: 0.6428785697144228
meta,dgl,1,1331,67.6427,0.6429

 F1-mic 0.6431,  F1-mac 0.3621
new best val f1: 0.6430705543556515
meta,dgl,1,1332,67.6933,0.6431

 F1-mic 0.6430,  F1-mac 0.3622
meta,dgl,1,1333,67.7440,0.6430

 F1-mic 0.6431,  F1-mac 0.3622
meta,dgl,1,1334,67.7947,0.6431

 F1-mic 0.6433,  F1-mac 0.3624
new best val f1: 0.6433405327573795
meta,dgl,1,1335,67.8453,0.6433

 F1-mic 0.6433,  F1-mac 0.3624
meta,dgl,1,1336,67.8959,0.6433

 F1-mic 0.6433,  F1-mac 0.3626
meta,dgl,1,1337,67.9463,0.6433

 F1-mic 0.6437,  F1-mac 0.3629
new best val f1: 0.643742500599952
meta,dgl,1,1338,67.9968,0.6437

 F1-mic 0.6435,  F1-mac 0.3629
meta,dgl,1,1339,68.0474,0.6435

epoch:1341/50, Iteration 32/32:training loss 1.116082787513733
Train F1-mic 0.6439, Train F1-mac 0.3640
 F1-mic 0.6437,  F1-mac 0.3631
meta,dgl,1,1340,68.0978,0.6437

 F1-mic 0.6440,  F1-mac 0.3634
new best val f1: 0.6439944804415647
meta,dgl,1,1341,68.1482,0.6440

 F1-mic 0.6440,  F1-mac 0.3635
meta,dgl,1,1342,68.1986,0.6440

 F1-mic 0.6441,  F1-mac 0.3637
new best val f1: 0.6440724742020638
meta,dgl,1,1343,68.2491,0.6441

 F1-mic 0.6443,  F1-mac 0.3638
new best val f1: 0.6442764578833693
meta,dgl,1,1344,68.2996,0.6443

 F1-mic 0.6444,  F1-mac 0.3640
new best val f1: 0.644378449724022
meta,dgl,1,1345,68.3502,0.6444

 F1-mic 0.6443,  F1-mac 0.3640
meta,dgl,1,1346,68.4007,0.6443

 F1-mic 0.6446,  F1-mac 0.3643
new best val f1: 0.6446064314854811
meta,dgl,1,1347,68.4513,0.6446

 F1-mic 0.6447,  F1-mac 0.3644
new best val f1: 0.6446544276457883
meta,dgl,1,1348,68.5017,0.6447

 F1-mic 0.6446,  F1-mac 0.3645
meta,dgl,1,1349,68.5523,0.6446

epoch:1351/50, Iteration 32/32:training loss 1.1127499341964722
Train F1-mic 0.6449, Train F1-mac 0.3655
 F1-mic 0.6449,  F1-mac 0.3649
new best val f1: 0.644936405087593
meta,dgl,1,1350,68.6028,0.6449

 F1-mic 0.6450,  F1-mac 0.3650
new best val f1: 0.6450323974082074
meta,dgl,1,1351,68.6533,0.6450

 F1-mic 0.6450,  F1-mac 0.3651
meta,dgl,1,1352,68.7039,0.6450

 F1-mic 0.6452,  F1-mac 0.3652
new best val f1: 0.6451523878089753
meta,dgl,1,1353,68.7544,0.6452

 F1-mic 0.6454,  F1-mac 0.3655
new best val f1: 0.6453623710103191
meta,dgl,1,1354,68.8049,0.6454

 F1-mic 0.6453,  F1-mac 0.3654
meta,dgl,1,1355,68.8554,0.6453

 F1-mic 0.6455,  F1-mac 0.3657
new best val f1: 0.6454523638108951
meta,dgl,1,1356,68.9059,0.6455

 F1-mic 0.6457,  F1-mac 0.3660
new best val f1: 0.645662347012239
meta,dgl,1,1357,68.9562,0.6457

 F1-mic 0.6457,  F1-mac 0.3662
new best val f1: 0.6457043436525078
meta,dgl,1,1358,69.0067,0.6457

 F1-mic 0.6458,  F1-mac 0.3662
new best val f1: 0.6458063354931606
meta,dgl,1,1359,69.0573,0.6458

epoch:1361/50, Iteration 32/32:training loss 1.10942804813385
Train F1-mic 0.6462, Train F1-mac 0.3673
 F1-mic 0.6459,  F1-mac 0.3663
new best val f1: 0.6459143268538516
meta,dgl,1,1360,69.1078,0.6459

 F1-mic 0.6459,  F1-mac 0.3664
new best val f1: 0.6459203263738901
meta,dgl,1,1361,69.1581,0.6459

 F1-mic 0.6460,  F1-mac 0.3666
new best val f1: 0.6460043196544276
meta,dgl,1,1362,69.2087,0.6460

 F1-mic 0.6462,  F1-mac 0.3668
new best val f1: 0.6461903047756179
meta,dgl,1,1363,69.2593,0.6462

 F1-mic 0.6463,  F1-mac 0.3669
new best val f1: 0.6462502999760019
meta,dgl,1,1364,69.3098,0.6463

 F1-mic 0.6464,  F1-mac 0.3671
new best val f1: 0.646418286537077
meta,dgl,1,1365,69.3604,0.6464

 F1-mic 0.6464,  F1-mac 0.3671
meta,dgl,1,1366,69.4109,0.6464

 F1-mic 0.6467,  F1-mac 0.3674
new best val f1: 0.6467062634989201
meta,dgl,1,1367,69.4614,0.6467

 F1-mic 0.6466,  F1-mac 0.3674
meta,dgl,1,1368,69.5120,0.6466

 F1-mic 0.6467,  F1-mac 0.3675
meta,dgl,1,1369,69.5625,0.6467

epoch:1371/50, Iteration 32/32:training loss 1.1061115264892578
Train F1-mic 0.6471, Train F1-mac 0.3686
 F1-mic 0.6470,  F1-mac 0.3679
new best val f1: 0.6470242380609551
meta,dgl,1,1370,69.6131,0.6470

 F1-mic 0.6470,  F1-mac 0.3680
new best val f1: 0.6470362371010319
meta,dgl,1,1371,69.6636,0.6470

 F1-mic 0.6471,  F1-mac 0.3681
new best val f1: 0.6470542356611471
meta,dgl,1,1372,69.7141,0.6471

 F1-mic 0.6474,  F1-mac 0.3684
new best val f1: 0.6473962083033358
meta,dgl,1,1373,69.7648,0.6474

 F1-mic 0.6472,  F1-mac 0.3684
meta,dgl,1,1374,69.8152,0.6472

 F1-mic 0.6475,  F1-mac 0.3685
new best val f1: 0.6474922006239501
meta,dgl,1,1375,69.8660,0.6475

 F1-mic 0.6477,  F1-mac 0.3688
new best val f1: 0.6477081833453324
meta,dgl,1,1376,69.9166,0.6477

 F1-mic 0.6477,  F1-mac 0.3690
meta,dgl,1,1377,69.9671,0.6477

 F1-mic 0.6480,  F1-mac 0.3691
new best val f1: 0.6479721622270218
meta,dgl,1,1378,70.0176,0.6480

 F1-mic 0.6477,  F1-mac 0.3690
meta,dgl,1,1379,70.0680,0.6477

epoch:1381/50, Iteration 32/32:training loss 1.102798342704773
Train F1-mic 0.6482, Train F1-mac 0.3701
 F1-mic 0.6483,  F1-mac 0.3696
new best val f1: 0.6483321334293256
meta,dgl,1,1380,70.1185,0.6483

 F1-mic 0.6481,  F1-mac 0.3695
meta,dgl,1,1381,70.1690,0.6481

 F1-mic 0.6481,  F1-mac 0.3695
meta,dgl,1,1382,70.2196,0.6481

 F1-mic 0.6485,  F1-mac 0.3698
new best val f1: 0.6484641228701704
meta,dgl,1,1383,70.2702,0.6485

 F1-mic 0.6483,  F1-mac 0.3698
meta,dgl,1,1384,70.3206,0.6483

 F1-mic 0.6484,  F1-mac 0.3700
meta,dgl,1,1385,70.3712,0.6484

 F1-mic 0.6488,  F1-mac 0.3702
new best val f1: 0.6488180945524358
meta,dgl,1,1386,70.4218,0.6488

 F1-mic 0.6487,  F1-mac 0.3702
meta,dgl,1,1387,70.4723,0.6487

 F1-mic 0.6487,  F1-mac 0.3702
meta,dgl,1,1388,70.5227,0.6487

 F1-mic 0.6494,  F1-mac 0.3709
new best val f1: 0.6494060475161987
meta,dgl,1,1389,70.5731,0.6494

epoch:1391/50, Iteration 32/32:training loss 1.099487543106079
Train F1-mic 0.6498, Train F1-mac 0.3721
 F1-mic 0.6490,  F1-mac 0.3707
meta,dgl,1,1390,70.6235,0.6490

 F1-mic 0.6491,  F1-mac 0.3708
meta,dgl,1,1391,70.6739,0.6491

 F1-mic 0.6496,  F1-mac 0.3713
new best val f1: 0.6496460283177345
meta,dgl,1,1392,70.7245,0.6496

 F1-mic 0.6492,  F1-mac 0.3711
meta,dgl,1,1393,70.7754,0.6492

 F1-mic 0.6496,  F1-mac 0.3715
meta,dgl,1,1394,70.8260,0.6496

 F1-mic 0.6500,  F1-mac 0.3717
new best val f1: 0.6499520038396929
meta,dgl,1,1395,70.8764,0.6500

 F1-mic 0.6496,  F1-mac 0.3714
meta,dgl,1,1396,70.9269,0.6496

 F1-mic 0.6500,  F1-mac 0.3720
new best val f1: 0.6500179985601152
meta,dgl,1,1397,70.9775,0.6500

 F1-mic 0.6502,  F1-mac 0.3722
new best val f1: 0.6501679865610751
meta,dgl,1,1398,71.0278,0.6502

 F1-mic 0.6501,  F1-mac 0.3722
meta,dgl,1,1399,71.0783,0.6501

epoch:1401/50, Iteration 32/32:training loss 1.0961748361587524
Train F1-mic 0.6504, Train F1-mac 0.3732
 F1-mic 0.6503,  F1-mac 0.3725
new best val f1: 0.6503419726421886
meta,dgl,1,1400,71.1288,0.6503

 F1-mic 0.6505,  F1-mac 0.3726
new best val f1: 0.650467962562995
meta,dgl,1,1401,71.1791,0.6505

 F1-mic 0.6505,  F1-mac 0.3728
meta,dgl,1,1402,71.2297,0.6505

 F1-mic 0.6508,  F1-mac 0.3731
new best val f1: 0.6507679385649148
meta,dgl,1,1403,71.2802,0.6508

 F1-mic 0.6509,  F1-mac 0.3732
new best val f1: 0.6508819294456444
meta,dgl,1,1404,71.3308,0.6509

 F1-mic 0.6507,  F1-mac 0.3732
meta,dgl,1,1405,71.3813,0.6507

 F1-mic 0.6512,  F1-mac 0.3738
new best val f1: 0.6512419006479482
meta,dgl,1,1406,71.4317,0.6512

 F1-mic 0.6514,  F1-mac 0.3739
new best val f1: 0.6513798896088313
meta,dgl,1,1407,71.4821,0.6514

 F1-mic 0.6511,  F1-mac 0.3738
meta,dgl,1,1408,71.5326,0.6511

 F1-mic 0.6515,  F1-mac 0.3740
new best val f1: 0.651511879049676
meta,dgl,1,1409,71.5829,0.6515

epoch:1411/50, Iteration 32/32:training loss 1.0928672552108765
Train F1-mic 0.6517, Train F1-mac 0.3747
 F1-mic 0.6517,  F1-mac 0.3743
new best val f1: 0.6517158627309815
meta,dgl,1,1410,71.6333,0.6517

 F1-mic 0.6511,  F1-mac 0.3740
meta,dgl,1,1411,71.6838,0.6511

 F1-mic 0.6521,  F1-mac 0.3746
new best val f1: 0.6521058315334773
meta,dgl,1,1412,71.7342,0.6521

 F1-mic 0.6518,  F1-mac 0.3745
meta,dgl,1,1413,71.7850,0.6518

 F1-mic 0.6517,  F1-mac 0.3746
meta,dgl,1,1414,71.8354,0.6517

 F1-mic 0.6522,  F1-mac 0.3749
new best val f1: 0.6522318214542837
meta,dgl,1,1415,71.8858,0.6522

 F1-mic 0.6520,  F1-mac 0.3747
meta,dgl,1,1416,71.9363,0.6520

 F1-mic 0.6519,  F1-mac 0.3747
meta,dgl,1,1417,71.9865,0.6519

 F1-mic 0.6527,  F1-mac 0.3754
new best val f1: 0.6527117830573554
meta,dgl,1,1418,72.0371,0.6527

 F1-mic 0.6524,  F1-mac 0.3751
meta,dgl,1,1419,72.0876,0.6524

epoch:1421/50, Iteration 32/32:training loss 1.0895593166351318
Train F1-mic 0.6526, Train F1-mac 0.3759
 F1-mic 0.6524,  F1-mac 0.3754
meta,dgl,1,1420,72.1380,0.6524

 F1-mic 0.6530,  F1-mac 0.3758
new best val f1: 0.6529757619390448
meta,dgl,1,1421,72.1883,0.6530

 F1-mic 0.6526,  F1-mac 0.3755
meta,dgl,1,1422,72.2388,0.6526

 F1-mic 0.6530,  F1-mac 0.3758
meta,dgl,1,1423,72.2891,0.6530

 F1-mic 0.6531,  F1-mac 0.3760
new best val f1: 0.653113750899928
meta,dgl,1,1424,72.3395,0.6531

 F1-mic 0.6530,  F1-mac 0.3760
meta,dgl,1,1425,72.3898,0.6530

 F1-mic 0.6533,  F1-mac 0.3763
new best val f1: 0.6533057355411567
meta,dgl,1,1426,72.4402,0.6533

 F1-mic 0.6536,  F1-mac 0.3765
new best val f1: 0.6535577153827694
meta,dgl,1,1427,72.4914,0.6536

 F1-mic 0.6534,  F1-mac 0.3766
meta,dgl,1,1428,72.5418,0.6534

 F1-mic 0.6535,  F1-mac 0.3768
meta,dgl,1,1429,72.5924,0.6535

epoch:1431/50, Iteration 32/32:training loss 1.0862573385238647
Train F1-mic 0.6536, Train F1-mac 0.3774
 F1-mic 0.6539,  F1-mac 0.3770
new best val f1: 0.6539356851451884
meta,dgl,1,1430,72.6429,0.6539

 F1-mic 0.6536,  F1-mac 0.3769
meta,dgl,1,1431,72.6934,0.6536

 F1-mic 0.6540,  F1-mac 0.3773
new best val f1: 0.6539956803455723
meta,dgl,1,1432,72.7439,0.6540

 F1-mic 0.6542,  F1-mac 0.3773
new best val f1: 0.6541696664266858
meta,dgl,1,1433,72.7945,0.6542

 F1-mic 0.6539,  F1-mac 0.3772
meta,dgl,1,1434,72.8450,0.6539

 F1-mic 0.6543,  F1-mac 0.3775
new best val f1: 0.6543136549076074
meta,dgl,1,1435,72.8955,0.6543

 F1-mic 0.6544,  F1-mac 0.3777
new best val f1: 0.6544396448284138
meta,dgl,1,1436,72.9459,0.6544

 F1-mic 0.6543,  F1-mac 0.3778
meta,dgl,1,1437,72.9963,0.6543

 F1-mic 0.6547,  F1-mac 0.3780
new best val f1: 0.6546676265898728
meta,dgl,1,1438,73.0493,0.6547

 F1-mic 0.6545,  F1-mac 0.3779
meta,dgl,1,1439,73.0999,0.6545

epoch:1441/50, Iteration 32/32:training loss 1.08295738697052
Train F1-mic 0.6547, Train F1-mac 0.3788
 F1-mic 0.6547,  F1-mac 0.3781
new best val f1: 0.6547036237101032
meta,dgl,1,1440,73.1503,0.6547

 F1-mic 0.6548,  F1-mac 0.3782
new best val f1: 0.6548476121910247
meta,dgl,1,1441,73.2007,0.6548

 F1-mic 0.6550,  F1-mac 0.3785
new best val f1: 0.655003599712023
meta,dgl,1,1442,73.2511,0.6550

 F1-mic 0.6550,  F1-mac 0.3784
meta,dgl,1,1443,73.3016,0.6550

 F1-mic 0.6552,  F1-mac 0.3787
new best val f1: 0.6551715862730981
meta,dgl,1,1444,73.3522,0.6552

 F1-mic 0.6552,  F1-mac 0.3788
meta,dgl,1,1445,73.4026,0.6552

 F1-mic 0.6554,  F1-mac 0.3791
new best val f1: 0.6553635709143268
meta,dgl,1,1446,73.4532,0.6554

 F1-mic 0.6555,  F1-mac 0.3792
new best val f1: 0.6554775617950563
meta,dgl,1,1447,73.5037,0.6555

 F1-mic 0.6555,  F1-mac 0.3793
new best val f1: 0.6555135589152867
meta,dgl,1,1448,73.5542,0.6555

 F1-mic 0.6557,  F1-mac 0.3796
new best val f1: 0.6557055435565154
meta,dgl,1,1449,73.6050,0.6557

epoch:1451/50, Iteration 32/32:training loss 1.0796560049057007
Train F1-mic 0.6558, Train F1-mac 0.3801
 F1-mic 0.6560,  F1-mac 0.3797
new best val f1: 0.6559515238780897
meta,dgl,1,1450,73.6555,0.6560

 F1-mic 0.6558,  F1-mac 0.3797
meta,dgl,1,1451,73.7060,0.6558

 F1-mic 0.6561,  F1-mac 0.3800
new best val f1: 0.6560895128389729
meta,dgl,1,1452,73.7565,0.6561

 F1-mic 0.6562,  F1-mac 0.3801
new best val f1: 0.6561735061195104
meta,dgl,1,1453,73.8069,0.6562

 F1-mic 0.6562,  F1-mac 0.3802
new best val f1: 0.6562095032397408
meta,dgl,1,1454,73.8573,0.6562

 F1-mic 0.6566,  F1-mac 0.3805
new best val f1: 0.6565514758819294
meta,dgl,1,1455,73.9077,0.6566

 F1-mic 0.6563,  F1-mac 0.3804
meta,dgl,1,1456,73.9581,0.6563

 F1-mic 0.6566,  F1-mac 0.3807
new best val f1: 0.6566414686825054
meta,dgl,1,1457,74.0089,0.6566

 F1-mic 0.6569,  F1-mac 0.3810
new best val f1: 0.6568514518838493
meta,dgl,1,1458,74.0595,0.6569

 F1-mic 0.6566,  F1-mac 0.3808
meta,dgl,1,1459,74.1100,0.6566

epoch:1461/50, Iteration 32/32:training loss 1.0763580799102783
Train F1-mic 0.6567, Train F1-mac 0.3813
 F1-mic 0.6571,  F1-mac 0.3813
new best val f1: 0.65707343412527
meta,dgl,1,1460,74.1605,0.6571

 F1-mic 0.6570,  F1-mac 0.3813
meta,dgl,1,1461,74.2111,0.6570

 F1-mic 0.6572,  F1-mac 0.3814
new best val f1: 0.6571814254859611
meta,dgl,1,1462,74.2617,0.6572

 F1-mic 0.6572,  F1-mac 0.3817
meta,dgl,1,1463,74.3130,0.6572

 F1-mic 0.6573,  F1-mac 0.3818
new best val f1: 0.6573194144468443
meta,dgl,1,1464,74.3638,0.6573

 F1-mic 0.6574,  F1-mac 0.3819
new best val f1: 0.6574274058075354
meta,dgl,1,1465,74.4143,0.6574

 F1-mic 0.6575,  F1-mac 0.3822
new best val f1: 0.657511399088073
meta,dgl,1,1466,74.4648,0.6575

 F1-mic 0.6579,  F1-mac 0.3825
new best val f1: 0.6579013678905687
meta,dgl,1,1467,74.5153,0.6579

 F1-mic 0.6576,  F1-mac 0.3824
meta,dgl,1,1468,74.5659,0.6576

 F1-mic 0.6578,  F1-mac 0.3826
meta,dgl,1,1469,74.6164,0.6578

epoch:1471/50, Iteration 32/32:training loss 1.073059320449829
Train F1-mic 0.6579, Train F1-mac 0.3827
 F1-mic 0.6583,  F1-mac 0.3829
new best val f1: 0.6582853371730262
meta,dgl,1,1470,74.6668,0.6583

 F1-mic 0.6579,  F1-mac 0.3828
meta,dgl,1,1471,74.7173,0.6579

 F1-mic 0.6584,  F1-mac 0.3832
new best val f1: 0.6584233261339093
meta,dgl,1,1472,74.7677,0.6584

 F1-mic 0.6584,  F1-mac 0.3833
meta,dgl,1,1473,74.8183,0.6584

 F1-mic 0.6583,  F1-mac 0.3833
meta,dgl,1,1474,74.8688,0.6583

 F1-mic 0.6588,  F1-mac 0.3836
new best val f1: 0.6587652987760979
meta,dgl,1,1475,74.9194,0.6588

 F1-mic 0.6587,  F1-mac 0.3836
meta,dgl,1,1476,74.9700,0.6587

 F1-mic 0.6587,  F1-mac 0.3837
meta,dgl,1,1477,75.0205,0.6587

 F1-mic 0.6590,  F1-mac 0.3840
new best val f1: 0.6590172786177105
meta,dgl,1,1478,75.0711,0.6590

 F1-mic 0.6590,  F1-mac 0.3840
meta,dgl,1,1479,75.1216,0.6590

epoch:1481/50, Iteration 32/32:training loss 1.069767713546753
Train F1-mic 0.6590, Train F1-mac 0.3840
 F1-mic 0.6591,  F1-mac 0.3841
new best val f1: 0.6591432685385169
meta,dgl,1,1480,75.1721,0.6591

 F1-mic 0.6593,  F1-mac 0.3842
new best val f1: 0.6592812574994
meta,dgl,1,1481,75.2230,0.6593

 F1-mic 0.6591,  F1-mac 0.3842
meta,dgl,1,1482,75.2734,0.6591

 F1-mic 0.6596,  F1-mac 0.3845
new best val f1: 0.6595752339812815
meta,dgl,1,1483,75.3238,0.6596

 F1-mic 0.6595,  F1-mac 0.3845
meta,dgl,1,1484,75.3742,0.6595

 F1-mic 0.6595,  F1-mac 0.3847
meta,dgl,1,1485,75.4247,0.6595

 F1-mic 0.6599,  F1-mac 0.3849
new best val f1: 0.6599472042236622
meta,dgl,1,1486,75.4750,0.6599

 F1-mic 0.6598,  F1-mac 0.3850
meta,dgl,1,1487,75.5255,0.6598

 F1-mic 0.6597,  F1-mac 0.3849
meta,dgl,1,1488,75.5766,0.6597

 F1-mic 0.6604,  F1-mac 0.3854
new best val f1: 0.6604091672666187
meta,dgl,1,1489,75.6271,0.6604

epoch:1491/50, Iteration 32/32:training loss 1.0664843320846558
Train F1-mic 0.6605, Train F1-mac 0.3855
 F1-mic 0.6599,  F1-mac 0.3851
meta,dgl,1,1490,75.6776,0.6599

 F1-mic 0.6602,  F1-mac 0.3854
meta,dgl,1,1491,75.7282,0.6602

 F1-mic 0.6606,  F1-mac 0.3857
new best val f1: 0.6606191504679626
meta,dgl,1,1492,75.7788,0.6606

 F1-mic 0.6601,  F1-mac 0.3855
meta,dgl,1,1493,75.8293,0.6601

 F1-mic 0.6605,  F1-mac 0.3858
meta,dgl,1,1494,75.8797,0.6605

 F1-mic 0.6608,  F1-mac 0.3860
new best val f1: 0.6608051355891529
meta,dgl,1,1495,75.9302,0.6608

 F1-mic 0.6604,  F1-mac 0.3859
meta,dgl,1,1496,75.9807,0.6604

 F1-mic 0.6609,  F1-mac 0.3864
new best val f1: 0.6608771298296137
meta,dgl,1,1497,76.0313,0.6609

 F1-mic 0.6612,  F1-mac 0.3865
new best val f1: 0.6611771058315334
meta,dgl,1,1498,76.0816,0.6612

 F1-mic 0.6605,  F1-mac 0.3863
meta,dgl,1,1499,76.1321,0.6605

epoch:1501/50, Iteration 32/32:training loss 1.0632020235061646
Train F1-mic 0.6605, Train F1-mac 0.3863
 F1-mic 0.6616,  F1-mac 0.3870
new best val f1: 0.6615970722342213
meta,dgl,1,1500,76.1826,0.6616

 F1-mic 0.6612,  F1-mac 0.3869
meta,dgl,1,1501,76.2331,0.6612

 F1-mic 0.6609,  F1-mac 0.3866
meta,dgl,1,1502,76.2836,0.6609

 F1-mic 0.6620,  F1-mac 0.3874
new best val f1: 0.6620110391168706
meta,dgl,1,1503,76.3341,0.6620

 F1-mic 0.6614,  F1-mac 0.3873
meta,dgl,1,1504,76.3847,0.6614

 F1-mic 0.6617,  F1-mac 0.3874
meta,dgl,1,1505,76.4355,0.6617

 F1-mic 0.6621,  F1-mac 0.3877
new best val f1: 0.6620530357571395
meta,dgl,1,1506,76.4860,0.6621

 F1-mic 0.6618,  F1-mac 0.3877
meta,dgl,1,1507,76.5366,0.6618

 F1-mic 0.6620,  F1-mac 0.3878
meta,dgl,1,1508,76.5871,0.6620

 F1-mic 0.6623,  F1-mac 0.3881
new best val f1: 0.6623170146388289
meta,dgl,1,1509,76.6376,0.6623

epoch:1511/50, Iteration 32/32:training loss 1.0599175691604614
Train F1-mic 0.6624, Train F1-mac 0.3883
 F1-mic 0.6622,  F1-mac 0.3881
meta,dgl,1,1510,76.6880,0.6622

 F1-mic 0.6623,  F1-mac 0.3882
meta,dgl,1,1511,76.7385,0.6623

 F1-mic 0.6627,  F1-mac 0.3885
new best val f1: 0.6626709863210943
meta,dgl,1,1512,76.7891,0.6627

 F1-mic 0.6624,  F1-mac 0.3883
meta,dgl,1,1513,76.8396,0.6624

 F1-mic 0.6627,  F1-mac 0.3887
meta,dgl,1,1514,76.8901,0.6627

 F1-mic 0.6628,  F1-mac 0.3889
new best val f1: 0.6628269738420927
meta,dgl,1,1515,76.9406,0.6628

 F1-mic 0.6629,  F1-mac 0.3890
new best val f1: 0.662892968562515
meta,dgl,1,1516,76.9915,0.6629

 F1-mic 0.6630,  F1-mac 0.3893
new best val f1: 0.6630429565634749
meta,dgl,1,1517,77.0418,0.6630

 F1-mic 0.6633,  F1-mac 0.3895
new best val f1: 0.6632829373650108
meta,dgl,1,1518,77.0926,0.6633

 F1-mic 0.6631,  F1-mac 0.3895
meta,dgl,1,1519,77.1432,0.6631

epoch:1521/50, Iteration 32/32:training loss 1.056642770767212
Train F1-mic 0.6631, Train F1-mac 0.3895
 F1-mic 0.6635,  F1-mac 0.3898
new best val f1: 0.6635109191264699
meta,dgl,1,1520,77.1937,0.6635

 F1-mic 0.6636,  F1-mac 0.3899
new best val f1: 0.6636069114470843
meta,dgl,1,1521,77.2440,0.6636

 F1-mic 0.6635,  F1-mac 0.3899
meta,dgl,1,1522,77.2949,0.6635

 F1-mic 0.6638,  F1-mac 0.3902
new best val f1: 0.663828893688505
meta,dgl,1,1523,77.3452,0.6638

 F1-mic 0.6637,  F1-mac 0.3902
meta,dgl,1,1524,77.3960,0.6637

 F1-mic 0.6640,  F1-mac 0.3904
new best val f1: 0.6640148788096952
meta,dgl,1,1525,77.4465,0.6640

 F1-mic 0.6640,  F1-mac 0.3905
meta,dgl,1,1526,77.4969,0.6640

 F1-mic 0.6641,  F1-mac 0.3906
new best val f1: 0.6640988720902328
meta,dgl,1,1527,77.5474,0.6641

 F1-mic 0.6643,  F1-mac 0.3908
new best val f1: 0.6642728581713463
meta,dgl,1,1528,77.5979,0.6643

 F1-mic 0.6643,  F1-mac 0.3910
new best val f1: 0.6643208543316534
meta,dgl,1,1529,77.6484,0.6643

epoch:1531/50, Iteration 32/32:training loss 1.053369402885437
Train F1-mic 0.6645, Train F1-mac 0.3912
 F1-mic 0.6645,  F1-mac 0.3912
new best val f1: 0.664494840412767
meta,dgl,1,1530,77.6989,0.6645

 F1-mic 0.6647,  F1-mac 0.3913
new best val f1: 0.6646688264938805
meta,dgl,1,1531,77.7492,0.6647

 F1-mic 0.6644,  F1-mac 0.3912
meta,dgl,1,1532,77.8000,0.6644

 F1-mic 0.6648,  F1-mac 0.3915
new best val f1: 0.6647948164146869
meta,dgl,1,1533,77.8505,0.6648

 F1-mic 0.6650,  F1-mac 0.3916
new best val f1: 0.6649568034557235
meta,dgl,1,1534,77.9011,0.6650

 F1-mic 0.6648,  F1-mac 0.3917
meta,dgl,1,1535,77.9516,0.6648

 F1-mic 0.6651,  F1-mac 0.3919
new best val f1: 0.6651127909767218
meta,dgl,1,1536,78.0020,0.6651

 F1-mic 0.6651,  F1-mac 0.3920
new best val f1: 0.6651487880969522
meta,dgl,1,1537,78.0524,0.6651

 F1-mic 0.6654,  F1-mac 0.3923
new best val f1: 0.6653707703383729
meta,dgl,1,1538,78.1029,0.6654

 F1-mic 0.6652,  F1-mac 0.3921
meta,dgl,1,1539,78.1534,0.6652

epoch:1541/50, Iteration 32/32:training loss 1.0500990152359009
Train F1-mic 0.6653, Train F1-mac 0.3922
 F1-mic 0.6657,  F1-mac 0.3924
new best val f1: 0.6657127429805616
meta,dgl,1,1540,78.2040,0.6657

 F1-mic 0.6654,  F1-mac 0.3926
meta,dgl,1,1541,78.2544,0.6654

 F1-mic 0.6657,  F1-mac 0.3926
meta,dgl,1,1542,78.3050,0.6657

 F1-mic 0.6657,  F1-mac 0.3926
new best val f1: 0.665748740100792
meta,dgl,1,1543,78.3554,0.6657

 F1-mic 0.6657,  F1-mac 0.3929
meta,dgl,1,1544,78.4059,0.6657

 F1-mic 0.6661,  F1-mac 0.3930
new best val f1: 0.6660787137029037
meta,dgl,1,1545,78.4563,0.6661

 F1-mic 0.6660,  F1-mac 0.3931
meta,dgl,1,1546,78.5068,0.6660

 F1-mic 0.6663,  F1-mac 0.3935
new best val f1: 0.6663186945044396
meta,dgl,1,1547,78.5573,0.6663

 F1-mic 0.6663,  F1-mac 0.3934
meta,dgl,1,1548,78.6078,0.6663

 F1-mic 0.6663,  F1-mac 0.3934
meta,dgl,1,1549,78.6582,0.6663

epoch:1551/50, Iteration 32/32:training loss 1.0468345880508423
Train F1-mic 0.6665, Train F1-mac 0.3937
 F1-mic 0.6668,  F1-mac 0.3939
new best val f1: 0.6667746580273578
meta,dgl,1,1550,78.7087,0.6668

 F1-mic 0.6665,  F1-mac 0.3938
meta,dgl,1,1551,78.7593,0.6665

 F1-mic 0.6670,  F1-mac 0.3941
new best val f1: 0.666972642188625
meta,dgl,1,1552,78.8099,0.6670

 F1-mic 0.6668,  F1-mac 0.3942
meta,dgl,1,1553,78.8606,0.6668

 F1-mic 0.6672,  F1-mac 0.3944
new best val f1: 0.6672186225101991
meta,dgl,1,1554,78.9113,0.6672

 F1-mic 0.6671,  F1-mac 0.3946
meta,dgl,1,1555,78.9618,0.6671

 F1-mic 0.6672,  F1-mac 0.3947
new best val f1: 0.6672366210703143
meta,dgl,1,1556,79.0123,0.6672

 F1-mic 0.6678,  F1-mac 0.3949
new best val f1: 0.6677525797936165
meta,dgl,1,1557,79.0629,0.6678

 F1-mic 0.6672,  F1-mac 0.3951
meta,dgl,1,1558,79.1135,0.6672

 F1-mic 0.6681,  F1-mac 0.3955
new best val f1: 0.6680885529157667
meta,dgl,1,1559,79.1640,0.6681

epoch:1561/50, Iteration 32/32:training loss 1.0435776710510254
Train F1-mic 0.6682, Train F1-mac 0.3956
 F1-mic 0.6675,  F1-mac 0.3953
meta,dgl,1,1560,79.2143,0.6675

 F1-mic 0.6675,  F1-mac 0.3954
meta,dgl,1,1561,79.2648,0.6675

 F1-mic 0.6685,  F1-mac 0.3963
new best val f1: 0.6685205183585313
meta,dgl,1,1562,79.3153,0.6685

 F1-mic 0.6679,  F1-mac 0.3959
meta,dgl,1,1563,79.3659,0.6679

 F1-mic 0.6682,  F1-mac 0.3960
meta,dgl,1,1564,79.4164,0.6682

 F1-mic 0.6685,  F1-mac 0.3966
new best val f1: 0.6685265178785698
meta,dgl,1,1565,79.4671,0.6685

 F1-mic 0.6683,  F1-mac 0.3964
meta,dgl,1,1566,79.5181,0.6683

 F1-mic 0.6686,  F1-mac 0.3965
new best val f1: 0.6685985121190304
meta,dgl,1,1567,79.5686,0.6686

 F1-mic 0.6685,  F1-mac 0.3966
meta,dgl,1,1568,79.6192,0.6685

 F1-mic 0.6688,  F1-mac 0.3968
new best val f1: 0.6687784977201824
meta,dgl,1,1569,79.6697,0.6688

epoch:1571/50, Iteration 32/32:training loss 1.0403209924697876
Train F1-mic 0.6689, Train F1-mac 0.3967
 F1-mic 0.6688,  F1-mac 0.3969
new best val f1: 0.6688444924406047
meta,dgl,1,1570,79.7201,0.6688

 F1-mic 0.6689,  F1-mac 0.3969
new best val f1: 0.6688564914806815
meta,dgl,1,1571,79.7708,0.6689

 F1-mic 0.6693,  F1-mac 0.3973
new best val f1: 0.6692764578833693
meta,dgl,1,1572,79.8214,0.6693

 F1-mic 0.6692,  F1-mac 0.3972
meta,dgl,1,1573,79.8717,0.6692

 F1-mic 0.6691,  F1-mac 0.3973
meta,dgl,1,1574,79.9223,0.6691

 F1-mic 0.6695,  F1-mac 0.3976
new best val f1: 0.6695404367650588
meta,dgl,1,1575,79.9727,0.6695

 F1-mic 0.6694,  F1-mac 0.3977
meta,dgl,1,1576,80.0233,0.6694

 F1-mic 0.6696,  F1-mac 0.3977
new best val f1: 0.6695644348452123
meta,dgl,1,1577,80.0741,0.6696

 F1-mic 0.6697,  F1-mac 0.3980
new best val f1: 0.6697324214062875
meta,dgl,1,1578,80.1245,0.6697

 F1-mic 0.6699,  F1-mac 0.3982
new best val f1: 0.6698884089272858
meta,dgl,1,1579,80.1748,0.6699

epoch:1581/50, Iteration 32/32:training loss 1.0370728969573975
Train F1-mic 0.6699, Train F1-mac 0.3980
 F1-mic 0.6699,  F1-mac 0.3981
meta,dgl,1,1580,80.2255,0.6699

 F1-mic 0.6699,  F1-mac 0.3982
new best val f1: 0.6699304055675546
meta,dgl,1,1581,80.2760,0.6699

 F1-mic 0.6705,  F1-mac 0.3988
new best val f1: 0.6705243580513559
meta,dgl,1,1582,80.3266,0.6705

 F1-mic 0.6701,  F1-mac 0.3987
meta,dgl,1,1583,80.3772,0.6701

 F1-mic 0.6706,  F1-mac 0.3989
new best val f1: 0.6705903527717783
meta,dgl,1,1584,80.4278,0.6706

 F1-mic 0.6706,  F1-mac 0.3990
new best val f1: 0.6706083513318934
meta,dgl,1,1585,80.4784,0.6706

 F1-mic 0.6703,  F1-mac 0.3992
meta,dgl,1,1586,80.5291,0.6703

 F1-mic 0.6712,  F1-mac 0.3994
new best val f1: 0.6711543076553875
meta,dgl,1,1587,80.5798,0.6712

 F1-mic 0.6707,  F1-mac 0.3994
meta,dgl,1,1588,80.6304,0.6707

 F1-mic 0.6707,  F1-mac 0.3995
meta,dgl,1,1589,80.6808,0.6707

epoch:1591/50, Iteration 32/32:training loss 1.033831000328064
Train F1-mic 0.6707, Train F1-mac 0.3994
 F1-mic 0.6716,  F1-mac 0.4001
new best val f1: 0.6715502759779217
meta,dgl,1,1590,80.7314,0.6716

 F1-mic 0.6710,  F1-mac 0.3999
meta,dgl,1,1591,80.7820,0.6710

 F1-mic 0.6711,  F1-mac 0.4000
meta,dgl,1,1592,80.8324,0.6711

 F1-mic 0.6721,  F1-mac 0.4007
new best val f1: 0.6720842332613391
meta,dgl,1,1593,80.8828,0.6721

 F1-mic 0.6708,  F1-mac 0.4003
meta,dgl,1,1594,80.9334,0.6708

 F1-mic 0.6721,  F1-mac 0.4008
meta,dgl,1,1595,80.9838,0.6721

 F1-mic 0.6720,  F1-mac 0.4009
meta,dgl,1,1596,81.0344,0.6720

 F1-mic 0.6712,  F1-mac 0.4007
meta,dgl,1,1597,81.0849,0.6712

 F1-mic 0.6726,  F1-mac 0.4015
new best val f1: 0.6726301895848332
meta,dgl,1,1598,81.1354,0.6726

 F1-mic 0.6720,  F1-mac 0.4013
meta,dgl,1,1599,81.1860,0.6720

epoch:1601/50, Iteration 32/32:training loss 1.0305984020233154
Train F1-mic 0.6720, Train F1-mac 0.4010
 F1-mic 0.6717,  F1-mac 0.4012
meta,dgl,1,1600,81.2366,0.6717

 F1-mic 0.6731,  F1-mac 0.4021
new best val f1: 0.6730981521478282
meta,dgl,1,1601,81.2871,0.6731

 F1-mic 0.6719,  F1-mac 0.4015
meta,dgl,1,1602,81.3377,0.6719

 F1-mic 0.6725,  F1-mac 0.4019
meta,dgl,1,1603,81.3882,0.6725

 F1-mic 0.6731,  F1-mac 0.4024
new best val f1: 0.6731401487880969
meta,dgl,1,1604,81.4387,0.6731

 F1-mic 0.6722,  F1-mac 0.4020
meta,dgl,1,1605,81.4892,0.6722

 F1-mic 0.6733,  F1-mac 0.4025
new best val f1: 0.6732601391888648
meta,dgl,1,1606,81.5395,0.6733

 F1-mic 0.6731,  F1-mac 0.4025
meta,dgl,1,1607,81.5900,0.6731

 F1-mic 0.6727,  F1-mac 0.4024
meta,dgl,1,1608,81.6405,0.6727

 F1-mic 0.6737,  F1-mac 0.4031
new best val f1: 0.6737401007919367
meta,dgl,1,1609,81.6911,0.6737

epoch:1611/50, Iteration 32/32:training loss 1.027374267578125
Train F1-mic 0.6737, Train F1-mac 0.4028
 F1-mic 0.6731,  F1-mac 0.4027
meta,dgl,1,1610,81.7416,0.6731

 F1-mic 0.6732,  F1-mac 0.4029
meta,dgl,1,1611,81.7921,0.6732

 F1-mic 0.6740,  F1-mac 0.4033
new best val f1: 0.6739500839932805
meta,dgl,1,1612,81.8426,0.6740

 F1-mic 0.6736,  F1-mac 0.4031
meta,dgl,1,1613,81.8931,0.6736

 F1-mic 0.6736,  F1-mac 0.4035
meta,dgl,1,1614,81.9437,0.6736

 F1-mic 0.6741,  F1-mac 0.4036
new best val f1: 0.6741180705543557
meta,dgl,1,1615,81.9942,0.6741

 F1-mic 0.6738,  F1-mac 0.4035
meta,dgl,1,1616,82.0447,0.6738

 F1-mic 0.6739,  F1-mac 0.4040
meta,dgl,1,1617,82.0951,0.6739

 F1-mic 0.6747,  F1-mac 0.4042
new best val f1: 0.6747120230381569
meta,dgl,1,1618,82.1455,0.6747

 F1-mic 0.6739,  F1-mac 0.4038
meta,dgl,1,1619,82.1959,0.6739

epoch:1621/50, Iteration 32/32:training loss 1.0241550207138062
Train F1-mic 0.6738, Train F1-mac 0.4037
 F1-mic 0.6744,  F1-mac 0.4043
meta,dgl,1,1620,82.2464,0.6744

 F1-mic 0.6748,  F1-mac 0.4047
new best val f1: 0.6748320134389248
meta,dgl,1,1621,82.2968,0.6748

 F1-mic 0.6747,  F1-mac 0.4045
meta,dgl,1,1622,82.3473,0.6747

 F1-mic 0.6745,  F1-mac 0.4044
meta,dgl,1,1623,82.3978,0.6745

 F1-mic 0.6750,  F1-mac 0.4052
new best val f1: 0.675
meta,dgl,1,1624,82.4484,0.6750

 F1-mic 0.6752,  F1-mac 0.4051
new best val f1: 0.6751859851211903
meta,dgl,1,1625,82.4989,0.6752

 F1-mic 0.6747,  F1-mac 0.4048
meta,dgl,1,1626,82.5495,0.6747

 F1-mic 0.6755,  F1-mac 0.4061
new best val f1: 0.6754619630429566
meta,dgl,1,1627,82.6000,0.6755

 F1-mic 0.6755,  F1-mac 0.4065
new best val f1: 0.6755099592032637
meta,dgl,1,1628,82.6512,0.6755

 F1-mic 0.6751,  F1-mac 0.4061
meta,dgl,1,1629,82.7017,0.6751

epoch:1631/50, Iteration 32/32:training loss 1.020940899848938
Train F1-mic 0.6750, Train F1-mac 0.4056
 F1-mic 0.6757,  F1-mac 0.4064
new best val f1: 0.6757379409647228
meta,dgl,1,1630,82.7522,0.6757

 F1-mic 0.6757,  F1-mac 0.4068
meta,dgl,1,1631,82.8028,0.6757

 F1-mic 0.6756,  F1-mac 0.4068
meta,dgl,1,1632,82.8532,0.6756

 F1-mic 0.6762,  F1-mac 0.4071
new best val f1: 0.6762059035277178
meta,dgl,1,1633,82.9037,0.6762

 F1-mic 0.6758,  F1-mac 0.4071
meta,dgl,1,1634,82.9542,0.6758

 F1-mic 0.6763,  F1-mac 0.4076
new best val f1: 0.6762898968082554
meta,dgl,1,1635,83.0048,0.6763

 F1-mic 0.6766,  F1-mac 0.4075
new best val f1: 0.6765838732901368
meta,dgl,1,1636,83.0553,0.6766

 F1-mic 0.6758,  F1-mac 0.4072
meta,dgl,1,1637,83.1058,0.6758

 F1-mic 0.6771,  F1-mac 0.4082
new best val f1: 0.6771358291336693
meta,dgl,1,1638,83.1563,0.6771

 F1-mic 0.6766,  F1-mac 0.4079
meta,dgl,1,1639,83.2067,0.6766

epoch:1641/50, Iteration 32/32:training loss 1.017727255821228
Train F1-mic 0.6763, Train F1-mac 0.4073
 F1-mic 0.6763,  F1-mac 0.4077
meta,dgl,1,1640,83.2573,0.6763

 F1-mic 0.6775,  F1-mac 0.4086
new best val f1: 0.6775257979361651
meta,dgl,1,1641,83.3078,0.6775

 F1-mic 0.6769,  F1-mac 0.4083
meta,dgl,1,1642,83.3582,0.6769

 F1-mic 0.6767,  F1-mac 0.4082
meta,dgl,1,1643,83.4087,0.6767

 F1-mic 0.6777,  F1-mac 0.4089
new best val f1: 0.6776877849772018
meta,dgl,1,1644,83.4591,0.6777

 F1-mic 0.6771,  F1-mac 0.4089
meta,dgl,1,1645,83.5096,0.6771

 F1-mic 0.6773,  F1-mac 0.4087
meta,dgl,1,1646,83.5600,0.6773

 F1-mic 0.6777,  F1-mac 0.4091
new best val f1: 0.6777297816174706
meta,dgl,1,1647,83.6106,0.6777

 F1-mic 0.6776,  F1-mac 0.4094
meta,dgl,1,1648,83.6611,0.6776

 F1-mic 0.6777,  F1-mac 0.4093
meta,dgl,1,1649,83.7117,0.6777

epoch:1651/50, Iteration 32/32:training loss 1.0145283937454224
Train F1-mic 0.6774, Train F1-mac 0.4086
 F1-mic 0.6779,  F1-mac 0.4096
new best val f1: 0.6779277657787377
meta,dgl,1,1650,83.7622,0.6779

 F1-mic 0.6778,  F1-mac 0.4095
meta,dgl,1,1651,83.8126,0.6778

 F1-mic 0.6783,  F1-mac 0.4100
new best val f1: 0.678263738900888
meta,dgl,1,1652,83.8631,0.6783

 F1-mic 0.6780,  F1-mac 0.4099
meta,dgl,1,1653,83.9137,0.6780

 F1-mic 0.6783,  F1-mac 0.4100
meta,dgl,1,1654,83.9640,0.6783

 F1-mic 0.6784,  F1-mac 0.4100
new best val f1: 0.6783537317014638
meta,dgl,1,1655,84.0152,0.6784

 F1-mic 0.6785,  F1-mac 0.4105
new best val f1: 0.6784797216222702
meta,dgl,1,1656,84.0657,0.6785

 F1-mic 0.6787,  F1-mac 0.4107
new best val f1: 0.6787017038636909
meta,dgl,1,1657,84.1184,0.6787

 F1-mic 0.6787,  F1-mac 0.4106
meta,dgl,1,1658,84.1689,0.6787

 F1-mic 0.6786,  F1-mac 0.4108
meta,dgl,1,1659,84.2194,0.6786

epoch:1661/50, Iteration 32/32:training loss 1.0113354921340942
Train F1-mic 0.6784, Train F1-mac 0.4103
 F1-mic 0.6791,  F1-mac 0.4111
new best val f1: 0.6791336693064555
meta,dgl,1,1660,84.2699,0.6791

 F1-mic 0.6789,  F1-mac 0.4109
meta,dgl,1,1661,84.3203,0.6789

 F1-mic 0.6789,  F1-mac 0.4112
meta,dgl,1,1662,84.3709,0.6789

 F1-mic 0.6797,  F1-mac 0.4118
new best val f1: 0.6796796256299497
meta,dgl,1,1663,84.4212,0.6797

 F1-mic 0.6791,  F1-mac 0.4113
meta,dgl,1,1664,84.4718,0.6791

 F1-mic 0.6793,  F1-mac 0.4117
meta,dgl,1,1665,84.5223,0.6793

 F1-mic 0.6799,  F1-mac 0.4124
new best val f1: 0.6799496040316775
meta,dgl,1,1666,84.5728,0.6799

 F1-mic 0.6795,  F1-mac 0.4119
meta,dgl,1,1667,84.6234,0.6795

 F1-mic 0.6797,  F1-mac 0.4120
meta,dgl,1,1668,84.6737,0.6797

 F1-mic 0.6802,  F1-mac 0.4126
new best val f1: 0.6801715862730981
meta,dgl,1,1669,84.7241,0.6802

epoch:1671/50, Iteration 32/32:training loss 1.0081450939178467
Train F1-mic 0.6799, Train F1-mac 0.4124
 F1-mic 0.6798,  F1-mac 0.4126
meta,dgl,1,1670,84.7754,0.6798

 F1-mic 0.6800,  F1-mac 0.4124
meta,dgl,1,1671,84.8259,0.6800

 F1-mic 0.6801,  F1-mac 0.4128
meta,dgl,1,1672,84.8763,0.6801

 F1-mic 0.6802,  F1-mac 0.4130
new best val f1: 0.6801835853131749
meta,dgl,1,1673,84.9268,0.6802

 F1-mic 0.6804,  F1-mac 0.4128
new best val f1: 0.6804355651547876
meta,dgl,1,1674,84.9773,0.6804

 F1-mic 0.6804,  F1-mac 0.4132
meta,dgl,1,1675,85.0278,0.6804

 F1-mic 0.6806,  F1-mac 0.4134
new best val f1: 0.680591552675786
meta,dgl,1,1676,85.0782,0.6806

 F1-mic 0.6808,  F1-mac 0.4134
new best val f1: 0.6807715382769378
meta,dgl,1,1677,85.1288,0.6808

 F1-mic 0.6807,  F1-mac 0.4136
meta,dgl,1,1678,85.1794,0.6807

 F1-mic 0.6809,  F1-mac 0.4137
new best val f1: 0.6808855291576674
meta,dgl,1,1679,85.2299,0.6809

epoch:1681/50, Iteration 32/32:training loss 1.004962682723999
Train F1-mic 0.6806, Train F1-mac 0.4137
 F1-mic 0.6812,  F1-mac 0.4140
new best val f1: 0.6811555075593952
meta,dgl,1,1680,85.2804,0.6812

 F1-mic 0.6811,  F1-mac 0.4139
meta,dgl,1,1681,85.3309,0.6811

 F1-mic 0.6812,  F1-mac 0.4143
new best val f1: 0.6812335013198945
meta,dgl,1,1682,85.3813,0.6812

 F1-mic 0.6816,  F1-mac 0.4144
new best val f1: 0.6815514758819294
meta,dgl,1,1683,85.4318,0.6816

 F1-mic 0.6814,  F1-mac 0.4144
meta,dgl,1,1684,85.4824,0.6814

 F1-mic 0.6814,  F1-mac 0.4147
meta,dgl,1,1685,85.5329,0.6814

 F1-mic 0.6820,  F1-mac 0.4150
new best val f1: 0.6820494360451164
meta,dgl,1,1686,85.5833,0.6820

 F1-mic 0.6816,  F1-mac 0.4149
meta,dgl,1,1687,85.6341,0.6816

 F1-mic 0.6818,  F1-mac 0.4150
meta,dgl,1,1688,85.6846,0.6818

 F1-mic 0.6823,  F1-mac 0.4154
new best val f1: 0.6822954163666907
meta,dgl,1,1689,85.7351,0.6823

epoch:1691/50, Iteration 32/32:training loss 1.001787543296814
Train F1-mic 0.6821, Train F1-mac 0.4154
 F1-mic 0.6821,  F1-mac 0.4154
meta,dgl,1,1690,85.7854,0.6821

 F1-mic 0.6821,  F1-mac 0.4155
meta,dgl,1,1691,85.8358,0.6821

 F1-mic 0.6827,  F1-mac 0.4158
new best val f1: 0.6826853851691864
meta,dgl,1,1692,85.8894,0.6827

 F1-mic 0.6821,  F1-mac 0.4155
meta,dgl,1,1693,85.9399,0.6821

 F1-mic 0.6826,  F1-mac 0.4159
meta,dgl,1,1694,85.9904,0.6826

 F1-mic 0.6829,  F1-mac 0.4161
new best val f1: 0.6828713702903768
meta,dgl,1,1695,86.0409,0.6829

 F1-mic 0.6820,  F1-mac 0.4158
meta,dgl,1,1696,86.0915,0.6820

 F1-mic 0.6833,  F1-mac 0.4165
new best val f1: 0.6833033357331414
meta,dgl,1,1697,86.1421,0.6833

 F1-mic 0.6829,  F1-mac 0.4162
meta,dgl,1,1698,86.1924,0.6829

 F1-mic 0.6824,  F1-mac 0.4162
meta,dgl,1,1699,86.2429,0.6824

epoch:1701/50, Iteration 32/32:training loss 0.9986252784729004
Train F1-mic 0.6823, Train F1-mac 0.4165
 F1-mic 0.6838,  F1-mac 0.4170
new best val f1: 0.6837652987760979
meta,dgl,1,1700,86.2936,0.6838

 F1-mic 0.6830,  F1-mac 0.4166
meta,dgl,1,1701,86.3441,0.6830

 F1-mic 0.6829,  F1-mac 0.4166
meta,dgl,1,1702,86.3946,0.6829

 F1-mic 0.6842,  F1-mac 0.4174
new best val f1: 0.6841972642188625
meta,dgl,1,1703,86.4452,0.6842

 F1-mic 0.6829,  F1-mac 0.4168
meta,dgl,1,1704,86.4957,0.6829

 F1-mic 0.6834,  F1-mac 0.4170
meta,dgl,1,1705,86.5462,0.6834

 F1-mic 0.6846,  F1-mac 0.4179
new best val f1: 0.6845572354211663
meta,dgl,1,1706,86.5968,0.6846

 F1-mic 0.6831,  F1-mac 0.4174
meta,dgl,1,1707,86.6473,0.6831

 F1-mic 0.6841,  F1-mac 0.4176
meta,dgl,1,1708,86.6979,0.6841

 F1-mic 0.6845,  F1-mac 0.4181
meta,dgl,1,1709,86.7485,0.6845

epoch:1711/50, Iteration 32/32:training loss 0.995463490486145
Train F1-mic 0.6844, Train F1-mac 0.4187
 F1-mic 0.6836,  F1-mac 0.4179
meta,dgl,1,1710,86.7991,0.6836

 F1-mic 0.6846,  F1-mac 0.4181
new best val f1: 0.6845992320614351
meta,dgl,1,1711,86.8494,0.6846

 F1-mic 0.6843,  F1-mac 0.4184
meta,dgl,1,1712,86.9006,0.6843

 F1-mic 0.6841,  F1-mac 0.4184
meta,dgl,1,1713,86.9512,0.6841

 F1-mic 0.6851,  F1-mac 0.4187
new best val f1: 0.6850611951043917
meta,dgl,1,1714,87.0017,0.6851

 F1-mic 0.6845,  F1-mac 0.4185
meta,dgl,1,1715,87.0523,0.6845

 F1-mic 0.6845,  F1-mac 0.4189
meta,dgl,1,1716,87.1028,0.6845

 F1-mic 0.6854,  F1-mac 0.4191
new best val f1: 0.6853851691864651
meta,dgl,1,1717,87.1532,0.6854

 F1-mic 0.6848,  F1-mac 0.4191
meta,dgl,1,1718,87.2036,0.6848

 F1-mic 0.6848,  F1-mac 0.4193
meta,dgl,1,1719,87.2540,0.6848

epoch:1721/50, Iteration 32/32:training loss 0.9923112988471985
Train F1-mic 0.6847, Train F1-mac 0.4200
 F1-mic 0.6859,  F1-mac 0.4195
new best val f1: 0.6858771298296137
meta,dgl,1,1720,87.3046,0.6859

 F1-mic 0.6848,  F1-mac 0.4195
meta,dgl,1,1721,87.3552,0.6848

 F1-mic 0.6854,  F1-mac 0.4198
meta,dgl,1,1722,87.4057,0.6854

 F1-mic 0.6864,  F1-mac 0.4202
new best val f1: 0.6864170866330693
meta,dgl,1,1723,87.4562,0.6864

 F1-mic 0.6850,  F1-mac 0.4198
meta,dgl,1,1724,87.5068,0.6850

 F1-mic 0.6858,  F1-mac 0.4202
meta,dgl,1,1725,87.5585,0.6858

 F1-mic 0.6868,  F1-mac 0.4207
new best val f1: 0.6868430525557956
meta,dgl,1,1726,87.6090,0.6868

 F1-mic 0.6851,  F1-mac 0.4201
meta,dgl,1,1727,87.6604,0.6851

 F1-mic 0.6864,  F1-mac 0.4207
meta,dgl,1,1728,87.7108,0.6864

 F1-mic 0.6870,  F1-mac 0.4211
new best val f1: 0.6869510439164866
meta,dgl,1,1729,87.7613,0.6870

epoch:1731/50, Iteration 32/32:training loss 0.9891765117645264
Train F1-mic 0.6868, Train F1-mac 0.4220
 F1-mic 0.6856,  F1-mac 0.4207
meta,dgl,1,1730,87.8117,0.6856

 F1-mic 0.6868,  F1-mac 0.4210
meta,dgl,1,1731,87.8620,0.6868

 F1-mic 0.6872,  F1-mac 0.4214
new best val f1: 0.6871550275977921
meta,dgl,1,1732,87.9133,0.6872

 F1-mic 0.6860,  F1-mac 0.4213
meta,dgl,1,1733,87.9637,0.6860

 F1-mic 0.6875,  F1-mac 0.4217
new best val f1: 0.687455003599712
meta,dgl,1,1734,88.0142,0.6875

 F1-mic 0.6872,  F1-mac 0.4217
meta,dgl,1,1735,88.0647,0.6872

 F1-mic 0.6867,  F1-mac 0.4218
meta,dgl,1,1736,88.1153,0.6867

 F1-mic 0.6874,  F1-mac 0.4221
meta,dgl,1,1737,88.1659,0.6874

 F1-mic 0.6876,  F1-mac 0.4222
new best val f1: 0.6876049916006719
meta,dgl,1,1738,88.2163,0.6876

 F1-mic 0.6871,  F1-mac 0.4222
meta,dgl,1,1739,88.2668,0.6871

epoch:1741/50, Iteration 32/32:training loss 0.9860456585884094
Train F1-mic 0.6867, Train F1-mac 0.4228
 F1-mic 0.6880,  F1-mac 0.4226
new best val f1: 0.6880009599232061
meta,dgl,1,1740,88.3176,0.6880

 F1-mic 0.6878,  F1-mac 0.4227
meta,dgl,1,1741,88.3684,0.6878

 F1-mic 0.6875,  F1-mac 0.4228
meta,dgl,1,1742,88.4189,0.6875

 F1-mic 0.6883,  F1-mac 0.4236
new best val f1: 0.6882529397648188
meta,dgl,1,1743,88.4694,0.6883

 F1-mic 0.6882,  F1-mac 0.4230
meta,dgl,1,1744,88.5199,0.6882

 F1-mic 0.6878,  F1-mac 0.4232
meta,dgl,1,1745,88.5704,0.6878

 F1-mic 0.6886,  F1-mac 0.4242
new best val f1: 0.6886309095272378
meta,dgl,1,1746,88.6208,0.6886

 F1-mic 0.6886,  F1-mac 0.4244
new best val f1: 0.688648908087353
meta,dgl,1,1747,88.6772,0.6886

 F1-mic 0.6882,  F1-mac 0.4243
meta,dgl,1,1748,88.7278,0.6882

 F1-mic 0.6888,  F1-mac 0.4245
new best val f1: 0.688828893688505
meta,dgl,1,1749,88.7786,0.6888

epoch:1751/50, Iteration 32/32:training loss 0.9829199314117432
Train F1-mic 0.6885, Train F1-mac 0.4247
 F1-mic 0.6890,  F1-mac 0.4249
new best val f1: 0.689026877849772
meta,dgl,1,1750,88.8292,0.6890

 F1-mic 0.6885,  F1-mac 0.4246
meta,dgl,1,1751,88.8798,0.6885

 F1-mic 0.6892,  F1-mac 0.4255
new best val f1: 0.6892308615310775
meta,dgl,1,1752,88.9305,0.6892

 F1-mic 0.6894,  F1-mac 0.4262
new best val f1: 0.689404847612191
meta,dgl,1,1753,88.9811,0.6894

 F1-mic 0.6888,  F1-mac 0.4254
meta,dgl,1,1754,89.0318,0.6888

 F1-mic 0.6892,  F1-mac 0.4256
meta,dgl,1,1755,89.0824,0.6892

 F1-mic 0.6899,  F1-mac 0.4264
new best val f1: 0.6898848092152627
meta,dgl,1,1756,89.1331,0.6899

 F1-mic 0.6894,  F1-mac 0.4261
meta,dgl,1,1757,89.1838,0.6894

 F1-mic 0.6891,  F1-mac 0.4261
meta,dgl,1,1758,89.2342,0.6891

 F1-mic 0.6903,  F1-mac 0.4272
new best val f1: 0.6903287736981042
meta,dgl,1,1759,89.2850,0.6903

epoch:1761/50, Iteration 32/32:training loss 0.9798160195350647
Train F1-mic 0.6901, Train F1-mac 0.4269
 F1-mic 0.6896,  F1-mac 0.4271
meta,dgl,1,1760,89.3354,0.6896

 F1-mic 0.6896,  F1-mac 0.4270
meta,dgl,1,1761,89.3859,0.6896

 F1-mic 0.6905,  F1-mac 0.4275
new best val f1: 0.6904607631389489
meta,dgl,1,1762,89.4364,0.6905

 F1-mic 0.6898,  F1-mac 0.4276
meta,dgl,1,1763,89.4870,0.6898

 F1-mic 0.6903,  F1-mac 0.4277
meta,dgl,1,1764,89.5375,0.6903

 F1-mic 0.6906,  F1-mac 0.4281
new best val f1: 0.690598752099832
meta,dgl,1,1765,89.5882,0.6906

 F1-mic 0.6905,  F1-mac 0.4281
meta,dgl,1,1766,89.6391,0.6905

 F1-mic 0.6905,  F1-mac 0.4281
meta,dgl,1,1767,89.6895,0.6905

 F1-mic 0.6909,  F1-mac 0.4284
new best val f1: 0.6908747300215983
meta,dgl,1,1768,89.7400,0.6909

 F1-mic 0.6911,  F1-mac 0.4289
new best val f1: 0.6910847132229422
meta,dgl,1,1769,89.7905,0.6911

epoch:1771/50, Iteration 32/32:training loss 0.9767128825187683
Train F1-mic 0.6908, Train F1-mac 0.4283
 F1-mic 0.6908,  F1-mac 0.4284
meta,dgl,1,1770,89.8411,0.6908

 F1-mic 0.6913,  F1-mac 0.4288
new best val f1: 0.6912706983441325
meta,dgl,1,1771,89.8915,0.6913

 F1-mic 0.6913,  F1-mac 0.4291
new best val f1: 0.691324694024478
meta,dgl,1,1772,89.9480,0.6913

 F1-mic 0.6911,  F1-mac 0.4288
meta,dgl,1,1773,89.9987,0.6911

 F1-mic 0.6916,  F1-mac 0.4292
new best val f1: 0.6915586753059755
meta,dgl,1,1774,90.0493,0.6916

 F1-mic 0.6916,  F1-mac 0.4296
new best val f1: 0.6915826733861291
meta,dgl,1,1775,90.0998,0.6916

 F1-mic 0.6915,  F1-mac 0.4294
meta,dgl,1,1776,90.1504,0.6915

 F1-mic 0.6919,  F1-mac 0.4295
new best val f1: 0.6918586513078954
meta,dgl,1,1777,90.2009,0.6919

 F1-mic 0.6918,  F1-mac 0.4300
meta,dgl,1,1778,90.2512,0.6918

 F1-mic 0.6920,  F1-mac 0.4298
new best val f1: 0.6919606431485481
meta,dgl,1,1779,90.3057,0.6920

epoch:1781/50, Iteration 32/32:training loss 0.97361820936203
Train F1-mic 0.6917, Train F1-mac 0.4294
 F1-mic 0.6920,  F1-mac 0.4297
new best val f1: 0.6919726421886249
meta,dgl,1,1780,90.3562,0.6920

 F1-mic 0.6921,  F1-mac 0.4301
new best val f1: 0.6921346292296616
meta,dgl,1,1781,90.4066,0.6921

 F1-mic 0.6923,  F1-mac 0.4304
new best val f1: 0.6923026157907367
meta,dgl,1,1782,90.4579,0.6923

 F1-mic 0.6923,  F1-mac 0.4300
meta,dgl,1,1783,90.5083,0.6923

 F1-mic 0.6925,  F1-mac 0.4304
new best val f1: 0.6925125989920806
meta,dgl,1,1784,90.5589,0.6925

 F1-mic 0.6926,  F1-mac 0.4307
new best val f1: 0.6925605951523878
meta,dgl,1,1785,90.6095,0.6926

 F1-mic 0.6928,  F1-mac 0.4307
new best val f1: 0.6927885769138469
meta,dgl,1,1786,90.6600,0.6928

 F1-mic 0.6927,  F1-mac 0.4308
meta,dgl,1,1787,90.7106,0.6927

 F1-mic 0.6929,  F1-mac 0.4310
new best val f1: 0.6929385649148068
meta,dgl,1,1788,90.7610,0.6929

 F1-mic 0.6930,  F1-mac 0.4310
new best val f1: 0.692986561075114
meta,dgl,1,1789,90.8114,0.6930

epoch:1791/50, Iteration 32/32:training loss 0.9705402851104736
Train F1-mic 0.6928, Train F1-mac 0.4307
 F1-mic 0.6931,  F1-mac 0.4312
new best val f1: 0.6930885529157668
meta,dgl,1,1790,90.8619,0.6931

 F1-mic 0.6932,  F1-mac 0.4313
new best val f1: 0.6932445404367651
meta,dgl,1,1791,90.9123,0.6932

 F1-mic 0.6936,  F1-mac 0.4316
new best val f1: 0.6935685145188385
meta,dgl,1,1792,90.9628,0.6936

 F1-mic 0.6934,  F1-mac 0.4315
meta,dgl,1,1793,91.0134,0.6934

 F1-mic 0.6936,  F1-mac 0.4319
new best val f1: 0.6936345092392608
meta,dgl,1,1794,91.0639,0.6936

 F1-mic 0.6938,  F1-mac 0.4319
new best val f1: 0.6938384929205663
meta,dgl,1,1795,91.1144,0.6938

 F1-mic 0.6937,  F1-mac 0.4318
meta,dgl,1,1796,91.1650,0.6937

 F1-mic 0.6938,  F1-mac 0.4321
meta,dgl,1,1797,91.2155,0.6938

 F1-mic 0.6942,  F1-mac 0.4329
new best val f1: 0.6942464602831774
meta,dgl,1,1798,91.2659,0.6942

 F1-mic 0.6942,  F1-mac 0.4329
meta,dgl,1,1799,91.3163,0.6942

epoch:1801/50, Iteration 32/32:training loss 0.9674689769744873
Train F1-mic 0.6939, Train F1-mac 0.4323
 F1-mic 0.6939,  F1-mac 0.4330
meta,dgl,1,1800,91.3671,0.6939

 F1-mic 0.6945,  F1-mac 0.4332
new best val f1: 0.69449844012479
meta,dgl,1,1801,91.4175,0.6945

 F1-mic 0.6945,  F1-mac 0.4334
meta,dgl,1,1802,91.4681,0.6945

 F1-mic 0.6943,  F1-mac 0.4335
meta,dgl,1,1803,91.5183,0.6943

 F1-mic 0.6950,  F1-mac 0.4335
new best val f1: 0.6950143988480921
meta,dgl,1,1804,91.5695,0.6950

 F1-mic 0.6947,  F1-mac 0.4338
meta,dgl,1,1805,91.6200,0.6947

 F1-mic 0.6948,  F1-mac 0.4338
meta,dgl,1,1806,91.6710,0.6948

 F1-mic 0.6952,  F1-mac 0.4338
new best val f1: 0.6951703863690905
meta,dgl,1,1807,91.7219,0.6952

 F1-mic 0.6948,  F1-mac 0.4343
meta,dgl,1,1808,91.7724,0.6948

 F1-mic 0.6955,  F1-mac 0.4343
new best val f1: 0.6954763618910487
meta,dgl,1,1809,91.8248,0.6955

epoch:1811/50, Iteration 32/32:training loss 0.9644148349761963
Train F1-mic 0.6951, Train F1-mac 0.4340
 F1-mic 0.6954,  F1-mac 0.4347
meta,dgl,1,1810,91.8753,0.6954

 F1-mic 0.6950,  F1-mac 0.4347
meta,dgl,1,1811,91.9258,0.6950

 F1-mic 0.6960,  F1-mac 0.4350
new best val f1: 0.6959923206143509
meta,dgl,1,1812,91.9764,0.6960

 F1-mic 0.6956,  F1-mac 0.4351
meta,dgl,1,1813,92.0269,0.6956

 F1-mic 0.6953,  F1-mac 0.4351
meta,dgl,1,1814,92.0773,0.6953

 F1-mic 0.6963,  F1-mac 0.4354
new best val f1: 0.6962742980561555
meta,dgl,1,1815,92.1278,0.6963

 F1-mic 0.6959,  F1-mac 0.4357
meta,dgl,1,1816,92.1783,0.6959

 F1-mic 0.6959,  F1-mac 0.4356
meta,dgl,1,1817,92.2288,0.6959

 F1-mic 0.6964,  F1-mac 0.4359
new best val f1: 0.6964122870170386
meta,dgl,1,1818,92.2793,0.6964

 F1-mic 0.6963,  F1-mac 0.4360
meta,dgl,1,1819,92.3299,0.6963

epoch:1821/50, Iteration 32/32:training loss 0.9613578915596008
Train F1-mic 0.6960, Train F1-mac 0.4355
 F1-mic 0.6962,  F1-mac 0.4360
meta,dgl,1,1820,92.3804,0.6962

 F1-mic 0.6969,  F1-mac 0.4363
new best val f1: 0.6968742500599951
meta,dgl,1,1821,92.4310,0.6969

 F1-mic 0.6964,  F1-mac 0.4363
meta,dgl,1,1822,92.4818,0.6964

 F1-mic 0.6966,  F1-mac 0.4367
meta,dgl,1,1823,92.5323,0.6966

 F1-mic 0.6972,  F1-mac 0.4368
new best val f1: 0.6971682265418766
meta,dgl,1,1824,92.5828,0.6972

 F1-mic 0.6967,  F1-mac 0.4369
meta,dgl,1,1825,92.6334,0.6967

 F1-mic 0.6969,  F1-mac 0.4372
meta,dgl,1,1826,92.6839,0.6969

 F1-mic 0.6976,  F1-mac 0.4375
new best val f1: 0.6975881929445644
meta,dgl,1,1827,92.7344,0.6976

 F1-mic 0.6971,  F1-mac 0.4374
meta,dgl,1,1828,92.7848,0.6971

 F1-mic 0.6973,  F1-mac 0.4375
meta,dgl,1,1829,92.8353,0.6973

epoch:1831/50, Iteration 32/32:training loss 0.9583193063735962
Train F1-mic 0.6969, Train F1-mac 0.4368
 F1-mic 0.6978,  F1-mac 0.4377
new best val f1: 0.6978341732661387
meta,dgl,1,1830,92.8857,0.6978

 F1-mic 0.6975,  F1-mac 0.4379
meta,dgl,1,1831,92.9362,0.6975

 F1-mic 0.6976,  F1-mac 0.4379
meta,dgl,1,1832,92.9867,0.6976

 F1-mic 0.6981,  F1-mac 0.4381
new best val f1: 0.698110151187905
meta,dgl,1,1833,93.0372,0.6981

 F1-mic 0.6979,  F1-mac 0.4383
meta,dgl,1,1834,93.0878,0.6979

 F1-mic 0.6980,  F1-mac 0.4384
meta,dgl,1,1835,93.1382,0.6980

 F1-mic 0.6984,  F1-mac 0.4384
new best val f1: 0.698398128149748
meta,dgl,1,1836,93.1887,0.6984

 F1-mic 0.6980,  F1-mac 0.4386
meta,dgl,1,1837,93.2393,0.6980

 F1-mic 0.6986,  F1-mac 0.4388
new best val f1: 0.6986081113510919
meta,dgl,1,1838,93.2898,0.6986

 F1-mic 0.6985,  F1-mac 0.4389
meta,dgl,1,1839,93.3404,0.6985

epoch:1841/50, Iteration 32/32:training loss 0.9552901387214661
Train F1-mic 0.6982, Train F1-mac 0.4382
 F1-mic 0.6986,  F1-mac 0.4390
meta,dgl,1,1840,93.3910,0.6986

 F1-mic 0.6988,  F1-mac 0.4393
new best val f1: 0.6987700983921287
meta,dgl,1,1841,93.4415,0.6988

 F1-mic 0.6989,  F1-mac 0.4394
new best val f1: 0.6989380849532038
meta,dgl,1,1842,93.4921,0.6989

 F1-mic 0.6988,  F1-mac 0.4393
meta,dgl,1,1843,93.5425,0.6988

 F1-mic 0.6990,  F1-mac 0.4395
new best val f1: 0.6989920806335493
meta,dgl,1,1844,93.5938,0.6990

 F1-mic 0.6994,  F1-mac 0.4398
new best val f1: 0.6994420446364291
meta,dgl,1,1845,93.6444,0.6994

 F1-mic 0.6989,  F1-mac 0.4396
meta,dgl,1,1846,93.6949,0.6989

 F1-mic 0.6994,  F1-mac 0.4398
meta,dgl,1,1847,93.7454,0.6994

 F1-mic 0.6994,  F1-mac 0.4400
meta,dgl,1,1848,93.7958,0.6994

 F1-mic 0.6995,  F1-mac 0.4401
new best val f1: 0.6995200383969282
meta,dgl,1,1849,93.8461,0.6995

epoch:1851/50, Iteration 32/32:training loss 0.9522702097892761
Train F1-mic 0.6993, Train F1-mac 0.4400
 F1-mic 0.6996,  F1-mac 0.4401
new best val f1: 0.6995740340772738
meta,dgl,1,1850,93.8966,0.6996

 F1-mic 0.6997,  F1-mac 0.4405
new best val f1: 0.6997000239980802
meta,dgl,1,1851,93.9470,0.6997

 F1-mic 0.6999,  F1-mac 0.4405
new best val f1: 0.6999040076793857
meta,dgl,1,1852,93.9975,0.6999

 F1-mic 0.6998,  F1-mac 0.4405
meta,dgl,1,1853,94.0480,0.6998

 F1-mic 0.7000,  F1-mac 0.4407
new best val f1: 0.7000119990400768
meta,dgl,1,1854,94.0986,0.7000

 F1-mic 0.7003,  F1-mac 0.4409
new best val f1: 0.7002639788816895
meta,dgl,1,1855,94.1489,0.7003

 F1-mic 0.7002,  F1-mac 0.4410
meta,dgl,1,1856,94.1993,0.7002

 F1-mic 0.7003,  F1-mac 0.4411
new best val f1: 0.7003239740820735
meta,dgl,1,1857,94.2498,0.7003

 F1-mic 0.7006,  F1-mac 0.4413
new best val f1: 0.7005639548836093
meta,dgl,1,1858,94.3003,0.7006

 F1-mic 0.7006,  F1-mac 0.4414
new best val f1: 0.7005879529637629
meta,dgl,1,1859,94.3508,0.7006

epoch:1861/50, Iteration 32/32:training loss 0.9492558836936951
Train F1-mic 0.7004, Train F1-mac 0.4415
 F1-mic 0.7008,  F1-mac 0.4415
new best val f1: 0.70078593712503
meta,dgl,1,1860,94.4011,0.7008

 F1-mic 0.7006,  F1-mac 0.4418
meta,dgl,1,1861,94.4516,0.7006

 F1-mic 0.7011,  F1-mac 0.4420
new best val f1: 0.7010859131269498
meta,dgl,1,1862,94.5022,0.7011

 F1-mic 0.7011,  F1-mac 0.4421
meta,dgl,1,1863,94.5526,0.7011

 F1-mic 0.7009,  F1-mac 0.4422
meta,dgl,1,1864,94.6039,0.7009

 F1-mic 0.7015,  F1-mac 0.4426
new best val f1: 0.7015058795296376
meta,dgl,1,1865,94.6545,0.7015

 F1-mic 0.7015,  F1-mac 0.4425
meta,dgl,1,1866,94.7049,0.7015

 F1-mic 0.7012,  F1-mac 0.4429
meta,dgl,1,1867,94.7554,0.7012

 F1-mic 0.7018,  F1-mac 0.4433
new best val f1: 0.7018478521718262
meta,dgl,1,1868,94.8057,0.7018

 F1-mic 0.7018,  F1-mac 0.4431
meta,dgl,1,1869,94.8560,0.7018

epoch:1871/50, Iteration 32/32:training loss 0.9462538361549377
Train F1-mic 0.7016, Train F1-mac 0.4433
 F1-mic 0.7015,  F1-mac 0.4433
meta,dgl,1,1870,94.9065,0.7015

 F1-mic 0.7023,  F1-mac 0.4438
new best val f1: 0.7022618190544756
meta,dgl,1,1871,94.9570,0.7023

 F1-mic 0.7020,  F1-mac 0.4437
meta,dgl,1,1872,95.0076,0.7020

 F1-mic 0.7019,  F1-mac 0.4437
meta,dgl,1,1873,95.0580,0.7019

 F1-mic 0.7026,  F1-mac 0.4441
new best val f1: 0.7026157907367411
meta,dgl,1,1874,95.1087,0.7026

 F1-mic 0.7023,  F1-mac 0.4442
meta,dgl,1,1875,95.1598,0.7023

 F1-mic 0.7024,  F1-mac 0.4441
meta,dgl,1,1876,95.2104,0.7024

 F1-mic 0.7028,  F1-mac 0.4445
new best val f1: 0.702765778737701
meta,dgl,1,1877,95.2610,0.7028

 F1-mic 0.7028,  F1-mac 0.4447
new best val f1: 0.7028497720182385
meta,dgl,1,1878,95.3115,0.7028

 F1-mic 0.7027,  F1-mac 0.4448
meta,dgl,1,1879,95.3621,0.7027

epoch:1881/50, Iteration 32/32:training loss 0.9432623386383057
Train F1-mic 0.7025, Train F1-mac 0.4450
 F1-mic 0.7031,  F1-mac 0.4452
new best val f1: 0.7030957523398128
meta,dgl,1,1880,95.4126,0.7031

 F1-mic 0.7031,  F1-mac 0.4455
new best val f1: 0.7031017518598512
meta,dgl,1,1881,95.4632,0.7031

 F1-mic 0.7029,  F1-mac 0.4455
meta,dgl,1,1882,95.5137,0.7029

 F1-mic 0.7035,  F1-mac 0.4455
new best val f1: 0.7034857211423086
meta,dgl,1,1883,95.5643,0.7035

 F1-mic 0.7033,  F1-mac 0.4459
meta,dgl,1,1884,95.6149,0.7033

 F1-mic 0.7033,  F1-mac 0.4461
meta,dgl,1,1885,95.6654,0.7033

 F1-mic 0.7040,  F1-mac 0.4460
new best val f1: 0.703959683225342
meta,dgl,1,1886,95.7164,0.7040

 F1-mic 0.7036,  F1-mac 0.4462
meta,dgl,1,1887,95.7669,0.7036

 F1-mic 0.7035,  F1-mac 0.4465
meta,dgl,1,1888,95.8172,0.7035

 F1-mic 0.7044,  F1-mac 0.4463
new best val f1: 0.7043616510679146
meta,dgl,1,1889,95.8678,0.7044

epoch:1891/50, Iteration 32/32:training loss 0.9402948617935181
Train F1-mic 0.7041, Train F1-mac 0.4464
 F1-mic 0.7037,  F1-mac 0.4467
meta,dgl,1,1890,95.9183,0.7037

 F1-mic 0.7041,  F1-mac 0.4468
meta,dgl,1,1891,95.9689,0.7041

 F1-mic 0.7045,  F1-mac 0.4469
new best val f1: 0.7044996400287977
meta,dgl,1,1892,96.0195,0.7045

 F1-mic 0.7040,  F1-mac 0.4471
meta,dgl,1,1893,96.0699,0.7040

 F1-mic 0.7044,  F1-mac 0.4472
meta,dgl,1,1894,96.1204,0.7044

 F1-mic 0.7049,  F1-mac 0.4475
new best val f1: 0.7048896088312935
meta,dgl,1,1895,96.1710,0.7049

 F1-mic 0.7042,  F1-mac 0.4477
meta,dgl,1,1896,96.2215,0.7042

 F1-mic 0.7049,  F1-mac 0.4475
meta,dgl,1,1897,96.2721,0.7049

 F1-mic 0.7051,  F1-mac 0.4482
new best val f1: 0.7051415886729062
meta,dgl,1,1898,96.3226,0.7051

 F1-mic 0.7047,  F1-mac 0.4480
meta,dgl,1,1899,96.3731,0.7047

epoch:1901/50, Iteration 32/32:training loss 0.9373235702514648
Train F1-mic 0.7045, Train F1-mac 0.4482
 F1-mic 0.7053,  F1-mac 0.4480
new best val f1: 0.7052675785937125
meta,dgl,1,1900,96.4240,0.7053

 F1-mic 0.7051,  F1-mac 0.4484
meta,dgl,1,1901,96.4743,0.7051

 F1-mic 0.7052,  F1-mac 0.4486
meta,dgl,1,1902,96.5248,0.7052

 F1-mic 0.7057,  F1-mac 0.4486
new best val f1: 0.7056575473962083
meta,dgl,1,1903,96.5754,0.7057

 F1-mic 0.7053,  F1-mac 0.4488
meta,dgl,1,1904,96.6263,0.7053

 F1-mic 0.7054,  F1-mac 0.4490
meta,dgl,1,1905,96.6769,0.7054

 F1-mic 0.7062,  F1-mac 0.4489
new best val f1: 0.706167506599472
meta,dgl,1,1906,96.7273,0.7062

 F1-mic 0.7053,  F1-mac 0.4491
meta,dgl,1,1907,96.7778,0.7053

 F1-mic 0.7061,  F1-mac 0.4494
meta,dgl,1,1908,96.8282,0.7061

 F1-mic 0.7063,  F1-mac 0.4494
new best val f1: 0.7062754979601632
meta,dgl,1,1909,96.8786,0.7063

epoch:1911/50, Iteration 32/32:training loss 0.9343790411949158
Train F1-mic 0.7061, Train F1-mac 0.4496
 F1-mic 0.7058,  F1-mac 0.4498
meta,dgl,1,1910,96.9295,0.7058

 F1-mic 0.7064,  F1-mac 0.4499
new best val f1: 0.7064494840412767
meta,dgl,1,1911,96.9800,0.7064

 F1-mic 0.7066,  F1-mac 0.4501
new best val f1: 0.7066294696424286
meta,dgl,1,1912,97.0303,0.7066

 F1-mic 0.7059,  F1-mac 0.4502
meta,dgl,1,1913,97.0806,0.7059

 F1-mic 0.7069,  F1-mac 0.4504
new best val f1: 0.7069354451643869
meta,dgl,1,1914,97.1310,0.7069

 F1-mic 0.7068,  F1-mac 0.4503
meta,dgl,1,1915,97.1820,0.7068

 F1-mic 0.7063,  F1-mac 0.4508
meta,dgl,1,1916,97.2324,0.7063

 F1-mic 0.7073,  F1-mac 0.4509
new best val f1: 0.7072834173266138
meta,dgl,1,1917,97.2828,0.7073

 F1-mic 0.7071,  F1-mac 0.4514
meta,dgl,1,1918,97.3339,0.7071

 F1-mic 0.7066,  F1-mac 0.4513
meta,dgl,1,1919,97.3844,0.7066

epoch:1921/50, Iteration 32/32:training loss 0.9314473867416382
Train F1-mic 0.7065, Train F1-mac 0.4514
 F1-mic 0.7075,  F1-mac 0.4517
new best val f1: 0.7075053995680346
meta,dgl,1,1920,97.4349,0.7075

 F1-mic 0.7074,  F1-mac 0.4518
meta,dgl,1,1921,97.4853,0.7074

 F1-mic 0.7069,  F1-mac 0.4516
meta,dgl,1,1922,97.5358,0.7069

 F1-mic 0.7080,  F1-mac 0.4522
new best val f1: 0.7079733621310296
meta,dgl,1,1923,97.5863,0.7080

 F1-mic 0.7076,  F1-mac 0.4524
meta,dgl,1,1924,97.6370,0.7076

 F1-mic 0.7072,  F1-mac 0.4523
meta,dgl,1,1925,97.6874,0.7072

 F1-mic 0.7083,  F1-mac 0.4526
new best val f1: 0.7083213342932565
meta,dgl,1,1926,97.7381,0.7083

 F1-mic 0.7078,  F1-mac 0.4529
meta,dgl,1,1927,97.7887,0.7078

 F1-mic 0.7078,  F1-mac 0.4532
meta,dgl,1,1928,97.8396,0.7078

 F1-mic 0.7085,  F1-mac 0.4530
new best val f1: 0.70849532037437
meta,dgl,1,1929,97.8901,0.7085

epoch:1931/50, Iteration 32/32:training loss 0.9285321235656738
Train F1-mic 0.7082, Train F1-mac 0.4530
 F1-mic 0.7083,  F1-mac 0.4537
meta,dgl,1,1930,97.9405,0.7083

 F1-mic 0.7082,  F1-mac 0.4538
meta,dgl,1,1931,97.9910,0.7082

 F1-mic 0.7087,  F1-mac 0.4534
new best val f1: 0.7086693064554835
meta,dgl,1,1932,98.0417,0.7087

 F1-mic 0.7086,  F1-mac 0.4547
meta,dgl,1,1933,98.0923,0.7086

 F1-mic 0.7088,  F1-mac 0.4544
new best val f1: 0.7087772978161747
meta,dgl,1,1934,98.1428,0.7088

 F1-mic 0.7090,  F1-mac 0.4545
new best val f1: 0.7089572834173266
meta,dgl,1,1935,98.1934,0.7090

 F1-mic 0.7087,  F1-mac 0.4549
meta,dgl,1,1936,98.2439,0.7087

 F1-mic 0.7093,  F1-mac 0.4556
new best val f1: 0.7093172546196305
meta,dgl,1,1937,98.2945,0.7093

 F1-mic 0.7095,  F1-mac 0.4550
new best val f1: 0.7095272378209744
meta,dgl,1,1938,98.3450,0.7095

 F1-mic 0.7087,  F1-mac 0.4552
meta,dgl,1,1939,98.3954,0.7087

epoch:1941/50, Iteration 32/32:training loss 0.9256336092948914
Train F1-mic 0.7084, Train F1-mac 0.4547
 F1-mic 0.7096,  F1-mac 0.4556
new best val f1: 0.7096172306215502
meta,dgl,1,1940,98.4459,0.7096

 F1-mic 0.7101,  F1-mac 0.4558
new best val f1: 0.7101331893448524
meta,dgl,1,1941,98.4963,0.7101

 F1-mic 0.7090,  F1-mac 0.4559
meta,dgl,1,1942,98.5468,0.7090

 F1-mic 0.7098,  F1-mac 0.4559
meta,dgl,1,1943,98.5972,0.7098

 F1-mic 0.7105,  F1-mac 0.4566
new best val f1: 0.7104511639068876
meta,dgl,1,1944,98.6477,0.7105

 F1-mic 0.7092,  F1-mac 0.4562
meta,dgl,1,1945,98.6982,0.7092

 F1-mic 0.7104,  F1-mac 0.4566
meta,dgl,1,1946,98.7487,0.7104

 F1-mic 0.7104,  F1-mac 0.4567
meta,dgl,1,1947,98.7992,0.7104

 F1-mic 0.7096,  F1-mac 0.4568
meta,dgl,1,1948,98.8496,0.7096

 F1-mic 0.7108,  F1-mac 0.4570
new best val f1: 0.7108411327093832
meta,dgl,1,1949,98.8999,0.7108

epoch:1951/50, Iteration 32/32:training loss 0.9227532744407654
Train F1-mic 0.7104, Train F1-mac 0.4562
 F1-mic 0.7105,  F1-mac 0.4572
meta,dgl,1,1950,98.9504,0.7105

 F1-mic 0.7103,  F1-mac 0.4572
meta,dgl,1,1951,99.0008,0.7103

 F1-mic 0.7110,  F1-mac 0.4575
new best val f1: 0.7109971202303815
meta,dgl,1,1952,99.0514,0.7110

 F1-mic 0.7109,  F1-mac 0.4579
meta,dgl,1,1953,99.1019,0.7109

 F1-mic 0.7107,  F1-mac 0.4579
meta,dgl,1,1954,99.1522,0.7107

 F1-mic 0.7112,  F1-mac 0.4577
new best val f1: 0.7112071034317254
meta,dgl,1,1955,99.2033,0.7112

 F1-mic 0.7111,  F1-mac 0.4583
meta,dgl,1,1956,99.2538,0.7111

 F1-mic 0.7113,  F1-mac 0.4583
new best val f1: 0.7113390928725702
meta,dgl,1,1957,99.3044,0.7113

 F1-mic 0.7114,  F1-mac 0.4585
new best val f1: 0.7114470842332614
meta,dgl,1,1958,99.3550,0.7114

 F1-mic 0.7115,  F1-mac 0.4585
new best val f1: 0.7114890808735301
meta,dgl,1,1959,99.4053,0.7115

epoch:1961/50, Iteration 32/32:training loss 0.9198663830757141
Train F1-mic 0.7111, Train F1-mac 0.4577
 F1-mic 0.7114,  F1-mac 0.4589
meta,dgl,1,1960,99.4557,0.7114

 F1-mic 0.7118,  F1-mac 0.4590
new best val f1: 0.7118310535157187
meta,dgl,1,1961,99.5070,0.7118

 F1-mic 0.7119,  F1-mac 0.4591
new best val f1: 0.7118730501559876
meta,dgl,1,1962,99.5574,0.7119

 F1-mic 0.7117,  F1-mac 0.4590
meta,dgl,1,1963,99.6077,0.7117

 F1-mic 0.7120,  F1-mac 0.4592
new best val f1: 0.7119750419966403
meta,dgl,1,1964,99.6582,0.7120

 F1-mic 0.7124,  F1-mac 0.4595
new best val f1: 0.712407007439405
meta,dgl,1,1965,99.7085,0.7124

 F1-mic 0.7118,  F1-mac 0.4595
meta,dgl,1,1966,99.7597,0.7118

 F1-mic 0.7124,  F1-mac 0.4595
new best val f1: 0.7124310055195584
meta,dgl,1,1967,99.8101,0.7124

 F1-mic 0.7126,  F1-mac 0.4596
new best val f1: 0.7125629949604032
meta,dgl,1,1968,99.8605,0.7126

 F1-mic 0.7121,  F1-mac 0.4602
meta,dgl,1,1969,99.9110,0.7121

epoch:1971/50, Iteration 32/32:training loss 0.9170214533805847
Train F1-mic 0.7118, Train F1-mac 0.4599
 F1-mic 0.7128,  F1-mac 0.4599
new best val f1: 0.7128269738420925
meta,dgl,1,1970,99.9614,0.7128

 F1-mic 0.7128,  F1-mac 0.4602
meta,dgl,1,1971,100.0119,0.7128

 F1-mic 0.7124,  F1-mac 0.4605
meta,dgl,1,1972,100.0625,0.7124

 F1-mic 0.7132,  F1-mac 0.4603
new best val f1: 0.7131869450443964
meta,dgl,1,1973,100.1131,0.7132

 F1-mic 0.7128,  F1-mac 0.4611
meta,dgl,1,1974,100.1639,0.7128

 F1-mic 0.7129,  F1-mac 0.4611
meta,dgl,1,1975,100.2144,0.7129

 F1-mic 0.7135,  F1-mac 0.4614
new best val f1: 0.7134749220062395
meta,dgl,1,1976,100.2649,0.7135

 F1-mic 0.7129,  F1-mac 0.4612
meta,dgl,1,1977,100.3154,0.7129

 F1-mic 0.7133,  F1-mac 0.4618
meta,dgl,1,1978,100.3658,0.7133

 F1-mic 0.7137,  F1-mac 0.4618
new best val f1: 0.7136849052075835
meta,dgl,1,1979,100.4166,0.7137

epoch:1981/50, Iteration 32/32:training loss 0.9141682982444763
Train F1-mic 0.7133, Train F1-mac 0.4613
 F1-mic 0.7132,  F1-mac 0.4620
meta,dgl,1,1980,100.4671,0.7132

 F1-mic 0.7137,  F1-mac 0.4622
new best val f1: 0.7137029037676986
meta,dgl,1,1981,100.5173,0.7137

 F1-mic 0.7138,  F1-mac 0.4622
new best val f1: 0.7138108951283896
meta,dgl,1,1982,100.5686,0.7138

 F1-mic 0.7134,  F1-mac 0.4622
meta,dgl,1,1983,100.6190,0.7134

 F1-mic 0.7139,  F1-mac 0.4627
new best val f1: 0.7139308855291576
meta,dgl,1,1984,100.6695,0.7139

 F1-mic 0.7141,  F1-mac 0.4629
new best val f1: 0.7140988720902328
meta,dgl,1,1985,100.7200,0.7141

 F1-mic 0.7138,  F1-mac 0.4627
meta,dgl,1,1986,100.7704,0.7138

 F1-mic 0.7141,  F1-mac 0.4628
new best val f1: 0.7141108711303095
meta,dgl,1,1987,100.8210,0.7141

 F1-mic 0.7143,  F1-mac 0.4632
new best val f1: 0.7142848572114232
meta,dgl,1,1988,100.8715,0.7143

 F1-mic 0.7143,  F1-mac 0.4635
new best val f1: 0.7143388528917688
meta,dgl,1,1989,100.9220,0.7143

epoch:1991/50, Iteration 32/32:training loss 0.9113299250602722
Train F1-mic 0.7141, Train F1-mac 0.4630
 F1-mic 0.7142,  F1-mac 0.4632
meta,dgl,1,1990,100.9725,0.7142

 F1-mic 0.7146,  F1-mac 0.4638
new best val f1: 0.7145788336933044
meta,dgl,1,1991,101.0230,0.7146

 F1-mic 0.7148,  F1-mac 0.4640
new best val f1: 0.7147888168946485
meta,dgl,1,1992,101.0736,0.7148

 F1-mic 0.7143,  F1-mac 0.4636
meta,dgl,1,1993,101.1242,0.7143

 F1-mic 0.7149,  F1-mac 0.4642
new best val f1: 0.7149388048956082
meta,dgl,1,1994,101.1751,0.7149

 F1-mic 0.7150,  F1-mac 0.4651
new best val f1: 0.7150047996160307
meta,dgl,1,1995,101.2254,0.7150

 F1-mic 0.7148,  F1-mac 0.4644
meta,dgl,1,1996,101.2758,0.7148

 F1-mic 0.7151,  F1-mac 0.4645
new best val f1: 0.7151127909767219
meta,dgl,1,1997,101.3262,0.7151

 F1-mic 0.7154,  F1-mac 0.4657
new best val f1: 0.7154127669786418
meta,dgl,1,1998,101.3766,0.7154

 F1-mic 0.7151,  F1-mac 0.4652
meta,dgl,1,1999,101.4274,0.7151

training using time 419.0181930065155
Test F1-mic 0.7151, Test F1-mac 0.4652
Namespace(csv='full.csv', dataset='arctic25', gpu=0, log_dir='test', lr=0.001, n_epochs=50, n_hidden=128, online=False)
Inited proc group
14931
torch.Size([14932, 64])
Max label: tensor(32.)
----Data statistics------'
    #Nodes 500044
    #Edges 46177615
    #Classes/Labels (multi binary labels) 33
    #Train samples 166681
    #Val samples 166681
    #Test samples 166682
Running on: 0
GCN(
  (layers): ModuleList(
    (0): GraphConv(in=64, out=128, normalization=both, activation=<function relu at 0x14aa90900c20>)
    (1): GraphConv(in=128, out=33, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0.1, inplace=False)
)
Namespace(csv='full.csv', dataset='arctic25', gpu=0, log_dir='test', lr=0.001, n_epochs=50, n_hidden=128, online=False)
epoch:1/50, Iteration 32/32:training loss 35.401756286621094
Train F1-mic 0.0003, Train F1-mac 0.0004
 F1-mic 0.0293,  F1-mac 0.0096
new best val f1: 0.029283305935853897
arctic25,dgl,1,0,0.3971,0.0293

 F1-mic 0.0236,  F1-mac 0.0047
arctic25,dgl,1,1,0.4558,0.0236

 F1-mic 0.0079,  F1-mac 0.0025
arctic25,dgl,1,2,0.5153,0.0079

 F1-mic 0.1305,  F1-mac 0.0188
new best val f1: 0.13049999400055196
arctic25,dgl,1,3,0.5741,0.1305

 F1-mic 0.1856,  F1-mac 0.0275
new best val f1: 0.1856229226911124
arctic25,dgl,1,4,0.6330,0.1856

 F1-mic 0.1914,  F1-mac 0.0395
new best val f1: 0.191370393923759
arctic25,dgl,1,5,0.6915,0.1914

 F1-mic 0.2392,  F1-mac 0.0578
new best val f1: 0.23916199709626712
arctic25,dgl,1,6,0.7501,0.2392

 F1-mic 0.2068,  F1-mac 0.0545
arctic25,dgl,1,7,0.8086,0.2068

 F1-mic 0.2192,  F1-mac 0.0556
arctic25,dgl,1,8,0.8672,0.2192

 F1-mic 0.2812,  F1-mac 0.0636
new best val f1: 0.28115213400367167
arctic25,dgl,1,9,0.9257,0.2812

epoch:11/50, Iteration 32/32:training loss 8.108634948730469
Train F1-mic 0.2814, Train F1-mac 0.0638
 F1-mic 0.2847,  F1-mac 0.0702
new best val f1: 0.2847158061458346
arctic25,dgl,1,10,0.9842,0.2847

 F1-mic 0.2040,  F1-mac 0.0683
arctic25,dgl,1,11,1.0426,0.2040

 F1-mic 0.1728,  F1-mac 0.0717
arctic25,dgl,1,12,1.1012,0.1728

 F1-mic 0.2067,  F1-mac 0.0893
arctic25,dgl,1,13,1.1597,0.2067

 F1-mic 0.2624,  F1-mac 0.1014
arctic25,dgl,1,14,1.2182,0.2624

 F1-mic 0.3310,  F1-mac 0.1165
new best val f1: 0.33100754730564785
arctic25,dgl,1,15,1.2767,0.3310

 F1-mic 0.3680,  F1-mac 0.1292
new best val f1: 0.3679581478503978
arctic25,dgl,1,16,1.3352,0.3680

 F1-mic 0.4270,  F1-mac 0.1468
new best val f1: 0.4270167144622694
arctic25,dgl,1,17,1.3937,0.4270

 F1-mic 0.4314,  F1-mac 0.1407
new best val f1: 0.4314143098834907
arctic25,dgl,1,18,1.4522,0.4314

 F1-mic 0.4184,  F1-mac 0.1392
arctic25,dgl,1,19,1.5107,0.4184

epoch:21/50, Iteration 32/32:training loss 4.502664566040039
Train F1-mic 0.4190, Train F1-mac 0.1395
 F1-mic 0.3562,  F1-mac 0.1271
arctic25,dgl,1,20,1.5692,0.3562

 F1-mic 0.3308,  F1-mac 0.1207
arctic25,dgl,1,21,1.6276,0.3308

 F1-mic 0.2909,  F1-mac 0.1203
arctic25,dgl,1,22,1.6863,0.2909

 F1-mic 0.2984,  F1-mac 0.1279
arctic25,dgl,1,23,1.7447,0.2984

 F1-mic 0.3531,  F1-mac 0.1523
arctic25,dgl,1,24,1.8033,0.3531

 F1-mic 0.4198,  F1-mac 0.1751
arctic25,dgl,1,25,1.8619,0.4198

 F1-mic 0.4646,  F1-mac 0.1852
new best val f1: 0.4645852581562496
arctic25,dgl,1,26,1.9203,0.4646

 F1-mic 0.4839,  F1-mac 0.1967
new best val f1: 0.4838614847434036
arctic25,dgl,1,27,1.9788,0.4839

 F1-mic 0.5008,  F1-mac 0.2022
new best val f1: 0.5008339232790583
arctic25,dgl,1,28,2.0373,0.5008

 F1-mic 0.5258,  F1-mac 0.2126
new best val f1: 0.5257976266183512
arctic25,dgl,1,29,2.0958,0.5258

epoch:31/50, Iteration 32/32:training loss 2.595970869064331
Train F1-mic 0.5250, Train F1-mac 0.2125
 F1-mic 0.5438,  F1-mac 0.2235
new best val f1: 0.5437659735304352
arctic25,dgl,1,30,2.1543,0.5438

 F1-mic 0.5629,  F1-mac 0.2370
new best val f1: 0.562856217228015
arctic25,dgl,1,31,2.2128,0.5629

 F1-mic 0.5498,  F1-mac 0.2467
arctic25,dgl,1,32,2.2713,0.5498

 F1-mic 0.5513,  F1-mac 0.2543
arctic25,dgl,1,33,2.3298,0.5513

 F1-mic 0.5857,  F1-mac 0.2726
new best val f1: 0.5856841170612304
arctic25,dgl,1,34,2.3883,0.5857

 F1-mic 0.6090,  F1-mac 0.2866
new best val f1: 0.6090399683229143
arctic25,dgl,1,35,2.4468,0.6090

 F1-mic 0.6340,  F1-mac 0.3015
new best val f1: 0.6339976722141563
arctic25,dgl,1,36,2.5052,0.6340

 F1-mic 0.6462,  F1-mac 0.3178
new best val f1: 0.646158553413086
arctic25,dgl,1,37,2.5637,0.6462

 F1-mic 0.6673,  F1-mac 0.3314
new best val f1: 0.6673246061362355
arctic25,dgl,1,38,2.6221,0.6673

 F1-mic 0.6845,  F1-mac 0.3438
new best val f1: 0.6845130248017183
arctic25,dgl,1,39,2.6806,0.6845

epoch:41/50, Iteration 32/32:training loss 1.5729800462722778
Train F1-mic 0.6838, Train F1-mac 0.3439
 F1-mic 0.6883,  F1-mac 0.3405
new best val f1: 0.6882866776256584
arctic25,dgl,1,40,2.7390,0.6883

 F1-mic 0.7070,  F1-mac 0.3444
new best val f1: 0.7070049555440899
arctic25,dgl,1,41,2.7974,0.7070

 F1-mic 0.7250,  F1-mac 0.3645
new best val f1: 0.7249673030081233
arctic25,dgl,1,42,2.8559,0.7250

 F1-mic 0.7450,  F1-mac 0.3809
new best val f1: 0.745011458945777
arctic25,dgl,1,43,2.9145,0.7450

 F1-mic 0.7598,  F1-mac 0.3975
new best val f1: 0.7597701011506941
arctic25,dgl,1,44,2.9730,0.7598

 F1-mic 0.7691,  F1-mac 0.4170
new best val f1: 0.7691352395579607
arctic25,dgl,1,45,3.0315,0.7691

 F1-mic 0.7919,  F1-mac 0.4221
new best val f1: 0.7919451410470236
arctic25,dgl,1,46,3.0900,0.7919

 F1-mic 0.8003,  F1-mac 0.4229
new best val f1: 0.8003083716298101
arctic25,dgl,1,47,3.1484,0.8003

 F1-mic 0.8077,  F1-mac 0.4357
new best val f1: 0.8077296888686241
arctic25,dgl,1,48,3.2069,0.8077

 F1-mic 0.8045,  F1-mac 0.4447
arctic25,dgl,1,49,3.2654,0.8045

epoch:51/50, Iteration 32/32:training loss 1.1379673480987549
Train F1-mic 0.8038, Train F1-mac 0.4452
 F1-mic 0.8267,  F1-mac 0.4595
new best val f1: 0.8266999436051883
arctic25,dgl,1,50,3.3240,0.8267

 F1-mic 0.8114,  F1-mac 0.4592
arctic25,dgl,1,51,3.3823,0.8114

 F1-mic 0.8299,  F1-mac 0.4625
new best val f1: 0.8299336461045583
arctic25,dgl,1,52,3.4408,0.8299

 F1-mic 0.8196,  F1-mac 0.4551
arctic25,dgl,1,53,3.4993,0.8196

 F1-mic 0.8241,  F1-mac 0.4607
arctic25,dgl,1,54,3.5580,0.8241

 F1-mic 0.8546,  F1-mac 0.4800
new best val f1: 0.8546213748335153
arctic25,dgl,1,55,3.6165,0.8546

 F1-mic 0.8570,  F1-mac 0.4835
new best val f1: 0.8569611595733193
arctic25,dgl,1,56,3.6749,0.8570

 F1-mic 0.8507,  F1-mac 0.4871
arctic25,dgl,1,57,3.7334,0.8507

 F1-mic 0.8644,  F1-mac 0.5031
new best val f1: 0.8644484707406918
arctic25,dgl,1,58,3.7919,0.8644

 F1-mic 0.8622,  F1-mac 0.5037
arctic25,dgl,1,59,3.8503,0.8622

epoch:61/50, Iteration 32/32:training loss 0.9309833645820618
Train F1-mic 0.8619, Train F1-mac 0.5050
 F1-mic 0.8660,  F1-mac 0.5166
new best val f1: 0.8659603316494883
arctic25,dgl,1,60,3.9088,0.8660

 F1-mic 0.8729,  F1-mac 0.5365
new best val f1: 0.8728896941481383
arctic25,dgl,1,61,3.9672,0.8729

 F1-mic 0.8658,  F1-mac 0.5398
arctic25,dgl,1,62,4.0258,0.8658

 F1-mic 0.8750,  F1-mac 0.5198
new best val f1: 0.8749835015178603
arctic25,dgl,1,63,4.0843,0.8750

 F1-mic 0.8732,  F1-mac 0.5110
arctic25,dgl,1,64,4.1428,0.8732

 F1-mic 0.8814,  F1-mac 0.5227
new best val f1: 0.8813969114841435
arctic25,dgl,1,65,4.2013,0.8814

 F1-mic 0.8795,  F1-mac 0.5320
arctic25,dgl,1,66,4.2598,0.8795

 F1-mic 0.8791,  F1-mac 0.5378
arctic25,dgl,1,67,4.3183,0.8791

 F1-mic 0.8851,  F1-mac 0.5447
new best val f1: 0.8850865720353728
arctic25,dgl,1,68,4.3767,0.8851

 F1-mic 0.8889,  F1-mac 0.5668
new best val f1: 0.8889442171320238
arctic25,dgl,1,69,4.4351,0.8889

epoch:71/50, Iteration 32/32:training loss 0.8005701899528503
Train F1-mic 0.8891, Train F1-mac 0.5676
 F1-mic 0.8954,  F1-mac 0.5747
new best val f1: 0.8954476188190686
arctic25,dgl,1,70,4.4936,0.8954

 F1-mic 0.8942,  F1-mac 0.5775
arctic25,dgl,1,71,4.5520,0.8942

 F1-mic 0.8942,  F1-mac 0.5730
arctic25,dgl,1,72,4.6111,0.8942

 F1-mic 0.8968,  F1-mac 0.5712
new best val f1: 0.8968454902149002
arctic25,dgl,1,73,4.6695,0.8968

 F1-mic 0.8997,  F1-mac 0.5900
new best val f1: 0.8996592313507158
arctic25,dgl,1,74,4.7280,0.8997

 F1-mic 0.9041,  F1-mac 0.5967
new best val f1: 0.9040928234602417
arctic25,dgl,1,75,4.7865,0.9041

 F1-mic 0.9005,  F1-mac 0.5953
arctic25,dgl,1,76,4.8450,0.9005

 F1-mic 0.9060,  F1-mac 0.5988
new best val f1: 0.9059646512520848
arctic25,dgl,1,77,4.9034,0.9060

 F1-mic 0.9019,  F1-mac 0.6017
arctic25,dgl,1,78,4.9619,0.9019

 F1-mic 0.9082,  F1-mac 0.6053
new best val f1: 0.9082264431672287
arctic25,dgl,1,79,5.0204,0.9082

epoch:81/50, Iteration 32/32:training loss 0.7043634653091431
Train F1-mic 0.9082, Train F1-mac 0.6066
 F1-mic 0.9080,  F1-mac 0.6068
arctic25,dgl,1,80,5.0788,0.9080

 F1-mic 0.9102,  F1-mac 0.6110
new best val f1: 0.910200261575935
arctic25,dgl,1,81,5.1372,0.9102

 F1-mic 0.9124,  F1-mac 0.6129
new best val f1: 0.9124200573547233
arctic25,dgl,1,82,5.1956,0.9124

 F1-mic 0.9121,  F1-mac 0.6136
arctic25,dgl,1,83,5.2540,0.9121

 F1-mic 0.9111,  F1-mac 0.6149
arctic25,dgl,1,84,5.3125,0.9111

 F1-mic 0.9149,  F1-mac 0.6187
new best val f1: 0.9149458249841015
arctic25,dgl,1,85,5.3710,0.9149

 F1-mic 0.9169,  F1-mac 0.6196
new best val f1: 0.9168596489123
arctic25,dgl,1,86,5.4295,0.9169

 F1-mic 0.9160,  F1-mac 0.6197
arctic25,dgl,1,87,5.4879,0.9160

 F1-mic 0.9169,  F1-mac 0.6231
arctic25,dgl,1,88,5.5464,0.9169

 F1-mic 0.9177,  F1-mac 0.6261
new best val f1: 0.9176695743991553
arctic25,dgl,1,89,5.6048,0.9177

epoch:91/50, Iteration 32/32:training loss 0.633491575717926
Train F1-mic 0.9180, Train F1-mac 0.6279
 F1-mic 0.9186,  F1-mac 0.6299
new best val f1: 0.9185874899509245
arctic25,dgl,1,90,5.6633,0.9186

 F1-mic 0.9204,  F1-mac 0.6317
new best val f1: 0.9203753254700567
arctic25,dgl,1,91,5.7216,0.9204

 F1-mic 0.9204,  F1-mac 0.6347
arctic25,dgl,1,92,5.7801,0.9204

 F1-mic 0.9213,  F1-mac 0.6356
new best val f1: 0.9213292377101306
arctic25,dgl,1,93,5.8385,0.9213

 F1-mic 0.9226,  F1-mac 0.6363
new best val f1: 0.9226431168332513
arctic25,dgl,1,94,5.8970,0.9226

 F1-mic 0.9231,  F1-mac 0.6389
new best val f1: 0.9230510793007043
arctic25,dgl,1,95,5.9555,0.9231

 F1-mic 0.9227,  F1-mac 0.6407
arctic25,dgl,1,96,6.0139,0.9227

 F1-mic 0.9247,  F1-mac 0.6421
new best val f1: 0.9246829291705163
arctic25,dgl,1,97,6.0725,0.9247

 F1-mic 0.9264,  F1-mac 0.6451
new best val f1: 0.926350775728633
arctic25,dgl,1,98,6.1311,0.9264

 F1-mic 0.9257,  F1-mac 0.6459
arctic25,dgl,1,99,6.1895,0.9257

epoch:101/50, Iteration 32/32:training loss 0.5783616304397583
Train F1-mic 0.9261, Train F1-mac 0.6477
 F1-mic 0.9260,  F1-mac 0.6469
arctic25,dgl,1,100,6.2480,0.9260

 F1-mic 0.9268,  F1-mac 0.6490
new best val f1: 0.9268067337804922
arctic25,dgl,1,101,6.3064,0.9268

 F1-mic 0.9282,  F1-mac 0.6519
new best val f1: 0.9282046051763237
arctic25,dgl,1,102,6.3649,0.9282

 F1-mic 0.9299,  F1-mac 0.6527
new best val f1: 0.9298964495266435
arctic25,dgl,1,103,6.4233,0.9299

 F1-mic 0.9300,  F1-mac 0.6530
new best val f1: 0.9300344368318115
arctic25,dgl,1,104,6.4818,0.9300

 F1-mic 0.9293,  F1-mac 0.6527
arctic25,dgl,1,105,6.5404,0.9293

 F1-mic 0.9299,  F1-mac 0.6549
arctic25,dgl,1,106,6.5988,0.9299

 F1-mic 0.9313,  F1-mac 0.6560
new best val f1: 0.931324318162729
arctic25,dgl,1,107,6.6572,0.9313

 F1-mic 0.9319,  F1-mac 0.6579
new best val f1: 0.9318822668314515
arctic25,dgl,1,108,6.7156,0.9319

 F1-mic 0.9322,  F1-mac 0.6599
new best val f1: 0.9321762397859397
arctic25,dgl,1,109,6.7741,0.9322

epoch:111/50, Iteration 32/32:training loss 0.5356349945068359
Train F1-mic 0.9325, Train F1-mac 0.6608
 F1-mic 0.9327,  F1-mac 0.6601
new best val f1: 0.9326681945261037
arctic25,dgl,1,110,6.8325,0.9327

 F1-mic 0.9326,  F1-mac 0.6605
arctic25,dgl,1,111,6.8909,0.9326

 F1-mic 0.9334,  F1-mac 0.6627
new best val f1: 0.933448122772705
arctic25,dgl,1,112,6.9493,0.9334

 F1-mic 0.9342,  F1-mac 0.6634
new best val f1: 0.9341920543310015
arctic25,dgl,1,113,7.0078,0.9342

 F1-mic 0.9339,  F1-mac 0.6632
arctic25,dgl,1,114,7.0663,0.9339

 F1-mic 0.9345,  F1-mac 0.6646
new best val f1: 0.9345220239737944
arctic25,dgl,1,115,7.1247,0.9345

 F1-mic 0.9353,  F1-mac 0.6664
new best val f1: 0.9352839538762434
arctic25,dgl,1,116,7.1831,0.9353

 F1-mic 0.9356,  F1-mac 0.6670
new best val f1: 0.9356199229670871
arctic25,dgl,1,117,7.2415,0.9356

 F1-mic 0.9358,  F1-mac 0.6675
new best val f1: 0.9358359030969152
arctic25,dgl,1,118,7.3000,0.9358

 F1-mic 0.9360,  F1-mac 0.6689
new best val f1: 0.9359798898501338
arctic25,dgl,1,119,7.3584,0.9360

epoch:121/50, Iteration 32/32:training loss 0.5007984638214111
Train F1-mic 0.9363, Train F1-mac 0.6693
 F1-mic 0.9368,  F1-mac 0.6712
new best val f1: 0.9368318114733445
arctic25,dgl,1,120,7.4168,0.9368

 F1-mic 0.9374,  F1-mac 0.6720
new best val f1: 0.9374437551745239
arctic25,dgl,1,121,7.4754,0.9374

 F1-mic 0.9376,  F1-mac 0.6722
new best val f1: 0.9375637441355396
arctic25,dgl,1,122,7.5339,0.9376

 F1-mic 0.9377,  F1-mac 0.6730
new best val f1: 0.937713730336809
arctic25,dgl,1,123,7.5923,0.9377

 F1-mic 0.9382,  F1-mac 0.6742
new best val f1: 0.9382116845250237
arctic25,dgl,1,124,7.6508,0.9382

 F1-mic 0.9386,  F1-mac 0.6755
new best val f1: 0.9386376453366291
arctic25,dgl,1,125,7.7093,0.9386

 F1-mic 0.9393,  F1-mac 0.6762
new best val f1: 0.9392795862780624
arctic25,dgl,1,126,7.7677,0.9393

 F1-mic 0.9389,  F1-mac 0.6766
arctic25,dgl,1,127,7.8261,0.9389

 F1-mic 0.9400,  F1-mac 0.6777
new best val f1: 0.9399575239078005
arctic25,dgl,1,128,7.8848,0.9400

 F1-mic 0.9401,  F1-mac 0.6790
new best val f1: 0.9400955112129684
arctic25,dgl,1,129,7.9433,0.9401

epoch:131/50, Iteration 32/32:training loss 0.46987107396125793
Train F1-mic 0.9405, Train F1-mac 0.6789
 F1-mic 0.9404,  F1-mac 0.6801
new best val f1: 0.9404074825116089
arctic25,dgl,1,130,8.0017,0.9404

 F1-mic 0.9409,  F1-mac 0.6802
new best val f1: 0.9409174355959252
arctic25,dgl,1,131,8.0600,0.9409

 F1-mic 0.9404,  F1-mac 0.6777
arctic25,dgl,1,132,8.1186,0.9404

 F1-mic 0.9414,  F1-mac 0.6792
new best val f1: 0.9413673941997336
arctic25,dgl,1,133,8.1770,0.9414

 F1-mic 0.9416,  F1-mac 0.6819
new best val f1: 0.9415653759854093
arctic25,dgl,1,134,8.2355,0.9416

 F1-mic 0.9417,  F1-mac 0.6822
new best val f1: 0.9416793654983742
arctic25,dgl,1,135,8.2939,0.9417

 F1-mic 0.9422,  F1-mac 0.6827
new best val f1: 0.9421773196865888
arctic25,dgl,1,136,8.3523,0.9422

 F1-mic 0.9420,  F1-mac 0.6833
arctic25,dgl,1,137,8.4107,0.9420

 F1-mic 0.9429,  F1-mac 0.6834
new best val f1: 0.9429152517968347
arctic25,dgl,1,138,8.4692,0.9429

 F1-mic 0.9422,  F1-mac 0.6847
arctic25,dgl,1,139,8.5277,0.9422

epoch:141/50, Iteration 32/32:training loss 0.44480618834495544
Train F1-mic 0.9426, Train F1-mac 0.6852
 F1-mic 0.9435,  F1-mac 0.6860
new best val f1: 0.9434612015694556
arctic25,dgl,1,140,8.5861,0.9435

 F1-mic 0.9431,  F1-mac 0.6851
arctic25,dgl,1,141,8.6445,0.9431

 F1-mic 0.9435,  F1-mac 0.6848
new best val f1: 0.9434851993616588
arctic25,dgl,1,142,8.7029,0.9435

 F1-mic 0.9439,  F1-mac 0.6859
new best val f1: 0.943887162381061
arctic25,dgl,1,143,8.7614,0.9439

 F1-mic 0.9439,  F1-mac 0.6867
new best val f1: 0.9439411574135179
arctic25,dgl,1,144,8.8198,0.9439

 F1-mic 0.9445,  F1-mac 0.6880
new best val f1: 0.9444871071861389
arctic25,dgl,1,145,8.8783,0.9445

 F1-mic 0.9441,  F1-mac 0.6890
arctic25,dgl,1,146,8.9367,0.9441

 F1-mic 0.9447,  F1-mac 0.6877
new best val f1: 0.94472708510817
arctic25,dgl,1,147,8.9951,0.9447

 F1-mic 0.9445,  F1-mac 0.6875
arctic25,dgl,1,148,9.0537,0.9445

 F1-mic 0.9452,  F1-mac 0.6883
new best val f1: 0.9452490370885879
arctic25,dgl,1,149,9.1121,0.9452

epoch:151/50, Iteration 32/32:training loss 0.42309635877609253
Train F1-mic 0.9459, Train F1-mac 0.6893
 F1-mic 0.9451,  F1-mac 0.6895
arctic25,dgl,1,150,9.1705,0.9451

 F1-mic 0.9456,  F1-mac 0.6892
new best val f1: 0.9455790067313807
arctic25,dgl,1,151,9.2289,0.9456

 F1-mic 0.9455,  F1-mac 0.6901
arctic25,dgl,1,152,9.2876,0.9455

 F1-mic 0.9457,  F1-mac 0.6916
new best val f1: 0.9456749979001932
arctic25,dgl,1,153,9.3460,0.9457

 F1-mic 0.9464,  F1-mac 0.6910
new best val f1: 0.9464369278026421
arctic25,dgl,1,154,9.4045,0.9464

 F1-mic 0.9460,  F1-mac 0.6911
arctic25,dgl,1,155,9.4629,0.9460

 F1-mic 0.9467,  F1-mac 0.6916
new best val f1: 0.9467369002051811
arctic25,dgl,1,156,9.5215,0.9467

 F1-mic 0.9461,  F1-mac 0.6921
arctic25,dgl,1,157,9.5800,0.9461

 F1-mic 0.9474,  F1-mac 0.6926
new best val f1: 0.9474388356271223
arctic25,dgl,1,158,9.6385,0.9474

 F1-mic 0.9471,  F1-mac 0.6942
arctic25,dgl,1,159,9.6969,0.9471

epoch:161/50, Iteration 32/32:training loss 0.4047015607357025
Train F1-mic 0.9475, Train F1-mac 0.6943
 F1-mic 0.9477,  F1-mac 0.6943
new best val f1: 0.947690812445255
arctic25,dgl,1,160,9.7553,0.9477

 F1-mic 0.9473,  F1-mac 0.6944
arctic25,dgl,1,161,9.8137,0.9473

 F1-mic 0.9479,  F1-mac 0.6943
new best val f1: 0.9479007931270325
arctic25,dgl,1,162,9.8721,0.9479

 F1-mic 0.9483,  F1-mac 0.7073
new best val f1: 0.9482607600100791
arctic25,dgl,1,163,9.9306,0.9483

 F1-mic 0.9484,  F1-mac 0.7075
new best val f1: 0.9484167456593994
arctic25,dgl,1,164,9.9891,0.9484

 F1-mic 0.9485,  F1-mac 0.7027
new best val f1: 0.948506737380161
arctic25,dgl,1,165,10.0475,0.9485

 F1-mic 0.9486,  F1-mac 0.6969
new best val f1: 0.9486447246853289
arctic25,dgl,1,166,10.1059,0.9486

 F1-mic 0.9490,  F1-mac 0.7045
new best val f1: 0.9489686948800711
arctic25,dgl,1,167,10.1643,0.9490

 F1-mic 0.9492,  F1-mac 0.7098
new best val f1: 0.9492026733540515
arctic25,dgl,1,168,10.2228,0.9492

 F1-mic 0.9496,  F1-mac 0.7094
new best val f1: 0.9496106358215044
arctic25,dgl,1,169,10.2812,0.9496

epoch:171/50, Iteration 32/32:training loss 0.38807573914527893
Train F1-mic 0.9498, Train F1-mac 0.7108
 F1-mic 0.9493,  F1-mac 0.7102
arctic25,dgl,1,170,10.3397,0.9493

 F1-mic 0.9501,  F1-mac 0.7105
new best val f1: 0.9501145894577698
arctic25,dgl,1,171,10.3981,0.9501

 F1-mic 0.9493,  F1-mac 0.7113
arctic25,dgl,1,172,10.4568,0.9493

 F1-mic 0.9505,  F1-mac 0.7108
new best val f1: 0.9504865552369182
arctic25,dgl,1,173,10.5152,0.9505

 F1-mic 0.9497,  F1-mac 0.7124
arctic25,dgl,1,174,10.5737,0.9497

 F1-mic 0.9510,  F1-mac 0.7165
new best val f1: 0.951008507217336
arctic25,dgl,1,175,10.6324,0.9510

 F1-mic 0.9502,  F1-mac 0.7172
arctic25,dgl,1,176,10.6908,0.9502

 F1-mic 0.9510,  F1-mac 0.7168
new best val f1: 0.9510325050095392
arctic25,dgl,1,177,10.7495,0.9510

 F1-mic 0.9505,  F1-mac 0.7139
arctic25,dgl,1,178,10.8080,0.9505

 F1-mic 0.9516,  F1-mac 0.7177
new best val f1: 0.9515664558860585
arctic25,dgl,1,179,10.8664,0.9516

epoch:181/50, Iteration 32/32:training loss 0.3739117980003357
Train F1-mic 0.9517, Train F1-mac 0.7169
 F1-mic 0.9509,  F1-mac 0.7192
arctic25,dgl,1,180,10.9249,0.9509

 F1-mic 0.9517,  F1-mac 0.7184
new best val f1: 0.9517044431912264
arctic25,dgl,1,181,10.9832,0.9517

 F1-mic 0.9514,  F1-mac 0.7186
arctic25,dgl,1,182,11.0417,0.9514

 F1-mic 0.9520,  F1-mac 0.7189
new best val f1: 0.952016414489867
arctic25,dgl,1,183,11.1001,0.9520

 F1-mic 0.9518,  F1-mac 0.7192
arctic25,dgl,1,184,11.1587,0.9518

 F1-mic 0.9513,  F1-mac 0.7191
arctic25,dgl,1,185,11.2171,0.9513

 F1-mic 0.9521,  F1-mac 0.7198
new best val f1: 0.9521424028989333
arctic25,dgl,1,186,11.2755,0.9521

 F1-mic 0.9514,  F1-mac 0.7205
arctic25,dgl,1,187,11.3339,0.9514

 F1-mic 0.9529,  F1-mac 0.7189
new best val f1: 0.9528743355611283
arctic25,dgl,1,188,11.3924,0.9529

 F1-mic 0.9522,  F1-mac 0.7200
arctic25,dgl,1,189,11.4509,0.9522

epoch:191/50, Iteration 32/32:training loss 0.36052608489990234
Train F1-mic 0.9521, Train F1-mac 0.7190
 F1-mic 0.9524,  F1-mac 0.7176
arctic25,dgl,1,190,11.5094,0.9524

 F1-mic 0.9531,  F1-mac 0.7222
new best val f1: 0.9530723173468041
arctic25,dgl,1,191,11.5678,0.9531

 F1-mic 0.9517,  F1-mac 0.7210
arctic25,dgl,1,192,11.6262,0.9517

 F1-mic 0.9534,  F1-mac 0.7214
new best val f1: 0.9534142858856985
arctic25,dgl,1,193,11.6848,0.9534

 F1-mic 0.9526,  F1-mac 0.7213
arctic25,dgl,1,194,11.7433,0.9526

 F1-mic 0.9521,  F1-mac 0.7209
arctic25,dgl,1,195,11.8017,0.9521

 F1-mic 0.9539,  F1-mac 0.7222
new best val f1: 0.9538522455934054
arctic25,dgl,1,196,11.8601,0.9539

 F1-mic 0.9533,  F1-mac 0.7214
arctic25,dgl,1,197,11.9185,0.9533

 F1-mic 0.9512,  F1-mac 0.7235
arctic25,dgl,1,198,11.9772,0.9512

 F1-mic 0.9538,  F1-mac 0.7248
arctic25,dgl,1,199,12.0357,0.9538

epoch:201/50, Iteration 32/32:training loss 0.36240679025650024
Train F1-mic 0.9540, Train F1-mac 0.7274
 F1-mic 0.9541,  F1-mac 0.7221
new best val f1: 0.9541042224115381
arctic25,dgl,1,200,12.0942,0.9541

 F1-mic 0.9294,  F1-mac 0.7144
arctic25,dgl,1,201,12.1525,0.9294

 F1-mic 0.9540,  F1-mac 0.7214
arctic25,dgl,1,202,12.2110,0.9540

 F1-mic 0.9541,  F1-mac 0.7220
new best val f1: 0.9541162213076397
arctic25,dgl,1,203,12.2694,0.9541

 F1-mic 0.9543,  F1-mac 0.7215
new best val f1: 0.9543442003335693
arctic25,dgl,1,204,12.3280,0.9543

 F1-mic 0.9297,  F1-mac 0.7241
arctic25,dgl,1,205,12.3866,0.9297

 F1-mic 0.9548,  F1-mac 0.7300
new best val f1: 0.9548301556256824
arctic25,dgl,1,206,12.4451,0.9548

 F1-mic 0.9546,  F1-mac 0.7243
arctic25,dgl,1,207,12.5035,0.9546

 F1-mic 0.9543,  F1-mac 0.7208
arctic25,dgl,1,208,12.5619,0.9543

 F1-mic 0.9345,  F1-mac 0.7231
arctic25,dgl,1,209,12.6204,0.9345

epoch:211/50, Iteration 32/32:training loss 0.3634209632873535
Train F1-mic 0.9344, Train F1-mac 0.7225
 F1-mic 0.9546,  F1-mac 0.7265
arctic25,dgl,1,210,12.6789,0.9546

 F1-mic 0.9545,  F1-mac 0.7205
arctic25,dgl,1,211,12.7372,0.9545

 F1-mic 0.9534,  F1-mac 0.7204
arctic25,dgl,1,212,12.7957,0.9534

 F1-mic 0.9468,  F1-mac 0.7293
arctic25,dgl,1,213,12.8541,0.9468

 F1-mic 0.9546,  F1-mac 0.7322
arctic25,dgl,1,214,12.9127,0.9546

 F1-mic 0.9540,  F1-mac 0.7315
arctic25,dgl,1,215,12.9711,0.9540

 F1-mic 0.9493,  F1-mac 0.7259
arctic25,dgl,1,216,13.0295,0.9493

 F1-mic 0.9538,  F1-mac 0.7262
arctic25,dgl,1,217,13.0879,0.9538

 F1-mic 0.9546,  F1-mac 0.7282
arctic25,dgl,1,218,13.1463,0.9546

 F1-mic 0.9525,  F1-mac 0.7365
arctic25,dgl,1,219,13.2047,0.9525

epoch:221/50, Iteration 32/32:training loss 0.33500877022743225
Train F1-mic 0.9524, Train F1-mac 0.7376
 F1-mic 0.9550,  F1-mac 0.7453
new best val f1: 0.9550161385152566
arctic25,dgl,1,220,13.2632,0.9550

 F1-mic 0.9557,  F1-mac 0.7441
new best val f1: 0.9557360722813502
arctic25,dgl,1,221,13.3215,0.9557

 F1-mic 0.9460,  F1-mac 0.7400
arctic25,dgl,1,222,13.3800,0.9460

 F1-mic 0.9561,  F1-mac 0.7447
new best val f1: 0.9561020386124477
arctic25,dgl,1,223,13.4385,0.9561

 F1-mic 0.9553,  F1-mac 0.7425
arctic25,dgl,1,224,13.4969,0.9553

 F1-mic 0.9539,  F1-mac 0.7403
arctic25,dgl,1,225,13.5553,0.9539

 F1-mic 0.9559,  F1-mac 0.7398
arctic25,dgl,1,226,13.6137,0.9559

 F1-mic 0.9562,  F1-mac 0.7478
new best val f1: 0.9561800314371078
arctic25,dgl,1,227,13.6721,0.9562

 F1-mic 0.9539,  F1-mac 0.7503
arctic25,dgl,1,228,13.7306,0.9539

 F1-mic 0.9568,  F1-mac 0.7559
new best val f1: 0.9567619778980334
arctic25,dgl,1,229,13.7890,0.9568

epoch:231/50, Iteration 32/32:training loss 0.3246303200721741
Train F1-mic 0.9568, Train F1-mac 0.7580
 F1-mic 0.9574,  F1-mac 0.7583
new best val f1: 0.9574219171836191
arctic25,dgl,1,230,13.8475,0.9574

 F1-mic 0.9503,  F1-mac 0.7518
arctic25,dgl,1,231,13.9058,0.9503

 F1-mic 0.9565,  F1-mac 0.7446
arctic25,dgl,1,232,13.9643,0.9565

 F1-mic 0.9566,  F1-mac 0.7460
arctic25,dgl,1,233,14.0227,0.9566

 F1-mic 0.9549,  F1-mac 0.7542
arctic25,dgl,1,234,14.0811,0.9549

 F1-mic 0.9571,  F1-mac 0.7553
arctic25,dgl,1,235,14.1396,0.9571

 F1-mic 0.9574,  F1-mac 0.7562
new best val f1: 0.9574459149758222
arctic25,dgl,1,236,14.1980,0.9574

 F1-mic 0.9566,  F1-mac 0.7599
arctic25,dgl,1,237,14.2565,0.9566

 F1-mic 0.9547,  F1-mac 0.7640
arctic25,dgl,1,238,14.3150,0.9547

 F1-mic 0.9576,  F1-mac 0.7574
new best val f1: 0.9575839022809901
arctic25,dgl,1,239,14.3733,0.9576

epoch:241/50, Iteration 32/32:training loss 0.3194911777973175
Train F1-mic 0.9577, Train F1-mac 0.7628
 F1-mic 0.9578,  F1-mac 0.7533
new best val f1: 0.957751886826412
arctic25,dgl,1,240,14.4318,0.9578

 F1-mic 0.9488,  F1-mac 0.7520
arctic25,dgl,1,241,14.4902,0.9488

 F1-mic 0.9574,  F1-mac 0.7515
arctic25,dgl,1,242,14.5487,0.9574

 F1-mic 0.9580,  F1-mac 0.7539
new best val f1: 0.9579618675081892
arctic25,dgl,1,243,14.6071,0.9580

 F1-mic 0.9561,  F1-mac 0.7556
arctic25,dgl,1,244,14.6658,0.9561

 F1-mic 0.9576,  F1-mac 0.7638
arctic25,dgl,1,245,14.7242,0.9576

 F1-mic 0.9582,  F1-mac 0.7632
new best val f1: 0.9582078448782712
arctic25,dgl,1,246,14.7826,0.9582

 F1-mic 0.9580,  F1-mac 0.7644
arctic25,dgl,1,247,14.8410,0.9580

 F1-mic 0.9554,  F1-mac 0.7702
arctic25,dgl,1,248,14.8995,0.9554

 F1-mic 0.9583,  F1-mac 0.7587
new best val f1: 0.9582618399107282
arctic25,dgl,1,249,14.9579,0.9583

epoch:251/50, Iteration 32/32:training loss 0.311594694852829
Train F1-mic 0.9583, Train F1-mac 0.7625
 F1-mic 0.9582,  F1-mac 0.7580
arctic25,dgl,1,250,15.0164,0.9582

 F1-mic 0.9525,  F1-mac 0.7771
arctic25,dgl,1,251,15.0747,0.9525

 F1-mic 0.9586,  F1-mac 0.7796
new best val f1: 0.9585738112093687
arctic25,dgl,1,252,15.1333,0.9586

 F1-mic 0.9584,  F1-mac 0.7805
arctic25,dgl,1,253,15.1918,0.9584

 F1-mic 0.9550,  F1-mac 0.7786
arctic25,dgl,1,254,15.2503,0.9550

 F1-mic 0.9588,  F1-mac 0.7649
new best val f1: 0.9587537946508923
arctic25,dgl,1,255,15.3087,0.9588

 F1-mic 0.9590,  F1-mac 0.7653
new best val f1: 0.9589877731248725
arctic25,dgl,1,256,15.3671,0.9590

 F1-mic 0.9563,  F1-mac 0.7791
arctic25,dgl,1,257,15.4255,0.9563

 F1-mic 0.9588,  F1-mac 0.7819
arctic25,dgl,1,258,15.4840,0.9588

 F1-mic 0.9588,  F1-mac 0.7836
arctic25,dgl,1,259,15.5424,0.9588

epoch:261/50, Iteration 32/32:training loss 0.3010251224040985
Train F1-mic 0.9588, Train F1-mac 0.7831
 F1-mic 0.9561,  F1-mac 0.7848
arctic25,dgl,1,260,15.6009,0.9561

 F1-mic 0.9592,  F1-mac 0.7822
new best val f1: 0.9592037532547005
arctic25,dgl,1,261,15.6592,0.9592

 F1-mic 0.9593,  F1-mac 0.7830
new best val f1: 0.9592637477352084
arctic25,dgl,1,262,15.7177,0.9593

 F1-mic 0.9549,  F1-mac 0.7810
arctic25,dgl,1,263,15.7761,0.9549

 F1-mic 0.9592,  F1-mac 0.7810
arctic25,dgl,1,264,15.8346,0.9592

 F1-mic 0.9593,  F1-mac 0.7869
new best val f1: 0.9592697471832592
arctic25,dgl,1,265,15.8931,0.9593

 F1-mic 0.9557,  F1-mac 0.7989
arctic25,dgl,1,266,15.9515,0.9557

 F1-mic 0.9595,  F1-mac 0.8011
new best val f1: 0.9594677289689348
arctic25,dgl,1,267,16.0100,0.9595

 F1-mic 0.9594,  F1-mac 0.8005
arctic25,dgl,1,268,16.0684,0.9594

 F1-mic 0.9575,  F1-mac 0.8025
arctic25,dgl,1,269,16.1269,0.9575

epoch:271/50, Iteration 32/32:training loss 0.295449823141098
Train F1-mic 0.9574, Train F1-mac 0.8028
 F1-mic 0.9595,  F1-mac 0.8021
new best val f1: 0.9595217240013919
arctic25,dgl,1,270,16.1853,0.9595

 F1-mic 0.9597,  F1-mac 0.8024
new best val f1: 0.9596777096507121
arctic25,dgl,1,271,16.2437,0.9597

 F1-mic 0.9582,  F1-mac 0.8036
arctic25,dgl,1,272,16.3021,0.9582

 F1-mic 0.9597,  F1-mac 0.8018
new best val f1: 0.95973770413122
arctic25,dgl,1,273,16.3606,0.9597

 F1-mic 0.9597,  F1-mac 0.8015
new best val f1: 0.9597497030273214
arctic25,dgl,1,274,16.4190,0.9597

 F1-mic 0.9582,  F1-mac 0.8027
arctic25,dgl,1,275,16.4775,0.9582

 F1-mic 0.9599,  F1-mac 0.8098
new best val f1: 0.9598816908844386
arctic25,dgl,1,276,16.5359,0.9599

 F1-mic 0.9599,  F1-mac 0.8106
arctic25,dgl,1,277,16.5943,0.9599

 F1-mic 0.9572,  F1-mac 0.8124
arctic25,dgl,1,278,16.6528,0.9572

 F1-mic 0.9599,  F1-mac 0.8107
new best val f1: 0.9599296864688449
arctic25,dgl,1,279,16.7114,0.9599

epoch:281/50, Iteration 32/32:training loss 0.291189968585968
Train F1-mic 0.9599, Train F1-mac 0.8192
 F1-mic 0.9600,  F1-mac 0.8116
new best val f1: 0.9600016798454543
arctic25,dgl,1,280,16.7698,0.9600

 F1-mic 0.9555,  F1-mac 0.8140
arctic25,dgl,1,281,16.8282,0.9555

 F1-mic 0.9600,  F1-mac 0.8112
new best val f1: 0.9600316770857081
arctic25,dgl,1,282,16.8867,0.9600

 F1-mic 0.9601,  F1-mac 0.8111
new best val f1: 0.9601036704623175
arctic25,dgl,1,283,16.9452,0.9601

 F1-mic 0.9569,  F1-mac 0.8213
arctic25,dgl,1,284,17.0036,0.9569

 F1-mic 0.9602,  F1-mac 0.8122
new best val f1: 0.9602176599752823
arctic25,dgl,1,285,17.0621,0.9602

 F1-mic 0.9603,  F1-mac 0.8118
new best val f1: 0.9602596561116378
arctic25,dgl,1,286,17.1205,0.9603

 F1-mic 0.9591,  F1-mac 0.8211
arctic25,dgl,1,287,17.1789,0.9591

 F1-mic 0.9600,  F1-mac 0.8123
arctic25,dgl,1,288,17.2373,0.9600

 F1-mic 0.9603,  F1-mac 0.8126
new best val f1: 0.9603196505921455
arctic25,dgl,1,289,17.2958,0.9603

epoch:291/50, Iteration 32/32:training loss 0.28232184052467346
Train F1-mic 0.9604, Train F1-mac 0.8224
 F1-mic 0.9598,  F1-mac 0.8213
arctic25,dgl,1,290,17.3543,0.9598

 F1-mic 0.9602,  F1-mac 0.8197
arctic25,dgl,1,291,17.4126,0.9602

 F1-mic 0.9604,  F1-mac 0.8197
new best val f1: 0.9603976434168057
arctic25,dgl,1,292,17.4711,0.9604

 F1-mic 0.9600,  F1-mac 0.8215
arctic25,dgl,1,293,17.5296,0.9600

 F1-mic 0.9602,  F1-mac 0.8218
arctic25,dgl,1,294,17.5880,0.9602

 F1-mic 0.9606,  F1-mac 0.8207
new best val f1: 0.9606196229946845
arctic25,dgl,1,295,17.6465,0.9606

 F1-mic 0.9604,  F1-mac 0.8203
arctic25,dgl,1,296,17.7049,0.9604

 F1-mic 0.9600,  F1-mac 0.8212
arctic25,dgl,1,297,17.7634,0.9600

 F1-mic 0.9608,  F1-mac 0.8218
new best val f1: 0.9607636097479032
arctic25,dgl,1,298,17.8219,0.9608

 F1-mic 0.9605,  F1-mac 0.8238
arctic25,dgl,1,299,17.8803,0.9605

epoch:301/50, Iteration 32/32:training loss 0.27614980936050415
Train F1-mic 0.9606, Train F1-mac 0.8323
 F1-mic 0.9600,  F1-mac 0.8236
arctic25,dgl,1,300,17.9388,0.9600

 F1-mic 0.9608,  F1-mac 0.8215
new best val f1: 0.9607756086440048
arctic25,dgl,1,301,17.9971,0.9608

 F1-mic 0.9608,  F1-mac 0.8243
new best val f1: 0.9608116053323095
arctic25,dgl,1,302,18.0558,0.9608

 F1-mic 0.9602,  F1-mac 0.8246
arctic25,dgl,1,303,18.1142,0.9602

 F1-mic 0.9609,  F1-mac 0.8235
new best val f1: 0.9609135959491727
arctic25,dgl,1,304,18.1727,0.9609

 F1-mic 0.9607,  F1-mac 0.8235
arctic25,dgl,1,305,18.2314,0.9607

 F1-mic 0.9597,  F1-mac 0.8247
arctic25,dgl,1,306,18.2899,0.9597

 F1-mic 0.9612,  F1-mac 0.8223
new best val f1: 0.9612195677997625
arctic25,dgl,1,307,18.3483,0.9612

 F1-mic 0.9610,  F1-mac 0.8240
arctic25,dgl,1,308,18.4067,0.9610

 F1-mic 0.9571,  F1-mac 0.8257
arctic25,dgl,1,309,18.4651,0.9571

epoch:311/50, Iteration 32/32:training loss 0.2755974233150482
Train F1-mic 0.9571, Train F1-mac 0.8365
 F1-mic 0.9613,  F1-mac 0.8256
new best val f1: 0.9612555644880671
arctic25,dgl,1,310,18.5236,0.9613

 F1-mic 0.9612,  F1-mac 0.8234
arctic25,dgl,1,311,18.5819,0.9612

 F1-mic 0.9587,  F1-mac 0.8258
arctic25,dgl,1,312,18.6404,0.9587

 F1-mic 0.9608,  F1-mac 0.8251
arctic25,dgl,1,313,18.6989,0.9608

 F1-mic 0.9614,  F1-mac 0.8226
new best val f1: 0.9613695540010319
arctic25,dgl,1,314,18.7573,0.9614

 F1-mic 0.9612,  F1-mac 0.8239
arctic25,dgl,1,315,18.8158,0.9612

 F1-mic 0.9576,  F1-mac 0.8278
arctic25,dgl,1,316,18.8743,0.9576

 F1-mic 0.9616,  F1-mac 0.8352
new best val f1: 0.961639529163317
arctic25,dgl,1,317,18.9327,0.9616

 F1-mic 0.9616,  F1-mac 0.8283
arctic25,dgl,1,318,18.9911,0.9616

 F1-mic 0.9592,  F1-mac 0.8271
arctic25,dgl,1,319,19.0496,0.9592

epoch:321/50, Iteration 32/32:training loss 0.2685078978538513
Train F1-mic 0.9593, Train F1-mac 0.8367
 F1-mic 0.9603,  F1-mac 0.8253
arctic25,dgl,1,320,19.1080,0.9603

 F1-mic 0.9615,  F1-mac 0.8284
arctic25,dgl,1,321,19.1664,0.9615

 F1-mic 0.9616,  F1-mac 0.8289
arctic25,dgl,1,322,19.2249,0.9616

 F1-mic 0.9539,  F1-mac 0.8338
arctic25,dgl,1,323,19.2833,0.9539

 F1-mic 0.9619,  F1-mac 0.8338
new best val f1: 0.9618795070853482
arctic25,dgl,1,324,19.3418,0.9619

 F1-mic 0.9620,  F1-mac 0.8375
new best val f1: 0.9619574999100082
arctic25,dgl,1,325,19.4003,0.9620

 F1-mic 0.9598,  F1-mac 0.8282
arctic25,dgl,1,326,19.4587,0.9598

 F1-mic 0.9615,  F1-mac 0.8265
arctic25,dgl,1,327,19.5171,0.9615

 F1-mic 0.9617,  F1-mac 0.8418
arctic25,dgl,1,328,19.5756,0.9617

 F1-mic 0.9620,  F1-mac 0.8336
new best val f1: 0.961963499358059
arctic25,dgl,1,329,19.6340,0.9620

epoch:331/50, Iteration 32/32:training loss 0.26077309250831604
Train F1-mic 0.9619, Train F1-mac 0.8420
 F1-mic 0.9618,  F1-mac 0.8351
arctic25,dgl,1,330,19.6925,0.9618

 F1-mic 0.9618,  F1-mac 0.8382
arctic25,dgl,1,331,19.7509,0.9618

 F1-mic 0.9616,  F1-mac 0.8405
arctic25,dgl,1,332,19.8094,0.9616

 F1-mic 0.9622,  F1-mac 0.8402
new best val f1: 0.9622154761761917
arctic25,dgl,1,333,19.8682,0.9622

 F1-mic 0.9615,  F1-mac 0.8420
arctic25,dgl,1,334,19.9269,0.9615

 F1-mic 0.9623,  F1-mac 0.8401
new best val f1: 0.9622994684489027
arctic25,dgl,1,335,19.9854,0.9623

 F1-mic 0.9619,  F1-mac 0.8402
arctic25,dgl,1,336,20.0438,0.9619

 F1-mic 0.9616,  F1-mac 0.8394
arctic25,dgl,1,337,20.1023,0.9616

 F1-mic 0.9624,  F1-mac 0.8387
new best val f1: 0.9624494546501722
arctic25,dgl,1,338,20.1607,0.9624

 F1-mic 0.9622,  F1-mac 0.8419
arctic25,dgl,1,339,20.2192,0.9622

epoch:341/50, Iteration 32/32:training loss 0.2555789053440094
Train F1-mic 0.9621, Train F1-mac 0.8454
 F1-mic 0.9619,  F1-mac 0.8373
arctic25,dgl,1,340,20.2776,0.9619

 F1-mic 0.9621,  F1-mac 0.8311
arctic25,dgl,1,341,20.3360,0.9621

 F1-mic 0.9622,  F1-mac 0.8417
arctic25,dgl,1,342,20.3944,0.9622

 F1-mic 0.9619,  F1-mac 0.8425
arctic25,dgl,1,343,20.4528,0.9619

 F1-mic 0.9626,  F1-mac 0.8375
new best val f1: 0.9626294380916957
arctic25,dgl,1,344,20.5113,0.9626

 F1-mic 0.9624,  F1-mac 0.8411
arctic25,dgl,1,345,20.5697,0.9624

 F1-mic 0.9620,  F1-mac 0.8414
arctic25,dgl,1,346,20.6281,0.9620

 F1-mic 0.9628,  F1-mac 0.8375
new best val f1: 0.962779424292965
arctic25,dgl,1,347,20.6866,0.9628

 F1-mic 0.9626,  F1-mac 0.8377
arctic25,dgl,1,348,20.7450,0.9626

 F1-mic 0.9615,  F1-mac 0.8373
arctic25,dgl,1,349,20.8034,0.9615

epoch:351/50, Iteration 32/32:training loss 0.25224030017852783
Train F1-mic 0.9613, Train F1-mac 0.8435
 F1-mic 0.9629,  F1-mac 0.8393
new best val f1: 0.9629294104942345
arctic25,dgl,1,350,20.8619,0.9629

 F1-mic 0.9630,  F1-mac 0.8426
new best val f1: 0.9629534082864376
arctic25,dgl,1,351,20.9203,0.9630

 F1-mic 0.9551,  F1-mac 0.8499
arctic25,dgl,1,352,20.9788,0.9551

 F1-mic 0.9631,  F1-mac 0.8461
new best val f1: 0.9630553989033009
arctic25,dgl,1,353,21.0373,0.9631

 F1-mic 0.9631,  F1-mac 0.8467
arctic25,dgl,1,354,21.0958,0.9631

 F1-mic 0.9599,  F1-mac 0.8445
arctic25,dgl,1,355,21.1544,0.9599

 F1-mic 0.9632,  F1-mac 0.8407
new best val f1: 0.9631753878643164
arctic25,dgl,1,356,21.2129,0.9632

 F1-mic 0.9632,  F1-mac 0.8407
new best val f1: 0.9631993856565197
arctic25,dgl,1,357,21.2713,0.9632

 F1-mic 0.9590,  F1-mac 0.8409
arctic25,dgl,1,358,21.3298,0.9590

 F1-mic 0.9633,  F1-mac 0.8471
new best val f1: 0.9632893773772813
arctic25,dgl,1,359,21.3883,0.9633

epoch:361/50, Iteration 32/32:training loss 0.25302836298942566
Train F1-mic 0.9633, Train F1-mac 0.8461
 F1-mic 0.9634,  F1-mac 0.8473
new best val f1: 0.9634213652343985
arctic25,dgl,1,360,21.4468,0.9634

 F1-mic 0.9602,  F1-mac 0.8502
arctic25,dgl,1,361,21.5051,0.9602

 F1-mic 0.9632,  F1-mac 0.8461
arctic25,dgl,1,362,21.5636,0.9632

 F1-mic 0.9633,  F1-mac 0.8402
arctic25,dgl,1,363,21.6220,0.9633

 F1-mic 0.9608,  F1-mac 0.8442
arctic25,dgl,1,364,21.6805,0.9608

 F1-mic 0.9636,  F1-mac 0.8448
new best val f1: 0.9636133475720233
arctic25,dgl,1,365,21.7390,0.9636

 F1-mic 0.9636,  F1-mac 0.8475
new best val f1: 0.9636433448122773
arctic25,dgl,1,366,21.7974,0.9636

 F1-mic 0.9582,  F1-mac 0.8449
arctic25,dgl,1,367,21.8558,0.9582

 F1-mic 0.9634,  F1-mac 0.8463
arctic25,dgl,1,368,21.9143,0.9634

 F1-mic 0.9636,  F1-mac 0.8470
arctic25,dgl,1,369,21.9729,0.9636

epoch:371/50, Iteration 32/32:training loss 0.24699798226356506
Train F1-mic 0.9636, Train F1-mac 0.8464
 F1-mic 0.9610,  F1-mac 0.8450
arctic25,dgl,1,370,22.0313,0.9610

 F1-mic 0.9637,  F1-mac 0.8415
new best val f1: 0.9637153381888867
arctic25,dgl,1,371,22.0897,0.9637

 F1-mic 0.9637,  F1-mac 0.8420
arctic25,dgl,1,372,22.1481,0.9637

 F1-mic 0.9614,  F1-mac 0.8516
arctic25,dgl,1,373,22.2068,0.9614

 F1-mic 0.9638,  F1-mac 0.8486
new best val f1: 0.9638173288057499
arctic25,dgl,1,374,22.2653,0.9638

 F1-mic 0.9640,  F1-mac 0.8481
new best val f1: 0.9639553161109178
arctic25,dgl,1,375,22.3238,0.9640

 F1-mic 0.9589,  F1-mac 0.8517
arctic25,dgl,1,376,22.3823,0.9589

 F1-mic 0.9638,  F1-mac 0.8473
arctic25,dgl,1,377,22.4408,0.9638

 F1-mic 0.9638,  F1-mac 0.8419
arctic25,dgl,1,378,22.4992,0.9638

 F1-mic 0.9612,  F1-mac 0.8477
arctic25,dgl,1,379,22.5576,0.9612

epoch:381/50, Iteration 32/32:training loss 0.24224059283733368
Train F1-mic 0.9610, Train F1-mac 0.8510
 F1-mic 0.9640,  F1-mac 0.8424
new best val f1: 0.9640093111433748
arctic25,dgl,1,380,22.6161,0.9640

 F1-mic 0.9640,  F1-mac 0.8420
arctic25,dgl,1,381,22.6745,0.9640

 F1-mic 0.9615,  F1-mac 0.8520
arctic25,dgl,1,382,22.7330,0.9615

 F1-mic 0.9640,  F1-mac 0.8488
new best val f1: 0.9640153105914255
arctic25,dgl,1,383,22.7914,0.9640

 F1-mic 0.9642,  F1-mac 0.8490
new best val f1: 0.9642072929290505
arctic25,dgl,1,384,22.8499,0.9642

 F1-mic 0.9595,  F1-mac 0.8467
arctic25,dgl,1,385,22.9083,0.9595

 F1-mic 0.9642,  F1-mac 0.8423
arctic25,dgl,1,386,22.9668,0.9642

 F1-mic 0.9642,  F1-mac 0.8486
arctic25,dgl,1,387,23.0252,0.9642

 F1-mic 0.9613,  F1-mac 0.8479
arctic25,dgl,1,388,23.0836,0.9613

 F1-mic 0.9643,  F1-mac 0.8425
new best val f1: 0.9643092835459138
arctic25,dgl,1,389,23.1421,0.9643

epoch:391/50, Iteration 32/32:training loss 0.23692290484905243
Train F1-mic 0.9643, Train F1-mac 0.8467
 F1-mic 0.9643,  F1-mac 0.8486
arctic25,dgl,1,390,23.2005,0.9643

 F1-mic 0.9609,  F1-mac 0.8540
arctic25,dgl,1,391,23.2589,0.9609

 F1-mic 0.9643,  F1-mac 0.8488
new best val f1: 0.9643272818900661
arctic25,dgl,1,392,23.3176,0.9643

 F1-mic 0.9645,  F1-mac 0.8487
new best val f1: 0.9644952664354879
arctic25,dgl,1,393,23.3762,0.9645

 F1-mic 0.9612,  F1-mac 0.8529
arctic25,dgl,1,394,23.4347,0.9612

 F1-mic 0.9645,  F1-mac 0.8438
arctic25,dgl,1,395,23.4931,0.9645

 F1-mic 0.9644,  F1-mac 0.8440
arctic25,dgl,1,396,23.5515,0.9644

 F1-mic 0.9621,  F1-mac 0.8478
arctic25,dgl,1,397,23.6100,0.9621

 F1-mic 0.9646,  F1-mac 0.8489
new best val f1: 0.9645852581562496
arctic25,dgl,1,398,23.6684,0.9646

 F1-mic 0.9647,  F1-mac 0.8494
new best val f1: 0.9647052471172652
arctic25,dgl,1,399,23.7269,0.9647

epoch:401/50, Iteration 32/32:training loss 0.23271000385284424
Train F1-mic 0.9647, Train F1-mac 0.8485
 F1-mic 0.9613,  F1-mac 0.8548
arctic25,dgl,1,400,23.7860,0.9613

 F1-mic 0.9645,  F1-mac 0.8488
arctic25,dgl,1,401,23.8447,0.9645

 F1-mic 0.9646,  F1-mac 0.8500
arctic25,dgl,1,402,23.9032,0.9646

 F1-mic 0.9615,  F1-mac 0.8488
arctic25,dgl,1,403,23.9616,0.9615

 F1-mic 0.9648,  F1-mac 0.8441
new best val f1: 0.9648192366302301
arctic25,dgl,1,404,24.0201,0.9648

 F1-mic 0.9648,  F1-mac 0.8444
arctic25,dgl,1,405,24.0785,0.9648

 F1-mic 0.9625,  F1-mac 0.8496
arctic25,dgl,1,406,24.1370,0.9625

 F1-mic 0.9648,  F1-mac 0.8509
arctic25,dgl,1,407,24.1954,0.9648

 F1-mic 0.9648,  F1-mac 0.8514
new best val f1: 0.9648492338704839
arctic25,dgl,1,408,24.2539,0.9648

 F1-mic 0.9623,  F1-mac 0.8543
arctic25,dgl,1,409,24.3124,0.9623

epoch:411/50, Iteration 32/32:training loss 0.2311427742242813
Train F1-mic 0.9621, Train F1-mac 0.8530
 F1-mic 0.9649,  F1-mac 0.8502
new best val f1: 0.9648612327665854
arctic25,dgl,1,410,24.3711,0.9649

 F1-mic 0.9649,  F1-mac 0.8509
new best val f1: 0.9649392255912456
arctic25,dgl,1,411,24.4295,0.9649

 F1-mic 0.9607,  F1-mac 0.8494
arctic25,dgl,1,412,24.4886,0.9607

 F1-mic 0.9649,  F1-mac 0.8474
arctic25,dgl,1,413,24.5471,0.9649

 F1-mic 0.9649,  F1-mac 0.8457
arctic25,dgl,1,414,24.6055,0.9649

 F1-mic 0.9624,  F1-mac 0.8553
arctic25,dgl,1,415,24.6640,0.9624

 F1-mic 0.9649,  F1-mac 0.8507
arctic25,dgl,1,416,24.7224,0.9649

 F1-mic 0.9650,  F1-mac 0.8508
new best val f1: 0.9649932206237026
arctic25,dgl,1,417,24.7809,0.9650

 F1-mic 0.9630,  F1-mac 0.8555
arctic25,dgl,1,418,24.8394,0.9630

 F1-mic 0.9651,  F1-mac 0.8547
new best val f1: 0.9650832123444643
arctic25,dgl,1,419,24.8978,0.9651

epoch:421/50, Iteration 32/32:training loss 0.22703850269317627
Train F1-mic 0.9651, Train F1-mac 0.8523
 F1-mic 0.9651,  F1-mac 0.8522
arctic25,dgl,1,420,24.9562,0.9651

 F1-mic 0.9614,  F1-mac 0.8491
arctic25,dgl,1,421,25.0147,0.9614

 F1-mic 0.9650,  F1-mac 0.8534
arctic25,dgl,1,422,25.0732,0.9650

 F1-mic 0.9652,  F1-mac 0.8555
new best val f1: 0.9652271990976831
arctic25,dgl,1,423,25.1316,0.9652

 F1-mic 0.9629,  F1-mac 0.8495
arctic25,dgl,1,424,25.1902,0.9629

 F1-mic 0.9651,  F1-mac 0.8524
arctic25,dgl,1,425,25.2486,0.9651

 F1-mic 0.9649,  F1-mac 0.8504
arctic25,dgl,1,426,25.3070,0.9649

 F1-mic 0.9647,  F1-mac 0.8551
arctic25,dgl,1,427,25.3654,0.9647

 F1-mic 0.9650,  F1-mac 0.8558
arctic25,dgl,1,428,25.4239,0.9650

 F1-mic 0.9654,  F1-mac 0.8554
new best val f1: 0.9653591869548002
arctic25,dgl,1,429,25.4823,0.9654

epoch:431/50, Iteration 32/32:training loss 0.22223807871341705
Train F1-mic 0.9654, Train F1-mac 0.8529
 F1-mic 0.9649,  F1-mac 0.8529
arctic25,dgl,1,430,25.5410,0.9649

 F1-mic 0.9647,  F1-mac 0.8543
arctic25,dgl,1,431,25.5994,0.9647

 F1-mic 0.9653,  F1-mac 0.8568
arctic25,dgl,1,432,25.6579,0.9653

 F1-mic 0.9653,  F1-mac 0.8488
arctic25,dgl,1,433,25.7163,0.9653

 F1-mic 0.9646,  F1-mac 0.8493
arctic25,dgl,1,434,25.7747,0.9646

 F1-mic 0.9655,  F1-mac 0.8550
new best val f1: 0.965473176467765
arctic25,dgl,1,435,25.8332,0.9655

 F1-mic 0.9654,  F1-mac 0.8566
arctic25,dgl,1,436,25.8916,0.9654

 F1-mic 0.9634,  F1-mac 0.8561
arctic25,dgl,1,437,25.9500,0.9634

 F1-mic 0.9654,  F1-mac 0.8550
arctic25,dgl,1,438,26.0084,0.9654

 F1-mic 0.9656,  F1-mac 0.8538
new best val f1: 0.9656051643248821
arctic25,dgl,1,439,26.0668,0.9656

epoch:441/50, Iteration 32/32:training loss 0.22057101130485535
Train F1-mic 0.9657, Train F1-mac 0.8529
 F1-mic 0.9606,  F1-mac 0.8576
arctic25,dgl,1,440,26.1253,0.9606

 F1-mic 0.9656,  F1-mac 0.8556
arctic25,dgl,1,441,26.1837,0.9656

 F1-mic 0.9655,  F1-mac 0.8471
arctic25,dgl,1,442,26.2421,0.9655

 F1-mic 0.9635,  F1-mac 0.8516
arctic25,dgl,1,443,26.3005,0.9635

 F1-mic 0.9657,  F1-mac 0.8570
new best val f1: 0.9657431516300501
arctic25,dgl,1,444,26.3592,0.9657

 F1-mic 0.9658,  F1-mac 0.8575
new best val f1: 0.9657611499742024
arctic25,dgl,1,445,26.4176,0.9658

 F1-mic 0.9643,  F1-mac 0.8559
arctic25,dgl,1,446,26.4760,0.9643

 F1-mic 0.9657,  F1-mac 0.8566
arctic25,dgl,1,447,26.5345,0.9657

 F1-mic 0.9658,  F1-mac 0.8575
new best val f1: 0.9658391427988625
arctic25,dgl,1,448,26.5930,0.9658

 F1-mic 0.9640,  F1-mac 0.8588
arctic25,dgl,1,449,26.6514,0.9640

epoch:451/50, Iteration 32/32:training loss 0.21789807081222534
Train F1-mic 0.9639, Train F1-mac 0.8567
 F1-mic 0.9658,  F1-mac 0.8567
arctic25,dgl,1,450,26.7098,0.9658

 F1-mic 0.9658,  F1-mac 0.8560
arctic25,dgl,1,451,26.7682,0.9658

 F1-mic 0.9617,  F1-mac 0.8586
arctic25,dgl,1,452,26.8266,0.9617

 F1-mic 0.9659,  F1-mac 0.8570
new best val f1: 0.9659111361754719
arctic25,dgl,1,453,26.8852,0.9659

 F1-mic 0.9660,  F1-mac 0.8570
new best val f1: 0.9659591317598781
arctic25,dgl,1,454,26.9437,0.9660

 F1-mic 0.9635,  F1-mac 0.8587
arctic25,dgl,1,455,27.0021,0.9635

 F1-mic 0.9660,  F1-mac 0.8566
arctic25,dgl,1,456,27.0605,0.9660

 F1-mic 0.9658,  F1-mac 0.8561
arctic25,dgl,1,457,27.1190,0.9658

 F1-mic 0.9640,  F1-mac 0.8590
arctic25,dgl,1,458,27.1775,0.9640

 F1-mic 0.9661,  F1-mac 0.8577
new best val f1: 0.9661211168572491
arctic25,dgl,1,459,27.2359,0.9661

epoch:461/50, Iteration 32/32:training loss 0.21533772349357605
Train F1-mic 0.9661, Train F1-mac 0.8553
 F1-mic 0.9661,  F1-mac 0.8579
new best val f1: 0.9661451146494523
arctic25,dgl,1,460,27.2943,0.9661

 F1-mic 0.9620,  F1-mac 0.8527
arctic25,dgl,1,461,27.3527,0.9620

 F1-mic 0.9660,  F1-mac 0.8567
arctic25,dgl,1,462,27.4112,0.9660

 F1-mic 0.9662,  F1-mac 0.8582
new best val f1: 0.9661751118897062
arctic25,dgl,1,463,27.4696,0.9662

 F1-mic 0.9638,  F1-mac 0.8620
arctic25,dgl,1,464,27.5281,0.9638

 F1-mic 0.9662,  F1-mac 0.8581
arctic25,dgl,1,465,27.5866,0.9662

 F1-mic 0.9661,  F1-mac 0.8568
arctic25,dgl,1,466,27.6451,0.9661

 F1-mic 0.9647,  F1-mac 0.8614
arctic25,dgl,1,467,27.7035,0.9647

 F1-mic 0.9663,  F1-mac 0.8582
new best val f1: 0.9662831019546202
arctic25,dgl,1,468,27.7620,0.9663

 F1-mic 0.9664,  F1-mac 0.8592
new best val f1: 0.9663730936753818
arctic25,dgl,1,469,27.8204,0.9664

epoch:471/50, Iteration 32/32:training loss 0.21029998362064362
Train F1-mic 0.9664, Train F1-mac 0.8564
 F1-mic 0.9640,  F1-mac 0.8598
arctic25,dgl,1,470,27.8789,0.9640

 F1-mic 0.9662,  F1-mac 0.8576
arctic25,dgl,1,471,27.9374,0.9662

 F1-mic 0.9663,  F1-mac 0.8586
arctic25,dgl,1,472,27.9959,0.9663

 F1-mic 0.9623,  F1-mac 0.8602
arctic25,dgl,1,473,28.0545,0.9623

 F1-mic 0.9663,  F1-mac 0.8581
arctic25,dgl,1,474,28.1132,0.9663

 F1-mic 0.9664,  F1-mac 0.8587
new best val f1: 0.9664150898117373
arctic25,dgl,1,475,28.1716,0.9664

 F1-mic 0.9640,  F1-mac 0.8625
arctic25,dgl,1,476,28.2301,0.9640

 F1-mic 0.9664,  F1-mac 0.8577
arctic25,dgl,1,477,28.2885,0.9664

 F1-mic 0.9664,  F1-mac 0.8585
arctic25,dgl,1,478,28.3470,0.9664

 F1-mic 0.9642,  F1-mac 0.8624
arctic25,dgl,1,479,28.4054,0.9642

epoch:481/50, Iteration 32/32:training loss 0.21009625494480133
Train F1-mic 0.9641, Train F1-mac 0.8596
 F1-mic 0.9666,  F1-mac 0.8598
new best val f1: 0.9665650760130068
arctic25,dgl,1,480,28.4639,0.9666

 F1-mic 0.9666,  F1-mac 0.8591
new best val f1: 0.9665710754610576
arctic25,dgl,1,481,28.5222,0.9666

 F1-mic 0.9627,  F1-mac 0.8628
arctic25,dgl,1,482,28.5806,0.9627

 F1-mic 0.9664,  F1-mac 0.8584
arctic25,dgl,1,483,28.6391,0.9664

 F1-mic 0.9665,  F1-mac 0.8591
arctic25,dgl,1,484,28.6976,0.9665

 F1-mic 0.9641,  F1-mac 0.8629
arctic25,dgl,1,485,28.7563,0.9641

 F1-mic 0.9666,  F1-mac 0.8589
arctic25,dgl,1,486,28.8150,0.9666

 F1-mic 0.9665,  F1-mac 0.8590
arctic25,dgl,1,487,28.8735,0.9665

 F1-mic 0.9648,  F1-mac 0.8629
arctic25,dgl,1,488,28.9319,0.9648

 F1-mic 0.9667,  F1-mac 0.8595
new best val f1: 0.9667030633181747
arctic25,dgl,1,489,28.9904,0.9667

epoch:491/50, Iteration 32/32:training loss 0.20653347671031952
Train F1-mic 0.9668, Train F1-mac 0.8583
 F1-mic 0.9668,  F1-mac 0.8599
new best val f1: 0.9667570583506319
arctic25,dgl,1,490,29.0488,0.9668

 F1-mic 0.9640,  F1-mac 0.8632
arctic25,dgl,1,491,29.1072,0.9640

 F1-mic 0.9666,  F1-mac 0.8592
arctic25,dgl,1,492,29.1656,0.9666

 F1-mic 0.9668,  F1-mac 0.8608
new best val f1: 0.966805053935038
arctic25,dgl,1,493,29.2241,0.9668

 F1-mic 0.9637,  F1-mac 0.8643
arctic25,dgl,1,494,29.2827,0.9637

 F1-mic 0.9667,  F1-mac 0.8592
arctic25,dgl,1,495,29.3412,0.9667

 F1-mic 0.9668,  F1-mac 0.8592
new best val f1: 0.9668410506233427
arctic25,dgl,1,496,29.3996,0.9668

 F1-mic 0.9642,  F1-mac 0.8642
arctic25,dgl,1,497,29.4581,0.9642

 F1-mic 0.9668,  F1-mac 0.8603
arctic25,dgl,1,498,29.5166,0.9668

 F1-mic 0.9669,  F1-mac 0.8599
new best val f1: 0.9668530495194442
arctic25,dgl,1,499,29.5750,0.9669

epoch:501/50, Iteration 32/32:training loss 0.20372135937213898
Train F1-mic 0.9670, Train F1-mac 0.8587
 F1-mic 0.9640,  F1-mac 0.8639
arctic25,dgl,1,500,29.6335,0.9640

 F1-mic 0.9669,  F1-mac 0.8596
new best val f1: 0.9668710478635966
arctic25,dgl,1,501,29.6919,0.9669

 F1-mic 0.9669,  F1-mac 0.8596
new best val f1: 0.9668830467596982
arctic25,dgl,1,502,29.7503,0.9669

 F1-mic 0.9641,  F1-mac 0.8645
arctic25,dgl,1,503,29.8088,0.9641

 F1-mic 0.9669,  F1-mac 0.8607
new best val f1: 0.9669070445519012
arctic25,dgl,1,504,29.8673,0.9669

 F1-mic 0.9671,  F1-mac 0.8612
new best val f1: 0.9671230246817293
arctic25,dgl,1,505,29.9257,0.9671

 F1-mic 0.9643,  F1-mac 0.8648
arctic25,dgl,1,506,29.9842,0.9643

 F1-mic 0.9670,  F1-mac 0.8599
arctic25,dgl,1,507,30.0426,0.9670

 F1-mic 0.9670,  F1-mac 0.8605
arctic25,dgl,1,508,30.1011,0.9670

 F1-mic 0.9636,  F1-mac 0.8654
arctic25,dgl,1,509,30.1595,0.9636

epoch:511/50, Iteration 32/32:training loss 0.20405477285385132
Train F1-mic 0.9636, Train F1-mac 0.8642
 F1-mic 0.9672,  F1-mac 0.8613
new best val f1: 0.9672010175063894
arctic25,dgl,1,510,30.2180,0.9672

 F1-mic 0.9671,  F1-mac 0.8603
arctic25,dgl,1,511,30.2763,0.9671

 F1-mic 0.9646,  F1-mac 0.8641
arctic25,dgl,1,512,30.3348,0.9646

 F1-mic 0.9672,  F1-mac 0.8617
arctic25,dgl,1,513,30.3932,0.9672

 F1-mic 0.9672,  F1-mac 0.8621
new best val f1: 0.9672250152985925
arctic25,dgl,1,514,30.4517,0.9672

 F1-mic 0.9656,  F1-mac 0.8659
arctic25,dgl,1,515,30.5101,0.9656

 F1-mic 0.9673,  F1-mac 0.8612
new best val f1: 0.9673090075713034
arctic25,dgl,1,516,30.5685,0.9673

 F1-mic 0.9673,  F1-mac 0.8611
new best val f1: 0.9673330053635065
arctic25,dgl,1,517,30.6269,0.9673

 F1-mic 0.9646,  F1-mac 0.8643
arctic25,dgl,1,518,30.6854,0.9646

 F1-mic 0.9673,  F1-mac 0.8621
new best val f1: 0.9673450042596081
arctic25,dgl,1,519,30.7438,0.9673

epoch:521/50, Iteration 32/32:training loss 0.20091883838176727
Train F1-mic 0.9674, Train F1-mac 0.8602
 F1-mic 0.9674,  F1-mac 0.8621
new best val f1: 0.9673810009479128
arctic25,dgl,1,520,30.8025,0.9674

 F1-mic 0.9645,  F1-mac 0.8665
arctic25,dgl,1,521,30.8613,0.9645

 F1-mic 0.9673,  F1-mac 0.8606
arctic25,dgl,1,522,30.9197,0.9673

 F1-mic 0.9674,  F1-mac 0.8605
arctic25,dgl,1,523,30.9781,0.9674

 F1-mic 0.9648,  F1-mac 0.8658
arctic25,dgl,1,524,31.0366,0.9648

 F1-mic 0.9674,  F1-mac 0.8625
new best val f1: 0.9674109981881667
arctic25,dgl,1,525,31.0950,0.9674

 F1-mic 0.9675,  F1-mac 0.8624
new best val f1: 0.9675369865972331
arctic25,dgl,1,526,31.1534,0.9675

 F1-mic 0.9648,  F1-mac 0.8661
arctic25,dgl,1,527,31.2119,0.9648

 F1-mic 0.9674,  F1-mac 0.8615
arctic25,dgl,1,528,31.2703,0.9674

 F1-mic 0.9675,  F1-mac 0.8616
arctic25,dgl,1,529,31.3288,0.9675

epoch:531/50, Iteration 32/32:training loss 0.19726838171482086
Train F1-mic 0.9676, Train F1-mac 0.8597
 F1-mic 0.9645,  F1-mac 0.8660
arctic25,dgl,1,530,31.3872,0.9645

 F1-mic 0.9675,  F1-mac 0.8627
arctic25,dgl,1,531,31.4456,0.9675

 F1-mic 0.9676,  F1-mac 0.8632
new best val f1: 0.9675729832855378
arctic25,dgl,1,532,31.5041,0.9676

 F1-mic 0.9648,  F1-mac 0.8667
arctic25,dgl,1,533,31.5626,0.9648

 F1-mic 0.9675,  F1-mac 0.8615
arctic25,dgl,1,534,31.6210,0.9675

 F1-mic 0.9676,  F1-mac 0.8615
arctic25,dgl,1,535,31.6795,0.9676

 F1-mic 0.9649,  F1-mac 0.8684
arctic25,dgl,1,536,31.7379,0.9649

 F1-mic 0.9677,  F1-mac 0.8633
new best val f1: 0.9676569755582486
arctic25,dgl,1,537,31.7963,0.9677

 F1-mic 0.9676,  F1-mac 0.8627
arctic25,dgl,1,538,31.8548,0.9676

 F1-mic 0.9646,  F1-mac 0.8664
arctic25,dgl,1,539,31.9132,0.9646

epoch:541/50, Iteration 32/32:training loss 0.1963428258895874
Train F1-mic 0.9646, Train F1-mac 0.8650
 F1-mic 0.9677,  F1-mac 0.8629
new best val f1: 0.9676689744543502
arctic25,dgl,1,540,31.9719,0.9677

 F1-mic 0.9678,  F1-mac 0.8635
new best val f1: 0.9677709650712134
arctic25,dgl,1,541,32.0302,0.9678

 F1-mic 0.9652,  F1-mac 0.8683
arctic25,dgl,1,542,32.0887,0.9652

 F1-mic 0.9677,  F1-mac 0.8628
arctic25,dgl,1,543,32.1472,0.9677

 F1-mic 0.9678,  F1-mac 0.8629
new best val f1: 0.9677769645192642
arctic25,dgl,1,544,32.2057,0.9678

 F1-mic 0.9658,  F1-mac 0.8663
arctic25,dgl,1,545,32.2641,0.9658

 F1-mic 0.9678,  F1-mac 0.8635
arctic25,dgl,1,546,32.3226,0.9678

 F1-mic 0.9679,  F1-mac 0.8641
new best val f1: 0.9678669562400259
arctic25,dgl,1,547,32.3812,0.9679

 F1-mic 0.9658,  F1-mac 0.8682
arctic25,dgl,1,548,32.4397,0.9658

 F1-mic 0.9679,  F1-mac 0.8630
new best val f1: 0.967890954032229
arctic25,dgl,1,549,32.4981,0.9679

epoch:551/50, Iteration 32/32:training loss 0.19221152365207672
Train F1-mic 0.9680, Train F1-mac 0.8612
 F1-mic 0.9680,  F1-mac 0.8630
new best val f1: 0.9679509485127368
arctic25,dgl,1,550,32.5565,0.9680

 F1-mic 0.9653,  F1-mac 0.8683
arctic25,dgl,1,551,32.6149,0.9653

 F1-mic 0.9679,  F1-mac 0.8636
arctic25,dgl,1,552,32.6733,0.9679

 F1-mic 0.9680,  F1-mac 0.8636
new best val f1: 0.9679869452010414
arctic25,dgl,1,553,32.7318,0.9680

 F1-mic 0.9652,  F1-mac 0.8681
arctic25,dgl,1,554,32.7903,0.9652

 F1-mic 0.9679,  F1-mac 0.8632
arctic25,dgl,1,555,32.8487,0.9679

 F1-mic 0.9680,  F1-mac 0.8636
new best val f1: 0.9680289413373969
arctic25,dgl,1,556,32.9072,0.9680

 F1-mic 0.9655,  F1-mac 0.8690
arctic25,dgl,1,557,32.9656,0.9655

 F1-mic 0.9680,  F1-mac 0.8639
arctic25,dgl,1,558,33.0240,0.9680

 F1-mic 0.9681,  F1-mac 0.8644
new best val f1: 0.9681189330581587
arctic25,dgl,1,559,33.0825,0.9681

epoch:561/50, Iteration 32/32:training loss 0.18922796845436096
Train F1-mic 0.9682, Train F1-mac 0.8627
 F1-mic 0.9658,  F1-mac 0.8684
arctic25,dgl,1,560,33.1409,0.9658

 F1-mic 0.9680,  F1-mac 0.8639
arctic25,dgl,1,561,33.1993,0.9680

 F1-mic 0.9681,  F1-mac 0.8639
arctic25,dgl,1,562,33.2577,0.9681

 F1-mic 0.9659,  F1-mac 0.8698
arctic25,dgl,1,563,33.3162,0.9659

 F1-mic 0.9682,  F1-mac 0.8643
new best val f1: 0.968244921467225
arctic25,dgl,1,564,33.3747,0.9682

 F1-mic 0.9682,  F1-mac 0.8645
arctic25,dgl,1,565,33.4331,0.9682

 F1-mic 0.9656,  F1-mac 0.8701
arctic25,dgl,1,566,33.4915,0.9656

 F1-mic 0.9681,  F1-mac 0.8640
arctic25,dgl,1,567,33.5500,0.9681

 F1-mic 0.9682,  F1-mac 0.8643
arctic25,dgl,1,568,33.6084,0.9682

 F1-mic 0.9656,  F1-mac 0.8705
arctic25,dgl,1,569,33.6668,0.9656

epoch:571/50, Iteration 32/32:training loss 0.1892896294593811
Train F1-mic 0.9656, Train F1-mac 0.8676
 F1-mic 0.9683,  F1-mac 0.8642
new best val f1: 0.9683109153957836
arctic25,dgl,1,570,33.7253,0.9683

 F1-mic 0.9683,  F1-mac 0.8645
new best val f1: 0.9683469120840883
arctic25,dgl,1,571,33.7837,0.9683

 F1-mic 0.9658,  F1-mac 0.8705
arctic25,dgl,1,572,33.8425,0.9658

 F1-mic 0.9683,  F1-mac 0.8643
arctic25,dgl,1,573,33.9009,0.9683

 F1-mic 0.9684,  F1-mac 0.8648
new best val f1: 0.9683589109801898
arctic25,dgl,1,574,33.9594,0.9684

 F1-mic 0.9659,  F1-mac 0.8706
arctic25,dgl,1,575,34.0179,0.9659

 F1-mic 0.9684,  F1-mac 0.8643
new best val f1: 0.9684489027009516
arctic25,dgl,1,576,34.0764,0.9684

 F1-mic 0.9684,  F1-mac 0.8647
arctic25,dgl,1,577,34.1348,0.9684

 F1-mic 0.9660,  F1-mac 0.8714
arctic25,dgl,1,578,34.1933,0.9660

 F1-mic 0.9684,  F1-mac 0.8646
arctic25,dgl,1,579,34.2517,0.9684

epoch:581/50, Iteration 32/32:training loss 0.18604037165641785
Train F1-mic 0.9685, Train F1-mac 0.8641
 F1-mic 0.9684,  F1-mac 0.8650
arctic25,dgl,1,580,34.3102,0.9684

 F1-mic 0.9659,  F1-mac 0.8713
arctic25,dgl,1,581,34.3686,0.9659

 F1-mic 0.9685,  F1-mac 0.8645
new best val f1: 0.9684729004931545
arctic25,dgl,1,582,34.4270,0.9685

 F1-mic 0.9686,  F1-mac 0.8651
new best val f1: 0.9686228866944241
arctic25,dgl,1,583,34.4854,0.9686

 F1-mic 0.9659,  F1-mac 0.8724
arctic25,dgl,1,584,34.5439,0.9659

 F1-mic 0.9686,  F1-mac 0.8652
arctic25,dgl,1,585,34.6023,0.9686

 F1-mic 0.9687,  F1-mac 0.8651
new best val f1: 0.9686588833827288
arctic25,dgl,1,586,34.6607,0.9687

 F1-mic 0.9660,  F1-mac 0.8714
arctic25,dgl,1,587,34.7192,0.9660

 F1-mic 0.9686,  F1-mac 0.8652
arctic25,dgl,1,588,34.7776,0.9686

 F1-mic 0.9687,  F1-mac 0.8653
new best val f1: 0.9687008795190842
arctic25,dgl,1,589,34.8360,0.9687

epoch:591/50, Iteration 32/32:training loss 0.18331235647201538
Train F1-mic 0.9687, Train F1-mac 0.8655
 F1-mic 0.9662,  F1-mac 0.8720
arctic25,dgl,1,590,34.8945,0.9662

 F1-mic 0.9687,  F1-mac 0.8653
new best val f1: 0.9687188778632366
arctic25,dgl,1,591,34.9528,0.9687

 F1-mic 0.9687,  F1-mac 0.8653
new best val f1: 0.9687308767593381
arctic25,dgl,1,592,35.0114,0.9687

 F1-mic 0.9662,  F1-mac 0.8728
arctic25,dgl,1,593,35.0698,0.9662

 F1-mic 0.9688,  F1-mac 0.8653
new best val f1: 0.9687548745515413
arctic25,dgl,1,594,35.1283,0.9688

 F1-mic 0.9688,  F1-mac 0.8654
new best val f1: 0.9688448662723029
arctic25,dgl,1,595,35.1868,0.9688

 F1-mic 0.9665,  F1-mac 0.8730
arctic25,dgl,1,596,35.2452,0.9665

 F1-mic 0.9688,  F1-mac 0.8655
arctic25,dgl,1,597,35.3036,0.9688

 F1-mic 0.9689,  F1-mac 0.8654
new best val f1: 0.9688808629606076
arctic25,dgl,1,598,35.3621,0.9689

 F1-mic 0.9664,  F1-mac 0.8731
arctic25,dgl,1,599,35.4205,0.9664

epoch:601/50, Iteration 32/32:training loss 0.1829882711172104
Train F1-mic 0.9663, Train F1-mac 0.8688
 F1-mic 0.9689,  F1-mac 0.8655
new best val f1: 0.9689108602008615
arctic25,dgl,1,600,35.4790,0.9689

 F1-mic 0.9689,  F1-mac 0.8659
new best val f1: 0.9689348579930647
arctic25,dgl,1,601,35.5373,0.9689

 F1-mic 0.9665,  F1-mac 0.8732
arctic25,dgl,1,602,35.5958,0.9665

 F1-mic 0.9689,  F1-mac 0.8656
arctic25,dgl,1,603,35.6543,0.9689

 F1-mic 0.9689,  F1-mac 0.8655
new best val f1: 0.9689408574411156
arctic25,dgl,1,604,35.7127,0.9689

 F1-mic 0.9667,  F1-mac 0.8725
arctic25,dgl,1,605,35.7714,0.9667

 F1-mic 0.9690,  F1-mac 0.8656
new best val f1: 0.9689828535774708
arctic25,dgl,1,606,35.8298,0.9690

 F1-mic 0.9691,  F1-mac 0.8665
new best val f1: 0.969090843642385
arctic25,dgl,1,607,35.8883,0.9691

 F1-mic 0.9665,  F1-mac 0.8731
arctic25,dgl,1,608,35.9467,0.9665

 F1-mic 0.9690,  F1-mac 0.8657
arctic25,dgl,1,609,36.0051,0.9690

epoch:611/50, Iteration 32/32:training loss 0.1809525191783905
Train F1-mic 0.9690, Train F1-mac 0.8653
 F1-mic 0.9691,  F1-mac 0.8661
new best val f1: 0.9691028425384864
arctic25,dgl,1,610,36.0636,0.9691

 F1-mic 0.9666,  F1-mac 0.8730
arctic25,dgl,1,611,36.1219,0.9666

 F1-mic 0.9691,  F1-mac 0.8659
arctic25,dgl,1,612,36.1805,0.9691

 F1-mic 0.9692,  F1-mac 0.8659
new best val f1: 0.9691748359150958
arctic25,dgl,1,613,36.2389,0.9692

 F1-mic 0.9668,  F1-mac 0.8729
arctic25,dgl,1,614,36.2974,0.9668

 F1-mic 0.9691,  F1-mac 0.8657
arctic25,dgl,1,615,36.3558,0.9691

 F1-mic 0.9693,  F1-mac 0.8685
new best val f1: 0.969276826531959
arctic25,dgl,1,616,36.4143,0.9693

 F1-mic 0.9667,  F1-mac 0.8732
arctic25,dgl,1,617,36.4727,0.9667

 F1-mic 0.9693,  F1-mac 0.8665
arctic25,dgl,1,618,36.5312,0.9693

 F1-mic 0.9693,  F1-mac 0.8663
arctic25,dgl,1,619,36.5896,0.9693

epoch:621/50, Iteration 32/32:training loss 0.17784835398197174
Train F1-mic 0.9693, Train F1-mac 0.8663
 F1-mic 0.9669,  F1-mac 0.8737
arctic25,dgl,1,620,36.6481,0.9669

 F1-mic 0.9694,  F1-mac 0.8664
new best val f1: 0.9693548193566192
arctic25,dgl,1,621,36.7065,0.9694

 F1-mic 0.9694,  F1-mac 0.8682
new best val f1: 0.9694448110773809
arctic25,dgl,1,622,36.7650,0.9694

 F1-mic 0.9671,  F1-mac 0.8733
arctic25,dgl,1,623,36.8235,0.9671

 F1-mic 0.9693,  F1-mac 0.8666
arctic25,dgl,1,624,36.8820,0.9693

 F1-mic 0.9694,  F1-mac 0.8659
arctic25,dgl,1,625,36.9405,0.9694

 F1-mic 0.9676,  F1-mac 0.8734
arctic25,dgl,1,626,36.9989,0.9676

 F1-mic 0.9695,  F1-mac 0.8694
new best val f1: 0.9694868072137364
arctic25,dgl,1,627,37.0574,0.9695

 F1-mic 0.9695,  F1-mac 0.8675
new best val f1: 0.9694988061098379
arctic25,dgl,1,628,37.1158,0.9695

 F1-mic 0.9673,  F1-mac 0.8731
arctic25,dgl,1,629,37.1742,0.9673

epoch:631/50, Iteration 32/32:training loss 0.17683301866054535
Train F1-mic 0.9671, Train F1-mac 0.8699
 F1-mic 0.9695,  F1-mac 0.8667
arctic25,dgl,1,630,37.2327,0.9695

 F1-mic 0.9696,  F1-mac 0.8689
new best val f1: 0.9695648000383965
arctic25,dgl,1,631,37.2910,0.9696

 F1-mic 0.9667,  F1-mac 0.8736
arctic25,dgl,1,632,37.3495,0.9667

 F1-mic 0.9695,  F1-mac 0.8662
arctic25,dgl,1,633,37.4079,0.9695

 F1-mic 0.9696,  F1-mac 0.8667
new best val f1: 0.9696127956228027
arctic25,dgl,1,634,37.4664,0.9696

 F1-mic 0.9671,  F1-mac 0.8734
arctic25,dgl,1,635,37.5248,0.9671

 F1-mic 0.9695,  F1-mac 0.8661
arctic25,dgl,1,636,37.5833,0.9695

 F1-mic 0.9696,  F1-mac 0.8655
arctic25,dgl,1,637,37.6416,0.9696

 F1-mic 0.9682,  F1-mac 0.8734
arctic25,dgl,1,638,37.7000,0.9682

 F1-mic 0.9696,  F1-mac 0.8700
arctic25,dgl,1,639,37.7587,0.9696

epoch:641/50, Iteration 32/32:training loss 0.17286884784698486
Train F1-mic 0.9696, Train F1-mac 0.8691
 F1-mic 0.9697,  F1-mac 0.8693
new best val f1: 0.9696607912072089
arctic25,dgl,1,640,37.8172,0.9697

 F1-mic 0.9685,  F1-mac 0.8729
arctic25,dgl,1,641,37.8755,0.9685

 F1-mic 0.9697,  F1-mac 0.8678
new best val f1: 0.9696667906552597
arctic25,dgl,1,642,37.9345,0.9697

 F1-mic 0.9697,  F1-mac 0.8677
new best val f1: 0.9697387840318691
arctic25,dgl,1,643,37.9929,0.9697

 F1-mic 0.9683,  F1-mac 0.8731
arctic25,dgl,1,644,38.0514,0.9683

 F1-mic 0.9698,  F1-mac 0.8692
new best val f1: 0.9698047779604276
arctic25,dgl,1,645,38.1099,0.9698

 F1-mic 0.9698,  F1-mac 0.8691
new best val f1: 0.9698287757526307
arctic25,dgl,1,646,38.1683,0.9698

 F1-mic 0.9675,  F1-mac 0.8737
arctic25,dgl,1,647,38.2270,0.9675

 F1-mic 0.9698,  F1-mac 0.8659
arctic25,dgl,1,648,38.2854,0.9698

 F1-mic 0.9699,  F1-mac 0.8675
new best val f1: 0.9698587729928847
arctic25,dgl,1,649,38.3439,0.9699

epoch:651/50, Iteration 32/32:training loss 0.17270012199878693
Train F1-mic 0.9699, Train F1-mac 0.8679
 F1-mic 0.9666,  F1-mac 0.8739
arctic25,dgl,1,650,38.4023,0.9666

 F1-mic 0.9698,  F1-mac 0.8658
arctic25,dgl,1,651,38.4607,0.9698

 F1-mic 0.9698,  F1-mac 0.8658
arctic25,dgl,1,652,38.5192,0.9698

 F1-mic 0.9674,  F1-mac 0.8738
arctic25,dgl,1,653,38.5777,0.9674

 F1-mic 0.9699,  F1-mac 0.8681
new best val f1: 0.9699367658175447
arctic25,dgl,1,654,38.6361,0.9699

 F1-mic 0.9700,  F1-mac 0.8670
new best val f1: 0.9699607636097479
arctic25,dgl,1,655,38.6948,0.9700

 F1-mic 0.9674,  F1-mac 0.8735
arctic25,dgl,1,656,38.7533,0.9674

 F1-mic 0.9700,  F1-mac 0.8667
new best val f1: 0.9699667630577987
arctic25,dgl,1,657,38.8117,0.9700

 F1-mic 0.9700,  F1-mac 0.8670
new best val f1: 0.9699907608500018
arctic25,dgl,1,658,38.8702,0.9700

 F1-mic 0.9674,  F1-mac 0.8739
arctic25,dgl,1,659,38.9286,0.9674

epoch:661/50, Iteration 32/32:training loss 0.1723119020462036
Train F1-mic 0.9672, Train F1-mac 0.8718
 F1-mic 0.9701,  F1-mac 0.8671
new best val f1: 0.9700507553305096
arctic25,dgl,1,660,38.9871,0.9701

 F1-mic 0.9701,  F1-mac 0.8671
new best val f1: 0.9700867520188142
arctic25,dgl,1,661,39.0456,0.9701

 F1-mic 0.9679,  F1-mac 0.8729
arctic25,dgl,1,662,39.1040,0.9679

 F1-mic 0.9700,  F1-mac 0.8665
arctic25,dgl,1,663,39.1625,0.9700

 F1-mic 0.9701,  F1-mac 0.8676
arctic25,dgl,1,664,39.2209,0.9701

 F1-mic 0.9673,  F1-mac 0.8739
arctic25,dgl,1,665,39.2793,0.9673

 F1-mic 0.9702,  F1-mac 0.8658
new best val f1: 0.9701587453954236
arctic25,dgl,1,666,39.3378,0.9702

 F1-mic 0.9702,  F1-mac 0.8657
new best val f1: 0.9701647448434744
arctic25,dgl,1,667,39.3962,0.9702

 F1-mic 0.9676,  F1-mac 0.8739
arctic25,dgl,1,668,39.4546,0.9676

 F1-mic 0.9702,  F1-mac 0.8677
new best val f1: 0.970176743739576
arctic25,dgl,1,669,39.5131,0.9702

epoch:671/50, Iteration 32/32:training loss 0.16879242658615112
Train F1-mic 0.9702, Train F1-mac 0.8692
 F1-mic 0.9702,  F1-mac 0.8669
new best val f1: 0.9702067409798298
arctic25,dgl,1,670,39.5716,0.9702

 F1-mic 0.9680,  F1-mac 0.8720
arctic25,dgl,1,671,39.6302,0.9680

 F1-mic 0.9702,  F1-mac 0.8667
arctic25,dgl,1,672,39.6887,0.9702

 F1-mic 0.9702,  F1-mac 0.8681
new best val f1: 0.9702427376681345
arctic25,dgl,1,673,39.7471,0.9702

 F1-mic 0.9676,  F1-mac 0.8741
arctic25,dgl,1,674,39.8056,0.9676

 F1-mic 0.9702,  F1-mac 0.8647
arctic25,dgl,1,675,39.8640,0.9702

 F1-mic 0.9703,  F1-mac 0.8638
new best val f1: 0.9702787343564392
arctic25,dgl,1,676,39.9224,0.9703

 F1-mic 0.9678,  F1-mac 0.8740
arctic25,dgl,1,677,39.9808,0.9678

 F1-mic 0.9703,  F1-mac 0.8679
new best val f1: 0.9703147310447439
arctic25,dgl,1,678,40.0393,0.9703

 F1-mic 0.9703,  F1-mac 0.8681
new best val f1: 0.9703447282849977
arctic25,dgl,1,679,40.0977,0.9703

epoch:681/50, Iteration 32/32:training loss 0.16684168577194214
Train F1-mic 0.9704, Train F1-mac 0.8692
 F1-mic 0.9681,  F1-mac 0.8742
arctic25,dgl,1,680,40.1561,0.9681

 F1-mic 0.9704,  F1-mac 0.8657
new best val f1: 0.9703687260772009
arctic25,dgl,1,681,40.2145,0.9704

 F1-mic 0.9704,  F1-mac 0.8655
new best val f1: 0.9704107222135564
arctic25,dgl,1,682,40.2730,0.9704

 F1-mic 0.9676,  F1-mac 0.8745
arctic25,dgl,1,683,40.3314,0.9676

 F1-mic 0.9704,  F1-mac 0.8681
arctic25,dgl,1,684,40.3899,0.9704

 F1-mic 0.9704,  F1-mac 0.8670
new best val f1: 0.9704287205577087
arctic25,dgl,1,685,40.4484,0.9704

 F1-mic 0.9682,  F1-mac 0.8742
arctic25,dgl,1,686,40.5068,0.9682

 F1-mic 0.9705,  F1-mac 0.8662
new best val f1: 0.9704707166940642
arctic25,dgl,1,687,40.5653,0.9705

 F1-mic 0.9705,  F1-mac 0.8666
new best val f1: 0.970476716142115
arctic25,dgl,1,688,40.6240,0.9705

 F1-mic 0.9689,  F1-mac 0.8739
arctic25,dgl,1,689,40.6825,0.9689

epoch:691/50, Iteration 32/32:training loss 0.1662386953830719
Train F1-mic 0.9687, Train F1-mac 0.8734
 F1-mic 0.9705,  F1-mac 0.8672
new best val f1: 0.9705067133823688
arctic25,dgl,1,690,40.7409,0.9705

 F1-mic 0.9705,  F1-mac 0.8670
new best val f1: 0.9705127128304196
arctic25,dgl,1,691,40.7995,0.9705

 F1-mic 0.9678,  F1-mac 0.8741
arctic25,dgl,1,692,40.8580,0.9678

 F1-mic 0.9706,  F1-mac 0.8643
new best val f1: 0.9705667078628766
arctic25,dgl,1,693,40.9164,0.9706

 F1-mic 0.9706,  F1-mac 0.8661
arctic25,dgl,1,694,40.9749,0.9706

 F1-mic 0.9686,  F1-mac 0.8740
arctic25,dgl,1,695,41.0333,0.9686

 F1-mic 0.9706,  F1-mac 0.8671
new best val f1: 0.9705907056550798
arctic25,dgl,1,696,41.0918,0.9706

 F1-mic 0.9705,  F1-mac 0.8647
arctic25,dgl,1,697,41.1502,0.9705

 F1-mic 0.9699,  F1-mac 0.8708
arctic25,dgl,1,698,41.2086,0.9699

 F1-mic 0.9706,  F1-mac 0.8696
new best val f1: 0.970608703999232
arctic25,dgl,1,699,41.2671,0.9706

epoch:701/50, Iteration 32/32:training loss 0.16249582171440125
Train F1-mic 0.9707, Train F1-mac 0.8701
 F1-mic 0.9706,  F1-mac 0.8695
arctic25,dgl,1,700,41.3256,0.9706

 F1-mic 0.9701,  F1-mac 0.8718
arctic25,dgl,1,701,41.3839,0.9701

 F1-mic 0.9707,  F1-mac 0.8673
new best val f1: 0.9706986957199938
arctic25,dgl,1,702,41.4426,0.9707

 F1-mic 0.9706,  F1-mac 0.8674
arctic25,dgl,1,703,41.5010,0.9706

 F1-mic 0.9696,  F1-mac 0.8721
arctic25,dgl,1,704,41.5596,0.9696

 F1-mic 0.9707,  F1-mac 0.8673
new best val f1: 0.9707166940641461
arctic25,dgl,1,705,41.6180,0.9707

 F1-mic 0.9708,  F1-mac 0.8696
new best val f1: 0.9707586902005015
arctic25,dgl,1,706,41.6767,0.9708

 F1-mic 0.9678,  F1-mac 0.8751
arctic25,dgl,1,707,41.7353,0.9678

 F1-mic 0.9707,  F1-mac 0.8632
arctic25,dgl,1,708,41.7940,0.9707

 F1-mic 0.9708,  F1-mac 0.8665
arctic25,dgl,1,709,41.8524,0.9708

epoch:711/50, Iteration 32/32:training loss 0.16554512083530426
Train F1-mic 0.9708, Train F1-mac 0.8680
 F1-mic 0.9687,  F1-mac 0.8745
arctic25,dgl,1,710,41.9110,0.9687

 F1-mic 0.9707,  F1-mac 0.8678
arctic25,dgl,1,711,41.9694,0.9707

 F1-mic 0.9707,  F1-mac 0.8669
arctic25,dgl,1,712,42.0279,0.9707

 F1-mic 0.9700,  F1-mac 0.8741
arctic25,dgl,1,713,42.0863,0.9700

 F1-mic 0.9709,  F1-mac 0.8687
new best val f1: 0.9708666802654156
arctic25,dgl,1,714,42.1448,0.9709

 F1-mic 0.9708,  F1-mac 0.8689
arctic25,dgl,1,715,42.2032,0.9708

 F1-mic 0.9702,  F1-mac 0.8741
arctic25,dgl,1,716,42.2617,0.9702

 F1-mic 0.9709,  F1-mac 0.8682
new best val f1: 0.9708786791615172
arctic25,dgl,1,717,42.3201,0.9709

 F1-mic 0.9708,  F1-mac 0.8676
arctic25,dgl,1,718,42.3786,0.9708

 F1-mic 0.9691,  F1-mac 0.8736
arctic25,dgl,1,719,42.4370,0.9691

epoch:721/50, Iteration 32/32:training loss 0.16185475885868073
Train F1-mic 0.9690, Train F1-mac 0.8732
 F1-mic 0.9709,  F1-mac 0.8681
arctic25,dgl,1,720,42.4956,0.9709

 F1-mic 0.9710,  F1-mac 0.8704
new best val f1: 0.970992668674482
arctic25,dgl,1,721,42.5541,0.9710

 F1-mic 0.9672,  F1-mac 0.8752
arctic25,dgl,1,722,42.6126,0.9672

 F1-mic 0.9710,  F1-mac 0.8666
arctic25,dgl,1,723,42.6710,0.9710

 F1-mic 0.9709,  F1-mac 0.8666
arctic25,dgl,1,724,42.7295,0.9709

 F1-mic 0.9688,  F1-mac 0.8756
arctic25,dgl,1,725,42.7880,0.9688

 F1-mic 0.9710,  F1-mac 0.8682
arctic25,dgl,1,726,42.8465,0.9710

 F1-mic 0.9710,  F1-mac 0.8686
arctic25,dgl,1,727,42.9049,0.9710

 F1-mic 0.9682,  F1-mac 0.8754
arctic25,dgl,1,728,42.9634,0.9682

 F1-mic 0.9709,  F1-mac 0.8681
arctic25,dgl,1,729,43.0219,0.9709

epoch:731/50, Iteration 32/32:training loss 0.162405863404274
Train F1-mic 0.9710, Train F1-mac 0.8678
 F1-mic 0.9710,  F1-mac 0.8700
arctic25,dgl,1,730,43.0804,0.9710

 F1-mic 0.9683,  F1-mac 0.8784
arctic25,dgl,1,731,43.1387,0.9683

 F1-mic 0.9712,  F1-mac 0.8734
new best val f1: 0.9711606532199037
arctic25,dgl,1,732,43.1971,0.9712

 F1-mic 0.9711,  F1-mac 0.8717
arctic25,dgl,1,733,43.2556,0.9711

 F1-mic 0.9687,  F1-mac 0.8785
arctic25,dgl,1,734,43.3141,0.9687

 F1-mic 0.9711,  F1-mac 0.8738
arctic25,dgl,1,735,43.3725,0.9711

 F1-mic 0.9712,  F1-mac 0.8759
new best val f1: 0.9711966499082084
arctic25,dgl,1,736,43.4310,0.9712

 F1-mic 0.9682,  F1-mac 0.8784
arctic25,dgl,1,737,43.4894,0.9682

 F1-mic 0.9712,  F1-mac 0.8707
arctic25,dgl,1,738,43.5479,0.9712

 F1-mic 0.9712,  F1-mac 0.8723
arctic25,dgl,1,739,43.6063,0.9712

epoch:741/50, Iteration 32/32:training loss 0.15970461070537567
Train F1-mic 0.9712, Train F1-mac 0.8708
 F1-mic 0.9687,  F1-mac 0.8783
arctic25,dgl,1,740,43.6648,0.9687

 F1-mic 0.9712,  F1-mac 0.8742
new best val f1: 0.9712146482523608
arctic25,dgl,1,741,43.7232,0.9712

 F1-mic 0.9713,  F1-mac 0.8739
new best val f1: 0.971292641077021
arctic25,dgl,1,742,43.7816,0.9713

 F1-mic 0.9689,  F1-mac 0.8790
arctic25,dgl,1,743,43.8401,0.9689

 F1-mic 0.9712,  F1-mac 0.8724
arctic25,dgl,1,744,43.8986,0.9712

 F1-mic 0.9712,  F1-mac 0.8739
arctic25,dgl,1,745,43.9571,0.9712

 F1-mic 0.9682,  F1-mac 0.8792
arctic25,dgl,1,746,44.0155,0.9682

 F1-mic 0.9713,  F1-mac 0.8734
new best val f1: 0.9713466361094779
arctic25,dgl,1,747,44.0740,0.9713

 F1-mic 0.9713,  F1-mac 0.8735
arctic25,dgl,1,748,44.1324,0.9713

 F1-mic 0.9689,  F1-mac 0.8812
arctic25,dgl,1,749,44.1910,0.9689

epoch:751/50, Iteration 32/32:training loss 0.15875506401062012
Train F1-mic 0.9688, Train F1-mac 0.8775
 F1-mic 0.9713,  F1-mac 0.8741
arctic25,dgl,1,750,44.2494,0.9713

 F1-mic 0.9713,  F1-mac 0.8740
arctic25,dgl,1,751,44.3078,0.9713

 F1-mic 0.9686,  F1-mac 0.8809
arctic25,dgl,1,752,44.3662,0.9686

 F1-mic 0.9714,  F1-mac 0.8726
new best val f1: 0.9713586350055795
arctic25,dgl,1,753,44.4247,0.9714

 F1-mic 0.9713,  F1-mac 0.8748
arctic25,dgl,1,754,44.4831,0.9713

 F1-mic 0.9686,  F1-mac 0.8814
arctic25,dgl,1,755,44.5415,0.9686

 F1-mic 0.9714,  F1-mac 0.8727
new best val f1: 0.9714126300380365
arctic25,dgl,1,756,44.6000,0.9714

 F1-mic 0.9714,  F1-mac 0.8726
new best val f1: 0.9714186294860873
arctic25,dgl,1,757,44.6584,0.9714

 F1-mic 0.9690,  F1-mac 0.8810
arctic25,dgl,1,758,44.7169,0.9690

 F1-mic 0.9715,  F1-mac 0.8762
new best val f1: 0.9714726245185443
arctic25,dgl,1,759,44.7753,0.9715

epoch:761/50, Iteration 32/32:training loss 0.15667343139648438
Train F1-mic 0.9716, Train F1-mac 0.8733
 F1-mic 0.9715,  F1-mac 0.8767
arctic25,dgl,1,760,44.8338,0.9715

 F1-mic 0.9686,  F1-mac 0.8812
arctic25,dgl,1,761,44.8922,0.9686

 F1-mic 0.9715,  F1-mac 0.8718
arctic25,dgl,1,762,44.9507,0.9715

 F1-mic 0.9715,  F1-mac 0.8738
new best val f1: 0.9714966223107474
arctic25,dgl,1,763,45.0091,0.9715

 F1-mic 0.9688,  F1-mac 0.8821
arctic25,dgl,1,764,45.0677,0.9688

 F1-mic 0.9716,  F1-mac 0.8754
new best val f1: 0.9715866140315091
arctic25,dgl,1,765,45.1261,0.9716

 F1-mic 0.9715,  F1-mac 0.8728
arctic25,dgl,1,766,45.1845,0.9715

 F1-mic 0.9690,  F1-mac 0.8810
arctic25,dgl,1,767,45.2429,0.9690

 F1-mic 0.9715,  F1-mac 0.8757
arctic25,dgl,1,768,45.3014,0.9715

 F1-mic 0.9716,  F1-mac 0.8776
arctic25,dgl,1,769,45.3598,0.9716

epoch:771/50, Iteration 32/32:training loss 0.15501974523067474
Train F1-mic 0.9716, Train F1-mac 0.8738
 F1-mic 0.9691,  F1-mac 0.8818
arctic25,dgl,1,770,45.4182,0.9691

 F1-mic 0.9717,  F1-mac 0.8731
new best val f1: 0.9716766057522708
arctic25,dgl,1,771,45.4766,0.9717

 F1-mic 0.9716,  F1-mac 0.8729
arctic25,dgl,1,772,45.5350,0.9716

 F1-mic 0.9694,  F1-mac 0.8817
arctic25,dgl,1,773,45.5937,0.9694

 F1-mic 0.9716,  F1-mac 0.8766
arctic25,dgl,1,774,45.6522,0.9716

 F1-mic 0.9717,  F1-mac 0.8759
new best val f1: 0.9717425996808293
arctic25,dgl,1,775,45.7106,0.9717

 F1-mic 0.9697,  F1-mac 0.8810
arctic25,dgl,1,776,45.7691,0.9697

 F1-mic 0.9717,  F1-mac 0.8751
arctic25,dgl,1,777,45.8274,0.9717

 F1-mic 0.9717,  F1-mac 0.8754
arctic25,dgl,1,778,45.8859,0.9717

 F1-mic 0.9690,  F1-mac 0.8818
arctic25,dgl,1,779,45.9443,0.9690

epoch:781/50, Iteration 32/32:training loss 0.15542246401309967
Train F1-mic 0.9688, Train F1-mac 0.8784
 F1-mic 0.9718,  F1-mac 0.8752
new best val f1: 0.9717545985769309
arctic25,dgl,1,780,46.0027,0.9718

 F1-mic 0.9718,  F1-mac 0.8756
new best val f1: 0.9717605980249817
arctic25,dgl,1,781,46.0611,0.9718

 F1-mic 0.9693,  F1-mac 0.8817
arctic25,dgl,1,782,46.1196,0.9693

 F1-mic 0.9717,  F1-mac 0.8751
arctic25,dgl,1,783,46.1780,0.9717

 F1-mic 0.9717,  F1-mac 0.8751
arctic25,dgl,1,784,46.2367,0.9717

 F1-mic 0.9698,  F1-mac 0.8809
arctic25,dgl,1,785,46.2952,0.9698

 F1-mic 0.9718,  F1-mac 0.8771
new best val f1: 0.9718205925054895
arctic25,dgl,1,786,46.3536,0.9718

 F1-mic 0.9718,  F1-mac 0.8784
new best val f1: 0.9718265919535403
arctic25,dgl,1,787,46.4121,0.9718

 F1-mic 0.9688,  F1-mac 0.8815
arctic25,dgl,1,788,46.4706,0.9688

 F1-mic 0.9718,  F1-mac 0.8732
arctic25,dgl,1,789,46.5291,0.9718

epoch:791/50, Iteration 32/32:training loss 0.1542019248008728
Train F1-mic 0.9719, Train F1-mac 0.8714
 F1-mic 0.9718,  F1-mac 0.8752
arctic25,dgl,1,790,46.5875,0.9718

 F1-mic 0.9692,  F1-mac 0.8825
arctic25,dgl,1,791,46.6459,0.9692

 F1-mic 0.9719,  F1-mac 0.8765
new best val f1: 0.9719285825704035
arctic25,dgl,1,792,46.7043,0.9719

 F1-mic 0.9719,  F1-mac 0.8749
arctic25,dgl,1,793,46.7627,0.9719

 F1-mic 0.9696,  F1-mac 0.8815
arctic25,dgl,1,794,46.8212,0.9696

 F1-mic 0.9719,  F1-mac 0.8758
arctic25,dgl,1,795,46.8796,0.9719

 F1-mic 0.9719,  F1-mac 0.8774
arctic25,dgl,1,796,46.9381,0.9719

 F1-mic 0.9690,  F1-mac 0.8826
arctic25,dgl,1,797,46.9965,0.9690

 F1-mic 0.9720,  F1-mac 0.8748
new best val f1: 0.9720365726353175
arctic25,dgl,1,798,47.0550,0.9720

 F1-mic 0.9720,  F1-mac 0.8757
arctic25,dgl,1,799,47.1134,0.9720

epoch:801/50, Iteration 32/32:training loss 0.15174032747745514
Train F1-mic 0.9720, Train F1-mac 0.8728
 F1-mic 0.9696,  F1-mac 0.8822
arctic25,dgl,1,800,47.1719,0.9696

 F1-mic 0.9720,  F1-mac 0.8768
arctic25,dgl,1,801,47.2302,0.9720

 F1-mic 0.9720,  F1-mac 0.8750
arctic25,dgl,1,802,47.2889,0.9720

 F1-mic 0.9699,  F1-mac 0.8811
arctic25,dgl,1,803,47.3473,0.9699

 F1-mic 0.9720,  F1-mac 0.8765
new best val f1: 0.9720425720833683
arctic25,dgl,1,804,47.4058,0.9720

 F1-mic 0.9720,  F1-mac 0.8774
arctic25,dgl,1,805,47.4642,0.9720

 F1-mic 0.9694,  F1-mac 0.8825
arctic25,dgl,1,806,47.5227,0.9694

 F1-mic 0.9720,  F1-mac 0.8742
new best val f1: 0.9720485715314191
arctic25,dgl,1,807,47.5811,0.9720

 F1-mic 0.9721,  F1-mac 0.8760
new best val f1: 0.9720845682197238
arctic25,dgl,1,808,47.6396,0.9721

 F1-mic 0.9697,  F1-mac 0.8833
arctic25,dgl,1,809,47.6980,0.9697

epoch:811/50, Iteration 32/32:training loss 0.15128234028816223
Train F1-mic 0.9696, Train F1-mac 0.8798
 F1-mic 0.9721,  F1-mac 0.8753
arctic25,dgl,1,810,47.7564,0.9721

 F1-mic 0.9721,  F1-mac 0.8749
new best val f1: 0.9721145654599777
arctic25,dgl,1,811,47.8148,0.9721

 F1-mic 0.9701,  F1-mac 0.8814
arctic25,dgl,1,812,47.8732,0.9701

 F1-mic 0.9721,  F1-mac 0.8775
arctic25,dgl,1,813,47.9317,0.9721

 F1-mic 0.9721,  F1-mac 0.8788
new best val f1: 0.9721265643560792
arctic25,dgl,1,814,47.9904,0.9721

 F1-mic 0.9697,  F1-mac 0.8828
arctic25,dgl,1,815,48.0489,0.9697

 F1-mic 0.9721,  F1-mac 0.8740
new best val f1: 0.9721385632521808
arctic25,dgl,1,816,48.1075,0.9721

 F1-mic 0.9722,  F1-mac 0.8755
new best val f1: 0.9721685604924347
arctic25,dgl,1,817,48.1660,0.9722

 F1-mic 0.9693,  F1-mac 0.8835
arctic25,dgl,1,818,48.2244,0.9693

 F1-mic 0.9723,  F1-mac 0.8764
new best val f1: 0.9722585522131963
arctic25,dgl,1,819,48.2829,0.9723

epoch:821/50, Iteration 32/32:training loss 0.14934217929840088
Train F1-mic 0.9723, Train F1-mac 0.8739
 F1-mic 0.9722,  F1-mac 0.8753
arctic25,dgl,1,820,48.3413,0.9722

 F1-mic 0.9699,  F1-mac 0.8829
arctic25,dgl,1,821,48.3997,0.9699

 F1-mic 0.9722,  F1-mac 0.8772
arctic25,dgl,1,822,48.4581,0.9722

 F1-mic 0.9722,  F1-mac 0.8772
arctic25,dgl,1,823,48.5166,0.9722

 F1-mic 0.9700,  F1-mac 0.8821
arctic25,dgl,1,824,48.5751,0.9700

 F1-mic 0.9723,  F1-mac 0.8755
new best val f1: 0.9722645516612471
arctic25,dgl,1,825,48.6336,0.9723

 F1-mic 0.9723,  F1-mac 0.8779
arctic25,dgl,1,826,48.6920,0.9723

 F1-mic 0.9692,  F1-mac 0.8835
arctic25,dgl,1,827,48.7504,0.9692

 F1-mic 0.9723,  F1-mac 0.8756
new best val f1: 0.9722765505573487
arctic25,dgl,1,828,48.8089,0.9723

 F1-mic 0.9723,  F1-mac 0.8756
new best val f1: 0.9722885494534503
arctic25,dgl,1,829,48.8674,0.9723

epoch:831/50, Iteration 32/32:training loss 0.14837050437927246
Train F1-mic 0.9724, Train F1-mac 0.8735
 F1-mic 0.9699,  F1-mac 0.8831
arctic25,dgl,1,830,48.9259,0.9699

 F1-mic 0.9723,  F1-mac 0.8769
arctic25,dgl,1,831,48.9843,0.9723

 F1-mic 0.9723,  F1-mac 0.8784
new best val f1: 0.9723185466937042
arctic25,dgl,1,832,49.0428,0.9723

 F1-mic 0.9698,  F1-mac 0.8834
arctic25,dgl,1,833,49.1014,0.9698

 F1-mic 0.9724,  F1-mac 0.8752
new best val f1: 0.9723545433820089
arctic25,dgl,1,834,49.1599,0.9724

 F1-mic 0.9724,  F1-mac 0.8765
new best val f1: 0.9723905400703136
arctic25,dgl,1,835,49.2184,0.9724

 F1-mic 0.9694,  F1-mac 0.8840
arctic25,dgl,1,836,49.2769,0.9694

 F1-mic 0.9724,  F1-mac 0.8760
arctic25,dgl,1,837,49.3354,0.9724

 F1-mic 0.9724,  F1-mac 0.8757
new best val f1: 0.972402538966415
arctic25,dgl,1,838,49.3939,0.9724

 F1-mic 0.9699,  F1-mac 0.8837
arctic25,dgl,1,839,49.4523,0.9699

epoch:841/50, Iteration 32/32:training loss 0.14813174307346344
Train F1-mic 0.9698, Train F1-mac 0.8803
 F1-mic 0.9724,  F1-mac 0.8784
arctic25,dgl,1,840,49.5107,0.9724

 F1-mic 0.9724,  F1-mac 0.8769
new best val f1: 0.9724265367586182
arctic25,dgl,1,841,49.5691,0.9724

 F1-mic 0.9703,  F1-mac 0.8829
arctic25,dgl,1,842,49.6275,0.9703

 F1-mic 0.9724,  F1-mac 0.8766
new best val f1: 0.9724385356547197
arctic25,dgl,1,843,49.6859,0.9724

 F1-mic 0.9725,  F1-mac 0.8785
new best val f1: 0.9724625334469229
arctic25,dgl,1,844,49.7444,0.9725

 F1-mic 0.9701,  F1-mac 0.8835
arctic25,dgl,1,845,49.8029,0.9701

 F1-mic 0.9725,  F1-mac 0.8767
new best val f1: 0.9725165284793799
arctic25,dgl,1,846,49.8613,0.9725

 F1-mic 0.9725,  F1-mac 0.8780
new best val f1: 0.9725225279274307
arctic25,dgl,1,847,49.9198,0.9725

 F1-mic 0.9698,  F1-mac 0.8838
arctic25,dgl,1,848,49.9783,0.9698

 F1-mic 0.9725,  F1-mac 0.8758
arctic25,dgl,1,849,50.0367,0.9725

epoch:851/50, Iteration 32/32:training loss 0.14635562896728516
Train F1-mic 0.9726, Train F1-mac 0.8741
 F1-mic 0.9725,  F1-mac 0.8771
arctic25,dgl,1,850,50.0952,0.9725

 F1-mic 0.9701,  F1-mac 0.8838
arctic25,dgl,1,851,50.1535,0.9701

 F1-mic 0.9726,  F1-mac 0.8762
new best val f1: 0.9725585246157353
arctic25,dgl,1,852,50.2119,0.9726

 F1-mic 0.9726,  F1-mac 0.8772
new best val f1: 0.9726125196481925
arctic25,dgl,1,853,50.2703,0.9726

 F1-mic 0.9702,  F1-mac 0.8837
arctic25,dgl,1,854,50.3288,0.9702

 F1-mic 0.9726,  F1-mac 0.8759
arctic25,dgl,1,855,50.3873,0.9726

 F1-mic 0.9726,  F1-mac 0.8763
arctic25,dgl,1,856,50.4457,0.9726

 F1-mic 0.9700,  F1-mac 0.8840
arctic25,dgl,1,857,50.5041,0.9700

 F1-mic 0.9727,  F1-mac 0.8774
new best val f1: 0.9726665146806494
arctic25,dgl,1,858,50.5628,0.9727

 F1-mic 0.9727,  F1-mac 0.8778
new best val f1: 0.9727265091611572
arctic25,dgl,1,859,50.6213,0.9727

epoch:861/50, Iteration 32/32:training loss 0.14457637071609497
Train F1-mic 0.9728, Train F1-mac 0.8750
 F1-mic 0.9700,  F1-mac 0.8839
arctic25,dgl,1,860,50.6798,0.9700

 F1-mic 0.9726,  F1-mac 0.8759
arctic25,dgl,1,861,50.7382,0.9726

 F1-mic 0.9727,  F1-mac 0.8769
new best val f1: 0.9727325086092079
arctic25,dgl,1,862,50.7967,0.9727

 F1-mic 0.9699,  F1-mac 0.8838
arctic25,dgl,1,863,50.8551,0.9699

 F1-mic 0.9727,  F1-mac 0.8775
new best val f1: 0.9727385080572587
arctic25,dgl,1,864,50.9136,0.9727

 F1-mic 0.9728,  F1-mac 0.8774
new best val f1: 0.9727805041936142
arctic25,dgl,1,865,50.9722,0.9728

 F1-mic 0.9700,  F1-mac 0.8832
arctic25,dgl,1,866,51.0307,0.9700

 F1-mic 0.9727,  F1-mac 0.8787
arctic25,dgl,1,867,51.0891,0.9727

 F1-mic 0.9728,  F1-mac 0.8787
arctic25,dgl,1,868,51.1476,0.9728

 F1-mic 0.9704,  F1-mac 0.8835
arctic25,dgl,1,869,51.2061,0.9704

epoch:871/50, Iteration 32/32:training loss 0.14467914402484894
Train F1-mic 0.9704, Train F1-mac 0.8817
 F1-mic 0.9728,  F1-mac 0.8761
new best val f1: 0.972786503641665
arctic25,dgl,1,870,51.2645,0.9728

 F1-mic 0.9728,  F1-mac 0.8779
arctic25,dgl,1,871,51.3229,0.9728

 F1-mic 0.9699,  F1-mac 0.8842
arctic25,dgl,1,872,51.3814,0.9699

 F1-mic 0.9728,  F1-mac 0.8775
new best val f1: 0.9728045019858172
arctic25,dgl,1,873,51.4399,0.9728

 F1-mic 0.9729,  F1-mac 0.8774
new best val f1: 0.9728704959143759
arctic25,dgl,1,874,51.4984,0.9729

 F1-mic 0.9702,  F1-mac 0.8835
arctic25,dgl,1,875,51.5568,0.9702

 F1-mic 0.9728,  F1-mac 0.8789
arctic25,dgl,1,876,51.6153,0.9728

 F1-mic 0.9728,  F1-mac 0.8776
arctic25,dgl,1,877,51.6737,0.9728

 F1-mic 0.9707,  F1-mac 0.8833
arctic25,dgl,1,878,51.7321,0.9707

 F1-mic 0.9729,  F1-mac 0.8775
new best val f1: 0.9728884942585282
arctic25,dgl,1,879,51.7906,0.9729

epoch:881/50, Iteration 32/32:training loss 0.14278730750083923
Train F1-mic 0.9730, Train F1-mac 0.8761
 F1-mic 0.9729,  F1-mac 0.8802
new best val f1: 0.9729124920507314
arctic25,dgl,1,880,51.8490,0.9729

 F1-mic 0.9700,  F1-mac 0.8835
arctic25,dgl,1,881,51.9074,0.9700

 F1-mic 0.9729,  F1-mac 0.8753
arctic25,dgl,1,882,51.9659,0.9729

 F1-mic 0.9728,  F1-mac 0.8771
arctic25,dgl,1,883,52.0243,0.9728

 F1-mic 0.9705,  F1-mac 0.8840
arctic25,dgl,1,884,52.0828,0.9705

 F1-mic 0.9729,  F1-mac 0.8788
new best val f1: 0.9729244909468329
arctic25,dgl,1,885,52.1412,0.9729

 F1-mic 0.9729,  F1-mac 0.8789
new best val f1: 0.972948488739036
arctic25,dgl,1,886,52.1997,0.9729

 F1-mic 0.9712,  F1-mac 0.8834
arctic25,dgl,1,887,52.2581,0.9712

 F1-mic 0.9729,  F1-mac 0.8780
arctic25,dgl,1,888,52.3166,0.9729

 F1-mic 0.9729,  F1-mac 0.8789
arctic25,dgl,1,889,52.3750,0.9729

epoch:891/50, Iteration 32/32:training loss 0.14042991399765015
Train F1-mic 0.9730, Train F1-mac 0.8770
 F1-mic 0.9705,  F1-mac 0.8840
arctic25,dgl,1,890,52.4335,0.9705

 F1-mic 0.9730,  F1-mac 0.8763
new best val f1: 0.9730204821156454
arctic25,dgl,1,891,52.4919,0.9730

 F1-mic 0.9730,  F1-mac 0.8790
arctic25,dgl,1,892,52.5504,0.9730

 F1-mic 0.9698,  F1-mac 0.8844
arctic25,dgl,1,893,52.6092,0.9698

 F1-mic 0.9729,  F1-mac 0.8781
arctic25,dgl,1,894,52.6677,0.9729

 F1-mic 0.9730,  F1-mac 0.8763
arctic25,dgl,1,895,52.7262,0.9730

 F1-mic 0.9707,  F1-mac 0.8839
arctic25,dgl,1,896,52.7846,0.9707

 F1-mic 0.9730,  F1-mac 0.8805
arctic25,dgl,1,897,52.8431,0.9730

 F1-mic 0.9731,  F1-mac 0.8802
new best val f1: 0.9730564788039501
arctic25,dgl,1,898,52.9015,0.9731

 F1-mic 0.9703,  F1-mac 0.8841
arctic25,dgl,1,899,52.9599,0.9703

epoch:901/50, Iteration 32/32:training loss 0.14221958816051483
Train F1-mic 0.9703, Train F1-mac 0.8819
 F1-mic 0.9730,  F1-mac 0.8764
arctic25,dgl,1,900,53.0184,0.9730

 F1-mic 0.9730,  F1-mac 0.8786
arctic25,dgl,1,901,53.0767,0.9730

 F1-mic 0.9702,  F1-mac 0.8858
arctic25,dgl,1,902,53.1352,0.9702

 F1-mic 0.9731,  F1-mac 0.8784
new best val f1: 0.973086476044204
arctic25,dgl,1,903,53.1936,0.9731

 F1-mic 0.9731,  F1-mac 0.8778
new best val f1: 0.9731344716286102
arctic25,dgl,1,904,53.2521,0.9731

 F1-mic 0.9702,  F1-mac 0.8845
arctic25,dgl,1,905,53.3105,0.9702

 F1-mic 0.9731,  F1-mac 0.8791
arctic25,dgl,1,906,53.3689,0.9731

 F1-mic 0.9731,  F1-mac 0.8783
arctic25,dgl,1,907,53.4273,0.9731

 F1-mic 0.9703,  F1-mac 0.8843
arctic25,dgl,1,908,53.4859,0.9703

 F1-mic 0.9732,  F1-mac 0.8780
new best val f1: 0.9731704683169149
arctic25,dgl,1,909,53.5444,0.9732

epoch:911/50, Iteration 32/32:training loss 0.14022482931613922
Train F1-mic 0.9732, Train F1-mac 0.8774
 F1-mic 0.9732,  F1-mac 0.8793
arctic25,dgl,1,910,53.6029,0.9732

 F1-mic 0.9707,  F1-mac 0.8846
arctic25,dgl,1,911,53.6612,0.9707

 F1-mic 0.9731,  F1-mac 0.8784
arctic25,dgl,1,912,53.7197,0.9731

 F1-mic 0.9732,  F1-mac 0.8779
arctic25,dgl,1,913,53.7781,0.9732

 F1-mic 0.9706,  F1-mac 0.8847
arctic25,dgl,1,914,53.8366,0.9706

 F1-mic 0.9732,  F1-mac 0.8794
new best val f1: 0.9731884666610672
arctic25,dgl,1,915,53.8951,0.9732

 F1-mic 0.9732,  F1-mac 0.8792
arctic25,dgl,1,916,53.9535,0.9732

 F1-mic 0.9705,  F1-mac 0.8840
arctic25,dgl,1,917,54.0120,0.9705

 F1-mic 0.9732,  F1-mac 0.8784
new best val f1: 0.973218463901321
arctic25,dgl,1,918,54.0704,0.9732

 F1-mic 0.9732,  F1-mac 0.8793
arctic25,dgl,1,919,54.1291,0.9732

epoch:921/50, Iteration 32/32:training loss 0.13845108449459076
Train F1-mic 0.9733, Train F1-mac 0.8792
 F1-mic 0.9709,  F1-mac 0.8846
arctic25,dgl,1,920,54.1876,0.9709

 F1-mic 0.9732,  F1-mac 0.8786
new best val f1: 0.9732424616935242
arctic25,dgl,1,921,54.2459,0.9732

 F1-mic 0.9732,  F1-mac 0.8788
arctic25,dgl,1,922,54.3044,0.9732

 F1-mic 0.9708,  F1-mac 0.8852
arctic25,dgl,1,923,54.3628,0.9708

 F1-mic 0.9732,  F1-mac 0.8789
arctic25,dgl,1,924,54.4215,0.9732

 F1-mic 0.9733,  F1-mac 0.8790
new best val f1: 0.9732664594857273
arctic25,dgl,1,925,54.4802,0.9733

 F1-mic 0.9712,  F1-mac 0.8851
arctic25,dgl,1,926,54.5386,0.9712

 F1-mic 0.9732,  F1-mac 0.8785
arctic25,dgl,1,927,54.5970,0.9732

 F1-mic 0.9733,  F1-mac 0.8793
arctic25,dgl,1,928,54.6555,0.9733

 F1-mic 0.9713,  F1-mac 0.8852
arctic25,dgl,1,929,54.7142,0.9713

epoch:931/50, Iteration 32/32:training loss 0.13860464096069336
Train F1-mic 0.9712, Train F1-mac 0.8840
 F1-mic 0.9732,  F1-mac 0.8790
arctic25,dgl,1,930,54.7729,0.9732

 F1-mic 0.9733,  F1-mac 0.8785
new best val f1: 0.9733264539662351
arctic25,dgl,1,931,54.8313,0.9733

 F1-mic 0.9703,  F1-mac 0.8856
arctic25,dgl,1,932,54.8898,0.9703

 F1-mic 0.9733,  F1-mac 0.8790
arctic25,dgl,1,933,54.9482,0.9733

 F1-mic 0.9733,  F1-mac 0.8798
arctic25,dgl,1,934,55.0067,0.9733

 F1-mic 0.9711,  F1-mac 0.8855
arctic25,dgl,1,935,55.0651,0.9711

 F1-mic 0.9733,  F1-mac 0.8790
new best val f1: 0.9733444523103875
arctic25,dgl,1,936,55.1237,0.9733

 F1-mic 0.9733,  F1-mac 0.8785
arctic25,dgl,1,937,55.1821,0.9733

 F1-mic 0.9714,  F1-mac 0.8853
arctic25,dgl,1,938,55.2406,0.9714

 F1-mic 0.9734,  F1-mac 0.8790
new best val f1: 0.973356451206489
arctic25,dgl,1,939,55.2990,0.9734

epoch:941/50, Iteration 32/32:training loss 0.13728724420070648
Train F1-mic 0.9735, Train F1-mac 0.8786
 F1-mic 0.9734,  F1-mac 0.8806
new best val f1: 0.9733684501025905
arctic25,dgl,1,940,55.3575,0.9734

 F1-mic 0.9703,  F1-mac 0.8855
arctic25,dgl,1,941,55.4159,0.9703

 F1-mic 0.9733,  F1-mac 0.8782
arctic25,dgl,1,942,55.4743,0.9733

 F1-mic 0.9734,  F1-mac 0.8792
arctic25,dgl,1,943,55.5398,0.9734

 F1-mic 0.9711,  F1-mac 0.8859
arctic25,dgl,1,944,55.5982,0.9711

 F1-mic 0.9734,  F1-mac 0.8786
new best val f1: 0.9733744495506413
arctic25,dgl,1,945,55.6567,0.9734

 F1-mic 0.9734,  F1-mac 0.8795
new best val f1: 0.9733864484467429
arctic25,dgl,1,946,55.7151,0.9734

 F1-mic 0.9716,  F1-mac 0.8856
arctic25,dgl,1,947,55.7736,0.9716

 F1-mic 0.9733,  F1-mac 0.8790
arctic25,dgl,1,948,55.8320,0.9733

 F1-mic 0.9734,  F1-mac 0.8791
new best val f1: 0.9733924478947936
arctic25,dgl,1,949,55.8904,0.9734

epoch:951/50, Iteration 32/32:training loss 0.13513436913490295
Train F1-mic 0.9735, Train F1-mac 0.8786
 F1-mic 0.9713,  F1-mac 0.8862
arctic25,dgl,1,950,55.9489,0.9713

 F1-mic 0.9734,  F1-mac 0.8791
new best val f1: 0.9734404434791999
arctic25,dgl,1,951,56.0072,0.9734

 F1-mic 0.9734,  F1-mac 0.8805
arctic25,dgl,1,952,56.0657,0.9734

 F1-mic 0.9710,  F1-mac 0.8861
arctic25,dgl,1,953,56.1241,0.9710

 F1-mic 0.9734,  F1-mac 0.8788
arctic25,dgl,1,954,56.1826,0.9734

 F1-mic 0.9735,  F1-mac 0.8775
new best val f1: 0.9734704407194538
arctic25,dgl,1,955,56.2410,0.9735

 F1-mic 0.9716,  F1-mac 0.8856
arctic25,dgl,1,956,56.2995,0.9716

 F1-mic 0.9734,  F1-mac 0.8804
arctic25,dgl,1,957,56.3579,0.9734

 F1-mic 0.9735,  F1-mac 0.8802
new best val f1: 0.9735064374077584
arctic25,dgl,1,958,56.4164,0.9735

 F1-mic 0.9718,  F1-mac 0.8851
arctic25,dgl,1,959,56.4749,0.9718

epoch:961/50, Iteration 32/32:training loss 0.13543236255645752
Train F1-mic 0.9718, Train F1-mac 0.8834
 F1-mic 0.9735,  F1-mac 0.8802
arctic25,dgl,1,960,56.5335,0.9735

 F1-mic 0.9735,  F1-mac 0.8815
new best val f1: 0.9735364346480124
arctic25,dgl,1,961,56.5919,0.9735

 F1-mic 0.9717,  F1-mac 0.8854
arctic25,dgl,1,962,56.6506,0.9717

 F1-mic 0.9736,  F1-mac 0.8789
new best val f1: 0.9735544329921647
arctic25,dgl,1,963,56.7091,0.9736

 F1-mic 0.9736,  F1-mac 0.8799
new best val f1: 0.9735784307843678
arctic25,dgl,1,964,56.7675,0.9736

 F1-mic 0.9712,  F1-mac 0.8860
arctic25,dgl,1,965,56.8260,0.9712

 F1-mic 0.9735,  F1-mac 0.8794
arctic25,dgl,1,966,56.8844,0.9735

 F1-mic 0.9736,  F1-mac 0.8799
new best val f1: 0.9735844302324186
arctic25,dgl,1,967,56.9429,0.9736

 F1-mic 0.9709,  F1-mac 0.8866
arctic25,dgl,1,968,57.0013,0.9709

 F1-mic 0.9736,  F1-mac 0.8780
arctic25,dgl,1,969,57.0597,0.9736

epoch:971/50, Iteration 32/32:training loss 0.13499660789966583
Train F1-mic 0.9737, Train F1-mac 0.8780
 F1-mic 0.9736,  F1-mac 0.8806
arctic25,dgl,1,970,57.1182,0.9736

 F1-mic 0.9714,  F1-mac 0.8869
arctic25,dgl,1,971,57.1765,0.9714

 F1-mic 0.9736,  F1-mac 0.8784
new best val f1: 0.9736204269207233
arctic25,dgl,1,972,57.2349,0.9736

 F1-mic 0.9736,  F1-mac 0.8782
arctic25,dgl,1,973,57.2934,0.9736

 F1-mic 0.9717,  F1-mac 0.8860
arctic25,dgl,1,974,57.3519,0.9717

 F1-mic 0.9736,  F1-mac 0.8807
arctic25,dgl,1,975,57.4103,0.9736

 F1-mic 0.9737,  F1-mac 0.8810
new best val f1: 0.9737224175375866
arctic25,dgl,1,976,57.4690,0.9737

 F1-mic 0.9711,  F1-mac 0.8860
arctic25,dgl,1,977,57.5275,0.9711

 F1-mic 0.9737,  F1-mac 0.8793
arctic25,dgl,1,978,57.5859,0.9737

 F1-mic 0.9737,  F1-mac 0.8801
arctic25,dgl,1,979,57.6444,0.9737

epoch:981/50, Iteration 32/32:training loss 0.13398106396198273
Train F1-mic 0.9738, Train F1-mac 0.8796
 F1-mic 0.9714,  F1-mac 0.8864
arctic25,dgl,1,980,57.7028,0.9714

 F1-mic 0.9737,  F1-mac 0.8792
new best val f1: 0.9737404158817389
arctic25,dgl,1,981,57.7613,0.9737

 F1-mic 0.9738,  F1-mac 0.8809
new best val f1: 0.973764413673942
arctic25,dgl,1,982,57.8197,0.9738

 F1-mic 0.9718,  F1-mac 0.8865
arctic25,dgl,1,983,57.8782,0.9718

 F1-mic 0.9737,  F1-mac 0.8810
arctic25,dgl,1,984,57.9367,0.9737

 F1-mic 0.9738,  F1-mac 0.8810
new best val f1: 0.9737884114661451
arctic25,dgl,1,985,57.9951,0.9738

 F1-mic 0.9711,  F1-mac 0.8855
arctic25,dgl,1,986,58.0536,0.9711

 F1-mic 0.9738,  F1-mac 0.8789
arctic25,dgl,1,987,58.1121,0.9738

 F1-mic 0.9738,  F1-mac 0.8824
arctic25,dgl,1,988,58.1706,0.9738

 F1-mic 0.9714,  F1-mac 0.8869
arctic25,dgl,1,989,58.2290,0.9714

epoch:991/50, Iteration 32/32:training loss 0.13404016196727753
Train F1-mic 0.9714, Train F1-mac 0.8855
 F1-mic 0.9738,  F1-mac 0.8778
arctic25,dgl,1,990,58.2875,0.9738

 F1-mic 0.9738,  F1-mac 0.8770
arctic25,dgl,1,991,58.3459,0.9738

 F1-mic 0.9718,  F1-mac 0.8864
arctic25,dgl,1,992,58.4046,0.9718

 F1-mic 0.9738,  F1-mac 0.8803
arctic25,dgl,1,993,58.4631,0.9738

 F1-mic 0.9738,  F1-mac 0.8821
new best val f1: 0.9738004103622466
arctic25,dgl,1,994,58.5215,0.9738

 F1-mic 0.9705,  F1-mac 0.8868
arctic25,dgl,1,995,58.5800,0.9705

 F1-mic 0.9738,  F1-mac 0.8803
new best val f1: 0.9738484059466529
arctic25,dgl,1,996,58.6404,0.9738

 F1-mic 0.9738,  F1-mac 0.8794
arctic25,dgl,1,997,58.6989,0.9738

 F1-mic 0.9717,  F1-mac 0.8849
arctic25,dgl,1,998,58.7573,0.9717

 F1-mic 0.9739,  F1-mac 0.8777
new best val f1: 0.9739323982193638
arctic25,dgl,1,999,58.8158,0.9739

epoch:1001/50, Iteration 32/32:training loss 0.13156196475028992
Train F1-mic 0.9740, Train F1-mac 0.8770
 F1-mic 0.9739,  F1-mac 0.8818
arctic25,dgl,1,1000,58.8743,0.9739

 F1-mic 0.9715,  F1-mac 0.8865
arctic25,dgl,1,1001,58.9327,0.9715

 F1-mic 0.9738,  F1-mac 0.8804
arctic25,dgl,1,1002,58.9911,0.9738

 F1-mic 0.9739,  F1-mac 0.8775
arctic25,dgl,1,1003,59.0496,0.9739

 F1-mic 0.9709,  F1-mac 0.8839
arctic25,dgl,1,1004,59.1081,0.9709

 F1-mic 0.9739,  F1-mac 0.8767
arctic25,dgl,1,1005,59.1668,0.9739

 F1-mic 0.9739,  F1-mac 0.8802
new best val f1: 0.9739383976674146
arctic25,dgl,1,1006,59.2253,0.9739

 F1-mic 0.9717,  F1-mac 0.8872
arctic25,dgl,1,1007,59.2837,0.9717

 F1-mic 0.9739,  F1-mac 0.8795
arctic25,dgl,1,1008,59.3423,0.9739

 F1-mic 0.9739,  F1-mac 0.8769
arctic25,dgl,1,1009,59.4007,0.9739

epoch:1011/50, Iteration 32/32:training loss 0.13055932521820068
Train F1-mic 0.9740, Train F1-mac 0.8763
 F1-mic 0.9717,  F1-mac 0.8862
arctic25,dgl,1,1010,59.4592,0.9717

 F1-mic 0.9740,  F1-mac 0.8812
new best val f1: 0.9739563960115669
arctic25,dgl,1,1011,59.5175,0.9740

 F1-mic 0.9740,  F1-mac 0.8821
new best val f1: 0.9740043915959732
arctic25,dgl,1,1012,59.5759,0.9740

 F1-mic 0.9714,  F1-mac 0.8869
arctic25,dgl,1,1013,59.6345,0.9714

 F1-mic 0.9740,  F1-mac 0.8808
arctic25,dgl,1,1014,59.6930,0.9740

 F1-mic 0.9740,  F1-mac 0.8834
arctic25,dgl,1,1015,59.7514,0.9740

 F1-mic 0.9717,  F1-mac 0.8877
arctic25,dgl,1,1016,59.8098,0.9717

 F1-mic 0.9740,  F1-mac 0.8813
arctic25,dgl,1,1017,59.8683,0.9740

 F1-mic 0.9740,  F1-mac 0.8804
new best val f1: 0.9740283893881763
arctic25,dgl,1,1018,59.9267,0.9740

 F1-mic 0.9718,  F1-mac 0.8865
arctic25,dgl,1,1019,59.9852,0.9718

epoch:1021/50, Iteration 32/32:training loss 0.13168679177761078
Train F1-mic 0.9716, Train F1-mac 0.8853
 F1-mic 0.9740,  F1-mac 0.8796
new best val f1: 0.9740343888362271
arctic25,dgl,1,1020,60.0436,0.9740

 F1-mic 0.9740,  F1-mac 0.8826
arctic25,dgl,1,1021,60.1020,0.9740

 F1-mic 0.9706,  F1-mac 0.8884
arctic25,dgl,1,1022,60.1604,0.9706

 F1-mic 0.9740,  F1-mac 0.8826
new best val f1: 0.974040388284278
arctic25,dgl,1,1023,60.2189,0.9740

 F1-mic 0.9739,  F1-mac 0.8787
arctic25,dgl,1,1024,60.2774,0.9739

 F1-mic 0.9721,  F1-mac 0.8850
arctic25,dgl,1,1025,60.3358,0.9721

 F1-mic 0.9740,  F1-mac 0.8826
arctic25,dgl,1,1026,60.3943,0.9740

 F1-mic 0.9741,  F1-mac 0.8840
new best val f1: 0.9740643860764809
arctic25,dgl,1,1027,60.4527,0.9741

 F1-mic 0.9724,  F1-mac 0.8862
arctic25,dgl,1,1028,60.5111,0.9724

 F1-mic 0.9741,  F1-mac 0.8833
arctic25,dgl,1,1029,60.5696,0.9741

epoch:1031/50, Iteration 32/32:training loss 0.129442036151886
Train F1-mic 0.9741, Train F1-mac 0.8814
 F1-mic 0.9741,  F1-mac 0.8838
new best val f1: 0.9740823844206333
arctic25,dgl,1,1030,60.6281,0.9741

 F1-mic 0.9720,  F1-mac 0.8868
arctic25,dgl,1,1031,60.6864,0.9720

 F1-mic 0.9740,  F1-mac 0.8807
arctic25,dgl,1,1032,60.7449,0.9740

 F1-mic 0.9741,  F1-mac 0.8817
arctic25,dgl,1,1033,60.8036,0.9741

 F1-mic 0.9714,  F1-mac 0.8871
arctic25,dgl,1,1034,60.8621,0.9714

 F1-mic 0.9740,  F1-mac 0.8821
arctic25,dgl,1,1035,60.9205,0.9740

 F1-mic 0.9740,  F1-mac 0.8832
arctic25,dgl,1,1036,60.9789,0.9740

 F1-mic 0.9718,  F1-mac 0.8871
arctic25,dgl,1,1037,61.0373,0.9718

 F1-mic 0.9741,  F1-mac 0.8812
new best val f1: 0.9741243805569888
arctic25,dgl,1,1038,61.0958,0.9741

 F1-mic 0.9741,  F1-mac 0.8820
arctic25,dgl,1,1039,61.1542,0.9741

epoch:1041/50, Iteration 32/32:training loss 0.1283387690782547
Train F1-mic 0.9742, Train F1-mac 0.8816
 F1-mic 0.9718,  F1-mac 0.8871
arctic25,dgl,1,1040,61.2126,0.9718

 F1-mic 0.9741,  F1-mac 0.8791
arctic25,dgl,1,1041,61.2710,0.9741

 F1-mic 0.9741,  F1-mac 0.8814
arctic25,dgl,1,1042,61.3294,0.9741

 F1-mic 0.9708,  F1-mac 0.8879
arctic25,dgl,1,1043,61.3878,0.9708

 F1-mic 0.9742,  F1-mac 0.8826
new best val f1: 0.9741663766933442
arctic25,dgl,1,1044,61.4464,0.9742

 F1-mic 0.9742,  F1-mac 0.8818
new best val f1: 0.9741843750374966
arctic25,dgl,1,1045,61.5048,0.9742

 F1-mic 0.9718,  F1-mac 0.8866
arctic25,dgl,1,1046,61.5633,0.9718

 F1-mic 0.9742,  F1-mac 0.8808
arctic25,dgl,1,1047,61.6217,0.9742

 F1-mic 0.9742,  F1-mac 0.8831
arctic25,dgl,1,1048,61.6802,0.9742

 F1-mic 0.9716,  F1-mac 0.8880
arctic25,dgl,1,1049,61.7386,0.9716

epoch:1051/50, Iteration 32/32:training loss 0.1297050565481186
Train F1-mic 0.9715, Train F1-mac 0.8868
 F1-mic 0.9741,  F1-mac 0.8818
arctic25,dgl,1,1050,61.7971,0.9741

 F1-mic 0.9742,  F1-mac 0.8819
new best val f1: 0.9742323706219028
arctic25,dgl,1,1051,61.8555,0.9742

 F1-mic 0.9713,  F1-mac 0.8872
arctic25,dgl,1,1052,61.9140,0.9713

 F1-mic 0.9742,  F1-mac 0.8824
arctic25,dgl,1,1053,61.9725,0.9742

 F1-mic 0.9742,  F1-mac 0.8822
arctic25,dgl,1,1054,62.0311,0.9742

 F1-mic 0.9717,  F1-mac 0.8872
arctic25,dgl,1,1055,62.0895,0.9717

 F1-mic 0.9742,  F1-mac 0.8823
new best val f1: 0.9742383700699536
arctic25,dgl,1,1056,62.1480,0.9742

 F1-mic 0.9742,  F1-mac 0.8842
new best val f1: 0.9742443695180044
arctic25,dgl,1,1057,62.2064,0.9742

 F1-mic 0.9715,  F1-mac 0.8878
arctic25,dgl,1,1058,62.2649,0.9715

 F1-mic 0.9742,  F1-mac 0.8813
arctic25,dgl,1,1059,62.3234,0.9742

epoch:1061/50, Iteration 32/32:training loss 0.1285679191350937
Train F1-mic 0.9743, Train F1-mac 0.8800
 F1-mic 0.9742,  F1-mac 0.8823
arctic25,dgl,1,1060,62.3818,0.9742

 F1-mic 0.9718,  F1-mac 0.8877
arctic25,dgl,1,1061,62.4403,0.9718

 F1-mic 0.9742,  F1-mac 0.8819
arctic25,dgl,1,1062,62.4988,0.9742

 F1-mic 0.9742,  F1-mac 0.8815
arctic25,dgl,1,1063,62.5573,0.9742

 F1-mic 0.9721,  F1-mac 0.8880
arctic25,dgl,1,1064,62.6158,0.9721

 F1-mic 0.9743,  F1-mac 0.8836
new best val f1: 0.9742683673102075
arctic25,dgl,1,1065,62.6742,0.9743

 F1-mic 0.9743,  F1-mac 0.8835
arctic25,dgl,1,1066,62.7327,0.9743

 F1-mic 0.9716,  F1-mac 0.8877
arctic25,dgl,1,1067,62.7911,0.9716

 F1-mic 0.9743,  F1-mac 0.8813
new best val f1: 0.9743223623426644
arctic25,dgl,1,1068,62.8496,0.9743

 F1-mic 0.9743,  F1-mac 0.8825
arctic25,dgl,1,1069,62.9080,0.9743

epoch:1071/50, Iteration 32/32:training loss 0.12740890681743622
Train F1-mic 0.9743, Train F1-mac 0.8810
 F1-mic 0.9719,  F1-mac 0.8883
arctic25,dgl,1,1070,62.9664,0.9719

 F1-mic 0.9744,  F1-mac 0.8827
new best val f1: 0.9743943557192738
arctic25,dgl,1,1071,63.0247,0.9744

 F1-mic 0.9743,  F1-mac 0.8824
arctic25,dgl,1,1072,63.0832,0.9743

 F1-mic 0.9721,  F1-mac 0.8872
arctic25,dgl,1,1073,63.1417,0.9721

 F1-mic 0.9743,  F1-mac 0.8837
arctic25,dgl,1,1074,63.2002,0.9743

 F1-mic 0.9744,  F1-mac 0.8837
arctic25,dgl,1,1075,63.2587,0.9744

 F1-mic 0.9719,  F1-mac 0.8875
arctic25,dgl,1,1076,63.3171,0.9719

 F1-mic 0.9743,  F1-mac 0.8821
arctic25,dgl,1,1077,63.3756,0.9743

 F1-mic 0.9743,  F1-mac 0.8837
arctic25,dgl,1,1078,63.4340,0.9743

 F1-mic 0.9721,  F1-mac 0.8881
arctic25,dgl,1,1079,63.4925,0.9721

epoch:1081/50, Iteration 32/32:training loss 0.12732435762882233
Train F1-mic 0.9720, Train F1-mac 0.8873
 F1-mic 0.9743,  F1-mac 0.8825
arctic25,dgl,1,1080,63.5510,0.9743

 F1-mic 0.9744,  F1-mac 0.8829
arctic25,dgl,1,1081,63.6093,0.9744

 F1-mic 0.9723,  F1-mac 0.8881
arctic25,dgl,1,1082,63.6678,0.9723

 F1-mic 0.9744,  F1-mac 0.8826
new best val f1: 0.9744123540634262
arctic25,dgl,1,1083,63.7262,0.9744

 F1-mic 0.9744,  F1-mac 0.8836
arctic25,dgl,1,1084,63.7847,0.9744

 F1-mic 0.9717,  F1-mac 0.8880
arctic25,dgl,1,1085,63.8432,0.9717

 F1-mic 0.9744,  F1-mac 0.8817
arctic25,dgl,1,1086,63.9017,0.9744

 F1-mic 0.9744,  F1-mac 0.8826
new best val f1: 0.974418353511477
arctic25,dgl,1,1087,63.9601,0.9744

 F1-mic 0.9716,  F1-mac 0.8878
arctic25,dgl,1,1088,64.0186,0.9716

 F1-mic 0.9744,  F1-mac 0.8827
new best val f1: 0.9744243529595277
arctic25,dgl,1,1089,64.0770,0.9744

epoch:1091/50, Iteration 32/32:training loss 0.12547588348388672
Train F1-mic 0.9745, Train F1-mac 0.8817
 F1-mic 0.9744,  F1-mac 0.8826
arctic25,dgl,1,1090,64.1355,0.9744

 F1-mic 0.9724,  F1-mac 0.8880
arctic25,dgl,1,1091,64.1938,0.9724

 F1-mic 0.9745,  F1-mac 0.8839
new best val f1: 0.9744543501997817
arctic25,dgl,1,1092,64.2523,0.9745

 F1-mic 0.9745,  F1-mac 0.8844
new best val f1: 0.9744843474400355
arctic25,dgl,1,1093,64.3107,0.9745

 F1-mic 0.9722,  F1-mac 0.8874
arctic25,dgl,1,1094,64.3692,0.9722

 F1-mic 0.9744,  F1-mac 0.8818
arctic25,dgl,1,1095,64.4277,0.9744

 F1-mic 0.9744,  F1-mac 0.8839
arctic25,dgl,1,1096,64.4861,0.9744

 F1-mic 0.9721,  F1-mac 0.8880
arctic25,dgl,1,1097,64.5445,0.9721

 F1-mic 0.9745,  F1-mac 0.8819
new best val f1: 0.9745023457841878
arctic25,dgl,1,1098,64.6030,0.9745

 F1-mic 0.9745,  F1-mac 0.8830
new best val f1: 0.9745203441283402
arctic25,dgl,1,1099,64.6614,0.9745

epoch:1101/50, Iteration 32/32:training loss 0.12449120730161667
Train F1-mic 0.9746, Train F1-mac 0.8814
 F1-mic 0.9722,  F1-mac 0.8882
arctic25,dgl,1,1100,64.7199,0.9722

 F1-mic 0.9745,  F1-mac 0.8828
arctic25,dgl,1,1101,64.7783,0.9745

 F1-mic 0.9745,  F1-mac 0.8832
new best val f1: 0.9745443419205433
arctic25,dgl,1,1102,64.8367,0.9745

 F1-mic 0.9721,  F1-mac 0.8880
arctic25,dgl,1,1103,64.8952,0.9721

 F1-mic 0.9746,  F1-mac 0.8832
new best val f1: 0.9745683397127464
arctic25,dgl,1,1104,64.9537,0.9746

 F1-mic 0.9746,  F1-mac 0.8831
arctic25,dgl,1,1105,65.0121,0.9746

 F1-mic 0.9720,  F1-mac 0.8881
arctic25,dgl,1,1106,65.0706,0.9720

 F1-mic 0.9746,  F1-mac 0.8819
arctic25,dgl,1,1107,65.1290,0.9746

 F1-mic 0.9746,  F1-mac 0.8832
new best val f1: 0.9746283341932542
arctic25,dgl,1,1108,65.1874,0.9746

 F1-mic 0.9718,  F1-mac 0.8888
arctic25,dgl,1,1109,65.2459,0.9718

epoch:1111/50, Iteration 32/32:training loss 0.12599612772464752
Train F1-mic 0.9718, Train F1-mac 0.8878
 F1-mic 0.9746,  F1-mac 0.8821
arctic25,dgl,1,1110,65.3044,0.9746

 F1-mic 0.9746,  F1-mac 0.8820
arctic25,dgl,1,1111,65.3629,0.9746

 F1-mic 0.9721,  F1-mac 0.8882
arctic25,dgl,1,1112,65.4213,0.9721

 F1-mic 0.9746,  F1-mac 0.8838
arctic25,dgl,1,1113,65.4800,0.9746

 F1-mic 0.9746,  F1-mac 0.8830
new best val f1: 0.974634333641305
arctic25,dgl,1,1114,65.5385,0.9746

 F1-mic 0.9719,  F1-mac 0.8884
arctic25,dgl,1,1115,65.5969,0.9719

 F1-mic 0.9747,  F1-mac 0.8827
new best val f1: 0.9746523319854573
arctic25,dgl,1,1116,65.6554,0.9747

 F1-mic 0.9747,  F1-mac 0.8831
new best val f1: 0.9746643308815589
arctic25,dgl,1,1117,65.7139,0.9747

 F1-mic 0.9718,  F1-mac 0.8879
arctic25,dgl,1,1118,65.7723,0.9718

 F1-mic 0.9747,  F1-mac 0.8835
arctic25,dgl,1,1119,65.8308,0.9747

epoch:1121/50, Iteration 32/32:training loss 0.12393832206726074
Train F1-mic 0.9747, Train F1-mac 0.8821
 F1-mic 0.9746,  F1-mac 0.8831
arctic25,dgl,1,1120,65.8893,0.9746

 F1-mic 0.9725,  F1-mac 0.8876
arctic25,dgl,1,1121,65.9476,0.9725

 F1-mic 0.9747,  F1-mac 0.8833
new best val f1: 0.9746943281218128
arctic25,dgl,1,1122,66.0061,0.9747

 F1-mic 0.9747,  F1-mac 0.8843
new best val f1: 0.9747303248101175
arctic25,dgl,1,1123,66.0645,0.9747

 F1-mic 0.9731,  F1-mac 0.8882
arctic25,dgl,1,1124,66.1230,0.9731

 F1-mic 0.9747,  F1-mac 0.8834
arctic25,dgl,1,1125,66.1815,0.9747

 F1-mic 0.9747,  F1-mac 0.8841
arctic25,dgl,1,1126,66.2399,0.9747

 F1-mic 0.9733,  F1-mac 0.8878
arctic25,dgl,1,1127,66.2986,0.9733

 F1-mic 0.9747,  F1-mac 0.8833
new best val f1: 0.974742323706219
arctic25,dgl,1,1128,66.3571,0.9747

 F1-mic 0.9747,  F1-mac 0.8847
arctic25,dgl,1,1129,66.4155,0.9747

epoch:1131/50, Iteration 32/32:training loss 0.12167759239673615
Train F1-mic 0.9748, Train F1-mac 0.8833
 F1-mic 0.9730,  F1-mac 0.8881
arctic25,dgl,1,1130,66.4739,0.9730

 F1-mic 0.9747,  F1-mac 0.8833
arctic25,dgl,1,1131,66.5323,0.9747

 F1-mic 0.9747,  F1-mac 0.8835
new best val f1: 0.9747483231542698
arctic25,dgl,1,1132,66.5907,0.9747

 F1-mic 0.9723,  F1-mac 0.8876
arctic25,dgl,1,1133,66.6492,0.9723

 F1-mic 0.9747,  F1-mac 0.8835
arctic25,dgl,1,1134,66.7077,0.9747

 F1-mic 0.9748,  F1-mac 0.8857
new best val f1: 0.9748383148750315
arctic25,dgl,1,1135,66.7662,0.9748

 F1-mic 0.9721,  F1-mac 0.8886
arctic25,dgl,1,1136,66.8246,0.9721

 F1-mic 0.9747,  F1-mac 0.8835
arctic25,dgl,1,1137,66.8833,0.9747

 F1-mic 0.9747,  F1-mac 0.8834
arctic25,dgl,1,1138,66.9420,0.9747

 F1-mic 0.9723,  F1-mac 0.8886
arctic25,dgl,1,1139,67.0004,0.9723

epoch:1141/50, Iteration 32/32:training loss 0.12358392775058746
Train F1-mic 0.9724, Train F1-mac 0.8878
 F1-mic 0.9748,  F1-mac 0.8836
arctic25,dgl,1,1140,67.0589,0.9748

 F1-mic 0.9749,  F1-mac 0.8847
new best val f1: 0.9748503137711331
arctic25,dgl,1,1141,67.1173,0.9749

 F1-mic 0.9724,  F1-mac 0.8890
arctic25,dgl,1,1142,67.1757,0.9724

 F1-mic 0.9749,  F1-mac 0.8833
new best val f1: 0.9748563132191839
arctic25,dgl,1,1143,67.2342,0.9749

 F1-mic 0.9748,  F1-mac 0.8835
arctic25,dgl,1,1144,67.2929,0.9748

 F1-mic 0.9723,  F1-mac 0.8881
arctic25,dgl,1,1145,67.3513,0.9723

 F1-mic 0.9748,  F1-mac 0.8832
arctic25,dgl,1,1146,67.4098,0.9748

 F1-mic 0.9749,  F1-mac 0.8838
new best val f1: 0.9748623126672347
arctic25,dgl,1,1147,67.4682,0.9749

 F1-mic 0.9726,  F1-mac 0.8891
arctic25,dgl,1,1148,67.5267,0.9726

 F1-mic 0.9749,  F1-mac 0.8834
new best val f1: 0.9748683121152854
arctic25,dgl,1,1149,67.5852,0.9749

epoch:1151/50, Iteration 32/32:training loss 0.12155907601118088
Train F1-mic 0.9749, Train F1-mac 0.8819
 F1-mic 0.9749,  F1-mac 0.8832
arctic25,dgl,1,1150,67.6438,0.9749

 F1-mic 0.9729,  F1-mac 0.8879
arctic25,dgl,1,1151,67.7021,0.9729

 F1-mic 0.9749,  F1-mac 0.8841
new best val f1: 0.9749463049399455
arctic25,dgl,1,1152,67.7606,0.9749

 F1-mic 0.9749,  F1-mac 0.8852
arctic25,dgl,1,1153,67.8191,0.9749

 F1-mic 0.9729,  F1-mac 0.8892
arctic25,dgl,1,1154,67.8777,0.9729

 F1-mic 0.9749,  F1-mac 0.8855
arctic25,dgl,1,1155,67.9361,0.9749

 F1-mic 0.9750,  F1-mac 0.8842
new best val f1: 0.9749763021801994
arctic25,dgl,1,1156,67.9945,0.9750

 F1-mic 0.9728,  F1-mac 0.8868
arctic25,dgl,1,1157,68.0530,0.9728

 F1-mic 0.9749,  F1-mac 0.8818
arctic25,dgl,1,1158,68.1114,0.9749

 F1-mic 0.9749,  F1-mac 0.8862
arctic25,dgl,1,1159,68.1700,0.9749

epoch:1161/50, Iteration 32/32:training loss 0.12059309333562851
Train F1-mic 0.9749, Train F1-mac 0.8837
 F1-mic 0.9724,  F1-mac 0.8895
arctic25,dgl,1,1160,68.2285,0.9724

 F1-mic 0.9749,  F1-mac 0.8838
arctic25,dgl,1,1161,68.2868,0.9749

 F1-mic 0.9749,  F1-mac 0.8819
arctic25,dgl,1,1162,68.3453,0.9749

 F1-mic 0.9725,  F1-mac 0.8874
arctic25,dgl,1,1163,68.4037,0.9725

 F1-mic 0.9749,  F1-mac 0.8817
arctic25,dgl,1,1164,68.4622,0.9749

 F1-mic 0.9749,  F1-mac 0.8847
arctic25,dgl,1,1165,68.5207,0.9749

 F1-mic 0.9729,  F1-mac 0.8898
arctic25,dgl,1,1166,68.5791,0.9729

 F1-mic 0.9749,  F1-mac 0.8851
arctic25,dgl,1,1167,68.6375,0.9749

 F1-mic 0.9750,  F1-mac 0.8841
arctic25,dgl,1,1168,68.6959,0.9750

 F1-mic 0.9726,  F1-mac 0.8866
arctic25,dgl,1,1169,68.7544,0.9726

epoch:1171/50, Iteration 32/32:training loss 0.12176093459129333
Train F1-mic 0.9727, Train F1-mac 0.8859
 F1-mic 0.9750,  F1-mac 0.8799
arctic25,dgl,1,1170,68.8129,0.9750

 F1-mic 0.9749,  F1-mac 0.8834
arctic25,dgl,1,1171,68.8713,0.9749

 F1-mic 0.9719,  F1-mac 0.8898
arctic25,dgl,1,1172,68.9297,0.9719

 F1-mic 0.9750,  F1-mac 0.8838
arctic25,dgl,1,1173,68.9882,0.9750

 F1-mic 0.9750,  F1-mac 0.8804
arctic25,dgl,1,1174,69.0467,0.9750

 F1-mic 0.9724,  F1-mac 0.8866
arctic25,dgl,1,1175,69.1051,0.9724

 F1-mic 0.9751,  F1-mac 0.8829
new best val f1: 0.9750542950048595
arctic25,dgl,1,1176,69.1635,0.9751

 F1-mic 0.9750,  F1-mac 0.8857
arctic25,dgl,1,1177,69.2220,0.9750

 F1-mic 0.9726,  F1-mac 0.8899
arctic25,dgl,1,1178,69.2804,0.9726

 F1-mic 0.9750,  F1-mac 0.8853
arctic25,dgl,1,1179,69.3388,0.9750

epoch:1181/50, Iteration 32/32:training loss 0.12019642442464828
Train F1-mic 0.9750, Train F1-mac 0.8832
 F1-mic 0.9750,  F1-mac 0.8837
arctic25,dgl,1,1180,69.3973,0.9750

 F1-mic 0.9727,  F1-mac 0.8874
arctic25,dgl,1,1181,69.4556,0.9727

 F1-mic 0.9751,  F1-mac 0.8837
new best val f1: 0.9750602944529103
arctic25,dgl,1,1182,69.5141,0.9751

 F1-mic 0.9750,  F1-mac 0.8847
arctic25,dgl,1,1183,69.5725,0.9750

 F1-mic 0.9727,  F1-mac 0.8897
arctic25,dgl,1,1184,69.6311,0.9727

 F1-mic 0.9750,  F1-mac 0.8857
arctic25,dgl,1,1185,69.6895,0.9750

 F1-mic 0.9750,  F1-mac 0.8839
arctic25,dgl,1,1186,69.7480,0.9750

 F1-mic 0.9727,  F1-mac 0.8881
arctic25,dgl,1,1187,69.8065,0.9727

 F1-mic 0.9751,  F1-mac 0.8838
new best val f1: 0.9750842922451135
arctic25,dgl,1,1188,69.8649,0.9751

 F1-mic 0.9750,  F1-mac 0.8852
arctic25,dgl,1,1189,69.9236,0.9750

epoch:1191/50, Iteration 32/32:training loss 0.11911298334598541
Train F1-mic 0.9751, Train F1-mac 0.8839
 F1-mic 0.9728,  F1-mac 0.8887
arctic25,dgl,1,1190,69.9820,0.9728

 F1-mic 0.9751,  F1-mac 0.8840
arctic25,dgl,1,1191,70.0403,0.9751

 F1-mic 0.9751,  F1-mac 0.8841
arctic25,dgl,1,1192,70.0988,0.9751

 F1-mic 0.9729,  F1-mac 0.8889
arctic25,dgl,1,1193,70.1572,0.9729

 F1-mic 0.9751,  F1-mac 0.8854
arctic25,dgl,1,1194,70.2160,0.9751

 F1-mic 0.9751,  F1-mac 0.8839
arctic25,dgl,1,1195,70.2744,0.9751

 F1-mic 0.9732,  F1-mac 0.8879
arctic25,dgl,1,1196,70.3329,0.9732

 F1-mic 0.9751,  F1-mac 0.8842
new best val f1: 0.9751322878295197
arctic25,dgl,1,1197,70.3913,0.9751

 F1-mic 0.9751,  F1-mac 0.8855
arctic25,dgl,1,1198,70.4497,0.9751

 F1-mic 0.9730,  F1-mac 0.8887
arctic25,dgl,1,1199,70.5082,0.9730

epoch:1201/50, Iteration 32/32:training loss 0.11949615925550461
Train F1-mic 0.9730, Train F1-mac 0.8879
 F1-mic 0.9752,  F1-mac 0.8864
new best val f1: 0.9751562856217229
arctic25,dgl,1,1200,70.5667,0.9752

 F1-mic 0.9751,  F1-mac 0.8842
arctic25,dgl,1,1201,70.6250,0.9751

 F1-mic 0.9726,  F1-mac 0.8880
arctic25,dgl,1,1202,70.6835,0.9726

 F1-mic 0.9751,  F1-mac 0.8840
arctic25,dgl,1,1203,70.7419,0.9751

 F1-mic 0.9752,  F1-mac 0.8858
new best val f1: 0.9751742839658751
arctic25,dgl,1,1204,70.8004,0.9752

 F1-mic 0.9725,  F1-mac 0.8893
arctic25,dgl,1,1205,70.8588,0.9725

 F1-mic 0.9751,  F1-mac 0.8851
arctic25,dgl,1,1206,70.9173,0.9751

 F1-mic 0.9752,  F1-mac 0.8867
new best val f1: 0.9752102806541798
arctic25,dgl,1,1207,70.9757,0.9752

 F1-mic 0.9729,  F1-mac 0.8885
arctic25,dgl,1,1208,71.0342,0.9729

 F1-mic 0.9752,  F1-mac 0.8838
arctic25,dgl,1,1209,71.0927,0.9752

epoch:1211/50, Iteration 32/32:training loss 0.11802920699119568
Train F1-mic 0.9752, Train F1-mac 0.8824
 F1-mic 0.9752,  F1-mac 0.8848
arctic25,dgl,1,1210,71.1514,0.9752

 F1-mic 0.9727,  F1-mac 0.8890
arctic25,dgl,1,1211,71.2097,0.9727

 F1-mic 0.9752,  F1-mac 0.8841
arctic25,dgl,1,1212,71.2683,0.9752

 F1-mic 0.9752,  F1-mac 0.8845
arctic25,dgl,1,1213,71.3267,0.9752

 F1-mic 0.9724,  F1-mac 0.8895
arctic25,dgl,1,1214,71.3852,0.9724

 F1-mic 0.9752,  F1-mac 0.8855
new best val f1: 0.9752222795502814
arctic25,dgl,1,1215,71.4437,0.9752

 F1-mic 0.9752,  F1-mac 0.8847
new best val f1: 0.9752342784463829
arctic25,dgl,1,1216,71.5022,0.9752

 F1-mic 0.9728,  F1-mac 0.8887
arctic25,dgl,1,1217,71.5606,0.9728

 F1-mic 0.9753,  F1-mac 0.8843
new best val f1: 0.9752702751346876
arctic25,dgl,1,1218,71.6191,0.9753

 F1-mic 0.9752,  F1-mac 0.8852
arctic25,dgl,1,1219,71.6775,0.9752

epoch:1221/50, Iteration 32/32:training loss 0.11751087754964828
Train F1-mic 0.9753, Train F1-mac 0.8838
 F1-mic 0.9725,  F1-mac 0.8894
arctic25,dgl,1,1220,71.7359,0.9725

 F1-mic 0.9753,  F1-mac 0.8843
arctic25,dgl,1,1221,71.7943,0.9753

 F1-mic 0.9753,  F1-mac 0.8846
arctic25,dgl,1,1222,71.8528,0.9753

 F1-mic 0.9727,  F1-mac 0.8891
arctic25,dgl,1,1223,71.9112,0.9727

 F1-mic 0.9753,  F1-mac 0.8842
new best val f1: 0.9752762745827384
arctic25,dgl,1,1224,71.9697,0.9753

 F1-mic 0.9753,  F1-mac 0.8843
new best val f1: 0.97528827347884
arctic25,dgl,1,1225,72.0282,0.9753

 F1-mic 0.9726,  F1-mac 0.8890
arctic25,dgl,1,1226,72.0866,0.9726

 F1-mic 0.9753,  F1-mac 0.8845
arctic25,dgl,1,1227,72.1454,0.9753

 F1-mic 0.9753,  F1-mac 0.8849
arctic25,dgl,1,1228,72.2038,0.9753

 F1-mic 0.9727,  F1-mac 0.8894
arctic25,dgl,1,1229,72.2622,0.9727

epoch:1231/50, Iteration 32/32:training loss 0.11868124455213547
Train F1-mic 0.9727, Train F1-mac 0.8886
 F1-mic 0.9753,  F1-mac 0.8841
new best val f1: 0.9753002723749415
arctic25,dgl,1,1230,72.3208,0.9753

 F1-mic 0.9753,  F1-mac 0.8861
new best val f1: 0.9753482679593477
arctic25,dgl,1,1231,72.3791,0.9753

 F1-mic 0.9722,  F1-mac 0.8893
arctic25,dgl,1,1232,72.4378,0.9722

 F1-mic 0.9753,  F1-mac 0.8842
arctic25,dgl,1,1233,72.4963,0.9753

 F1-mic 0.9753,  F1-mac 0.8845
arctic25,dgl,1,1234,72.5548,0.9753

 F1-mic 0.9727,  F1-mac 0.8895
arctic25,dgl,1,1235,72.6132,0.9727

 F1-mic 0.9753,  F1-mac 0.8845
arctic25,dgl,1,1236,72.6717,0.9753

 F1-mic 0.9753,  F1-mac 0.8843
arctic25,dgl,1,1237,72.7302,0.9753

 F1-mic 0.9729,  F1-mac 0.8894
arctic25,dgl,1,1238,72.7886,0.9729

 F1-mic 0.9753,  F1-mac 0.8846
arctic25,dgl,1,1239,72.8470,0.9753

epoch:1241/50, Iteration 32/32:training loss 0.1163976863026619
Train F1-mic 0.9754, Train F1-mac 0.8835
 F1-mic 0.9754,  F1-mac 0.8852
new best val f1: 0.9753602668554493
arctic25,dgl,1,1240,72.9055,0.9754

 F1-mic 0.9731,  F1-mac 0.8900
arctic25,dgl,1,1241,72.9639,0.9731

 F1-mic 0.9754,  F1-mac 0.8849
arctic25,dgl,1,1242,73.0224,0.9754

 F1-mic 0.9754,  F1-mac 0.8865
new best val f1: 0.9753902640957032
arctic25,dgl,1,1243,73.0808,0.9754

 F1-mic 0.9726,  F1-mac 0.8890
arctic25,dgl,1,1244,73.1393,0.9726

 F1-mic 0.9754,  F1-mac 0.8851
new best val f1: 0.9754142618879064
arctic25,dgl,1,1245,73.1978,0.9754

 F1-mic 0.9754,  F1-mac 0.8853
arctic25,dgl,1,1246,73.2562,0.9754

 F1-mic 0.9727,  F1-mac 0.8894
arctic25,dgl,1,1247,73.3146,0.9727

 F1-mic 0.9754,  F1-mac 0.8844
arctic25,dgl,1,1248,73.3732,0.9754

 F1-mic 0.9754,  F1-mac 0.8850
arctic25,dgl,1,1249,73.4316,0.9754

epoch:1251/50, Iteration 32/32:training loss 0.11603880673646927
Train F1-mic 0.9754, Train F1-mac 0.8839
 F1-mic 0.9728,  F1-mac 0.8891
arctic25,dgl,1,1250,73.4901,0.9728

 F1-mic 0.9754,  F1-mac 0.8846
new best val f1: 0.9754262607840078
arctic25,dgl,1,1251,73.5485,0.9754

 F1-mic 0.9754,  F1-mac 0.8853
new best val f1: 0.9754382596801094
arctic25,dgl,1,1252,73.6070,0.9754

 F1-mic 0.9727,  F1-mac 0.8898
arctic25,dgl,1,1253,73.6654,0.9727

 F1-mic 0.9754,  F1-mac 0.8848
arctic25,dgl,1,1254,73.7240,0.9754

 F1-mic 0.9755,  F1-mac 0.8846
new best val f1: 0.9754622574723125
arctic25,dgl,1,1255,73.7824,0.9755

 F1-mic 0.9729,  F1-mac 0.8889
arctic25,dgl,1,1256,73.8409,0.9729

 F1-mic 0.9754,  F1-mac 0.8842
arctic25,dgl,1,1257,73.8993,0.9754

 F1-mic 0.9754,  F1-mac 0.8849
arctic25,dgl,1,1258,73.9578,0.9754

 F1-mic 0.9731,  F1-mac 0.8902
arctic25,dgl,1,1259,74.0162,0.9731

epoch:1261/50, Iteration 32/32:training loss 0.11676618456840515
Train F1-mic 0.9731, Train F1-mac 0.8896
 F1-mic 0.9754,  F1-mac 0.8846
arctic25,dgl,1,1260,74.0749,0.9754

 F1-mic 0.9755,  F1-mac 0.8842
new best val f1: 0.9754682569203633
arctic25,dgl,1,1261,74.1333,0.9755

 F1-mic 0.9733,  F1-mac 0.8888
arctic25,dgl,1,1262,74.1918,0.9733

 F1-mic 0.9755,  F1-mac 0.8847
new best val f1: 0.9754802558164649
arctic25,dgl,1,1263,74.2502,0.9755

 F1-mic 0.9755,  F1-mac 0.8867
new best val f1: 0.9755342508489219
arctic25,dgl,1,1264,74.3087,0.9755

 F1-mic 0.9733,  F1-mac 0.8899
arctic25,dgl,1,1265,74.3671,0.9733

 F1-mic 0.9755,  F1-mac 0.8867
arctic25,dgl,1,1266,74.4255,0.9755

 F1-mic 0.9755,  F1-mac 0.8847
new best val f1: 0.9755462497450235
arctic25,dgl,1,1267,74.4840,0.9755

 F1-mic 0.9734,  F1-mac 0.8886
arctic25,dgl,1,1268,74.5425,0.9734

 F1-mic 0.9756,  F1-mac 0.8842
new best val f1: 0.9756002447774804
arctic25,dgl,1,1269,74.6009,0.9756

epoch:1271/50, Iteration 32/32:training loss 0.11485065519809723
Train F1-mic 0.9756, Train F1-mac 0.8828
 F1-mic 0.9756,  F1-mac 0.8855
new best val f1: 0.9756422409138359
arctic25,dgl,1,1270,74.6594,0.9756

 F1-mic 0.9733,  F1-mac 0.8904
arctic25,dgl,1,1271,74.7177,0.9733

 F1-mic 0.9756,  F1-mac 0.8875
arctic25,dgl,1,1272,74.7763,0.9756

 F1-mic 0.9757,  F1-mac 0.8847
new best val f1: 0.9757082348423946
arctic25,dgl,1,1273,74.8347,0.9757

 F1-mic 0.9735,  F1-mac 0.8881
arctic25,dgl,1,1274,74.8932,0.9735

 F1-mic 0.9756,  F1-mac 0.8847
arctic25,dgl,1,1275,74.9516,0.9756

 F1-mic 0.9757,  F1-mac 0.8878
arctic25,dgl,1,1276,75.0101,0.9757

 F1-mic 0.9733,  F1-mac 0.8904
arctic25,dgl,1,1277,75.0685,0.9733

 F1-mic 0.9757,  F1-mac 0.8853
arctic25,dgl,1,1278,75.1270,0.9757

 F1-mic 0.9757,  F1-mac 0.8853
arctic25,dgl,1,1279,75.1854,0.9757

epoch:1281/50, Iteration 32/32:training loss 0.11422687023878098
Train F1-mic 0.9757, Train F1-mac 0.8844
 F1-mic 0.9729,  F1-mac 0.8875
arctic25,dgl,1,1280,75.2441,0.9729

 F1-mic 0.9756,  F1-mac 0.8847
arctic25,dgl,1,1281,75.3025,0.9756

 F1-mic 0.9757,  F1-mac 0.8855
arctic25,dgl,1,1282,75.3610,0.9757

 F1-mic 0.9736,  F1-mac 0.8906
arctic25,dgl,1,1283,75.4194,0.9736

 F1-mic 0.9757,  F1-mac 0.8877
new best val f1: 0.9757142342904452
arctic25,dgl,1,1284,75.4779,0.9757

 F1-mic 0.9757,  F1-mac 0.8870
new best val f1: 0.9757382320826484
arctic25,dgl,1,1285,75.5363,0.9757

 F1-mic 0.9738,  F1-mac 0.8879
arctic25,dgl,1,1286,75.5948,0.9738

 F1-mic 0.9758,  F1-mac 0.8843
new best val f1: 0.9758162249073086
arctic25,dgl,1,1287,75.6532,0.9758

 F1-mic 0.9758,  F1-mac 0.8884
arctic25,dgl,1,1288,75.7116,0.9758

 F1-mic 0.9730,  F1-mac 0.8902
arctic25,dgl,1,1289,75.7700,0.9730

epoch:1291/50, Iteration 32/32:training loss 0.11490007489919662
Train F1-mic 0.9731, Train F1-mac 0.8896
 F1-mic 0.9758,  F1-mac 0.8864
arctic25,dgl,1,1290,75.8285,0.9758

 F1-mic 0.9758,  F1-mac 0.8855
arctic25,dgl,1,1291,75.8869,0.9758

 F1-mic 0.9733,  F1-mac 0.8898
arctic25,dgl,1,1292,75.9454,0.9733

 F1-mic 0.9758,  F1-mac 0.8880
arctic25,dgl,1,1293,76.0038,0.9758

 F1-mic 0.9758,  F1-mac 0.8851
new best val f1: 0.97582822380341
arctic25,dgl,1,1294,76.0625,0.9758

 F1-mic 0.9737,  F1-mac 0.8892
arctic25,dgl,1,1295,76.1210,0.9737

 F1-mic 0.9758,  F1-mac 0.8849
arctic25,dgl,1,1296,76.1794,0.9758

 F1-mic 0.9758,  F1-mac 0.8876
new best val f1: 0.9758342232514609
arctic25,dgl,1,1297,76.2379,0.9758

 F1-mic 0.9732,  F1-mac 0.8904
arctic25,dgl,1,1298,76.2965,0.9732

 F1-mic 0.9759,  F1-mac 0.8843
new best val f1: 0.9759062166280702
arctic25,dgl,1,1299,76.3550,0.9759

epoch:1301/50, Iteration 32/32:training loss 0.11384514719247818
Train F1-mic 0.9759, Train F1-mac 0.8831
 F1-mic 0.9759,  F1-mac 0.8849
arctic25,dgl,1,1300,76.4135,0.9759

 F1-mic 0.9730,  F1-mac 0.8890
arctic25,dgl,1,1301,76.4719,0.9730

 F1-mic 0.9759,  F1-mac 0.8871
arctic25,dgl,1,1302,76.5304,0.9759

 F1-mic 0.9759,  F1-mac 0.8874
new best val f1: 0.9759482127644257
arctic25,dgl,1,1303,76.5888,0.9759

 F1-mic 0.9738,  F1-mac 0.8902
arctic25,dgl,1,1304,76.6473,0.9738

 F1-mic 0.9758,  F1-mac 0.8881
arctic25,dgl,1,1305,76.7057,0.9758

 F1-mic 0.9759,  F1-mac 0.8868
arctic25,dgl,1,1306,76.7642,0.9759

 F1-mic 0.9738,  F1-mac 0.8888
arctic25,dgl,1,1307,76.8226,0.9738

 F1-mic 0.9759,  F1-mac 0.8856
arctic25,dgl,1,1308,76.8811,0.9759

 F1-mic 0.9760,  F1-mac 0.8882
new best val f1: 0.9759542122124765
arctic25,dgl,1,1309,76.9395,0.9760

epoch:1311/50, Iteration 32/32:training loss 0.11193609237670898
Train F1-mic 0.9760, Train F1-mac 0.8869
 F1-mic 0.9735,  F1-mac 0.8908
arctic25,dgl,1,1310,76.9980,0.9735

 F1-mic 0.9759,  F1-mac 0.8879
arctic25,dgl,1,1311,77.0564,0.9759

 F1-mic 0.9760,  F1-mac 0.8857
arctic25,dgl,1,1312,77.1148,0.9760

 F1-mic 0.9742,  F1-mac 0.8882
arctic25,dgl,1,1313,77.1733,0.9742

 F1-mic 0.9759,  F1-mac 0.8880
arctic25,dgl,1,1314,77.2317,0.9759

 F1-mic 0.9760,  F1-mac 0.8885
new best val f1: 0.9759662111085781
arctic25,dgl,1,1315,77.2902,0.9760

 F1-mic 0.9746,  F1-mac 0.8899
arctic25,dgl,1,1316,77.3487,0.9746

 F1-mic 0.9760,  F1-mac 0.8883
new best val f1: 0.9760022077968827
arctic25,dgl,1,1317,77.4071,0.9760

 F1-mic 0.9759,  F1-mac 0.8882
arctic25,dgl,1,1318,77.4656,0.9759

 F1-mic 0.9741,  F1-mac 0.8894
arctic25,dgl,1,1319,77.5240,0.9741

epoch:1321/50, Iteration 32/32:training loss 0.11205912381410599
Train F1-mic 0.9741, Train F1-mac 0.8887
 F1-mic 0.9760,  F1-mac 0.8857
arctic25,dgl,1,1320,77.5825,0.9760

 F1-mic 0.9761,  F1-mac 0.8887
new best val f1: 0.9760682017254413
arctic25,dgl,1,1321,77.6408,0.9761

 F1-mic 0.9736,  F1-mac 0.8899
arctic25,dgl,1,1322,77.6993,0.9736

 F1-mic 0.9760,  F1-mac 0.8863
arctic25,dgl,1,1323,77.7577,0.9760

 F1-mic 0.9760,  F1-mac 0.8877
arctic25,dgl,1,1324,77.8162,0.9760

 F1-mic 0.9741,  F1-mac 0.8906
arctic25,dgl,1,1325,77.8749,0.9741

 F1-mic 0.9760,  F1-mac 0.8881
arctic25,dgl,1,1326,77.9334,0.9760

 F1-mic 0.9761,  F1-mac 0.8886
new best val f1: 0.9760742011734921
arctic25,dgl,1,1327,77.9919,0.9761

 F1-mic 0.9742,  F1-mac 0.8897
arctic25,dgl,1,1328,78.0503,0.9742

 F1-mic 0.9760,  F1-mac 0.8854
arctic25,dgl,1,1329,78.1087,0.9760

epoch:1331/50, Iteration 32/32:training loss 0.11085551232099533
Train F1-mic 0.9761, Train F1-mac 0.8845
 F1-mic 0.9760,  F1-mac 0.8885
arctic25,dgl,1,1330,78.1672,0.9760

 F1-mic 0.9734,  F1-mac 0.8911
arctic25,dgl,1,1331,78.2256,0.9734

 F1-mic 0.9760,  F1-mac 0.8858
arctic25,dgl,1,1332,78.2841,0.9760

 F1-mic 0.9760,  F1-mac 0.8860
arctic25,dgl,1,1333,78.3425,0.9760

 F1-mic 0.9739,  F1-mac 0.8898
arctic25,dgl,1,1334,78.4010,0.9739

 F1-mic 0.9760,  F1-mac 0.8851
arctic25,dgl,1,1335,78.4594,0.9760

 F1-mic 0.9760,  F1-mac 0.8857
arctic25,dgl,1,1336,78.5179,0.9760

 F1-mic 0.9747,  F1-mac 0.8910
arctic25,dgl,1,1337,78.5763,0.9747

 F1-mic 0.9761,  F1-mac 0.8882
new best val f1: 0.9761401951020505
arctic25,dgl,1,1338,78.6348,0.9761

 F1-mic 0.9762,  F1-mac 0.8876
new best val f1: 0.9761521939981521
arctic25,dgl,1,1339,78.6932,0.9762

epoch:1341/50, Iteration 32/32:training loss 0.10896465927362442
Train F1-mic 0.9762, Train F1-mac 0.8864
 F1-mic 0.9742,  F1-mac 0.8899
arctic25,dgl,1,1340,78.7517,0.9742

 F1-mic 0.9761,  F1-mac 0.8844
arctic25,dgl,1,1341,78.8101,0.9761

 F1-mic 0.9761,  F1-mac 0.8857
arctic25,dgl,1,1342,78.8686,0.9761

 F1-mic 0.9728,  F1-mac 0.8916
arctic25,dgl,1,1343,78.9273,0.9728

 F1-mic 0.9762,  F1-mac 0.8868
new best val f1: 0.9761941901345076
arctic25,dgl,1,1344,78.9859,0.9762

 F1-mic 0.9762,  F1-mac 0.8857
arctic25,dgl,1,1345,79.0443,0.9762

 F1-mic 0.9742,  F1-mac 0.8893
arctic25,dgl,1,1346,79.1027,0.9742

 F1-mic 0.9761,  F1-mac 0.8858
arctic25,dgl,1,1347,79.1611,0.9761

 F1-mic 0.9762,  F1-mac 0.8868
new best val f1: 0.9762001895825584
arctic25,dgl,1,1348,79.2197,0.9762

 F1-mic 0.9743,  F1-mac 0.8905
arctic25,dgl,1,1349,79.2781,0.9743

epoch:1351/50, Iteration 32/32:training loss 0.11030957102775574
Train F1-mic 0.9743, Train F1-mac 0.8905
 F1-mic 0.9762,  F1-mac 0.8889
arctic25,dgl,1,1350,79.3366,0.9762

 F1-mic 0.9762,  F1-mac 0.8873
new best val f1: 0.9762241873747616
arctic25,dgl,1,1351,79.3952,0.9762

 F1-mic 0.9733,  F1-mac 0.8898
arctic25,dgl,1,1352,79.4536,0.9733

 F1-mic 0.9762,  F1-mac 0.8863
arctic25,dgl,1,1353,79.5121,0.9762

 F1-mic 0.9763,  F1-mac 0.8886
new best val f1: 0.9762661835111169
arctic25,dgl,1,1354,79.5706,0.9763

 F1-mic 0.9741,  F1-mac 0.8908
arctic25,dgl,1,1355,79.6291,0.9741

 F1-mic 0.9762,  F1-mac 0.8884
arctic25,dgl,1,1356,79.6875,0.9762

 F1-mic 0.9762,  F1-mac 0.8879
arctic25,dgl,1,1357,79.7459,0.9762

 F1-mic 0.9741,  F1-mac 0.8897
arctic25,dgl,1,1358,79.8044,0.9741

 F1-mic 0.9762,  F1-mac 0.8860
arctic25,dgl,1,1359,79.8628,0.9762

epoch:1361/50, Iteration 32/32:training loss 0.11017162352800369
Train F1-mic 0.9763, Train F1-mac 0.8852
 F1-mic 0.9762,  F1-mac 0.8889
arctic25,dgl,1,1360,79.9213,0.9762

 F1-mic 0.9733,  F1-mac 0.8911
arctic25,dgl,1,1361,79.9796,0.9733

 F1-mic 0.9763,  F1-mac 0.8866
arctic25,dgl,1,1362,80.0381,0.9763

 F1-mic 0.9763,  F1-mac 0.8864
new best val f1: 0.9762841818552693
arctic25,dgl,1,1363,80.0965,0.9763

 F1-mic 0.9740,  F1-mac 0.8899
arctic25,dgl,1,1364,80.1550,0.9740

 F1-mic 0.9763,  F1-mac 0.8882
arctic25,dgl,1,1365,80.2135,0.9763

 F1-mic 0.9763,  F1-mac 0.8882
new best val f1: 0.9763321774396756
arctic25,dgl,1,1366,80.2719,0.9763

 F1-mic 0.9736,  F1-mac 0.8909
arctic25,dgl,1,1367,80.3303,0.9736

 F1-mic 0.9763,  F1-mac 0.8878
arctic25,dgl,1,1368,80.3888,0.9763

 F1-mic 0.9763,  F1-mac 0.8889
arctic25,dgl,1,1369,80.4473,0.9763

epoch:1371/50, Iteration 32/32:training loss 0.10897877812385559
Train F1-mic 0.9763, Train F1-mac 0.8879
 F1-mic 0.9740,  F1-mac 0.8905
arctic25,dgl,1,1370,80.5057,0.9740

 F1-mic 0.9764,  F1-mac 0.8865
new best val f1: 0.976374173576031
arctic25,dgl,1,1371,80.5642,0.9764

 F1-mic 0.9764,  F1-mac 0.8885
arctic25,dgl,1,1372,80.6226,0.9764

 F1-mic 0.9738,  F1-mac 0.8907
arctic25,dgl,1,1373,80.6811,0.9738

 F1-mic 0.9764,  F1-mac 0.8875
new best val f1: 0.9763981713682341
arctic25,dgl,1,1374,80.7396,0.9764

 F1-mic 0.9764,  F1-mac 0.8873
arctic25,dgl,1,1375,80.7981,0.9764

 F1-mic 0.9737,  F1-mac 0.8904
arctic25,dgl,1,1376,80.8566,0.9737

 F1-mic 0.9764,  F1-mac 0.8875
arctic25,dgl,1,1377,80.9151,0.9764

 F1-mic 0.9764,  F1-mac 0.8880
new best val f1: 0.9764161697123864
arctic25,dgl,1,1378,80.9736,0.9764

 F1-mic 0.9739,  F1-mac 0.8909
arctic25,dgl,1,1379,81.0320,0.9739

epoch:1381/50, Iteration 32/32:training loss 0.10927993804216385
Train F1-mic 0.9740, Train F1-mac 0.8907
 F1-mic 0.9763,  F1-mac 0.8885
arctic25,dgl,1,1380,81.0905,0.9763

 F1-mic 0.9764,  F1-mac 0.8886
arctic25,dgl,1,1381,81.1488,0.9764

 F1-mic 0.9737,  F1-mac 0.8907
arctic25,dgl,1,1382,81.2073,0.9737

 F1-mic 0.9764,  F1-mac 0.8862
arctic25,dgl,1,1383,81.2658,0.9764

 F1-mic 0.9764,  F1-mac 0.8892
new best val f1: 0.9764341680565388
arctic25,dgl,1,1384,81.3243,0.9764

 F1-mic 0.9741,  F1-mac 0.8909
arctic25,dgl,1,1385,81.3828,0.9741

 F1-mic 0.9764,  F1-mac 0.8866
arctic25,dgl,1,1386,81.4412,0.9764

 F1-mic 0.9764,  F1-mac 0.8875
new best val f1: 0.9764401675045896
arctic25,dgl,1,1387,81.4997,0.9764

 F1-mic 0.9739,  F1-mac 0.8904
arctic25,dgl,1,1388,81.5581,0.9739

 F1-mic 0.9764,  F1-mac 0.8865
arctic25,dgl,1,1389,81.6165,0.9764

epoch:1391/50, Iteration 32/32:training loss 0.10835125297307968
Train F1-mic 0.9764, Train F1-mac 0.8856
 F1-mic 0.9764,  F1-mac 0.8875
arctic25,dgl,1,1390,81.6750,0.9764

 F1-mic 0.9738,  F1-mac 0.8912
arctic25,dgl,1,1391,81.7334,0.9738

 F1-mic 0.9764,  F1-mac 0.8874
arctic25,dgl,1,1392,81.7919,0.9764

 F1-mic 0.9764,  F1-mac 0.8870
arctic25,dgl,1,1393,81.8503,0.9764

 F1-mic 0.9738,  F1-mac 0.8902
arctic25,dgl,1,1394,81.9088,0.9738

 F1-mic 0.9764,  F1-mac 0.8884
new best val f1: 0.9764461669526403
arctic25,dgl,1,1395,81.9673,0.9764

 F1-mic 0.9765,  F1-mac 0.8884
new best val f1: 0.9764521664006911
arctic25,dgl,1,1396,82.0258,0.9765

 F1-mic 0.9737,  F1-mac 0.8914
arctic25,dgl,1,1397,82.0842,0.9737

 F1-mic 0.9765,  F1-mac 0.8892
new best val f1: 0.9764881630889958
arctic25,dgl,1,1398,82.1430,0.9765

 F1-mic 0.9765,  F1-mac 0.8884
arctic25,dgl,1,1399,82.2014,0.9765

epoch:1401/50, Iteration 32/32:training loss 0.10680853575468063
Train F1-mic 0.9765, Train F1-mac 0.8877
 F1-mic 0.9742,  F1-mac 0.8902
arctic25,dgl,1,1400,82.2602,0.9742

 F1-mic 0.9765,  F1-mac 0.8878
arctic25,dgl,1,1401,82.3185,0.9765

 F1-mic 0.9765,  F1-mac 0.8892
arctic25,dgl,1,1402,82.3770,0.9765

 F1-mic 0.9739,  F1-mac 0.8909
arctic25,dgl,1,1403,82.4354,0.9739

 F1-mic 0.9765,  F1-mac 0.8876
new best val f1: 0.9765301592253512
arctic25,dgl,1,1404,82.4939,0.9765

 F1-mic 0.9765,  F1-mac 0.8889
new best val f1: 0.976536158673402
arctic25,dgl,1,1405,82.5524,0.9765

 F1-mic 0.9740,  F1-mac 0.8900
arctic25,dgl,1,1406,82.6111,0.9740

 F1-mic 0.9765,  F1-mac 0.8868
arctic25,dgl,1,1407,82.6695,0.9765

 F1-mic 0.9765,  F1-mac 0.8883
arctic25,dgl,1,1408,82.7279,0.9765

 F1-mic 0.9745,  F1-mac 0.8908
arctic25,dgl,1,1409,82.7864,0.9745

epoch:1411/50, Iteration 32/32:training loss 0.10712786018848419
Train F1-mic 0.9746, Train F1-mac 0.8909
 F1-mic 0.9765,  F1-mac 0.8885
arctic25,dgl,1,1410,82.8448,0.9765

 F1-mic 0.9765,  F1-mac 0.8882
arctic25,dgl,1,1411,82.9032,0.9765

 F1-mic 0.9743,  F1-mac 0.8904
arctic25,dgl,1,1412,82.9617,0.9743

 F1-mic 0.9765,  F1-mac 0.8878
new best val f1: 0.9765481575695036
arctic25,dgl,1,1413,83.0201,0.9765

 F1-mic 0.9765,  F1-mac 0.8889
arctic25,dgl,1,1414,83.0786,0.9765

 F1-mic 0.9739,  F1-mac 0.8910
arctic25,dgl,1,1415,83.1370,0.9739

 F1-mic 0.9766,  F1-mac 0.8895
new best val f1: 0.9765661559136559
arctic25,dgl,1,1416,83.1955,0.9766

 F1-mic 0.9766,  F1-mac 0.8889
new best val f1: 0.9765901537058591
arctic25,dgl,1,1417,83.2542,0.9766

 F1-mic 0.9744,  F1-mac 0.8899
arctic25,dgl,1,1418,83.3126,0.9744

 F1-mic 0.9765,  F1-mac 0.8876
arctic25,dgl,1,1419,83.3710,0.9765

epoch:1421/50, Iteration 32/32:training loss 0.10583668947219849
Train F1-mic 0.9766, Train F1-mac 0.8871
 F1-mic 0.9765,  F1-mac 0.8902
arctic25,dgl,1,1420,83.4294,0.9765

 F1-mic 0.9745,  F1-mac 0.8905
arctic25,dgl,1,1421,83.4878,0.9745

 F1-mic 0.9766,  F1-mac 0.8890
new best val f1: 0.976620150946113
arctic25,dgl,1,1422,83.5463,0.9766

 F1-mic 0.9766,  F1-mac 0.8892
arctic25,dgl,1,1423,83.6047,0.9766

 F1-mic 0.9745,  F1-mac 0.8908
arctic25,dgl,1,1424,83.6632,0.9745

 F1-mic 0.9766,  F1-mac 0.8878
arctic25,dgl,1,1425,83.7217,0.9766

 F1-mic 0.9766,  F1-mac 0.8881
arctic25,dgl,1,1426,83.7801,0.9766

 F1-mic 0.9743,  F1-mac 0.8902
arctic25,dgl,1,1427,83.8386,0.9743

 F1-mic 0.9766,  F1-mac 0.8879
arctic25,dgl,1,1428,83.8971,0.9766

 F1-mic 0.9767,  F1-mac 0.8896
new best val f1: 0.9766621470824685
arctic25,dgl,1,1429,83.9555,0.9767

epoch:1431/50, Iteration 32/32:training loss 0.10516148805618286
Train F1-mic 0.9767, Train F1-mac 0.8885
 F1-mic 0.9743,  F1-mac 0.8910
arctic25,dgl,1,1430,84.0140,0.9743

 F1-mic 0.9766,  F1-mac 0.8877
arctic25,dgl,1,1431,84.0724,0.9766

 F1-mic 0.9766,  F1-mac 0.8888
arctic25,dgl,1,1432,84.1309,0.9766

 F1-mic 0.9745,  F1-mac 0.8905
arctic25,dgl,1,1433,84.1893,0.9745

 F1-mic 0.9766,  F1-mac 0.8877
arctic25,dgl,1,1434,84.2478,0.9766

 F1-mic 0.9767,  F1-mac 0.8892
arctic25,dgl,1,1435,84.3062,0.9767

 F1-mic 0.9746,  F1-mac 0.8911
arctic25,dgl,1,1436,84.3647,0.9746

 F1-mic 0.9766,  F1-mac 0.8880
arctic25,dgl,1,1437,84.4233,0.9766

 F1-mic 0.9766,  F1-mac 0.8888
arctic25,dgl,1,1438,84.4818,0.9766

 F1-mic 0.9746,  F1-mac 0.8902
arctic25,dgl,1,1439,84.5403,0.9746

epoch:1441/50, Iteration 32/32:training loss 0.10584969073534012
Train F1-mic 0.9746, Train F1-mac 0.8907
 F1-mic 0.9766,  F1-mac 0.8881
arctic25,dgl,1,1440,84.5987,0.9766

 F1-mic 0.9767,  F1-mac 0.8890
new best val f1: 0.9766801454266207
arctic25,dgl,1,1441,84.6571,0.9767

 F1-mic 0.9744,  F1-mac 0.8909
arctic25,dgl,1,1442,84.7156,0.9744

 F1-mic 0.9766,  F1-mac 0.8880
arctic25,dgl,1,1443,84.7741,0.9766

 F1-mic 0.9767,  F1-mac 0.8881
new best val f1: 0.9766861448746715
arctic25,dgl,1,1444,84.8326,0.9767

 F1-mic 0.9747,  F1-mac 0.8908
arctic25,dgl,1,1445,84.8970,0.9747

 F1-mic 0.9766,  F1-mac 0.8872
arctic25,dgl,1,1446,84.9555,0.9766

 F1-mic 0.9767,  F1-mac 0.8887
new best val f1: 0.9766981437707731
arctic25,dgl,1,1447,85.0139,0.9767

 F1-mic 0.9746,  F1-mac 0.8908
arctic25,dgl,1,1448,85.0724,0.9746

 F1-mic 0.9766,  F1-mac 0.8864
arctic25,dgl,1,1449,85.1310,0.9766

epoch:1451/50, Iteration 32/32:training loss 0.10480381548404694
Train F1-mic 0.9767, Train F1-mac 0.8856
 F1-mic 0.9767,  F1-mac 0.8876
arctic25,dgl,1,1450,85.1894,0.9767

 F1-mic 0.9740,  F1-mac 0.8910
arctic25,dgl,1,1451,85.2477,0.9740

 F1-mic 0.9767,  F1-mac 0.8872
arctic25,dgl,1,1452,85.3062,0.9767

 F1-mic 0.9767,  F1-mac 0.8871
arctic25,dgl,1,1453,85.3647,0.9767

 F1-mic 0.9743,  F1-mac 0.8907
arctic25,dgl,1,1454,85.4232,0.9743

 F1-mic 0.9767,  F1-mac 0.8897
new best val f1: 0.9767161421149254
arctic25,dgl,1,1455,85.4817,0.9767

 F1-mic 0.9767,  F1-mac 0.8882
new best val f1: 0.9767341404590778
arctic25,dgl,1,1456,85.5401,0.9767

 F1-mic 0.9750,  F1-mac 0.8905
arctic25,dgl,1,1457,85.5985,0.9750

 F1-mic 0.9767,  F1-mac 0.8904
arctic25,dgl,1,1458,85.6571,0.9767

 F1-mic 0.9767,  F1-mac 0.8890
arctic25,dgl,1,1459,85.7157,0.9767

epoch:1461/50, Iteration 32/32:training loss 0.10304779559373856
Train F1-mic 0.9768, Train F1-mac 0.8882
 F1-mic 0.9749,  F1-mac 0.8910
arctic25,dgl,1,1460,85.7743,0.9749

 F1-mic 0.9768,  F1-mac 0.8905
new best val f1: 0.9767881354915348
arctic25,dgl,1,1461,85.8326,0.9768

 F1-mic 0.9767,  F1-mac 0.8900
arctic25,dgl,1,1462,85.8910,0.9767

 F1-mic 0.9743,  F1-mac 0.8906
arctic25,dgl,1,1463,85.9495,0.9743

 F1-mic 0.9768,  F1-mac 0.8900
new best val f1: 0.9768421305239918
arctic25,dgl,1,1464,86.0079,0.9768

 F1-mic 0.9768,  F1-mac 0.8900
new best val f1: 0.9768481299720426
arctic25,dgl,1,1465,86.0664,0.9768

 F1-mic 0.9747,  F1-mac 0.8905
arctic25,dgl,1,1466,86.1249,0.9747

 F1-mic 0.9768,  F1-mac 0.8896
arctic25,dgl,1,1467,86.1835,0.9768

 F1-mic 0.9768,  F1-mac 0.8909
arctic25,dgl,1,1468,86.2420,0.9768

 F1-mic 0.9749,  F1-mac 0.8909
arctic25,dgl,1,1469,86.3005,0.9749

epoch:1471/50, Iteration 32/32:training loss 0.10404274612665176
Train F1-mic 0.9750, Train F1-mac 0.8906
 F1-mic 0.9768,  F1-mac 0.8892
arctic25,dgl,1,1470,86.3589,0.9768

 F1-mic 0.9768,  F1-mac 0.8903
arctic25,dgl,1,1471,86.4173,0.9768

 F1-mic 0.9743,  F1-mac 0.8909
arctic25,dgl,1,1472,86.4758,0.9743

 F1-mic 0.9769,  F1-mac 0.8883
new best val f1: 0.9768721277642457
arctic25,dgl,1,1473,86.5345,0.9769

 F1-mic 0.9769,  F1-mac 0.8896
arctic25,dgl,1,1474,86.5930,0.9769

 F1-mic 0.9746,  F1-mac 0.8907
arctic25,dgl,1,1475,86.6514,0.9746

 F1-mic 0.9769,  F1-mac 0.8893
new best val f1: 0.9768781272122965
arctic25,dgl,1,1476,86.7099,0.9769

 F1-mic 0.9769,  F1-mac 0.8897
new best val f1: 0.9769081244525503
arctic25,dgl,1,1477,86.7683,0.9769

 F1-mic 0.9745,  F1-mac 0.8911
arctic25,dgl,1,1478,86.8268,0.9745

 F1-mic 0.9769,  F1-mac 0.8904
arctic25,dgl,1,1479,86.8852,0.9769

epoch:1481/50, Iteration 32/32:training loss 0.10386660695075989
Train F1-mic 0.9769, Train F1-mac 0.8893
 F1-mic 0.9769,  F1-mac 0.8900
arctic25,dgl,1,1480,86.9437,0.9769

 F1-mic 0.9744,  F1-mac 0.8911
arctic25,dgl,1,1481,87.0020,0.9744

 F1-mic 0.9769,  F1-mac 0.8895
new best val f1: 0.9769321222447535
arctic25,dgl,1,1482,87.0605,0.9769

 F1-mic 0.9769,  F1-mac 0.8908
arctic25,dgl,1,1483,87.1189,0.9769

 F1-mic 0.9747,  F1-mac 0.8916
arctic25,dgl,1,1484,87.1774,0.9747

 F1-mic 0.9769,  F1-mac 0.8895
arctic25,dgl,1,1485,87.2359,0.9769

 F1-mic 0.9769,  F1-mac 0.8907
arctic25,dgl,1,1486,87.2943,0.9769

 F1-mic 0.9744,  F1-mac 0.8907
arctic25,dgl,1,1487,87.3528,0.9744

 F1-mic 0.9770,  F1-mac 0.8888
new best val f1: 0.9769801178291597
arctic25,dgl,1,1488,87.4113,0.9770

 F1-mic 0.9769,  F1-mac 0.8890
arctic25,dgl,1,1489,87.4697,0.9769

epoch:1491/50, Iteration 32/32:training loss 0.10284167528152466
Train F1-mic 0.9769, Train F1-mac 0.8884
 F1-mic 0.9743,  F1-mac 0.8906
arctic25,dgl,1,1490,87.5282,0.9743

 F1-mic 0.9769,  F1-mac 0.8896
arctic25,dgl,1,1491,87.5865,0.9769

 F1-mic 0.9770,  F1-mac 0.8900
new best val f1: 0.9770161145174644
arctic25,dgl,1,1492,87.6452,0.9770

 F1-mic 0.9745,  F1-mac 0.8909
arctic25,dgl,1,1493,87.7036,0.9745

 F1-mic 0.9770,  F1-mac 0.8887
arctic25,dgl,1,1494,87.7622,0.9770

 F1-mic 0.9770,  F1-mac 0.8903
arctic25,dgl,1,1495,87.8206,0.9770

 F1-mic 0.9742,  F1-mac 0.8909
arctic25,dgl,1,1496,87.8791,0.9742

 F1-mic 0.9770,  F1-mac 0.8887
arctic25,dgl,1,1497,87.9376,0.9770

 F1-mic 0.9771,  F1-mac 0.8908
new best val f1: 0.9770581106538199
arctic25,dgl,1,1498,87.9961,0.9771

 F1-mic 0.9748,  F1-mac 0.8910
arctic25,dgl,1,1499,88.0545,0.9748

epoch:1501/50, Iteration 32/32:training loss 0.1031450629234314
Train F1-mic 0.9748, Train F1-mac 0.8915
 F1-mic 0.9769,  F1-mac 0.8886
arctic25,dgl,1,1500,88.1130,0.9769

 F1-mic 0.9770,  F1-mac 0.8895
arctic25,dgl,1,1501,88.1714,0.9770

 F1-mic 0.9745,  F1-mac 0.8908
arctic25,dgl,1,1502,88.2298,0.9745

 F1-mic 0.9771,  F1-mac 0.8891
arctic25,dgl,1,1503,88.2882,0.9771

 F1-mic 0.9770,  F1-mac 0.8902
arctic25,dgl,1,1504,88.3467,0.9770

 F1-mic 0.9745,  F1-mac 0.8912
arctic25,dgl,1,1505,88.4052,0.9745

 F1-mic 0.9771,  F1-mac 0.8886
arctic25,dgl,1,1506,88.4636,0.9771

 F1-mic 0.9770,  F1-mac 0.8889
arctic25,dgl,1,1507,88.5220,0.9770

 F1-mic 0.9747,  F1-mac 0.8918
arctic25,dgl,1,1508,88.5805,0.9747

 F1-mic 0.9770,  F1-mac 0.8877
arctic25,dgl,1,1509,88.6389,0.9770

epoch:1511/50, Iteration 32/32:training loss 0.10234624892473221
Train F1-mic 0.9771, Train F1-mac 0.8870
 F1-mic 0.9771,  F1-mac 0.8886
new best val f1: 0.9770881078940737
arctic25,dgl,1,1510,88.6974,0.9771

 F1-mic 0.9741,  F1-mac 0.8915
arctic25,dgl,1,1511,88.7558,0.9741

 F1-mic 0.9770,  F1-mac 0.8870
arctic25,dgl,1,1512,88.8143,0.9770

 F1-mic 0.9770,  F1-mac 0.8868
arctic25,dgl,1,1513,88.8729,0.9770

 F1-mic 0.9745,  F1-mac 0.8924
arctic25,dgl,1,1514,88.9314,0.9745

 F1-mic 0.9771,  F1-mac 0.8901
new best val f1: 0.9770941073421245
arctic25,dgl,1,1515,88.9899,0.9771

 F1-mic 0.9771,  F1-mac 0.8899
arctic25,dgl,1,1516,89.0483,0.9771

 F1-mic 0.9750,  F1-mac 0.8912
arctic25,dgl,1,1517,89.1067,0.9750

 F1-mic 0.9771,  F1-mac 0.8883
arctic25,dgl,1,1518,89.1652,0.9771

 F1-mic 0.9770,  F1-mac 0.8889
arctic25,dgl,1,1519,89.2236,0.9770

epoch:1521/50, Iteration 32/32:training loss 0.10071296989917755
Train F1-mic 0.9771, Train F1-mac 0.8880
 F1-mic 0.9750,  F1-mac 0.8920
arctic25,dgl,1,1520,89.2823,0.9750

 F1-mic 0.9772,  F1-mac 0.8902
new best val f1: 0.9771601012706831
arctic25,dgl,1,1521,89.3406,0.9772

 F1-mic 0.9771,  F1-mac 0.8899
arctic25,dgl,1,1522,89.3991,0.9771

 F1-mic 0.9750,  F1-mac 0.8905
arctic25,dgl,1,1523,89.4576,0.9750

 F1-mic 0.9771,  F1-mac 0.8888
arctic25,dgl,1,1524,89.5161,0.9771

 F1-mic 0.9772,  F1-mac 0.8891
arctic25,dgl,1,1525,89.5745,0.9772

 F1-mic 0.9752,  F1-mac 0.8909
arctic25,dgl,1,1526,89.6330,0.9752

 F1-mic 0.9771,  F1-mac 0.8902
arctic25,dgl,1,1527,89.6914,0.9771

 F1-mic 0.9772,  F1-mac 0.8904
arctic25,dgl,1,1528,89.7499,0.9772

 F1-mic 0.9750,  F1-mac 0.8912
arctic25,dgl,1,1529,89.8083,0.9750

epoch:1531/50, Iteration 32/32:training loss 0.10181833803653717
Train F1-mic 0.9751, Train F1-mac 0.8914
 F1-mic 0.9772,  F1-mac 0.8892
new best val f1: 0.977190098510937
arctic25,dgl,1,1530,89.8668,0.9772

 F1-mic 0.9771,  F1-mac 0.8902
arctic25,dgl,1,1531,89.9251,0.9771

 F1-mic 0.9747,  F1-mac 0.8910
arctic25,dgl,1,1532,89.9836,0.9747

 F1-mic 0.9772,  F1-mac 0.8903
arctic25,dgl,1,1533,90.0420,0.9772

 F1-mic 0.9772,  F1-mac 0.8902
arctic25,dgl,1,1534,90.1008,0.9772

 F1-mic 0.9748,  F1-mac 0.8908
arctic25,dgl,1,1535,90.1592,0.9748

 F1-mic 0.9772,  F1-mac 0.8904
new best val f1: 0.9772140963031402
arctic25,dgl,1,1536,90.2177,0.9772

 F1-mic 0.9772,  F1-mac 0.8903
arctic25,dgl,1,1537,90.2761,0.9772

 F1-mic 0.9750,  F1-mac 0.8914
arctic25,dgl,1,1538,90.3345,0.9750

 F1-mic 0.9772,  F1-mac 0.8917
new best val f1: 0.9772200957511908
arctic25,dgl,1,1539,90.3930,0.9772

epoch:1541/50, Iteration 32/32:training loss 0.10050000995397568
Train F1-mic 0.9772, Train F1-mac 0.8903
 F1-mic 0.9772,  F1-mac 0.8903
arctic25,dgl,1,1540,90.4514,0.9772

 F1-mic 0.9748,  F1-mac 0.8910
arctic25,dgl,1,1541,90.5097,0.9748

 F1-mic 0.9772,  F1-mac 0.8915
arctic25,dgl,1,1542,90.5682,0.9772

 F1-mic 0.9772,  F1-mac 0.8917
new best val f1: 0.9772260951992416
arctic25,dgl,1,1543,90.6267,0.9772

 F1-mic 0.9744,  F1-mac 0.8916
arctic25,dgl,1,1544,90.6852,0.9744

 F1-mic 0.9772,  F1-mac 0.8908
arctic25,dgl,1,1545,90.7437,0.9772

 F1-mic 0.9772,  F1-mac 0.8914
new best val f1: 0.977244093543394
arctic25,dgl,1,1546,90.8021,0.9772

 F1-mic 0.9747,  F1-mac 0.8918
arctic25,dgl,1,1547,90.8606,0.9747

 F1-mic 0.9772,  F1-mac 0.8911
arctic25,dgl,1,1548,90.9190,0.9772

 F1-mic 0.9772,  F1-mac 0.8914
arctic25,dgl,1,1549,90.9775,0.9772

epoch:1551/50, Iteration 32/32:training loss 0.10005228221416473
Train F1-mic 0.9772, Train F1-mac 0.8905
 F1-mic 0.9747,  F1-mac 0.8919
arctic25,dgl,1,1550,91.0360,0.9747

 F1-mic 0.9772,  F1-mac 0.8903
arctic25,dgl,1,1551,91.0944,0.9772

 F1-mic 0.9771,  F1-mac 0.8903
arctic25,dgl,1,1552,91.1529,0.9771

 F1-mic 0.9752,  F1-mac 0.8916
arctic25,dgl,1,1553,91.2113,0.9752

 F1-mic 0.9772,  F1-mac 0.8891
arctic25,dgl,1,1554,91.2698,0.9772

 F1-mic 0.9772,  F1-mac 0.8910
arctic25,dgl,1,1555,91.3283,0.9772

 F1-mic 0.9755,  F1-mac 0.8915
arctic25,dgl,1,1556,91.3867,0.9755

 F1-mic 0.9771,  F1-mac 0.8891
arctic25,dgl,1,1557,91.4451,0.9771

 F1-mic 0.9772,  F1-mac 0.8908
arctic25,dgl,1,1558,91.5036,0.9772

 F1-mic 0.9753,  F1-mac 0.8911
arctic25,dgl,1,1559,91.5620,0.9753

epoch:1561/50, Iteration 32/32:training loss 0.10032621026039124
Train F1-mic 0.9753, Train F1-mac 0.8914
 F1-mic 0.9772,  F1-mac 0.8896
arctic25,dgl,1,1560,91.6205,0.9772

 F1-mic 0.9772,  F1-mac 0.8906
arctic25,dgl,1,1561,91.6789,0.9772

 F1-mic 0.9750,  F1-mac 0.8912
arctic25,dgl,1,1562,91.7374,0.9750

 F1-mic 0.9773,  F1-mac 0.8910
new best val f1: 0.9772620918875463
arctic25,dgl,1,1563,91.7958,0.9773

 F1-mic 0.9772,  F1-mac 0.8906
arctic25,dgl,1,1564,91.8543,0.9772

 F1-mic 0.9752,  F1-mac 0.8912
arctic25,dgl,1,1565,91.9128,0.9752

 F1-mic 0.9773,  F1-mac 0.8918
new best val f1: 0.9773220863680542
arctic25,dgl,1,1566,91.9713,0.9773

 F1-mic 0.9773,  F1-mac 0.8910
arctic25,dgl,1,1567,92.0297,0.9773

 F1-mic 0.9754,  F1-mac 0.8909
arctic25,dgl,1,1568,92.0882,0.9754

 F1-mic 0.9773,  F1-mac 0.8917
arctic25,dgl,1,1569,92.1466,0.9773

epoch:1571/50, Iteration 32/32:training loss 0.09900885075330734
Train F1-mic 0.9773, Train F1-mac 0.8901
 F1-mic 0.9773,  F1-mac 0.8908
arctic25,dgl,1,1570,92.2052,0.9773

 F1-mic 0.9749,  F1-mac 0.8911
arctic25,dgl,1,1571,92.2635,0.9749

 F1-mic 0.9773,  F1-mac 0.8901
arctic25,dgl,1,1572,92.3224,0.9773

 F1-mic 0.9773,  F1-mac 0.8916
arctic25,dgl,1,1573,92.3808,0.9773

 F1-mic 0.9750,  F1-mac 0.8908
arctic25,dgl,1,1574,92.4393,0.9750

 F1-mic 0.9773,  F1-mac 0.8900
new best val f1: 0.9773340852641557
arctic25,dgl,1,1575,92.4978,0.9773

 F1-mic 0.9773,  F1-mac 0.8912
new best val f1: 0.9773460841602573
arctic25,dgl,1,1576,92.5563,0.9773

 F1-mic 0.9754,  F1-mac 0.8913
arctic25,dgl,1,1577,92.6147,0.9754

 F1-mic 0.9773,  F1-mac 0.8911
arctic25,dgl,1,1578,92.6731,0.9773

 F1-mic 0.9773,  F1-mac 0.8911
arctic25,dgl,1,1579,92.7315,0.9773

epoch:1581/50, Iteration 32/32:training loss 0.09790167957544327
Train F1-mic 0.9773, Train F1-mac 0.8898
 F1-mic 0.9754,  F1-mac 0.8913
arctic25,dgl,1,1580,92.7900,0.9754

 F1-mic 0.9774,  F1-mac 0.8910
new best val f1: 0.977352083608308
arctic25,dgl,1,1581,92.8483,0.9774

 F1-mic 0.9773,  F1-mac 0.8911
arctic25,dgl,1,1582,92.9068,0.9773

 F1-mic 0.9752,  F1-mac 0.8916
arctic25,dgl,1,1583,92.9653,0.9752

 F1-mic 0.9774,  F1-mac 0.8911
arctic25,dgl,1,1584,93.0237,0.9774

 F1-mic 0.9773,  F1-mac 0.8912
arctic25,dgl,1,1585,93.0822,0.9773

 F1-mic 0.9753,  F1-mac 0.8913
arctic25,dgl,1,1586,93.1406,0.9753

 F1-mic 0.9774,  F1-mac 0.8912
new best val f1: 0.9773700819524603
arctic25,dgl,1,1587,93.1990,0.9774

 F1-mic 0.9774,  F1-mac 0.8915
arctic25,dgl,1,1588,93.2575,0.9774

 F1-mic 0.9754,  F1-mac 0.8917
arctic25,dgl,1,1589,93.3159,0.9754

epoch:1591/50, Iteration 32/32:training loss 0.09915147721767426
Train F1-mic 0.9754, Train F1-mac 0.8918
 F1-mic 0.9773,  F1-mac 0.8898
arctic25,dgl,1,1590,93.3744,0.9773

 F1-mic 0.9773,  F1-mac 0.8909
arctic25,dgl,1,1591,93.4327,0.9773

 F1-mic 0.9750,  F1-mac 0.8912
arctic25,dgl,1,1592,93.4914,0.9750

 F1-mic 0.9774,  F1-mac 0.8895
arctic25,dgl,1,1593,93.5501,0.9774

 F1-mic 0.9774,  F1-mac 0.8911
arctic25,dgl,1,1594,93.6087,0.9774

 F1-mic 0.9748,  F1-mac 0.8913
arctic25,dgl,1,1595,93.6671,0.9748

 F1-mic 0.9774,  F1-mac 0.8901
arctic25,dgl,1,1596,93.7258,0.9774

 F1-mic 0.9774,  F1-mac 0.8908
arctic25,dgl,1,1597,93.7842,0.9774

 F1-mic 0.9753,  F1-mac 0.8910
arctic25,dgl,1,1598,93.8427,0.9753

 F1-mic 0.9773,  F1-mac 0.8907
arctic25,dgl,1,1599,93.9012,0.9773

epoch:1601/50, Iteration 32/32:training loss 0.09756802767515182
Train F1-mic 0.9774, Train F1-mac 0.8897
 F1-mic 0.9773,  F1-mac 0.8911
arctic25,dgl,1,1600,93.9597,0.9773

 F1-mic 0.9757,  F1-mac 0.8912
arctic25,dgl,1,1601,94.0180,0.9757

 F1-mic 0.9774,  F1-mac 0.8912
new best val f1: 0.9773760814005111
arctic25,dgl,1,1602,94.0765,0.9774

 F1-mic 0.9773,  F1-mac 0.8915
arctic25,dgl,1,1603,94.1349,0.9773

 F1-mic 0.9756,  F1-mac 0.8916
arctic25,dgl,1,1604,94.1934,0.9756

 F1-mic 0.9774,  F1-mac 0.8902
new best val f1: 0.9774180775368666
arctic25,dgl,1,1605,94.2519,0.9774

 F1-mic 0.9774,  F1-mac 0.8908
arctic25,dgl,1,1606,94.3105,0.9774

 F1-mic 0.9750,  F1-mac 0.8913
arctic25,dgl,1,1607,94.3690,0.9750

 F1-mic 0.9774,  F1-mac 0.8895
new best val f1: 0.9774240769849174
arctic25,dgl,1,1608,94.4274,0.9774

 F1-mic 0.9774,  F1-mac 0.8917
arctic25,dgl,1,1609,94.4859,0.9774

epoch:1611/50, Iteration 32/32:training loss 0.09826347976922989
Train F1-mic 0.9774, Train F1-mac 0.8906
 F1-mic 0.9747,  F1-mac 0.8925
arctic25,dgl,1,1610,94.5444,0.9747

 F1-mic 0.9774,  F1-mac 0.8887
new best val f1: 0.9774420753290697
arctic25,dgl,1,1611,94.6028,0.9774

 F1-mic 0.9774,  F1-mac 0.8895
arctic25,dgl,1,1612,94.6613,0.9774

 F1-mic 0.9748,  F1-mac 0.8916
arctic25,dgl,1,1613,94.7198,0.9748

 F1-mic 0.9774,  F1-mac 0.8886
arctic25,dgl,1,1614,94.7783,0.9774

 F1-mic 0.9774,  F1-mac 0.8889
arctic25,dgl,1,1615,94.8368,0.9774

 F1-mic 0.9741,  F1-mac 0.8933
arctic25,dgl,1,1616,94.8953,0.9741

 F1-mic 0.9774,  F1-mac 0.8896
new best val f1: 0.9774480747771205
arctic25,dgl,1,1617,94.9537,0.9774

 F1-mic 0.9774,  F1-mac 0.8884
arctic25,dgl,1,1618,95.0122,0.9774

 F1-mic 0.9752,  F1-mac 0.8911
arctic25,dgl,1,1619,95.0706,0.9752

epoch:1621/50, Iteration 32/32:training loss 0.09865053743124008
Train F1-mic 0.9753, Train F1-mac 0.8911
 F1-mic 0.9775,  F1-mac 0.8910
new best val f1: 0.9774720725693237
arctic25,dgl,1,1620,95.1293,0.9775

 F1-mic 0.9774,  F1-mac 0.8919
arctic25,dgl,1,1621,95.1877,0.9774

 F1-mic 0.9749,  F1-mac 0.8936
arctic25,dgl,1,1622,95.2462,0.9749

 F1-mic 0.9775,  F1-mac 0.8925
arctic25,dgl,1,1623,95.3047,0.9775

 F1-mic 0.9775,  F1-mac 0.8892
arctic25,dgl,1,1624,95.3632,0.9775

 F1-mic 0.9751,  F1-mac 0.8899
arctic25,dgl,1,1625,95.4216,0.9751

 F1-mic 0.9773,  F1-mac 0.8907
arctic25,dgl,1,1626,95.4801,0.9773

 F1-mic 0.9775,  F1-mac 0.8924
new best val f1: 0.9775200681537298
arctic25,dgl,1,1627,95.5385,0.9775

 F1-mic 0.9754,  F1-mac 0.8938
arctic25,dgl,1,1628,95.5969,0.9754

 F1-mic 0.9772,  F1-mac 0.8920
arctic25,dgl,1,1629,95.6553,0.9772

epoch:1631/50, Iteration 32/32:training loss 0.09781176596879959
Train F1-mic 0.9773, Train F1-mac 0.8920
 F1-mic 0.9775,  F1-mac 0.8895
arctic25,dgl,1,1630,95.7138,0.9775

 F1-mic 0.9750,  F1-mac 0.8914
arctic25,dgl,1,1631,95.7722,0.9750

 F1-mic 0.9772,  F1-mac 0.8905
arctic25,dgl,1,1632,95.8307,0.9772

 F1-mic 0.9775,  F1-mac 0.8907
new best val f1: 0.9775320670498314
arctic25,dgl,1,1633,95.8891,0.9775

 F1-mic 0.9754,  F1-mac 0.8926
arctic25,dgl,1,1634,95.9478,0.9754

 F1-mic 0.9772,  F1-mac 0.8917
arctic25,dgl,1,1635,96.0065,0.9772

 F1-mic 0.9775,  F1-mac 0.8902
arctic25,dgl,1,1636,96.0650,0.9775

 F1-mic 0.9760,  F1-mac 0.8912
arctic25,dgl,1,1637,96.1235,0.9760

 F1-mic 0.9771,  F1-mac 0.8900
arctic25,dgl,1,1638,96.1819,0.9771

 F1-mic 0.9775,  F1-mac 0.8897
arctic25,dgl,1,1639,96.2404,0.9775

epoch:1641/50, Iteration 32/32:training loss 0.09591631591320038
Train F1-mic 0.9776, Train F1-mac 0.8889
 F1-mic 0.9756,  F1-mac 0.8926
arctic25,dgl,1,1640,96.2988,0.9756

 F1-mic 0.9771,  F1-mac 0.8930
arctic25,dgl,1,1641,96.3572,0.9771

 F1-mic 0.9775,  F1-mac 0.8916
arctic25,dgl,1,1642,96.4157,0.9775

 F1-mic 0.9749,  F1-mac 0.8927
arctic25,dgl,1,1643,96.4741,0.9749

 F1-mic 0.9773,  F1-mac 0.8902
arctic25,dgl,1,1644,96.5327,0.9773

 F1-mic 0.9775,  F1-mac 0.8901
arctic25,dgl,1,1645,96.5911,0.9775

 F1-mic 0.9755,  F1-mac 0.8925
arctic25,dgl,1,1646,96.6496,0.9755

 F1-mic 0.9774,  F1-mac 0.8917
arctic25,dgl,1,1647,96.7082,0.9774

 F1-mic 0.9775,  F1-mac 0.8919
arctic25,dgl,1,1648,96.7667,0.9775

 F1-mic 0.9757,  F1-mac 0.8924
arctic25,dgl,1,1649,96.8252,0.9757

epoch:1651/50, Iteration 32/32:training loss 0.09704355150461197
Train F1-mic 0.9757, Train F1-mac 0.8917
 F1-mic 0.9774,  F1-mac 0.8902
arctic25,dgl,1,1650,96.8837,0.9774

 F1-mic 0.9774,  F1-mac 0.8901
arctic25,dgl,1,1651,96.9420,0.9774

 F1-mic 0.9754,  F1-mac 0.8932
arctic25,dgl,1,1652,97.0005,0.9754

 F1-mic 0.9775,  F1-mac 0.8918
arctic25,dgl,1,1653,97.0589,0.9775

 F1-mic 0.9774,  F1-mac 0.8918
arctic25,dgl,1,1654,97.1175,0.9774

 F1-mic 0.9753,  F1-mac 0.8925
arctic25,dgl,1,1655,97.1759,0.9753

 F1-mic 0.9775,  F1-mac 0.8896
arctic25,dgl,1,1656,97.2343,0.9775

 F1-mic 0.9774,  F1-mac 0.8905
arctic25,dgl,1,1657,97.2927,0.9774

 F1-mic 0.9756,  F1-mac 0.8921
arctic25,dgl,1,1658,97.3512,0.9756

 F1-mic 0.9775,  F1-mac 0.8902
arctic25,dgl,1,1659,97.4096,0.9775

epoch:1661/50, Iteration 32/32:training loss 0.0959474965929985
Train F1-mic 0.9776, Train F1-mac 0.8894
 F1-mic 0.9774,  F1-mac 0.8918
arctic25,dgl,1,1660,97.4681,0.9774

 F1-mic 0.9756,  F1-mac 0.8918
arctic25,dgl,1,1661,97.5265,0.9756

 F1-mic 0.9776,  F1-mac 0.8902
new best val f1: 0.9776040604264408
arctic25,dgl,1,1662,97.5849,0.9776

 F1-mic 0.9774,  F1-mac 0.8906
arctic25,dgl,1,1663,97.6434,0.9774

 F1-mic 0.9756,  F1-mac 0.8910
arctic25,dgl,1,1664,97.7019,0.9756

 F1-mic 0.9776,  F1-mac 0.8914
arctic25,dgl,1,1665,97.7603,0.9776

 F1-mic 0.9775,  F1-mac 0.8923
arctic25,dgl,1,1666,97.8188,0.9775

 F1-mic 0.9757,  F1-mac 0.8921
arctic25,dgl,1,1667,97.8774,0.9757

 F1-mic 0.9776,  F1-mac 0.8922
new best val f1: 0.9776460565627962
arctic25,dgl,1,1668,97.9359,0.9776

 F1-mic 0.9775,  F1-mac 0.8906
arctic25,dgl,1,1669,97.9943,0.9775

epoch:1671/50, Iteration 32/32:training loss 0.09509096294641495
Train F1-mic 0.9776, Train F1-mac 0.8900
 F1-mic 0.9756,  F1-mac 0.8917
arctic25,dgl,1,1670,98.0528,0.9756

 F1-mic 0.9776,  F1-mac 0.8908
arctic25,dgl,1,1671,98.1112,0.9776

 F1-mic 0.9776,  F1-mac 0.8909
arctic25,dgl,1,1672,98.1696,0.9776

 F1-mic 0.9756,  F1-mac 0.8925
arctic25,dgl,1,1673,98.2280,0.9756

 F1-mic 0.9776,  F1-mac 0.8897
arctic25,dgl,1,1674,98.2865,0.9776

 F1-mic 0.9776,  F1-mac 0.8915
arctic25,dgl,1,1675,98.3450,0.9776

 F1-mic 0.9754,  F1-mac 0.8925
arctic25,dgl,1,1676,98.4035,0.9754

 F1-mic 0.9776,  F1-mac 0.8880
arctic25,dgl,1,1677,98.4619,0.9776

 F1-mic 0.9776,  F1-mac 0.8907
arctic25,dgl,1,1678,98.5204,0.9776

 F1-mic 0.9751,  F1-mac 0.8929
arctic25,dgl,1,1679,98.5788,0.9751

epoch:1681/50, Iteration 32/32:training loss 0.09705580025911331
Train F1-mic 0.9752, Train F1-mac 0.8932
 F1-mic 0.9776,  F1-mac 0.8891
arctic25,dgl,1,1680,98.6373,0.9776

 F1-mic 0.9776,  F1-mac 0.8892
arctic25,dgl,1,1681,98.6959,0.9776

 F1-mic 0.9751,  F1-mac 0.8918
arctic25,dgl,1,1682,98.7544,0.9751

 F1-mic 0.9776,  F1-mac 0.8903
arctic25,dgl,1,1683,98.8128,0.9776

 F1-mic 0.9776,  F1-mac 0.8912
arctic25,dgl,1,1684,98.8713,0.9776

 F1-mic 0.9753,  F1-mac 0.8944
arctic25,dgl,1,1685,98.9298,0.9753

 F1-mic 0.9777,  F1-mac 0.8918
new best val f1: 0.9776700543549993
arctic25,dgl,1,1686,98.9882,0.9777

 F1-mic 0.9776,  F1-mac 0.8890
arctic25,dgl,1,1687,99.0466,0.9776

 F1-mic 0.9754,  F1-mac 0.8908
arctic25,dgl,1,1688,99.1051,0.9754

 F1-mic 0.9777,  F1-mac 0.8900
arctic25,dgl,1,1689,99.1635,0.9777

epoch:1691/50, Iteration 32/32:training loss 0.09502870589494705
Train F1-mic 0.9777, Train F1-mac 0.8894
 F1-mic 0.9777,  F1-mac 0.8926
arctic25,dgl,1,1690,99.2220,0.9777

 F1-mic 0.9755,  F1-mac 0.8933
arctic25,dgl,1,1691,99.2803,0.9755

 F1-mic 0.9777,  F1-mac 0.8905
arctic25,dgl,1,1692,99.3387,0.9777

 F1-mic 0.9776,  F1-mac 0.8898
arctic25,dgl,1,1693,99.3972,0.9776

 F1-mic 0.9754,  F1-mac 0.8899
arctic25,dgl,1,1694,99.4557,0.9754

 F1-mic 0.9777,  F1-mac 0.8904
arctic25,dgl,1,1695,99.5142,0.9777

 F1-mic 0.9777,  F1-mac 0.8921
new best val f1: 0.9776820532511009
arctic25,dgl,1,1696,99.5726,0.9777

 F1-mic 0.9754,  F1-mac 0.8933
arctic25,dgl,1,1697,99.6310,0.9754

 F1-mic 0.9777,  F1-mac 0.8918
arctic25,dgl,1,1698,99.6895,0.9777

 F1-mic 0.9777,  F1-mac 0.8900
arctic25,dgl,1,1699,99.7480,0.9777

epoch:1701/50, Iteration 32/32:training loss 0.09460324794054031
Train F1-mic 0.9777, Train F1-mac 0.8898
 F1-mic 0.9754,  F1-mac 0.8916
arctic25,dgl,1,1700,99.8065,0.9754

 F1-mic 0.9776,  F1-mac 0.8908
arctic25,dgl,1,1701,99.8648,0.9776

 F1-mic 0.9777,  F1-mac 0.8924
new best val f1: 0.9777120504913548
arctic25,dgl,1,1702,99.9233,0.9777

 F1-mic 0.9755,  F1-mac 0.8925
arctic25,dgl,1,1703,99.9817,0.9755

 F1-mic 0.9777,  F1-mac 0.8919
new best val f1: 0.9777300488355072
arctic25,dgl,1,1704,100.0402,0.9777

 F1-mic 0.9777,  F1-mac 0.8922
arctic25,dgl,1,1705,100.0987,0.9777

 F1-mic 0.9754,  F1-mac 0.8915
arctic25,dgl,1,1706,100.1572,0.9754

 F1-mic 0.9777,  F1-mac 0.8904
arctic25,dgl,1,1707,100.2156,0.9777

 F1-mic 0.9777,  F1-mac 0.8923
arctic25,dgl,1,1708,100.2741,0.9777

 F1-mic 0.9748,  F1-mac 0.8931
arctic25,dgl,1,1709,100.3325,0.9748

epoch:1711/50, Iteration 32/32:training loss 0.09630531072616577
Train F1-mic 0.9750, Train F1-mac 0.8932
 F1-mic 0.9777,  F1-mac 0.8919
new best val f1: 0.9777360482835579
arctic25,dgl,1,1710,100.3910,0.9777

 F1-mic 0.9777,  F1-mac 0.8914
arctic25,dgl,1,1711,100.4495,0.9777

 F1-mic 0.9757,  F1-mac 0.8920
arctic25,dgl,1,1712,100.5079,0.9757

 F1-mic 0.9777,  F1-mac 0.8921
arctic25,dgl,1,1713,100.5664,0.9777

 F1-mic 0.9777,  F1-mac 0.8919
arctic25,dgl,1,1714,100.6248,0.9777

 F1-mic 0.9760,  F1-mac 0.8919
arctic25,dgl,1,1715,100.6833,0.9760

 F1-mic 0.9778,  F1-mac 0.8924
new best val f1: 0.9777540466277103
arctic25,dgl,1,1716,100.7417,0.9778

 F1-mic 0.9777,  F1-mac 0.8924
arctic25,dgl,1,1717,100.8004,0.9777

 F1-mic 0.9758,  F1-mac 0.8920
arctic25,dgl,1,1718,100.8588,0.9758

 F1-mic 0.9777,  F1-mac 0.8925
arctic25,dgl,1,1719,100.9173,0.9777

epoch:1721/50, Iteration 32/32:training loss 0.09422001987695694
Train F1-mic 0.9778, Train F1-mac 0.8916
 F1-mic 0.9778,  F1-mac 0.8920
arctic25,dgl,1,1720,100.9758,0.9778

 F1-mic 0.9758,  F1-mac 0.8919
arctic25,dgl,1,1721,101.0341,0.9758

 F1-mic 0.9777,  F1-mac 0.8916
arctic25,dgl,1,1722,101.0926,0.9777

 F1-mic 0.9777,  F1-mac 0.8921
arctic25,dgl,1,1723,101.1511,0.9777

 F1-mic 0.9759,  F1-mac 0.8916
arctic25,dgl,1,1724,101.2095,0.9759

 F1-mic 0.9777,  F1-mac 0.8924
arctic25,dgl,1,1725,101.2680,0.9777

 F1-mic 0.9777,  F1-mac 0.8922
arctic25,dgl,1,1726,101.3265,0.9777

 F1-mic 0.9753,  F1-mac 0.8923
arctic25,dgl,1,1727,101.3849,0.9753

 F1-mic 0.9777,  F1-mac 0.8913
arctic25,dgl,1,1728,101.4434,0.9777

 F1-mic 0.9777,  F1-mac 0.8920
arctic25,dgl,1,1729,101.5019,0.9777

epoch:1731/50, Iteration 32/32:training loss 0.09463362395763397
Train F1-mic 0.9778, Train F1-mac 0.8913
 F1-mic 0.9758,  F1-mac 0.8921
arctic25,dgl,1,1730,101.5604,0.9758

 F1-mic 0.9777,  F1-mac 0.8927
arctic25,dgl,1,1731,101.6188,0.9777

 F1-mic 0.9778,  F1-mac 0.8925
new best val f1: 0.9777840438679641
arctic25,dgl,1,1732,101.6774,0.9778

 F1-mic 0.9766,  F1-mac 0.8922
arctic25,dgl,1,1733,101.7358,0.9766

 F1-mic 0.9777,  F1-mac 0.8914
arctic25,dgl,1,1734,101.7944,0.9777

 F1-mic 0.9777,  F1-mac 0.8916
arctic25,dgl,1,1735,101.8528,0.9777

 F1-mic 0.9759,  F1-mac 0.8920
arctic25,dgl,1,1736,101.9113,0.9759

 F1-mic 0.9777,  F1-mac 0.8916
arctic25,dgl,1,1737,101.9697,0.9777

 F1-mic 0.9778,  F1-mac 0.8919
arctic25,dgl,1,1738,102.0282,0.9778

 F1-mic 0.9747,  F1-mac 0.8920
arctic25,dgl,1,1739,102.0866,0.9747

epoch:1741/50, Iteration 32/32:training loss 0.09564892202615738
Train F1-mic 0.9749, Train F1-mac 0.8930
 F1-mic 0.9777,  F1-mac 0.8913
arctic25,dgl,1,1740,102.1452,0.9777

 F1-mic 0.9777,  F1-mac 0.8914
arctic25,dgl,1,1741,102.2037,0.9777

 F1-mic 0.9759,  F1-mac 0.8931
arctic25,dgl,1,1742,102.2621,0.9759

 F1-mic 0.9777,  F1-mac 0.8912
arctic25,dgl,1,1743,102.3206,0.9777

 F1-mic 0.9777,  F1-mac 0.8921
arctic25,dgl,1,1744,102.3791,0.9777

 F1-mic 0.9758,  F1-mac 0.8932
arctic25,dgl,1,1745,102.4375,0.9758

 F1-mic 0.9777,  F1-mac 0.8915
arctic25,dgl,1,1746,102.4960,0.9777

 F1-mic 0.9777,  F1-mac 0.8917
arctic25,dgl,1,1747,102.5544,0.9777

 F1-mic 0.9747,  F1-mac 0.8936
arctic25,dgl,1,1748,102.6129,0.9747

 F1-mic 0.9778,  F1-mac 0.8923
arctic25,dgl,1,1749,102.6714,0.9778

epoch:1751/50, Iteration 32/32:training loss 0.09332065284252167
Train F1-mic 0.9779, Train F1-mac 0.8915
 F1-mic 0.9778,  F1-mac 0.8919
arctic25,dgl,1,1750,102.7299,0.9778

 F1-mic 0.9757,  F1-mac 0.8927
arctic25,dgl,1,1751,102.7884,0.9757

 F1-mic 0.9778,  F1-mac 0.8920
arctic25,dgl,1,1752,102.8472,0.9778

 F1-mic 0.9777,  F1-mac 0.8919
arctic25,dgl,1,1753,102.9057,0.9777

 F1-mic 0.9754,  F1-mac 0.8922
arctic25,dgl,1,1754,102.9642,0.9754

 F1-mic 0.9778,  F1-mac 0.8925
new best val f1: 0.9778260400043196
arctic25,dgl,1,1755,103.0227,0.9778

 F1-mic 0.9777,  F1-mac 0.8918
arctic25,dgl,1,1756,103.0811,0.9777

 F1-mic 0.9752,  F1-mac 0.8920
arctic25,dgl,1,1757,103.1396,0.9752

 F1-mic 0.9778,  F1-mac 0.8923
arctic25,dgl,1,1758,103.1981,0.9778

 F1-mic 0.9777,  F1-mac 0.8920
arctic25,dgl,1,1759,103.2565,0.9777

epoch:1761/50, Iteration 32/32:training loss 0.09250175207853317
Train F1-mic 0.9778, Train F1-mac 0.8912
 F1-mic 0.9757,  F1-mac 0.8922
arctic25,dgl,1,1760,103.3157,0.9757

 F1-mic 0.9778,  F1-mac 0.8925
arctic25,dgl,1,1761,103.3742,0.9778

 F1-mic 0.9777,  F1-mac 0.8921
arctic25,dgl,1,1762,103.4327,0.9777

 F1-mic 0.9751,  F1-mac 0.8919
arctic25,dgl,1,1763,103.4912,0.9751

 F1-mic 0.9778,  F1-mac 0.8930
arctic25,dgl,1,1764,103.5497,0.9778

 F1-mic 0.9778,  F1-mac 0.8923
arctic25,dgl,1,1765,103.6082,0.9778

 F1-mic 0.9754,  F1-mac 0.8917
arctic25,dgl,1,1766,103.6666,0.9754

 F1-mic 0.9778,  F1-mac 0.8924
arctic25,dgl,1,1767,103.7250,0.9778

 F1-mic 0.9778,  F1-mac 0.8922
arctic25,dgl,1,1768,103.7835,0.9778

 F1-mic 0.9753,  F1-mac 0.8921
arctic25,dgl,1,1769,103.8419,0.9753

epoch:1771/50, Iteration 32/32:training loss 0.0940304845571518
Train F1-mic 0.9755, Train F1-mac 0.8930
 F1-mic 0.9778,  F1-mac 0.8923
arctic25,dgl,1,1770,103.9004,0.9778

 F1-mic 0.9778,  F1-mac 0.8919
arctic25,dgl,1,1771,103.9588,0.9778

 F1-mic 0.9755,  F1-mac 0.8923
arctic25,dgl,1,1772,104.0175,0.9755

 F1-mic 0.9778,  F1-mac 0.8924
arctic25,dgl,1,1773,104.0759,0.9778

 F1-mic 0.9778,  F1-mac 0.8920
arctic25,dgl,1,1774,104.1344,0.9778

 F1-mic 0.9756,  F1-mac 0.8919
arctic25,dgl,1,1775,104.1929,0.9756

 F1-mic 0.9778,  F1-mac 0.8921
arctic25,dgl,1,1776,104.2513,0.9778

 F1-mic 0.9778,  F1-mac 0.8924
arctic25,dgl,1,1777,104.3098,0.9778

 F1-mic 0.9755,  F1-mac 0.8920
arctic25,dgl,1,1778,104.3682,0.9755

 F1-mic 0.9779,  F1-mac 0.8925
new best val f1: 0.9778560372445735
arctic25,dgl,1,1779,104.4266,0.9779

epoch:1781/50, Iteration 32/32:training loss 0.09278156608343124
Train F1-mic 0.9780, Train F1-mac 0.8916
 F1-mic 0.9778,  F1-mac 0.8927
arctic25,dgl,1,1780,104.4851,0.9778

 F1-mic 0.9753,  F1-mac 0.8921
arctic25,dgl,1,1781,104.5435,0.9753

 F1-mic 0.9778,  F1-mac 0.8925
arctic25,dgl,1,1782,104.6020,0.9778

 F1-mic 0.9778,  F1-mac 0.8922
arctic25,dgl,1,1783,104.6605,0.9778

 F1-mic 0.9753,  F1-mac 0.8920
arctic25,dgl,1,1784,104.7190,0.9753

 F1-mic 0.9778,  F1-mac 0.8917
arctic25,dgl,1,1785,104.7775,0.9778

 F1-mic 0.9778,  F1-mac 0.8922
arctic25,dgl,1,1786,104.8362,0.9778

 F1-mic 0.9753,  F1-mac 0.8922
arctic25,dgl,1,1787,104.8947,0.9753

 F1-mic 0.9779,  F1-mac 0.8919
new best val f1: 0.9778620366926243
arctic25,dgl,1,1788,104.9533,0.9779

 F1-mic 0.9779,  F1-mac 0.8928
new best val f1: 0.9778860344848274
arctic25,dgl,1,1789,105.0117,0.9779

epoch:1791/50, Iteration 32/32:training loss 0.09206083416938782
Train F1-mic 0.9780, Train F1-mac 0.8921
 F1-mic 0.9755,  F1-mac 0.8933
arctic25,dgl,1,1790,105.0702,0.9755

 F1-mic 0.9778,  F1-mac 0.8907
arctic25,dgl,1,1791,105.1286,0.9778

 F1-mic 0.9779,  F1-mac 0.8924
arctic25,dgl,1,1792,105.1871,0.9779

 F1-mic 0.9754,  F1-mac 0.8932
arctic25,dgl,1,1793,105.2456,0.9754

 F1-mic 0.9778,  F1-mac 0.8900
arctic25,dgl,1,1794,105.3041,0.9778

 F1-mic 0.9778,  F1-mac 0.8917
arctic25,dgl,1,1795,105.3626,0.9778

 F1-mic 0.9750,  F1-mac 0.8940
arctic25,dgl,1,1796,105.4211,0.9750

 F1-mic 0.9778,  F1-mac 0.8895
arctic25,dgl,1,1797,105.4796,0.9778

 F1-mic 0.9778,  F1-mac 0.8894
arctic25,dgl,1,1798,105.5381,0.9778

 F1-mic 0.9753,  F1-mac 0.8922
arctic25,dgl,1,1799,105.5965,0.9753

epoch:1801/50, Iteration 32/32:training loss 0.09353569149971008
Train F1-mic 0.9755, Train F1-mac 0.8930
 F1-mic 0.9776,  F1-mac 0.8923
arctic25,dgl,1,1800,105.6551,0.9776

 F1-mic 0.9778,  F1-mac 0.8897
arctic25,dgl,1,1801,105.7134,0.9778

 F1-mic 0.9758,  F1-mac 0.8946
arctic25,dgl,1,1802,105.7719,0.9758

 F1-mic 0.9774,  F1-mac 0.8921
arctic25,dgl,1,1803,105.8304,0.9774

 F1-mic 0.9778,  F1-mac 0.8870
arctic25,dgl,1,1804,105.8889,0.9778

 F1-mic 0.9756,  F1-mac 0.8882
arctic25,dgl,1,1805,105.9473,0.9756

 F1-mic 0.9775,  F1-mac 0.8909
arctic25,dgl,1,1806,106.0058,0.9775

 F1-mic 0.9779,  F1-mac 0.8923
new best val f1: 0.9779040328289798
arctic25,dgl,1,1807,106.0642,0.9779

 F1-mic 0.9758,  F1-mac 0.8937
arctic25,dgl,1,1808,106.1227,0.9758

 F1-mic 0.9778,  F1-mac 0.8938
arctic25,dgl,1,1809,106.1812,0.9778

epoch:1811/50, Iteration 32/32:training loss 0.09200973808765411
Train F1-mic 0.9779, Train F1-mac 0.8931
 F1-mic 0.9778,  F1-mac 0.8928
arctic25,dgl,1,1810,106.2396,0.9778

 F1-mic 0.9756,  F1-mac 0.8920
arctic25,dgl,1,1811,106.2980,0.9756

 F1-mic 0.9778,  F1-mac 0.8877
arctic25,dgl,1,1812,106.3565,0.9778

 F1-mic 0.9778,  F1-mac 0.8894
arctic25,dgl,1,1813,106.4150,0.9778

 F1-mic 0.9756,  F1-mac 0.8922
arctic25,dgl,1,1814,106.4735,0.9756

 F1-mic 0.9777,  F1-mac 0.8927
arctic25,dgl,1,1815,106.5319,0.9777

 F1-mic 0.9778,  F1-mac 0.8924
arctic25,dgl,1,1816,106.5904,0.9778

 F1-mic 0.9758,  F1-mac 0.8931
arctic25,dgl,1,1817,106.6488,0.9758

 F1-mic 0.9779,  F1-mac 0.8916
arctic25,dgl,1,1818,106.7075,0.9779

 F1-mic 0.9777,  F1-mac 0.8906
arctic25,dgl,1,1819,106.7659,0.9777

epoch:1821/50, Iteration 32/32:training loss 0.09132935106754303
Train F1-mic 0.9779, Train F1-mac 0.8907
 F1-mic 0.9754,  F1-mac 0.8907
arctic25,dgl,1,1820,106.8244,0.9754

 F1-mic 0.9778,  F1-mac 0.8904
arctic25,dgl,1,1821,106.8828,0.9778

 F1-mic 0.9779,  F1-mac 0.8927
arctic25,dgl,1,1822,106.9412,0.9779

 F1-mic 0.9755,  F1-mac 0.8947
arctic25,dgl,1,1823,106.9997,0.9755

 F1-mic 0.9779,  F1-mac 0.8922
new best val f1: 0.9779160317250813
arctic25,dgl,1,1824,107.0583,0.9779

 F1-mic 0.9779,  F1-mac 0.8931
arctic25,dgl,1,1825,107.1168,0.9779

 F1-mic 0.9760,  F1-mac 0.8931
arctic25,dgl,1,1826,107.1755,0.9760

 F1-mic 0.9779,  F1-mac 0.8916
new best val f1: 0.9779340300692336
arctic25,dgl,1,1827,107.2339,0.9779

 F1-mic 0.9779,  F1-mac 0.8913
arctic25,dgl,1,1828,107.2924,0.9779

 F1-mic 0.9760,  F1-mac 0.8924
arctic25,dgl,1,1829,107.3509,0.9760

epoch:1831/50, Iteration 32/32:training loss 0.09151429682970047
Train F1-mic 0.9762, Train F1-mac 0.8925
 F1-mic 0.9779,  F1-mac 0.8920
new best val f1: 0.9779460289653352
arctic25,dgl,1,1830,107.4093,0.9779

 F1-mic 0.9780,  F1-mac 0.8928
new best val f1: 0.978006023445843
arctic25,dgl,1,1831,107.4677,0.9780

 F1-mic 0.9755,  F1-mac 0.8934
arctic25,dgl,1,1832,107.5262,0.9755

 F1-mic 0.9779,  F1-mac 0.8933
arctic25,dgl,1,1833,107.5847,0.9779

 F1-mic 0.9779,  F1-mac 0.8918
arctic25,dgl,1,1834,107.6431,0.9779

 F1-mic 0.9759,  F1-mac 0.8924
arctic25,dgl,1,1835,107.7015,0.9759

 F1-mic 0.9780,  F1-mac 0.8916
arctic25,dgl,1,1836,107.7600,0.9780

 F1-mic 0.9780,  F1-mac 0.8921
arctic25,dgl,1,1837,107.8184,0.9780

 F1-mic 0.9763,  F1-mac 0.8934
arctic25,dgl,1,1838,107.8769,0.9763

 F1-mic 0.9779,  F1-mac 0.8928
arctic25,dgl,1,1839,107.9353,0.9779

epoch:1841/50, Iteration 32/32:training loss 0.09026671200990677
Train F1-mic 0.9781, Train F1-mac 0.8918
 F1-mic 0.9780,  F1-mac 0.8933
arctic25,dgl,1,1840,107.9938,0.9780

 F1-mic 0.9760,  F1-mac 0.8926
arctic25,dgl,1,1841,108.0522,0.9760

 F1-mic 0.9780,  F1-mac 0.8919
arctic25,dgl,1,1842,108.1107,0.9780

 F1-mic 0.9779,  F1-mac 0.8927
arctic25,dgl,1,1843,108.1691,0.9779

 F1-mic 0.9758,  F1-mac 0.8940
arctic25,dgl,1,1844,108.2276,0.9758

 F1-mic 0.9780,  F1-mac 0.8928
arctic25,dgl,1,1845,108.2860,0.9780

 F1-mic 0.9780,  F1-mac 0.8931
arctic25,dgl,1,1846,108.3446,0.9780

 F1-mic 0.9757,  F1-mac 0.8942
arctic25,dgl,1,1847,108.4032,0.9757

 F1-mic 0.9779,  F1-mac 0.8925
arctic25,dgl,1,1848,108.4617,0.9779

 F1-mic 0.9779,  F1-mac 0.8921
arctic25,dgl,1,1849,108.5201,0.9779

epoch:1851/50, Iteration 32/32:training loss 0.0902358666062355
Train F1-mic 0.9781, Train F1-mac 0.8918
 F1-mic 0.9757,  F1-mac 0.8943
arctic25,dgl,1,1850,108.5786,0.9757

 F1-mic 0.9779,  F1-mac 0.8921
arctic25,dgl,1,1851,108.6370,0.9779

 F1-mic 0.9779,  F1-mac 0.8925
arctic25,dgl,1,1852,108.6954,0.9779

 F1-mic 0.9756,  F1-mac 0.8941
arctic25,dgl,1,1853,108.7538,0.9756

 F1-mic 0.9780,  F1-mac 0.8907
arctic25,dgl,1,1854,108.8123,0.9780

 F1-mic 0.9780,  F1-mac 0.8915
arctic25,dgl,1,1855,108.8708,0.9780

 F1-mic 0.9758,  F1-mac 0.8930
arctic25,dgl,1,1856,108.9293,0.9758

 F1-mic 0.9780,  F1-mac 0.8899
arctic25,dgl,1,1857,108.9877,0.9780

 F1-mic 0.9780,  F1-mac 0.8913
arctic25,dgl,1,1858,109.0465,0.9780

 F1-mic 0.9761,  F1-mac 0.8948
arctic25,dgl,1,1859,109.1049,0.9761

epoch:1861/50, Iteration 32/32:training loss 0.09105172753334045
Train F1-mic 0.9763, Train F1-mac 0.8944
 F1-mic 0.9781,  F1-mac 0.8938
new best val f1: 0.9780840162705031
arctic25,dgl,1,1860,109.1634,0.9781

 F1-mic 0.9779,  F1-mac 0.8906
arctic25,dgl,1,1861,109.2217,0.9779

 F1-mic 0.9766,  F1-mac 0.8915
arctic25,dgl,1,1862,109.2802,0.9766

 F1-mic 0.9780,  F1-mac 0.8927
arctic25,dgl,1,1863,109.3386,0.9780

 F1-mic 0.9780,  F1-mac 0.8933
arctic25,dgl,1,1864,109.3971,0.9780

 F1-mic 0.9767,  F1-mac 0.8946
arctic25,dgl,1,1865,109.4555,0.9767

 F1-mic 0.9781,  F1-mac 0.8935
arctic25,dgl,1,1866,109.5139,0.9781

 F1-mic 0.9780,  F1-mac 0.8919
arctic25,dgl,1,1867,109.5724,0.9780

 F1-mic 0.9757,  F1-mac 0.8919
arctic25,dgl,1,1868,109.6308,0.9757

 F1-mic 0.9780,  F1-mac 0.8907
arctic25,dgl,1,1869,109.6893,0.9780

epoch:1871/50, Iteration 32/32:training loss 0.09151578694581985
Train F1-mic 0.9781, Train F1-mac 0.8898
 F1-mic 0.9780,  F1-mac 0.8922
arctic25,dgl,1,1870,109.7477,0.9780

 F1-mic 0.9753,  F1-mac 0.8946
arctic25,dgl,1,1871,109.8061,0.9753

 F1-mic 0.9781,  F1-mac 0.8927
arctic25,dgl,1,1872,109.8646,0.9781

 F1-mic 0.9780,  F1-mac 0.8906
arctic25,dgl,1,1873,109.9231,0.9780

 F1-mic 0.9762,  F1-mac 0.8913
arctic25,dgl,1,1874,109.9816,0.9762

 F1-mic 0.9781,  F1-mac 0.8927
arctic25,dgl,1,1875,110.0400,0.9781

 F1-mic 0.9781,  F1-mac 0.8934
new best val f1: 0.9780900157185539
arctic25,dgl,1,1876,110.0985,0.9781

 F1-mic 0.9760,  F1-mac 0.8941
arctic25,dgl,1,1877,110.1569,0.9760

 F1-mic 0.9780,  F1-mac 0.8913
arctic25,dgl,1,1878,110.2153,0.9780

 F1-mic 0.9780,  F1-mac 0.8912
arctic25,dgl,1,1879,110.2737,0.9780

epoch:1881/50, Iteration 32/32:training loss 0.0895414724946022
Train F1-mic 0.9782, Train F1-mac 0.8904
 F1-mic 0.9756,  F1-mac 0.8930
arctic25,dgl,1,1880,110.3323,0.9756

 F1-mic 0.9780,  F1-mac 0.8920
arctic25,dgl,1,1881,110.3907,0.9780

 F1-mic 0.9781,  F1-mac 0.8936
arctic25,dgl,1,1882,110.4491,0.9781

 F1-mic 0.9759,  F1-mac 0.8945
arctic25,dgl,1,1883,110.5078,0.9759

 F1-mic 0.9781,  F1-mac 0.8936
arctic25,dgl,1,1884,110.5663,0.9781

 F1-mic 0.9781,  F1-mac 0.8914
arctic25,dgl,1,1885,110.6247,0.9781

 F1-mic 0.9764,  F1-mac 0.8915
arctic25,dgl,1,1886,110.6832,0.9764

 F1-mic 0.9781,  F1-mac 0.8923
arctic25,dgl,1,1887,110.7416,0.9781

 F1-mic 0.9781,  F1-mac 0.8932
arctic25,dgl,1,1888,110.8000,0.9781

 F1-mic 0.9760,  F1-mac 0.8948
arctic25,dgl,1,1889,110.8585,0.9760

epoch:1891/50, Iteration 32/32:training loss 0.09023422002792358
Train F1-mic 0.9763, Train F1-mac 0.8946
 F1-mic 0.9781,  F1-mac 0.8934
arctic25,dgl,1,1890,110.9170,0.9781

 F1-mic 0.9781,  F1-mac 0.8928
new best val f1: 0.9781380113029601
arctic25,dgl,1,1891,110.9754,0.9781

 F1-mic 0.9759,  F1-mac 0.8919
arctic25,dgl,1,1892,111.0339,0.9759

 F1-mic 0.9780,  F1-mac 0.8915
arctic25,dgl,1,1893,111.0924,0.9780

 F1-mic 0.9781,  F1-mac 0.8933
arctic25,dgl,1,1894,111.1508,0.9781

 F1-mic 0.9765,  F1-mac 0.8939
arctic25,dgl,1,1895,111.2092,0.9765

 F1-mic 0.9781,  F1-mac 0.8934
arctic25,dgl,1,1896,111.2677,0.9781

 F1-mic 0.9781,  F1-mac 0.8938
arctic25,dgl,1,1897,111.3261,0.9781

 F1-mic 0.9763,  F1-mac 0.8928
arctic25,dgl,1,1898,111.3845,0.9763

 F1-mic 0.9780,  F1-mac 0.8918
arctic25,dgl,1,1899,111.4430,0.9780

epoch:1901/50, Iteration 32/32:training loss 0.08931431919336319
Train F1-mic 0.9782, Train F1-mac 0.8922
 F1-mic 0.9780,  F1-mac 0.8925
arctic25,dgl,1,1900,111.5015,0.9780

 F1-mic 0.9759,  F1-mac 0.8931
arctic25,dgl,1,1901,111.5598,0.9759

 F1-mic 0.9781,  F1-mac 0.8929
arctic25,dgl,1,1902,111.6183,0.9781

 F1-mic 0.9781,  F1-mac 0.8927
arctic25,dgl,1,1903,111.6767,0.9781

 F1-mic 0.9759,  F1-mac 0.8935
arctic25,dgl,1,1904,111.7353,0.9759

 F1-mic 0.9781,  F1-mac 0.8926
arctic25,dgl,1,1905,111.7937,0.9781

 F1-mic 0.9780,  F1-mac 0.8920
arctic25,dgl,1,1906,111.8522,0.9780

 F1-mic 0.9761,  F1-mac 0.8930
arctic25,dgl,1,1907,111.9106,0.9761

 F1-mic 0.9782,  F1-mac 0.8933
new best val f1: 0.9781560096471125
arctic25,dgl,1,1908,111.9691,0.9782

 F1-mic 0.9780,  F1-mac 0.8920
arctic25,dgl,1,1909,112.0276,0.9780

epoch:1911/50, Iteration 32/32:training loss 0.08830079436302185
Train F1-mic 0.9782, Train F1-mac 0.8926
 F1-mic 0.9761,  F1-mac 0.8939
arctic25,dgl,1,1910,112.0861,0.9761

 F1-mic 0.9781,  F1-mac 0.8933
arctic25,dgl,1,1911,112.1444,0.9781

 F1-mic 0.9781,  F1-mac 0.8929
arctic25,dgl,1,1912,112.2029,0.9781

 F1-mic 0.9757,  F1-mac 0.8941
arctic25,dgl,1,1913,112.2614,0.9757

 F1-mic 0.9781,  F1-mac 0.8932
arctic25,dgl,1,1914,112.3200,0.9781

 F1-mic 0.9782,  F1-mac 0.8934
arctic25,dgl,1,1915,112.3784,0.9782

 F1-mic 0.9759,  F1-mac 0.8940
arctic25,dgl,1,1916,112.4369,0.9759

 F1-mic 0.9781,  F1-mac 0.8924
arctic25,dgl,1,1917,112.4954,0.9781

 F1-mic 0.9781,  F1-mac 0.8932
arctic25,dgl,1,1918,112.5538,0.9781

 F1-mic 0.9758,  F1-mac 0.8932
arctic25,dgl,1,1919,112.6122,0.9758

epoch:1921/50, Iteration 32/32:training loss 0.08995205909013748
Train F1-mic 0.9760, Train F1-mac 0.8940
 F1-mic 0.9781,  F1-mac 0.8923
arctic25,dgl,1,1920,112.6707,0.9781

 F1-mic 0.9782,  F1-mac 0.8932
new best val f1: 0.9781680085432141
arctic25,dgl,1,1921,112.7291,0.9782

 F1-mic 0.9760,  F1-mac 0.8932
arctic25,dgl,1,1922,112.7876,0.9760

 F1-mic 0.9781,  F1-mac 0.8921
arctic25,dgl,1,1923,112.8460,0.9781

 F1-mic 0.9781,  F1-mac 0.8926
arctic25,dgl,1,1924,112.9045,0.9781

 F1-mic 0.9760,  F1-mac 0.8932
arctic25,dgl,1,1925,112.9631,0.9760

 F1-mic 0.9782,  F1-mac 0.8931
new best val f1: 0.9781980057834679
arctic25,dgl,1,1926,113.0216,0.9782

 F1-mic 0.9781,  F1-mac 0.8921
arctic25,dgl,1,1927,113.0800,0.9781

 F1-mic 0.9758,  F1-mac 0.8935
arctic25,dgl,1,1928,113.1387,0.9758

 F1-mic 0.9782,  F1-mac 0.8931
arctic25,dgl,1,1929,113.1972,0.9782

epoch:1931/50, Iteration 32/32:training loss 0.08862724900245667
Train F1-mic 0.9783, Train F1-mac 0.8925
 F1-mic 0.9782,  F1-mac 0.8933
arctic25,dgl,1,1930,113.2557,0.9782

 F1-mic 0.9758,  F1-mac 0.8935
arctic25,dgl,1,1931,113.3140,0.9758

 F1-mic 0.9781,  F1-mac 0.8931
arctic25,dgl,1,1932,113.3726,0.9781

 F1-mic 0.9782,  F1-mac 0.8932
new best val f1: 0.9782040052315187
arctic25,dgl,1,1933,113.4310,0.9782

 F1-mic 0.9758,  F1-mac 0.8936
arctic25,dgl,1,1934,113.4895,0.9758

 F1-mic 0.9782,  F1-mac 0.8929
arctic25,dgl,1,1935,113.5480,0.9782

 F1-mic 0.9782,  F1-mac 0.8932
arctic25,dgl,1,1936,113.6065,0.9782

 F1-mic 0.9759,  F1-mac 0.8932
arctic25,dgl,1,1937,113.6649,0.9759

 F1-mic 0.9782,  F1-mac 0.8931
arctic25,dgl,1,1938,113.7236,0.9782

 F1-mic 0.9782,  F1-mac 0.8925
arctic25,dgl,1,1939,113.7820,0.9782

epoch:1941/50, Iteration 32/32:training loss 0.08815749734640121
Train F1-mic 0.9784, Train F1-mac 0.8928
 F1-mic 0.9759,  F1-mac 0.8934
arctic25,dgl,1,1940,113.8405,0.9759

 F1-mic 0.9782,  F1-mac 0.8936
new best val f1: 0.978222003575671
arctic25,dgl,1,1941,113.8988,0.9782

 F1-mic 0.9781,  F1-mac 0.8923
arctic25,dgl,1,1942,113.9574,0.9781

 F1-mic 0.9760,  F1-mac 0.8937
arctic25,dgl,1,1943,114.0158,0.9760

 F1-mic 0.9782,  F1-mac 0.8935
arctic25,dgl,1,1944,114.0743,0.9782

 F1-mic 0.9782,  F1-mac 0.8930
arctic25,dgl,1,1945,114.1327,0.9782

 F1-mic 0.9761,  F1-mac 0.8942
arctic25,dgl,1,1946,114.1912,0.9761

 F1-mic 0.9781,  F1-mac 0.8935
arctic25,dgl,1,1947,114.2496,0.9781

 F1-mic 0.9783,  F1-mac 0.8935
new best val f1: 0.9782639997120265
arctic25,dgl,1,1948,114.3083,0.9783

 F1-mic 0.9761,  F1-mac 0.8932
arctic25,dgl,1,1949,114.3667,0.9761

epoch:1951/50, Iteration 32/32:training loss 0.08886045217514038
Train F1-mic 0.9764, Train F1-mac 0.8940
 F1-mic 0.9782,  F1-mac 0.8932
arctic25,dgl,1,1950,114.4252,0.9782

 F1-mic 0.9782,  F1-mac 0.8934
arctic25,dgl,1,1951,114.4835,0.9782

 F1-mic 0.9761,  F1-mac 0.8934
arctic25,dgl,1,1952,114.5420,0.9761

 F1-mic 0.9782,  F1-mac 0.8932
arctic25,dgl,1,1953,114.6005,0.9782

 F1-mic 0.9782,  F1-mac 0.8935
arctic25,dgl,1,1954,114.6590,0.9782

 F1-mic 0.9761,  F1-mac 0.8932
arctic25,dgl,1,1955,114.7174,0.9761

 F1-mic 0.9782,  F1-mac 0.8929
arctic25,dgl,1,1956,114.7759,0.9782

 F1-mic 0.9782,  F1-mac 0.8926
arctic25,dgl,1,1957,114.8343,0.9782

 F1-mic 0.9761,  F1-mac 0.8935
arctic25,dgl,1,1958,114.8927,0.9761

 F1-mic 0.9783,  F1-mac 0.8935
new best val f1: 0.9782759986081281
arctic25,dgl,1,1959,114.9511,0.9783

epoch:1961/50, Iteration 32/32:training loss 0.08801441639661789
Train F1-mic 0.9784, Train F1-mac 0.8926
 F1-mic 0.9782,  F1-mac 0.8930
arctic25,dgl,1,1960,115.0097,0.9782

 F1-mic 0.9760,  F1-mac 0.8934
arctic25,dgl,1,1961,115.0681,0.9760

 F1-mic 0.9782,  F1-mac 0.8928
arctic25,dgl,1,1962,115.1266,0.9782

 F1-mic 0.9782,  F1-mac 0.8931
arctic25,dgl,1,1963,115.1850,0.9782

 F1-mic 0.9761,  F1-mac 0.8936
arctic25,dgl,1,1964,115.2435,0.9761

 F1-mic 0.9782,  F1-mac 0.8932
arctic25,dgl,1,1965,115.3020,0.9782

 F1-mic 0.9782,  F1-mac 0.8932
arctic25,dgl,1,1966,115.3605,0.9782

 F1-mic 0.9762,  F1-mac 0.8942
arctic25,dgl,1,1967,115.4189,0.9762

 F1-mic 0.9783,  F1-mac 0.8934
arctic25,dgl,1,1968,115.4773,0.9783

 F1-mic 0.9782,  F1-mac 0.8931
arctic25,dgl,1,1969,115.5358,0.9782

epoch:1971/50, Iteration 32/32:training loss 0.08714036643505096
Train F1-mic 0.9784, Train F1-mac 0.8931
 F1-mic 0.9760,  F1-mac 0.8944
arctic25,dgl,1,1970,115.5943,0.9760

 F1-mic 0.9783,  F1-mac 0.8936
new best val f1: 0.978305995848382
arctic25,dgl,1,1971,115.6527,0.9783

 F1-mic 0.9783,  F1-mac 0.8934
arctic25,dgl,1,1972,115.7111,0.9783

 F1-mic 0.9758,  F1-mac 0.8941
arctic25,dgl,1,1973,115.7698,0.9758

 F1-mic 0.9783,  F1-mac 0.8934
arctic25,dgl,1,1974,115.8284,0.9783

 F1-mic 0.9783,  F1-mac 0.8933
arctic25,dgl,1,1975,115.8869,0.9783

 F1-mic 0.9762,  F1-mac 0.8937
arctic25,dgl,1,1976,115.9453,0.9762

 F1-mic 0.9783,  F1-mac 0.8928
arctic25,dgl,1,1977,116.0038,0.9783

 F1-mic 0.9783,  F1-mac 0.8940
arctic25,dgl,1,1978,116.0623,0.9783

 F1-mic 0.9758,  F1-mac 0.8946
arctic25,dgl,1,1979,116.1207,0.9758

epoch:1981/50, Iteration 32/32:training loss 0.08892079442739487
Train F1-mic 0.9760, Train F1-mac 0.8950
 F1-mic 0.9783,  F1-mac 0.8936
new best val f1: 0.9783179947444836
arctic25,dgl,1,1980,116.1792,0.9783

 F1-mic 0.9783,  F1-mac 0.8929
new best val f1: 0.978329993640585
arctic25,dgl,1,1981,116.2376,0.9783

 F1-mic 0.9756,  F1-mac 0.8944
arctic25,dgl,1,1982,116.2960,0.9756

 F1-mic 0.9783,  F1-mac 0.8926
arctic25,dgl,1,1983,116.3546,0.9783

 F1-mic 0.9783,  F1-mac 0.8937
arctic25,dgl,1,1984,116.4131,0.9783

 F1-mic 0.9759,  F1-mac 0.8946
arctic25,dgl,1,1985,116.4715,0.9759

 F1-mic 0.9783,  F1-mac 0.8918
new best val f1: 0.9783479919847374
arctic25,dgl,1,1986,116.5299,0.9783

 F1-mic 0.9783,  F1-mac 0.8917
arctic25,dgl,1,1987,116.5884,0.9783

 F1-mic 0.9757,  F1-mac 0.8937
arctic25,dgl,1,1988,116.6468,0.9757

 F1-mic 0.9783,  F1-mac 0.8941
arctic25,dgl,1,1989,116.7053,0.9783

epoch:1991/50, Iteration 32/32:training loss 0.0874905213713646
Train F1-mic 0.9785, Train F1-mac 0.8931
 F1-mic 0.9783,  F1-mac 0.8944
arctic25,dgl,1,1990,116.7638,0.9783

 F1-mic 0.9761,  F1-mac 0.8950
arctic25,dgl,1,1991,116.8221,0.9761

 F1-mic 0.9784,  F1-mac 0.8937
new best val f1: 0.9783659903288897
arctic25,dgl,1,1992,116.8806,0.9784

 F1-mic 0.9783,  F1-mac 0.8923
arctic25,dgl,1,1993,116.9390,0.9783

 F1-mic 0.9763,  F1-mac 0.8923
arctic25,dgl,1,1994,116.9975,0.9763

 F1-mic 0.9784,  F1-mac 0.8934
new best val f1: 0.9783959875691436
arctic25,dgl,1,1995,117.0560,0.9784

 F1-mic 0.9783,  F1-mac 0.8940
arctic25,dgl,1,1996,117.1144,0.9783

 F1-mic 0.9764,  F1-mac 0.8952
arctic25,dgl,1,1997,117.1729,0.9764

 F1-mic 0.9784,  F1-mac 0.8925
arctic25,dgl,1,1998,117.2314,0.9784

 F1-mic 0.9784,  F1-mac 0.8929
new best val f1: 0.9784079864652452
arctic25,dgl,1,1999,117.2898,0.9784

training using time 746.9886720180511
Test F1-mic 0.9784, Test F1-mac 0.8929
Namespace(csv='full.csv', dataset='oral', gpu=0, log_dir='test', lr=0.001, n_epochs=50, n_hidden=128, online=False)
Inited proc group
15042
torch.Size([15043, 32])
15012
torch.Size([15013, 32])
15025
torch.Size([15026, 32])
15048
torch.Size([15049, 32])
14989
torch.Size([14990, 32])
15079
torch.Size([15080, 32])
15030
torch.Size([15031, 32])
14972
torch.Size([14973, 32])
15072
torch.Size([15074, 32])
15015
torch.Size([15016, 32])
15038
torch.Size([15039, 32])
Max label: tensor(24.)
----Data statistics------'
    #Nodes 1000000
    #Edges 21734972
    #Classes/Labels (multi binary labels) 32
    #Train samples 333333
    #Val samples 333333
    #Test samples 333334
Running on: 0
GCN(
  (layers): ModuleList(
    (0): GraphConv(in=32, out=128, normalization=both, activation=<function relu at 0x1510bc778c20>)
    (1): GraphConv(in=128, out=32, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0.1, inplace=False)
)
Namespace(csv='full.csv', dataset='oral', gpu=0, log_dir='test', lr=0.001, n_epochs=50, n_hidden=128, online=False)
epoch:1/50, Iteration 32/32:training loss 8.901935577392578
Train F1-mic 0.0242, Train F1-mac 0.0091
 F1-mic 0.0236,  F1-mac 0.0082
new best val f1: 0.023588952822094354
oral,dgl,1,0,0.3932,0.0236

 F1-mic 0.0767,  F1-mac 0.0171
new best val f1: 0.07670984658030684
oral,dgl,1,1,0.4655,0.0767

 F1-mic 0.2750,  F1-mac 0.0432
new best val f1: 0.2749584500830998
oral,dgl,1,2,0.5393,0.2750

 F1-mic 0.4283,  F1-mac 0.0472
new best val f1: 0.4282941434117132
oral,dgl,1,3,0.6121,0.4283

 F1-mic 0.4586,  F1-mac 0.0492
new best val f1: 0.4585760828478343
oral,dgl,1,4,0.6851,0.4586

 F1-mic 0.4652,  F1-mac 0.0524
new best val f1: 0.4652240695518609
oral,dgl,1,5,0.7581,0.4652

 F1-mic 0.4627,  F1-mac 0.0586
oral,dgl,1,6,0.8312,0.4627

 F1-mic 0.4534,  F1-mac 0.0649
oral,dgl,1,7,0.9041,0.4534

 F1-mic 0.4486,  F1-mac 0.0725
oral,dgl,1,8,0.9769,0.4486

 F1-mic 0.4433,  F1-mac 0.0810
oral,dgl,1,9,1.0500,0.4433

epoch:11/50, Iteration 32/32:training loss 2.9334511756896973
Train F1-mic 0.4429, Train F1-mac 0.0810
 F1-mic 0.4409,  F1-mac 0.0922
oral,dgl,1,10,1.1229,0.4409

 F1-mic 0.4620,  F1-mac 0.0977
oral,dgl,1,11,1.1949,0.4620

 F1-mic 0.4659,  F1-mac 0.1046
new best val f1: 0.4658960682078636
oral,dgl,1,12,1.2677,0.4659

 F1-mic 0.4235,  F1-mac 0.1020
oral,dgl,1,13,1.3408,0.4235

 F1-mic 0.4243,  F1-mac 0.0991
oral,dgl,1,14,1.4139,0.4243

 F1-mic 0.4613,  F1-mac 0.1006
oral,dgl,1,15,1.4867,0.4613

 F1-mic 0.5038,  F1-mac 0.1058
new best val f1: 0.5038009923980152
oral,dgl,1,16,1.5598,0.5038

 F1-mic 0.5418,  F1-mac 0.1177
new best val f1: 0.5418019163961673
oral,dgl,1,17,1.6328,0.5418

 F1-mic 0.5774,  F1-mac 0.1333
new best val f1: 0.5773818452363095
oral,dgl,1,18,1.7056,0.5774

 F1-mic 0.5813,  F1-mac 0.1408
new best val f1: 0.5812728374543251
oral,dgl,1,19,1.7784,0.5813

epoch:21/50, Iteration 32/32:training loss 2.0864522457122803
Train F1-mic 0.5809, Train F1-mac 0.1411
 F1-mic 0.5710,  F1-mac 0.1442
oral,dgl,1,20,1.8518,0.5710

 F1-mic 0.5806,  F1-mac 0.1492
oral,dgl,1,21,1.9239,0.5806

 F1-mic 0.6010,  F1-mac 0.1568
new best val f1: 0.6009857980284039
oral,dgl,1,22,1.9968,0.6010

 F1-mic 0.6126,  F1-mac 0.1598
new best val f1: 0.6126047747904504
oral,dgl,1,23,2.0697,0.6126

 F1-mic 0.6136,  F1-mac 0.1611
new best val f1: 0.6136217727564545
oral,dgl,1,24,2.1424,0.6136

 F1-mic 0.6183,  F1-mac 0.1653
new best val f1: 0.6183377633244733
oral,dgl,1,25,2.2151,0.6183

 F1-mic 0.6272,  F1-mac 0.1725
new best val f1: 0.6271517456965086
oral,dgl,1,26,2.2881,0.6272

 F1-mic 0.6328,  F1-mac 0.1800
new best val f1: 0.6328277343445313
oral,dgl,1,27,2.3608,0.6328

 F1-mic 0.6375,  F1-mac 0.1822
new best val f1: 0.6374747250505499
oral,dgl,1,28,2.4335,0.6375

 F1-mic 0.6487,  F1-mac 0.1853
new best val f1: 0.6486797026405947
oral,dgl,1,29,2.5065,0.6487

epoch:31/50, Iteration 32/32:training loss 1.7597516775131226
Train F1-mic 0.6487, Train F1-mac 0.1849
 F1-mic 0.6553,  F1-mac 0.1890
new best val f1: 0.6552766894466211
oral,dgl,1,30,2.5794,0.6553

 F1-mic 0.6545,  F1-mac 0.1912
oral,dgl,1,31,2.6515,0.6545

 F1-mic 0.6570,  F1-mac 0.1960
new best val f1: 0.6570346859306282
oral,dgl,1,32,2.7245,0.6570

 F1-mic 0.6660,  F1-mac 0.2049
new best val f1: 0.666016667966664
oral,dgl,1,33,2.7974,0.6660

 F1-mic 0.6755,  F1-mac 0.2129
new best val f1: 0.6755176489647021
oral,dgl,1,34,2.8700,0.6755

 F1-mic 0.6806,  F1-mac 0.2162
new best val f1: 0.6806266387467225
oral,dgl,1,35,2.9429,0.6806

 F1-mic 0.6835,  F1-mac 0.2166
new best val f1: 0.683503632992734
oral,dgl,1,36,3.0158,0.6835

 F1-mic 0.6862,  F1-mac 0.2181
new best val f1: 0.6861736276527447
oral,dgl,1,37,3.0885,0.6862

 F1-mic 0.6878,  F1-mac 0.2215
new best val f1: 0.6877756244487511
oral,dgl,1,38,3.1614,0.6878

 F1-mic 0.6895,  F1-mac 0.2265
new best val f1: 0.6894706210587579
oral,dgl,1,39,3.2341,0.6895

epoch:41/50, Iteration 32/32:training loss 1.5367435216903687
Train F1-mic 0.6892, Train F1-mac 0.2259
 F1-mic 0.6926,  F1-mac 0.2312
new best val f1: 0.6926416147167705
oral,dgl,1,40,3.3071,0.6926

 F1-mic 0.6965,  F1-mac 0.2344
new best val f1: 0.6964666070667859
oral,dgl,1,41,3.3791,0.6965

 F1-mic 0.6987,  F1-mac 0.2362
new best val f1: 0.6987256025487949
oral,dgl,1,42,3.4517,0.6987

 F1-mic 0.7019,  F1-mac 0.2405
new best val f1: 0.7018605962788075
oral,dgl,1,43,3.5246,0.7019

 F1-mic 0.7070,  F1-mac 0.2473
new best val f1: 0.7070145859708281
oral,dgl,1,44,3.5973,0.7070

 F1-mic 0.7120,  F1-mac 0.2536
new best val f1: 0.712012575974848
oral,dgl,1,45,3.6700,0.7120

 F1-mic 0.7124,  F1-mac 0.2566
new best val f1: 0.7123605752788494
oral,dgl,1,46,3.7429,0.7124

 F1-mic 0.7103,  F1-mac 0.2561
oral,dgl,1,47,3.8158,0.7103

 F1-mic 0.7136,  F1-mac 0.2584
new best val f1: 0.7135875728248542
oral,dgl,1,48,3.8887,0.7136

 F1-mic 0.7218,  F1-mac 0.2628
new best val f1: 0.7217865564268872
oral,dgl,1,49,3.9615,0.7218

epoch:51/50, Iteration 32/32:training loss 1.397247552871704
Train F1-mic 0.7215, Train F1-mac 0.2626
 F1-mic 0.7273,  F1-mac 0.2654
new best val f1: 0.7272765454469092
oral,dgl,1,50,4.0344,0.7273

 F1-mic 0.7286,  F1-mac 0.2667
new best val f1: 0.7286325427349146
oral,dgl,1,51,4.1064,0.7286

 F1-mic 0.7273,  F1-mac 0.2666
oral,dgl,1,52,4.1792,0.7273

 F1-mic 0.7297,  F1-mac 0.2700
new best val f1: 0.7296795406409187
oral,dgl,1,53,4.2519,0.7297

 F1-mic 0.7360,  F1-mac 0.2751
new best val f1: 0.7360095279809441
oral,dgl,1,54,4.3249,0.7360

 F1-mic 0.7403,  F1-mac 0.2797
new best val f1: 0.740257519484961
oral,dgl,1,55,4.3977,0.7403

 F1-mic 0.7401,  F1-mac 0.2809
oral,dgl,1,56,4.4705,0.7401

 F1-mic 0.7402,  F1-mac 0.2826
oral,dgl,1,57,4.5434,0.7402

 F1-mic 0.7431,  F1-mac 0.2853
new best val f1: 0.7430985138029724
oral,dgl,1,58,4.6163,0.7431

 F1-mic 0.7474,  F1-mac 0.2893
new best val f1: 0.7474185051629897
oral,dgl,1,59,4.6891,0.7474

epoch:61/50, Iteration 32/32:training loss 1.2951964139938354
Train F1-mic 0.7479, Train F1-mac 0.2901
 F1-mic 0.7495,  F1-mac 0.2920
new best val f1: 0.7495155009689981
oral,dgl,1,60,4.7618,0.7495

 F1-mic 0.7487,  F1-mac 0.2930
oral,dgl,1,61,4.8338,0.7487

 F1-mic 0.7499,  F1-mac 0.2947
new best val f1: 0.7499175001649997
oral,dgl,1,62,4.9065,0.7499

 F1-mic 0.7535,  F1-mac 0.2976
new best val f1: 0.753460493079014
oral,dgl,1,63,4.9791,0.7535

 F1-mic 0.7569,  F1-mac 0.3003
new best val f1: 0.7568504862990274
oral,dgl,1,64,5.0520,0.7569

 F1-mic 0.7567,  F1-mac 0.3014
oral,dgl,1,65,5.1247,0.7567

 F1-mic 0.7562,  F1-mac 0.3027
oral,dgl,1,66,5.1975,0.7562

 F1-mic 0.7579,  F1-mac 0.3053
new best val f1: 0.7579484841030318
oral,dgl,1,67,5.2705,0.7579

 F1-mic 0.7612,  F1-mac 0.3088
new best val f1: 0.7611884776230448
oral,dgl,1,68,5.3433,0.7612

 F1-mic 0.7634,  F1-mac 0.3112
new best val f1: 0.7634444731110538
oral,dgl,1,69,5.4162,0.7634

epoch:71/50, Iteration 32/32:training loss 1.2192094326019287
Train F1-mic 0.7640, Train F1-mac 0.3118
 F1-mic 0.7634,  F1-mac 0.3123
oral,dgl,1,70,5.4889,0.7634

 F1-mic 0.7637,  F1-mac 0.3139
new best val f1: 0.7637354725290549
oral,dgl,1,71,5.5609,0.7637

 F1-mic 0.7670,  F1-mac 0.3164
new best val f1: 0.7670354659290681
oral,dgl,1,72,5.6338,0.7670

 F1-mic 0.7689,  F1-mac 0.3185
new best val f1: 0.7688714622570754
oral,dgl,1,73,5.7066,0.7689

 F1-mic 0.7685,  F1-mac 0.3201
oral,dgl,1,74,5.7793,0.7685

 F1-mic 0.7691,  F1-mac 0.3222
new best val f1: 0.7690664618670763
oral,dgl,1,75,5.8521,0.7691

 F1-mic 0.7714,  F1-mac 0.3247
new best val f1: 0.7713764572470854
oral,dgl,1,76,5.9249,0.7714

 F1-mic 0.7731,  F1-mac 0.3267
new best val f1: 0.7730564538870922
oral,dgl,1,77,5.9979,0.7731

 F1-mic 0.7739,  F1-mac 0.3283
new best val f1: 0.7738874522250956
oral,dgl,1,78,6.0708,0.7739

 F1-mic 0.7744,  F1-mac 0.3295
new best val f1: 0.7744424511150978
oral,dgl,1,79,6.1435,0.7744

epoch:81/50, Iteration 32/32:training loss 1.1601152420043945
Train F1-mic 0.7749, Train F1-mac 0.3306
 F1-mic 0.7755,  F1-mac 0.3312
new best val f1: 0.7755224489551021
oral,dgl,1,80,6.2162,0.7755

 F1-mic 0.7774,  F1-mac 0.3339
new best val f1: 0.7773554452891094
oral,dgl,1,81,6.2883,0.7774

 F1-mic 0.7771,  F1-mac 0.3357
oral,dgl,1,82,6.3610,0.7771

 F1-mic 0.7772,  F1-mac 0.3374
oral,dgl,1,83,6.4339,0.7772

 F1-mic 0.7791,  F1-mac 0.3400
new best val f1: 0.7790954418091164
oral,dgl,1,84,6.5068,0.7791

 F1-mic 0.7807,  F1-mac 0.3420
new best val f1: 0.7807424385151229
oral,dgl,1,85,6.5794,0.7807

 F1-mic 0.7808,  F1-mac 0.3430
new best val f1: 0.7808174383651233
oral,dgl,1,86,6.6521,0.7808

 F1-mic 0.7806,  F1-mac 0.3439
oral,dgl,1,87,6.7252,0.7806

 F1-mic 0.7826,  F1-mac 0.3465
new best val f1: 0.7826474347051305
oral,dgl,1,88,6.7981,0.7826

 F1-mic 0.7840,  F1-mac 0.3485
new best val f1: 0.7839824320351358
oral,dgl,1,89,6.8709,0.7840

epoch:91/50, Iteration 32/32:training loss 1.1127574443817139
Train F1-mic 0.7844, Train F1-mac 0.3493
 F1-mic 0.7831,  F1-mac 0.3490
oral,dgl,1,90,6.9437,0.7831

 F1-mic 0.7836,  F1-mac 0.3510
oral,dgl,1,91,7.0158,0.7836

 F1-mic 0.7859,  F1-mac 0.3537
new best val f1: 0.7858934282131436
oral,dgl,1,92,7.0885,0.7859

 F1-mic 0.7860,  F1-mac 0.3552
new best val f1: 0.7859564280871438
oral,dgl,1,93,7.1614,0.7860

 F1-mic 0.7851,  F1-mac 0.3561
oral,dgl,1,94,7.2343,0.7851

 F1-mic 0.7865,  F1-mac 0.3578
new best val f1: 0.7865474269051462
oral,dgl,1,95,7.3070,0.7865

 F1-mic 0.7880,  F1-mac 0.3590
new best val f1: 0.7880204239591521
oral,dgl,1,96,7.3800,0.7880

 F1-mic 0.7877,  F1-mac 0.3601
oral,dgl,1,97,7.4529,0.7877

 F1-mic 0.7875,  F1-mac 0.3612
oral,dgl,1,98,7.5257,0.7875

 F1-mic 0.7892,  F1-mac 0.3636
new best val f1: 0.7891814216371568
oral,dgl,1,99,7.5987,0.7892

epoch:101/50, Iteration 32/32:training loss 1.0728886127471924
Train F1-mic 0.7897, Train F1-mac 0.3644
 F1-mic 0.7898,  F1-mac 0.3649
new best val f1: 0.7898264203471592
oral,dgl,1,100,7.6714,0.7898

 F1-mic 0.7888,  F1-mac 0.3652
oral,dgl,1,101,7.7435,0.7888

 F1-mic 0.7899,  F1-mac 0.3673
new best val f1: 0.7899224201551597
oral,dgl,1,102,7.8162,0.7899

 F1-mic 0.7913,  F1-mac 0.3690
new best val f1: 0.7913264173471654
oral,dgl,1,103,7.8889,0.7913

 F1-mic 0.7909,  F1-mac 0.3700
oral,dgl,1,104,7.9616,0.7909

 F1-mic 0.7914,  F1-mac 0.3710
new best val f1: 0.7913864172271655
oral,dgl,1,105,8.0347,0.7914

 F1-mic 0.7922,  F1-mac 0.3728
new best val f1: 0.7922114155771689
oral,dgl,1,106,8.1076,0.7922

 F1-mic 0.7926,  F1-mac 0.3740
new best val f1: 0.7926224147551704
oral,dgl,1,107,8.1804,0.7926

 F1-mic 0.7932,  F1-mac 0.3758
new best val f1: 0.7931504136991725
oral,dgl,1,108,8.2533,0.7932

 F1-mic 0.7934,  F1-mac 0.3764
new best val f1: 0.7933844132311736
oral,dgl,1,109,8.3263,0.7934

epoch:111/50, Iteration 32/32:training loss 1.039229154586792
Train F1-mic 0.7940, Train F1-mac 0.3769
 F1-mic 0.7937,  F1-mac 0.3768
new best val f1: 0.793747412505175
oral,dgl,1,110,8.3991,0.7937

 F1-mic 0.7948,  F1-mac 0.3784
new best val f1: 0.794773410453179
oral,dgl,1,111,8.4712,0.7948

 F1-mic 0.7951,  F1-mac 0.3800
new best val f1: 0.7951454097091806
oral,dgl,1,112,8.5439,0.7951

 F1-mic 0.7951,  F1-mac 0.3809
oral,dgl,1,113,8.6169,0.7951

 F1-mic 0.7959,  F1-mac 0.3830
new best val f1: 0.7959044081911836
oral,dgl,1,114,8.6899,0.7959

 F1-mic 0.7964,  F1-mac 0.3841
new best val f1: 0.7964204071591857
oral,dgl,1,115,8.7628,0.7964

 F1-mic 0.7966,  F1-mac 0.3850
new best val f1: 0.7966184067631865
oral,dgl,1,116,8.8358,0.7966

 F1-mic 0.7969,  F1-mac 0.3858
new best val f1: 0.7969154061691877
oral,dgl,1,117,8.9090,0.7969

 F1-mic 0.7979,  F1-mac 0.3872
new best val f1: 0.7979084041831916
oral,dgl,1,118,8.9818,0.7979

 F1-mic 0.7977,  F1-mac 0.3875
oral,dgl,1,119,9.0545,0.7977

epoch:121/50, Iteration 32/32:training loss 1.0105605125427246
Train F1-mic 0.7984, Train F1-mac 0.3887
 F1-mic 0.7982,  F1-mac 0.3885
new best val f1: 0.7982294035411929
oral,dgl,1,120,9.1272,0.7982

 F1-mic 0.7988,  F1-mac 0.3902
new best val f1: 0.7988294023411954
oral,dgl,1,121,9.1993,0.7988

 F1-mic 0.7987,  F1-mac 0.3912
oral,dgl,1,122,9.2721,0.7987

 F1-mic 0.7996,  F1-mac 0.3928
new best val f1: 0.7996454007091984
oral,dgl,1,123,9.3450,0.7996

 F1-mic 0.7998,  F1-mac 0.3932
new best val f1: 0.799756400487199
oral,dgl,1,124,9.4177,0.7998

 F1-mic 0.7999,  F1-mac 0.3946
new best val f1: 0.7999484001031998
oral,dgl,1,125,9.4906,0.7999

 F1-mic 0.8006,  F1-mac 0.3965
new best val f1: 0.8005993988012023
oral,dgl,1,126,9.5634,0.8006

 F1-mic 0.8010,  F1-mac 0.3977
new best val f1: 0.801010397979204
oral,dgl,1,127,9.6362,0.8010

 F1-mic 0.8004,  F1-mac 0.3977
oral,dgl,1,128,9.7091,0.8004

 F1-mic 0.8015,  F1-mac 0.3991
new best val f1: 0.8015413969172062
oral,dgl,1,129,9.7821,0.8015

epoch:131/50, Iteration 32/32:training loss 0.9855063557624817
Train F1-mic 0.8023, Train F1-mac 0.4005
 F1-mic 0.8021,  F1-mac 0.4005
new best val f1: 0.8020723958552083
oral,dgl,1,130,9.8548,0.8021

 F1-mic 0.8020,  F1-mac 0.4008
oral,dgl,1,131,9.9269,0.8020

 F1-mic 0.8026,  F1-mac 0.4015
new best val f1: 0.8025943948112104
oral,dgl,1,132,10.0001,0.8026

 F1-mic 0.8036,  F1-mac 0.4030
new best val f1: 0.8036053927892144
oral,dgl,1,133,10.0730,0.8036

 F1-mic 0.8029,  F1-mac 0.4034
oral,dgl,1,134,10.1458,0.8029

 F1-mic 0.8041,  F1-mac 0.4059
new best val f1: 0.8040703918592162
oral,dgl,1,135,10.2186,0.8041

 F1-mic 0.8037,  F1-mac 0.4070
oral,dgl,1,136,10.2914,0.8037

 F1-mic 0.8044,  F1-mac 0.4081
new best val f1: 0.8043853912292176
oral,dgl,1,137,10.3641,0.8044

 F1-mic 0.8049,  F1-mac 0.4090
new best val f1: 0.8049133901732196
oral,dgl,1,138,10.4369,0.8049

 F1-mic 0.8052,  F1-mac 0.4094
new best val f1: 0.8051503896992206
oral,dgl,1,139,10.5098,0.8052

epoch:141/50, Iteration 32/32:training loss 0.9634661078453064
Train F1-mic 0.8059, Train F1-mac 0.4115
 F1-mic 0.8051,  F1-mac 0.4095
oral,dgl,1,140,10.5828,0.8051

 F1-mic 0.8060,  F1-mac 0.4113
new best val f1: 0.8059633880732239
oral,dgl,1,141,10.6551,0.8060

 F1-mic 0.8057,  F1-mac 0.4121
oral,dgl,1,142,10.7278,0.8057

 F1-mic 0.8061,  F1-mac 0.4130
new best val f1: 0.8061433877132246
oral,dgl,1,143,10.8007,0.8061

 F1-mic 0.8067,  F1-mac 0.4144
new best val f1: 0.8067043865912268
oral,dgl,1,144,10.8736,0.8067

 F1-mic 0.8063,  F1-mac 0.4156
oral,dgl,1,145,10.9466,0.8063

 F1-mic 0.8073,  F1-mac 0.4172
new best val f1: 0.8073043853912292
oral,dgl,1,146,11.0199,0.8073

 F1-mic 0.8069,  F1-mac 0.4174
oral,dgl,1,147,11.0927,0.8069

 F1-mic 0.8078,  F1-mac 0.4187
new best val f1: 0.807769384461231
oral,dgl,1,148,11.1654,0.8078

 F1-mic 0.8076,  F1-mac 0.4194
oral,dgl,1,149,11.2382,0.8076

epoch:151/50, Iteration 32/32:training loss 0.9439694881439209
Train F1-mic 0.8082, Train F1-mac 0.4214
 F1-mic 0.8080,  F1-mac 0.4206
new best val f1: 0.808027383945232
oral,dgl,1,150,11.3112,0.8080

 F1-mic 0.8083,  F1-mac 0.4214
new best val f1: 0.8083303833392333
oral,dgl,1,151,11.3832,0.8083

 F1-mic 0.8082,  F1-mac 0.4221
oral,dgl,1,152,11.4561,0.8082

 F1-mic 0.8091,  F1-mac 0.4239
new best val f1: 0.8091343817312365
oral,dgl,1,153,11.5288,0.8091

 F1-mic 0.8087,  F1-mac 0.4237
oral,dgl,1,154,11.6015,0.8087

 F1-mic 0.8094,  F1-mac 0.4252
new best val f1: 0.8094013811972376
oral,dgl,1,155,11.6743,0.8094

 F1-mic 0.8098,  F1-mac 0.4261
new best val f1: 0.8098153803692393
oral,dgl,1,156,11.7476,0.8098

 F1-mic 0.8087,  F1-mac 0.4255
oral,dgl,1,157,11.8205,0.8087

 F1-mic 0.8105,  F1-mac 0.4277
new best val f1: 0.8105413789172423
oral,dgl,1,158,11.8933,0.8105

 F1-mic 0.8095,  F1-mac 0.4273
oral,dgl,1,159,11.9662,0.8095

epoch:161/50, Iteration 32/32:training loss 0.926359236240387
Train F1-mic 0.8099, Train F1-mac 0.4291
 F1-mic 0.8097,  F1-mac 0.4279
oral,dgl,1,160,12.0390,0.8097

 F1-mic 0.8110,  F1-mac 0.4298
new best val f1: 0.810994378011244
oral,dgl,1,161,12.1110,0.8110

 F1-mic 0.8092,  F1-mac 0.4286
oral,dgl,1,162,12.1840,0.8092

 F1-mic 0.8115,  F1-mac 0.4315
new best val f1: 0.8114503770992458
oral,dgl,1,163,12.2567,0.8115

 F1-mic 0.8104,  F1-mac 0.4311
oral,dgl,1,164,12.3295,0.8104

 F1-mic 0.8109,  F1-mac 0.4322
oral,dgl,1,165,12.4023,0.8109

 F1-mic 0.8111,  F1-mac 0.4329
oral,dgl,1,166,12.4752,0.8111

 F1-mic 0.8111,  F1-mac 0.4335
oral,dgl,1,167,12.5481,0.8111

 F1-mic 0.8120,  F1-mac 0.4353
new best val f1: 0.811984376031248
oral,dgl,1,168,12.6208,0.8120

 F1-mic 0.8111,  F1-mac 0.4349
oral,dgl,1,169,12.6935,0.8111

epoch:171/50, Iteration 32/32:training loss 0.9102575778961182
Train F1-mic 0.8116, Train F1-mac 0.4366
 F1-mic 0.8123,  F1-mac 0.4367
new best val f1: 0.8123323753352494
oral,dgl,1,170,12.7663,0.8123

 F1-mic 0.8120,  F1-mac 0.4370
oral,dgl,1,171,12.8385,0.8120

 F1-mic 0.8118,  F1-mac 0.4371
oral,dgl,1,172,12.9111,0.8118

 F1-mic 0.8132,  F1-mac 0.4393
new best val f1: 0.8131753736492527
oral,dgl,1,173,12.9841,0.8132

 F1-mic 0.8116,  F1-mac 0.4381
oral,dgl,1,174,13.0570,0.8116

 F1-mic 0.8136,  F1-mac 0.4407
new best val f1: 0.8136343727312545
oral,dgl,1,175,13.1298,0.8136

 F1-mic 0.8122,  F1-mac 0.4402
oral,dgl,1,176,13.2025,0.8122

 F1-mic 0.8135,  F1-mac 0.4415
oral,dgl,1,177,13.2753,0.8135

 F1-mic 0.8132,  F1-mac 0.4415
oral,dgl,1,178,13.3481,0.8132

 F1-mic 0.8130,  F1-mac 0.4422
oral,dgl,1,179,13.4208,0.8130

epoch:181/50, Iteration 32/32:training loss 0.8952437043190002
Train F1-mic 0.8135, Train F1-mac 0.4443
 F1-mic 0.8137,  F1-mac 0.4429
new best val f1: 0.8137423725152549
oral,dgl,1,180,13.4937,0.8137

 F1-mic 0.8132,  F1-mac 0.4429
oral,dgl,1,181,13.5657,0.8132

 F1-mic 0.8139,  F1-mac 0.4441
new best val f1: 0.8139253721492558
oral,dgl,1,182,13.6387,0.8139

 F1-mic 0.8137,  F1-mac 0.4440
oral,dgl,1,183,13.7114,0.8137

 F1-mic 0.8138,  F1-mac 0.4446
oral,dgl,1,184,13.7844,0.8138

 F1-mic 0.8143,  F1-mac 0.4458
new best val f1: 0.8142583714832571
oral,dgl,1,185,13.8572,0.8143

 F1-mic 0.8138,  F1-mac 0.4456
oral,dgl,1,186,13.9302,0.8138

 F1-mic 0.8149,  F1-mac 0.4478
new best val f1: 0.8149273701452597
oral,dgl,1,187,14.0031,0.8149

 F1-mic 0.8138,  F1-mac 0.4465
oral,dgl,1,188,14.0759,0.8138

 F1-mic 0.8157,  F1-mac 0.4491
new best val f1: 0.8157313685372629
oral,dgl,1,189,14.1488,0.8157

epoch:191/50, Iteration 32/32:training loss 0.8812717795372009
Train F1-mic 0.8162, Train F1-mac 0.4524
 F1-mic 0.8134,  F1-mac 0.4471
oral,dgl,1,190,14.2216,0.8134

 F1-mic 0.8162,  F1-mac 0.4508
new best val f1: 0.8161843676312648
oral,dgl,1,191,14.2939,0.8162

 F1-mic 0.8134,  F1-mac 0.4476
oral,dgl,1,192,14.3666,0.8134

 F1-mic 0.8170,  F1-mac 0.4520
new best val f1: 0.816994366011268
oral,dgl,1,193,14.4395,0.8170

 F1-mic 0.8135,  F1-mac 0.4487
oral,dgl,1,194,14.5126,0.8135

 F1-mic 0.8169,  F1-mac 0.4534
oral,dgl,1,195,14.5864,0.8169

 F1-mic 0.8147,  F1-mac 0.4511
oral,dgl,1,196,14.6592,0.8147

 F1-mic 0.8160,  F1-mac 0.4534
oral,dgl,1,197,14.7319,0.8160

 F1-mic 0.8162,  F1-mac 0.4537
oral,dgl,1,198,14.8048,0.8162

 F1-mic 0.8154,  F1-mac 0.4532
oral,dgl,1,199,14.8776,0.8154

epoch:201/50, Iteration 32/32:training loss 0.8681313991546631
Train F1-mic 0.8160, Train F1-mac 0.4563
 F1-mic 0.8169,  F1-mac 0.4562
oral,dgl,1,200,14.9505,0.8169

 F1-mic 0.8153,  F1-mac 0.4544
oral,dgl,1,201,15.0227,0.8153

 F1-mic 0.8172,  F1-mac 0.4569
new best val f1: 0.8171503656992686
oral,dgl,1,202,15.0955,0.8172

 F1-mic 0.8157,  F1-mac 0.4559
oral,dgl,1,203,15.1681,0.8157

 F1-mic 0.8170,  F1-mac 0.4586
oral,dgl,1,204,15.2408,0.8170

 F1-mic 0.8162,  F1-mac 0.4578
oral,dgl,1,205,15.3136,0.8162

 F1-mic 0.8168,  F1-mac 0.4589
oral,dgl,1,206,15.3864,0.8168

 F1-mic 0.8168,  F1-mac 0.4597
oral,dgl,1,207,15.4593,0.8168

 F1-mic 0.8167,  F1-mac 0.4597
oral,dgl,1,208,15.5320,0.8167

 F1-mic 0.8171,  F1-mac 0.4603
oral,dgl,1,209,15.6047,0.8171

epoch:211/50, Iteration 32/32:training loss 0.8557347655296326
Train F1-mic 0.8179, Train F1-mac 0.4633
 F1-mic 0.8172,  F1-mac 0.4609
new best val f1: 0.8171743656512686
oral,dgl,1,210,15.6774,0.8172

 F1-mic 0.8170,  F1-mac 0.4614
oral,dgl,1,211,15.7494,0.8170

 F1-mic 0.8178,  F1-mac 0.4624
new best val f1: 0.8178373643252713
oral,dgl,1,212,15.8222,0.8178

 F1-mic 0.8166,  F1-mac 0.4612
oral,dgl,1,213,15.8952,0.8166

 F1-mic 0.8189,  F1-mac 0.4644
new best val f1: 0.8188753622492755
oral,dgl,1,214,15.9679,0.8189

 F1-mic 0.8155,  F1-mac 0.4618
oral,dgl,1,215,16.0407,0.8155

 F1-mic 0.8205,  F1-mac 0.4677
new best val f1: 0.820489359021282
oral,dgl,1,216,16.1134,0.8205

 F1-mic 0.8126,  F1-mac 0.4590
oral,dgl,1,217,16.1866,0.8126

 F1-mic 0.8219,  F1-mac 0.4708
new best val f1: 0.8218513562972874
oral,dgl,1,218,16.2596,0.8219

 F1-mic 0.8140,  F1-mac 0.4615
oral,dgl,1,219,16.3326,0.8140

epoch:221/50, Iteration 32/32:training loss 0.8456745147705078
Train F1-mic 0.8147, Train F1-mac 0.4638
 F1-mic 0.8191,  F1-mac 0.4675
oral,dgl,1,220,16.4055,0.8191

 F1-mic 0.8203,  F1-mac 0.4694
oral,dgl,1,221,16.4775,0.8203

 F1-mic 0.8143,  F1-mac 0.4630
oral,dgl,1,222,16.5503,0.8143

 F1-mic 0.8209,  F1-mac 0.4704
oral,dgl,1,223,16.6232,0.8209

 F1-mic 0.8184,  F1-mac 0.4683
oral,dgl,1,224,16.6960,0.8184

 F1-mic 0.8166,  F1-mac 0.4664
oral,dgl,1,225,16.7688,0.8166

 F1-mic 0.8214,  F1-mac 0.4717
oral,dgl,1,226,16.8418,0.8214

 F1-mic 0.8168,  F1-mac 0.4674
oral,dgl,1,227,16.9149,0.8168

 F1-mic 0.8188,  F1-mac 0.4699
oral,dgl,1,228,16.9876,0.8188

 F1-mic 0.8208,  F1-mac 0.4718
oral,dgl,1,229,17.0604,0.8208

epoch:231/50, Iteration 32/32:training loss 0.8342652320861816
Train F1-mic 0.8213, Train F1-mac 0.4748
 F1-mic 0.8162,  F1-mac 0.4672
oral,dgl,1,230,17.1331,0.8162

 F1-mic 0.8207,  F1-mac 0.4723
oral,dgl,1,231,17.2053,0.8207

 F1-mic 0.8198,  F1-mac 0.4711
oral,dgl,1,232,17.2783,0.8198

 F1-mic 0.8171,  F1-mac 0.4685
oral,dgl,1,233,17.3510,0.8171

 F1-mic 0.8214,  F1-mac 0.4741
oral,dgl,1,234,17.4238,0.8214

 F1-mic 0.8182,  F1-mac 0.4704
oral,dgl,1,235,17.4966,0.8182

 F1-mic 0.8190,  F1-mac 0.4711
oral,dgl,1,236,17.5695,0.8190

 F1-mic 0.8212,  F1-mac 0.4735
oral,dgl,1,237,17.6424,0.8212

 F1-mic 0.8179,  F1-mac 0.4706
oral,dgl,1,238,17.7155,0.8179

 F1-mic 0.8201,  F1-mac 0.4733
oral,dgl,1,239,17.7885,0.8201

epoch:241/50, Iteration 32/32:training loss 0.8237355351448059
Train F1-mic 0.8207, Train F1-mac 0.4768
 F1-mic 0.8205,  F1-mac 0.4738
oral,dgl,1,240,17.8613,0.8205

 F1-mic 0.8185,  F1-mac 0.4713
oral,dgl,1,241,17.9333,0.8185

 F1-mic 0.8208,  F1-mac 0.4740
oral,dgl,1,242,18.0060,0.8208

 F1-mic 0.8197,  F1-mac 0.4730
oral,dgl,1,243,18.0787,0.8197

 F1-mic 0.8194,  F1-mac 0.4725
oral,dgl,1,244,18.1515,0.8194

 F1-mic 0.8212,  F1-mac 0.4747
oral,dgl,1,245,18.2242,0.8212

 F1-mic 0.8190,  F1-mac 0.4726
oral,dgl,1,246,18.2972,0.8190

 F1-mic 0.8207,  F1-mac 0.4750
oral,dgl,1,247,18.3699,0.8207

 F1-mic 0.8206,  F1-mac 0.4753
oral,dgl,1,248,18.4427,0.8206

 F1-mic 0.8196,  F1-mac 0.4745
oral,dgl,1,249,18.5156,0.8196

epoch:251/50, Iteration 32/32:training loss 0.8143130540847778
Train F1-mic 0.8201, Train F1-mac 0.4781
 F1-mic 0.8211,  F1-mac 0.4764
oral,dgl,1,250,18.5884,0.8211

 F1-mic 0.8199,  F1-mac 0.4747
oral,dgl,1,251,18.6603,0.8199

 F1-mic 0.8206,  F1-mac 0.4772
oral,dgl,1,252,18.7331,0.8206

 F1-mic 0.8206,  F1-mac 0.4769
oral,dgl,1,253,18.8060,0.8206

 F1-mic 0.8202,  F1-mac 0.4763
oral,dgl,1,254,18.8790,0.8202

 F1-mic 0.8209,  F1-mac 0.4779
oral,dgl,1,255,18.9519,0.8209

 F1-mic 0.8204,  F1-mac 0.4773
oral,dgl,1,256,19.0246,0.8204

 F1-mic 0.8208,  F1-mac 0.4781
oral,dgl,1,257,19.0974,0.8208

 F1-mic 0.8209,  F1-mac 0.4786
oral,dgl,1,258,19.1701,0.8209

 F1-mic 0.8203,  F1-mac 0.4780
oral,dgl,1,259,19.2428,0.8203

epoch:261/50, Iteration 32/32:training loss 0.805324375629425
Train F1-mic 0.8207, Train F1-mac 0.4809
 F1-mic 0.8216,  F1-mac 0.4796
oral,dgl,1,260,19.3155,0.8216

 F1-mic 0.8198,  F1-mac 0.4781
oral,dgl,1,261,19.3875,0.8198

 F1-mic 0.8218,  F1-mac 0.4811
oral,dgl,1,262,19.4605,0.8218

 F1-mic 0.8203,  F1-mac 0.4787
oral,dgl,1,263,19.5333,0.8203

 F1-mic 0.8213,  F1-mac 0.4805
oral,dgl,1,264,19.6061,0.8213

 F1-mic 0.8214,  F1-mac 0.4806
oral,dgl,1,265,19.6789,0.8214

 F1-mic 0.8203,  F1-mac 0.4798
oral,dgl,1,266,19.7517,0.8203

 F1-mic 0.8221,  F1-mac 0.4826
new best val f1: 0.8221063557872884
oral,dgl,1,267,19.8245,0.8221

 F1-mic 0.8201,  F1-mac 0.4796
oral,dgl,1,268,19.8975,0.8201

 F1-mic 0.8222,  F1-mac 0.4829
new best val f1: 0.8222443555112889
oral,dgl,1,269,19.9704,0.8222

epoch:271/50, Iteration 32/32:training loss 0.7968360781669617
Train F1-mic 0.8225, Train F1-mac 0.4852
 F1-mic 0.8204,  F1-mac 0.4812
oral,dgl,1,270,20.0432,0.8204

 F1-mic 0.8219,  F1-mac 0.4833
oral,dgl,1,271,20.1153,0.8219

 F1-mic 0.8212,  F1-mac 0.4817
oral,dgl,1,272,20.1881,0.8212

 F1-mic 0.8212,  F1-mac 0.4823
oral,dgl,1,273,20.2608,0.8212

 F1-mic 0.8220,  F1-mac 0.4835
oral,dgl,1,274,20.3336,0.8220

 F1-mic 0.8205,  F1-mac 0.4816
oral,dgl,1,275,20.4065,0.8205

 F1-mic 0.8226,  F1-mac 0.4855
new best val f1: 0.8226133547732905
oral,dgl,1,276,20.4793,0.8226

 F1-mic 0.8197,  F1-mac 0.4816
oral,dgl,1,277,20.5520,0.8197

 F1-mic 0.8232,  F1-mac 0.4871
new best val f1: 0.8232373535252929
oral,dgl,1,278,20.6248,0.8232

 F1-mic 0.8196,  F1-mac 0.4818
oral,dgl,1,279,20.6975,0.8196

epoch:281/50, Iteration 32/32:training loss 0.7890616059303284
Train F1-mic 0.8201, Train F1-mac 0.4838
 F1-mic 0.8231,  F1-mac 0.4874
oral,dgl,1,280,20.7701,0.8231

 F1-mic 0.8201,  F1-mac 0.4818
oral,dgl,1,281,20.8422,0.8201

 F1-mic 0.8229,  F1-mac 0.4874
oral,dgl,1,282,20.9148,0.8229

 F1-mic 0.8207,  F1-mac 0.4841
oral,dgl,1,283,20.9875,0.8207

 F1-mic 0.8222,  F1-mac 0.4863
oral,dgl,1,284,21.0602,0.8222

 F1-mic 0.8219,  F1-mac 0.4865
oral,dgl,1,285,21.1330,0.8219

 F1-mic 0.8211,  F1-mac 0.4852
oral,dgl,1,286,21.2056,0.8211

 F1-mic 0.8229,  F1-mac 0.4879
oral,dgl,1,287,21.2785,0.8229

 F1-mic 0.8202,  F1-mac 0.4836
oral,dgl,1,288,21.3514,0.8202

 F1-mic 0.8232,  F1-mac 0.4894
oral,dgl,1,289,21.4241,0.8232

epoch:291/50, Iteration 32/32:training loss 0.781316339969635
Train F1-mic 0.8236, Train F1-mac 0.4911
 F1-mic 0.8202,  F1-mac 0.4831
oral,dgl,1,290,21.4969,0.8202

 F1-mic 0.8233,  F1-mac 0.4895
new best val f1: 0.8233153533692933
oral,dgl,1,291,21.5690,0.8233

 F1-mic 0.8199,  F1-mac 0.4843
oral,dgl,1,292,21.6417,0.8199

 F1-mic 0.8234,  F1-mac 0.4891
new best val f1: 0.8233633532732935
oral,dgl,1,293,21.7146,0.8234

 F1-mic 0.8209,  F1-mac 0.4857
oral,dgl,1,294,21.7874,0.8209

 F1-mic 0.8222,  F1-mac 0.4889
oral,dgl,1,295,21.8601,0.8222

 F1-mic 0.8218,  F1-mac 0.4872
oral,dgl,1,296,21.9328,0.8218

 F1-mic 0.8220,  F1-mac 0.4880
oral,dgl,1,297,22.0055,0.8220

 F1-mic 0.8219,  F1-mac 0.4890
oral,dgl,1,298,22.0784,0.8219

 F1-mic 0.8217,  F1-mac 0.4872
oral,dgl,1,299,22.1510,0.8217

epoch:301/50, Iteration 32/32:training loss 0.7734667658805847
Train F1-mic 0.8222, Train F1-mac 0.4894
 F1-mic 0.8229,  F1-mac 0.4900
oral,dgl,1,300,22.2237,0.8229

 F1-mic 0.8203,  F1-mac 0.4867
oral,dgl,1,301,22.2959,0.8203

 F1-mic 0.8236,  F1-mac 0.4917
new best val f1: 0.8235793528412944
oral,dgl,1,302,22.3685,0.8236

 F1-mic 0.8195,  F1-mac 0.4839
oral,dgl,1,303,22.4415,0.8195

 F1-mic 0.8247,  F1-mac 0.4942
new best val f1: 0.8246863506272988
oral,dgl,1,304,22.5142,0.8247

 F1-mic 0.8181,  F1-mac 0.4830
oral,dgl,1,305,22.5868,0.8181

 F1-mic 0.8251,  F1-mac 0.4948
new best val f1: 0.8250583498833002
oral,dgl,1,306,22.6597,0.8251

 F1-mic 0.8189,  F1-mac 0.4844
oral,dgl,1,307,22.7324,0.8189

 F1-mic 0.8235,  F1-mac 0.4926
oral,dgl,1,308,22.8053,0.8235

 F1-mic 0.8224,  F1-mac 0.4905
oral,dgl,1,309,22.8779,0.8224

epoch:311/50, Iteration 32/32:training loss 0.7665196657180786
Train F1-mic 0.8228, Train F1-mac 0.4923
 F1-mic 0.8208,  F1-mac 0.4887
oral,dgl,1,310,22.9508,0.8208

 F1-mic 0.8240,  F1-mac 0.4942
oral,dgl,1,311,23.0231,0.8240

 F1-mic 0.8199,  F1-mac 0.4863
oral,dgl,1,312,23.0961,0.8199

 F1-mic 0.8240,  F1-mac 0.4942
oral,dgl,1,313,23.1688,0.8240

 F1-mic 0.8210,  F1-mac 0.4900
oral,dgl,1,314,23.2417,0.8210

 F1-mic 0.8223,  F1-mac 0.4915
oral,dgl,1,315,23.3144,0.8223

 F1-mic 0.8238,  F1-mac 0.4943
oral,dgl,1,316,23.3874,0.8238

 F1-mic 0.8201,  F1-mac 0.4888
oral,dgl,1,317,23.4601,0.8201

 F1-mic 0.8243,  F1-mac 0.4962
oral,dgl,1,318,23.5330,0.8243

 F1-mic 0.8204,  F1-mac 0.4890
oral,dgl,1,319,23.6058,0.8204

epoch:321/50, Iteration 32/32:training loss 0.7608112692832947
Train F1-mic 0.8210, Train F1-mac 0.4909
 F1-mic 0.8236,  F1-mac 0.4955
oral,dgl,1,320,23.6784,0.8236

 F1-mic 0.8223,  F1-mac 0.4927
oral,dgl,1,321,23.7505,0.8223

 F1-mic 0.8218,  F1-mac 0.4911
oral,dgl,1,322,23.8232,0.8218

 F1-mic 0.8238,  F1-mac 0.4965
oral,dgl,1,323,23.8959,0.8238

 F1-mic 0.8206,  F1-mac 0.4906
oral,dgl,1,324,23.9685,0.8206

 F1-mic 0.8242,  F1-mac 0.4964
oral,dgl,1,325,24.0414,0.8242

 F1-mic 0.8213,  F1-mac 0.4916
oral,dgl,1,326,24.1144,0.8213

 F1-mic 0.8232,  F1-mac 0.4947
oral,dgl,1,327,24.1874,0.8232

 F1-mic 0.8227,  F1-mac 0.4942
oral,dgl,1,328,24.2600,0.8227

 F1-mic 0.8222,  F1-mac 0.4936
oral,dgl,1,329,24.3326,0.8222

epoch:331/50, Iteration 32/32:training loss 0.7537724375724792
Train F1-mic 0.8228, Train F1-mac 0.4958
 F1-mic 0.8232,  F1-mac 0.4953
oral,dgl,1,330,24.4053,0.8232

 F1-mic 0.8223,  F1-mac 0.4931
oral,dgl,1,331,24.4774,0.8223

 F1-mic 0.8231,  F1-mac 0.4956
oral,dgl,1,332,24.5505,0.8231

 F1-mic 0.8226,  F1-mac 0.4945
oral,dgl,1,333,24.6232,0.8226

 F1-mic 0.8227,  F1-mac 0.4950
oral,dgl,1,334,24.6959,0.8227

 F1-mic 0.8233,  F1-mac 0.4960
oral,dgl,1,335,24.7688,0.8233

 F1-mic 0.8219,  F1-mac 0.4941
oral,dgl,1,336,24.8416,0.8219

 F1-mic 0.8237,  F1-mac 0.4972
oral,dgl,1,337,24.9143,0.8237

 F1-mic 0.8221,  F1-mac 0.4943
oral,dgl,1,338,24.9873,0.8221

 F1-mic 0.8234,  F1-mac 0.4969
oral,dgl,1,339,25.0602,0.8234

epoch:341/50, Iteration 32/32:training loss 0.7477999925613403
Train F1-mic 0.8239, Train F1-mac 0.4990
 F1-mic 0.8227,  F1-mac 0.4956
oral,dgl,1,340,25.1330,0.8227

 F1-mic 0.8229,  F1-mac 0.4963
oral,dgl,1,341,25.2051,0.8229

 F1-mic 0.8232,  F1-mac 0.4966
oral,dgl,1,342,25.2778,0.8232

 F1-mic 0.8225,  F1-mac 0.4954
oral,dgl,1,343,25.3505,0.8225

 F1-mic 0.8236,  F1-mac 0.4983
oral,dgl,1,344,25.4232,0.8236

 F1-mic 0.8219,  F1-mac 0.4946
oral,dgl,1,345,25.4959,0.8219

 F1-mic 0.8244,  F1-mac 0.4993
oral,dgl,1,346,25.5687,0.8244

 F1-mic 0.8212,  F1-mac 0.4939
oral,dgl,1,347,25.6416,0.8212

 F1-mic 0.8245,  F1-mac 0.5004
oral,dgl,1,348,25.7143,0.8245

 F1-mic 0.8211,  F1-mac 0.4926
oral,dgl,1,349,25.7870,0.8211

epoch:351/50, Iteration 32/32:training loss 0.7428932785987854
Train F1-mic 0.8215, Train F1-mac 0.4942
 F1-mic 0.8249,  F1-mac 0.5013
oral,dgl,1,350,25.8598,0.8249

 F1-mic 0.8205,  F1-mac 0.4925
oral,dgl,1,351,25.9319,0.8205

 F1-mic 0.8251,  F1-mac 0.5005
new best val f1: 0.8250613498773003
oral,dgl,1,352,26.0046,0.8251

 F1-mic 0.8211,  F1-mac 0.4937
oral,dgl,1,353,26.0774,0.8211

 F1-mic 0.8243,  F1-mac 0.4992
oral,dgl,1,354,26.1502,0.8243

 F1-mic 0.8224,  F1-mac 0.4958
oral,dgl,1,355,26.2231,0.8224

 F1-mic 0.8232,  F1-mac 0.4974
oral,dgl,1,356,26.2959,0.8232

 F1-mic 0.8237,  F1-mac 0.4976
oral,dgl,1,357,26.3688,0.8237

 F1-mic 0.8220,  F1-mac 0.4954
oral,dgl,1,358,26.4417,0.8220

 F1-mic 0.8244,  F1-mac 0.4996
oral,dgl,1,359,26.5144,0.8244

epoch:361/50, Iteration 32/32:training loss 0.7367251515388489
Train F1-mic 0.8249, Train F1-mac 0.5028
 F1-mic 0.8215,  F1-mac 0.4943
oral,dgl,1,360,26.5873,0.8215

 F1-mic 0.8247,  F1-mac 0.5011
oral,dgl,1,361,26.6593,0.8247

 F1-mic 0.8213,  F1-mac 0.4949
oral,dgl,1,362,26.7321,0.8213

 F1-mic 0.8247,  F1-mac 0.5013
oral,dgl,1,363,26.8050,0.8247

 F1-mic 0.8213,  F1-mac 0.4956
oral,dgl,1,364,26.8778,0.8213

 F1-mic 0.8247,  F1-mac 0.5016
oral,dgl,1,365,26.9506,0.8247

 F1-mic 0.8217,  F1-mac 0.4955
oral,dgl,1,366,27.0235,0.8217

 F1-mic 0.8244,  F1-mac 0.5014
oral,dgl,1,367,27.0962,0.8244

 F1-mic 0.8218,  F1-mac 0.4966
oral,dgl,1,368,27.1688,0.8218

 F1-mic 0.8242,  F1-mac 0.5006
oral,dgl,1,369,27.2417,0.8242

epoch:371/50, Iteration 32/32:training loss 0.7307281494140625
Train F1-mic 0.8247, Train F1-mac 0.5030
 F1-mic 0.8225,  F1-mac 0.4982
oral,dgl,1,370,27.3146,0.8225

 F1-mic 0.8235,  F1-mac 0.5000
oral,dgl,1,371,27.3868,0.8235

 F1-mic 0.8230,  F1-mac 0.4982
oral,dgl,1,372,27.4596,0.8230

 F1-mic 0.8234,  F1-mac 0.5004
oral,dgl,1,373,27.5325,0.8234

 F1-mic 0.8227,  F1-mac 0.4989
oral,dgl,1,374,27.6053,0.8227

 F1-mic 0.8241,  F1-mac 0.5007
oral,dgl,1,375,27.6781,0.8241

 F1-mic 0.8221,  F1-mac 0.4979
oral,dgl,1,376,27.7510,0.8221

 F1-mic 0.8245,  F1-mac 0.5022
oral,dgl,1,377,27.8236,0.8245

 F1-mic 0.8212,  F1-mac 0.4957
oral,dgl,1,378,27.8964,0.8212

 F1-mic 0.8253,  F1-mac 0.5035
new best val f1: 0.8252893494213012
oral,dgl,1,379,27.9691,0.8253

epoch:381/50, Iteration 32/32:training loss 0.727056086063385
Train F1-mic 0.8259, Train F1-mac 0.5078
 F1-mic 0.8193,  F1-mac 0.4928
oral,dgl,1,380,28.0421,0.8193

 F1-mic 0.8261,  F1-mac 0.5055
new best val f1: 0.8260963478073043
oral,dgl,1,381,28.1143,0.8261

 F1-mic 0.8182,  F1-mac 0.4921
oral,dgl,1,382,28.1869,0.8182

 F1-mic 0.8257,  F1-mac 0.5043
oral,dgl,1,383,28.2596,0.8257

 F1-mic 0.8227,  F1-mac 0.4989
oral,dgl,1,384,28.3322,0.8227

 F1-mic 0.8221,  F1-mac 0.4988
oral,dgl,1,385,28.4050,0.8221

 F1-mic 0.8256,  F1-mac 0.5044
oral,dgl,1,386,28.4777,0.8256

 F1-mic 0.8205,  F1-mac 0.4949
oral,dgl,1,387,28.5509,0.8205

 F1-mic 0.8254,  F1-mac 0.5040
oral,dgl,1,388,28.6238,0.8254

 F1-mic 0.8229,  F1-mac 0.4997
oral,dgl,1,389,28.6967,0.8229

epoch:391/50, Iteration 32/32:training loss 0.7201006412506104
Train F1-mic 0.8234, Train F1-mac 0.5020
 F1-mic 0.8226,  F1-mac 0.4990
oral,dgl,1,390,28.7696,0.8226

 F1-mic 0.8253,  F1-mac 0.5046
oral,dgl,1,391,28.8418,0.8253

 F1-mic 0.8215,  F1-mac 0.4980
oral,dgl,1,392,28.9148,0.8215

 F1-mic 0.8253,  F1-mac 0.5044
oral,dgl,1,393,28.9877,0.8253

 F1-mic 0.8228,  F1-mac 0.5010
oral,dgl,1,394,29.0606,0.8228

 F1-mic 0.8231,  F1-mac 0.5012
oral,dgl,1,395,29.1334,0.8231

 F1-mic 0.8251,  F1-mac 0.5040
oral,dgl,1,396,29.2062,0.8251

 F1-mic 0.8222,  F1-mac 0.4988
oral,dgl,1,397,29.2793,0.8222

 F1-mic 0.8251,  F1-mac 0.5049
oral,dgl,1,398,29.3522,0.8251

 F1-mic 0.8231,  F1-mac 0.5011
oral,dgl,1,399,29.4252,0.8231

epoch:401/50, Iteration 32/32:training loss 0.715618908405304
Train F1-mic 0.8236, Train F1-mac 0.5038
 F1-mic 0.8237,  F1-mac 0.5030
oral,dgl,1,400,29.4979,0.8237

 F1-mic 0.8244,  F1-mac 0.5047
oral,dgl,1,401,29.5699,0.8244

 F1-mic 0.8231,  F1-mac 0.5004
oral,dgl,1,402,29.6427,0.8231

 F1-mic 0.8246,  F1-mac 0.5052
oral,dgl,1,403,29.7153,0.8246

 F1-mic 0.8234,  F1-mac 0.5029
oral,dgl,1,404,29.7881,0.8234

 F1-mic 0.8235,  F1-mac 0.5032
oral,dgl,1,405,29.8610,0.8235

 F1-mic 0.8247,  F1-mac 0.5053
oral,dgl,1,406,29.9337,0.8247

 F1-mic 0.8232,  F1-mac 0.5018
oral,dgl,1,407,30.0066,0.8232

 F1-mic 0.8247,  F1-mac 0.5053
oral,dgl,1,408,30.0793,0.8247

 F1-mic 0.8238,  F1-mac 0.5042
oral,dgl,1,409,30.1524,0.8238

epoch:411/50, Iteration 32/32:training loss 0.7111757397651672
Train F1-mic 0.8243, Train F1-mac 0.5061
 F1-mic 0.8236,  F1-mac 0.5028
oral,dgl,1,410,30.2252,0.8236

 F1-mic 0.8250,  F1-mac 0.5055
oral,dgl,1,411,30.2973,0.8250

 F1-mic 0.8230,  F1-mac 0.5020
oral,dgl,1,412,30.3704,0.8230

 F1-mic 0.8250,  F1-mac 0.5057
oral,dgl,1,413,30.4436,0.8250

 F1-mic 0.8231,  F1-mac 0.5015
oral,dgl,1,414,30.5174,0.8231

 F1-mic 0.8251,  F1-mac 0.5062
oral,dgl,1,415,30.5903,0.8251

 F1-mic 0.8235,  F1-mac 0.5028
oral,dgl,1,416,30.6634,0.8235

 F1-mic 0.8246,  F1-mac 0.5054
oral,dgl,1,417,30.7365,0.8246

 F1-mic 0.8242,  F1-mac 0.5052
oral,dgl,1,418,30.8091,0.8242

 F1-mic 0.8239,  F1-mac 0.5037
oral,dgl,1,419,30.8818,0.8239

epoch:421/50, Iteration 32/32:training loss 0.7071211934089661
Train F1-mic 0.8245, Train F1-mac 0.5062
 F1-mic 0.8247,  F1-mac 0.5055
oral,dgl,1,420,30.9548,0.8247

 F1-mic 0.8241,  F1-mac 0.5043
oral,dgl,1,421,31.0267,0.8241

 F1-mic 0.8246,  F1-mac 0.5050
oral,dgl,1,422,31.0998,0.8246

 F1-mic 0.8243,  F1-mac 0.5047
oral,dgl,1,423,31.1727,0.8243

 F1-mic 0.8241,  F1-mac 0.5050
oral,dgl,1,424,31.2456,0.8241

 F1-mic 0.8250,  F1-mac 0.5061
oral,dgl,1,425,31.3184,0.8250

 F1-mic 0.8240,  F1-mac 0.5043
oral,dgl,1,426,31.3913,0.8240

 F1-mic 0.8249,  F1-mac 0.5072
oral,dgl,1,427,31.4641,0.8249

 F1-mic 0.8239,  F1-mac 0.5036
oral,dgl,1,428,31.5367,0.8239

 F1-mic 0.8254,  F1-mac 0.5075
oral,dgl,1,429,31.6094,0.8254

epoch:431/50, Iteration 32/32:training loss 0.7033758759498596
Train F1-mic 0.8258, Train F1-mac 0.5098
 F1-mic 0.8239,  F1-mac 0.5047
oral,dgl,1,430,31.6824,0.8239

 F1-mic 0.8253,  F1-mac 0.5074
oral,dgl,1,431,31.7543,0.8253

 F1-mic 0.8243,  F1-mac 0.5050
oral,dgl,1,432,31.8273,0.8243

 F1-mic 0.8246,  F1-mac 0.5067
oral,dgl,1,433,31.9000,0.8246

 F1-mic 0.8251,  F1-mac 0.5064
oral,dgl,1,434,31.9729,0.8251

 F1-mic 0.8245,  F1-mac 0.5060
oral,dgl,1,435,32.0456,0.8245

 F1-mic 0.8249,  F1-mac 0.5078
oral,dgl,1,436,32.1183,0.8249

 F1-mic 0.8245,  F1-mac 0.5053
oral,dgl,1,437,32.1912,0.8245

 F1-mic 0.8254,  F1-mac 0.5082
oral,dgl,1,438,32.2638,0.8254

 F1-mic 0.8242,  F1-mac 0.5052
oral,dgl,1,439,32.3365,0.8242

epoch:441/50, Iteration 32/32:training loss 0.6996806859970093
Train F1-mic 0.8246, Train F1-mac 0.5069
 F1-mic 0.8257,  F1-mac 0.5087
oral,dgl,1,440,32.4092,0.8257

 F1-mic 0.8241,  F1-mac 0.5053
oral,dgl,1,441,32.4813,0.8241

 F1-mic 0.8256,  F1-mac 0.5085
oral,dgl,1,442,32.5540,0.8256

 F1-mic 0.8246,  F1-mac 0.5057
oral,dgl,1,443,32.6268,0.8246

 F1-mic 0.8256,  F1-mac 0.5091
oral,dgl,1,444,32.6996,0.8256

 F1-mic 0.8244,  F1-mac 0.5056
oral,dgl,1,445,32.7724,0.8244

 F1-mic 0.8258,  F1-mac 0.5086
oral,dgl,1,446,32.8453,0.8258

 F1-mic 0.8243,  F1-mac 0.5065
oral,dgl,1,447,32.9180,0.8243

 F1-mic 0.8259,  F1-mac 0.5084
oral,dgl,1,448,32.9907,0.8259

 F1-mic 0.8247,  F1-mac 0.5064
oral,dgl,1,449,33.0636,0.8247

epoch:451/50, Iteration 32/32:training loss 0.696097731590271
Train F1-mic 0.8251, Train F1-mac 0.5083
 F1-mic 0.8258,  F1-mac 0.5100
oral,dgl,1,450,33.1365,0.8258

 F1-mic 0.8242,  F1-mac 0.5054
oral,dgl,1,451,33.2085,0.8242

 F1-mic 0.8269,  F1-mac 0.5122
new best val f1: 0.8269063461873075
oral,dgl,1,452,33.2812,0.8269

 F1-mic 0.8229,  F1-mac 0.5030
oral,dgl,1,453,33.3540,0.8229

 F1-mic 0.8276,  F1-mac 0.5141
new best val f1: 0.8276053447893105
oral,dgl,1,454,33.4268,0.8276

 F1-mic 0.8217,  F1-mac 0.5000
oral,dgl,1,455,33.4995,0.8217

 F1-mic 0.8279,  F1-mac 0.5152
new best val f1: 0.8279023441953116
oral,dgl,1,456,33.5727,0.8279

 F1-mic 0.8222,  F1-mac 0.4998
oral,dgl,1,457,33.6454,0.8222

 F1-mic 0.8272,  F1-mac 0.5134
oral,dgl,1,458,33.7182,0.8272

 F1-mic 0.8248,  F1-mac 0.5071
oral,dgl,1,459,33.7909,0.8248

epoch:461/50, Iteration 32/32:training loss 0.6927673816680908
Train F1-mic 0.8252, Train F1-mac 0.5090
 F1-mic 0.8252,  F1-mac 0.5072
oral,dgl,1,460,33.8636,0.8252

 F1-mic 0.8272,  F1-mac 0.5132
oral,dgl,1,461,33.9358,0.8272

 F1-mic 0.8232,  F1-mac 0.5030
oral,dgl,1,462,34.0085,0.8232

 F1-mic 0.8276,  F1-mac 0.5135
oral,dgl,1,463,34.0813,0.8276

 F1-mic 0.8244,  F1-mac 0.5066
oral,dgl,1,464,34.1542,0.8244

 F1-mic 0.8258,  F1-mac 0.5091
oral,dgl,1,465,34.2268,0.8258

 F1-mic 0.8269,  F1-mac 0.5109
oral,dgl,1,466,34.2996,0.8269

 F1-mic 0.8237,  F1-mac 0.5054
oral,dgl,1,467,34.3723,0.8237

 F1-mic 0.8276,  F1-mac 0.5139
oral,dgl,1,468,34.4450,0.8276

 F1-mic 0.8246,  F1-mac 0.5059
oral,dgl,1,469,34.5177,0.8246

epoch:471/50, Iteration 32/32:training loss 0.6901695132255554
Train F1-mic 0.8250, Train F1-mac 0.5072
 F1-mic 0.8264,  F1-mac 0.5104
oral,dgl,1,470,34.5905,0.8264

 F1-mic 0.8261,  F1-mac 0.5097
oral,dgl,1,471,34.6625,0.8261

 F1-mic 0.8251,  F1-mac 0.5077
oral,dgl,1,472,34.7354,0.8251

 F1-mic 0.8272,  F1-mac 0.5126
oral,dgl,1,473,34.8081,0.8272

 F1-mic 0.8248,  F1-mac 0.5067
oral,dgl,1,474,34.8810,0.8248

 F1-mic 0.8272,  F1-mac 0.5112
oral,dgl,1,475,34.9539,0.8272

 F1-mic 0.8252,  F1-mac 0.5083
oral,dgl,1,476,35.0268,0.8252

 F1-mic 0.8261,  F1-mac 0.5094
oral,dgl,1,477,35.0997,0.8261

 F1-mic 0.8268,  F1-mac 0.5108
oral,dgl,1,478,35.1724,0.8268

 F1-mic 0.8251,  F1-mac 0.5083
oral,dgl,1,479,35.2451,0.8251

epoch:481/50, Iteration 32/32:training loss 0.6867498755455017
Train F1-mic 0.8255, Train F1-mac 0.5100
 F1-mic 0.8272,  F1-mac 0.5111
oral,dgl,1,480,35.3178,0.8272

 F1-mic 0.8258,  F1-mac 0.5090
oral,dgl,1,481,35.3898,0.8258

 F1-mic 0.8262,  F1-mac 0.5103
oral,dgl,1,482,35.4625,0.8262

 F1-mic 0.8265,  F1-mac 0.5103
oral,dgl,1,483,35.5354,0.8265

 F1-mic 0.8260,  F1-mac 0.5094
oral,dgl,1,484,35.6081,0.8260

 F1-mic 0.8264,  F1-mac 0.5110
oral,dgl,1,485,35.6809,0.8264

 F1-mic 0.8264,  F1-mac 0.5101
oral,dgl,1,486,35.7539,0.8264

 F1-mic 0.8263,  F1-mac 0.5104
oral,dgl,1,487,35.8271,0.8263

 F1-mic 0.8265,  F1-mac 0.5111
oral,dgl,1,488,35.9000,0.8265

 F1-mic 0.8262,  F1-mac 0.5096
oral,dgl,1,489,35.9727,0.8262

epoch:491/50, Iteration 32/32:training loss 0.6835860013961792
Train F1-mic 0.8268, Train F1-mac 0.5120
 F1-mic 0.8268,  F1-mac 0.5113
oral,dgl,1,490,36.0456,0.8268

 F1-mic 0.8262,  F1-mac 0.5101
oral,dgl,1,491,36.1177,0.8262

 F1-mic 0.8268,  F1-mac 0.5103
oral,dgl,1,492,36.1930,0.8268

 F1-mic 0.8267,  F1-mac 0.5107
oral,dgl,1,493,36.2658,0.8267

 F1-mic 0.8262,  F1-mac 0.5102
oral,dgl,1,494,36.3387,0.8262

 F1-mic 0.8270,  F1-mac 0.5110
oral,dgl,1,495,36.4116,0.8270

 F1-mic 0.8264,  F1-mac 0.5103
oral,dgl,1,496,36.4842,0.8264

 F1-mic 0.8269,  F1-mac 0.5111
oral,dgl,1,497,36.5569,0.8269

 F1-mic 0.8267,  F1-mac 0.5107
oral,dgl,1,498,36.6298,0.8267

 F1-mic 0.8268,  F1-mac 0.5107
oral,dgl,1,499,36.7027,0.8268

epoch:501/50, Iteration 32/32:training loss 0.6806678175926208
Train F1-mic 0.8274, Train F1-mac 0.5141
 F1-mic 0.8269,  F1-mac 0.5111
oral,dgl,1,500,36.7757,0.8269

 F1-mic 0.8268,  F1-mac 0.5108
oral,dgl,1,501,36.8477,0.8268

 F1-mic 0.8268,  F1-mac 0.5109
oral,dgl,1,502,36.9205,0.8268

 F1-mic 0.8271,  F1-mac 0.5116
oral,dgl,1,503,36.9933,0.8271

 F1-mic 0.8267,  F1-mac 0.5106
oral,dgl,1,504,37.0662,0.8267

 F1-mic 0.8274,  F1-mac 0.5122
oral,dgl,1,505,37.1389,0.8274

 F1-mic 0.8266,  F1-mac 0.5104
oral,dgl,1,506,37.2117,0.8266

 F1-mic 0.8274,  F1-mac 0.5124
oral,dgl,1,507,37.2843,0.8274

 F1-mic 0.8267,  F1-mac 0.5104
oral,dgl,1,508,37.3572,0.8267

 F1-mic 0.8275,  F1-mac 0.5118
oral,dgl,1,509,37.4299,0.8275

epoch:511/50, Iteration 32/32:training loss 0.6779900789260864
Train F1-mic 0.8280, Train F1-mac 0.5153
 F1-mic 0.8270,  F1-mac 0.5114
oral,dgl,1,510,37.5027,0.8270

 F1-mic 0.8271,  F1-mac 0.5109
oral,dgl,1,511,37.5750,0.8271

 F1-mic 0.8276,  F1-mac 0.5124
oral,dgl,1,512,37.6478,0.8276

 F1-mic 0.8266,  F1-mac 0.5105
oral,dgl,1,513,37.7205,0.8266

 F1-mic 0.8277,  F1-mac 0.5126
oral,dgl,1,514,37.7934,0.8277

 F1-mic 0.8269,  F1-mac 0.5097
oral,dgl,1,515,37.8662,0.8269

 F1-mic 0.8277,  F1-mac 0.5123
oral,dgl,1,516,37.9390,0.8277

 F1-mic 0.8272,  F1-mac 0.5113
oral,dgl,1,517,38.0117,0.8272

 F1-mic 0.8275,  F1-mac 0.5118
oral,dgl,1,518,38.0844,0.8275

 F1-mic 0.8277,  F1-mac 0.5126
oral,dgl,1,519,38.1574,0.8277

epoch:521/50, Iteration 32/32:training loss 0.675369143486023
Train F1-mic 0.8282, Train F1-mac 0.5161
 F1-mic 0.8273,  F1-mac 0.5112
oral,dgl,1,520,38.2304,0.8273

 F1-mic 0.8279,  F1-mac 0.5124
oral,dgl,1,521,38.3024,0.8279

 F1-mic 0.8269,  F1-mac 0.5111
oral,dgl,1,522,38.3753,0.8269

 F1-mic 0.8282,  F1-mac 0.5127
new best val f1: 0.8281873436253127
oral,dgl,1,523,38.4480,0.8282

 F1-mic 0.8270,  F1-mac 0.5107
oral,dgl,1,524,38.5209,0.8270

 F1-mic 0.8284,  F1-mac 0.5137
new best val f1: 0.8284093431813137
oral,dgl,1,525,38.5939,0.8284

 F1-mic 0.8269,  F1-mac 0.5101
oral,dgl,1,526,38.6666,0.8269

 F1-mic 0.8288,  F1-mac 0.5157
new best val f1: 0.8288143423713152
oral,dgl,1,527,38.7396,0.8288

 F1-mic 0.8262,  F1-mac 0.5081
oral,dgl,1,528,38.8125,0.8262

 F1-mic 0.8292,  F1-mac 0.5163
new best val f1: 0.8291833416333168
oral,dgl,1,529,38.8852,0.8292

epoch:531/50, Iteration 32/32:training loss 0.6740168929100037
Train F1-mic 0.8299, Train F1-mac 0.5200
 F1-mic 0.8257,  F1-mac 0.5069
oral,dgl,1,530,38.9578,0.8257

 F1-mic 0.8293,  F1-mac 0.5181
new best val f1: 0.8293153413693173
oral,dgl,1,531,39.0302,0.8293

 F1-mic 0.8258,  F1-mac 0.5067
oral,dgl,1,532,39.1029,0.8258

 F1-mic 0.8295,  F1-mac 0.5172
new best val f1: 0.8294743410513179
oral,dgl,1,533,39.1756,0.8295

 F1-mic 0.8265,  F1-mac 0.5093
oral,dgl,1,534,39.2483,0.8265

 F1-mic 0.8287,  F1-mac 0.5137
oral,dgl,1,535,39.3210,0.8287

 F1-mic 0.8279,  F1-mac 0.5132
oral,dgl,1,536,39.3939,0.8279

 F1-mic 0.8273,  F1-mac 0.5099
oral,dgl,1,537,39.4667,0.8273

 F1-mic 0.8295,  F1-mac 0.5169
oral,dgl,1,538,39.5396,0.8295

 F1-mic 0.8255,  F1-mac 0.5079
oral,dgl,1,539,39.6126,0.8255

epoch:541/50, Iteration 32/32:training loss 0.6717767715454102
Train F1-mic 0.8260, Train F1-mac 0.5109
 F1-mic 0.8301,  F1-mac 0.5185
new best val f1: 0.8301133397733205
oral,dgl,1,540,39.6854,0.8301

 F1-mic 0.8259,  F1-mac 0.5075
oral,dgl,1,541,39.7574,0.8259

 F1-mic 0.8295,  F1-mac 0.5176
oral,dgl,1,542,39.8304,0.8295

 F1-mic 0.8275,  F1-mac 0.5100
oral,dgl,1,543,39.9031,0.8275

 F1-mic 0.8287,  F1-mac 0.5148
oral,dgl,1,544,39.9759,0.8287

 F1-mic 0.8286,  F1-mac 0.5147
oral,dgl,1,545,40.0485,0.8286

 F1-mic 0.8276,  F1-mac 0.5105
oral,dgl,1,546,40.1214,0.8276

 F1-mic 0.8295,  F1-mac 0.5183
oral,dgl,1,547,40.1944,0.8295

 F1-mic 0.8267,  F1-mac 0.5095
oral,dgl,1,548,40.2674,0.8267

 F1-mic 0.8300,  F1-mac 0.5189
oral,dgl,1,549,40.3406,0.8300

epoch:551/50, Iteration 32/32:training loss 0.6687758564949036
Train F1-mic 0.8306, Train F1-mac 0.5211
 F1-mic 0.8269,  F1-mac 0.5098
oral,dgl,1,550,40.4136,0.8269

 F1-mic 0.8297,  F1-mac 0.5176
oral,dgl,1,551,40.4860,0.8297

 F1-mic 0.8279,  F1-mac 0.5113
oral,dgl,1,552,40.5591,0.8279

 F1-mic 0.8284,  F1-mac 0.5149
oral,dgl,1,553,40.6317,0.8284

 F1-mic 0.8292,  F1-mac 0.5143
oral,dgl,1,554,40.7043,0.8292

 F1-mic 0.8276,  F1-mac 0.5115
oral,dgl,1,555,40.7771,0.8276

 F1-mic 0.8297,  F1-mac 0.5184
oral,dgl,1,556,40.8498,0.8297

 F1-mic 0.8275,  F1-mac 0.5104
oral,dgl,1,557,40.9226,0.8275

 F1-mic 0.8300,  F1-mac 0.5187
oral,dgl,1,558,40.9956,0.8300

 F1-mic 0.8275,  F1-mac 0.5109
oral,dgl,1,559,41.0685,0.8275

epoch:561/50, Iteration 32/32:training loss 0.6660009622573853
Train F1-mic 0.8281, Train F1-mac 0.5139
 F1-mic 0.8296,  F1-mac 0.5169
oral,dgl,1,560,41.1414,0.8296

 F1-mic 0.8281,  F1-mac 0.5122
oral,dgl,1,561,41.2134,0.8281

 F1-mic 0.8291,  F1-mac 0.5151
oral,dgl,1,562,41.2863,0.8291

 F1-mic 0.8291,  F1-mac 0.5152
oral,dgl,1,563,41.3593,0.8291

 F1-mic 0.8284,  F1-mac 0.5125
oral,dgl,1,564,41.4321,0.8284

 F1-mic 0.8297,  F1-mac 0.5168
oral,dgl,1,565,41.5050,0.8297

 F1-mic 0.8281,  F1-mac 0.5117
oral,dgl,1,566,41.5778,0.8281

 F1-mic 0.8299,  F1-mac 0.5180
oral,dgl,1,567,41.6505,0.8299

 F1-mic 0.8281,  F1-mac 0.5121
oral,dgl,1,568,41.7232,0.8281

 F1-mic 0.8297,  F1-mac 0.5172
oral,dgl,1,569,41.7960,0.8297

epoch:571/50, Iteration 32/32:training loss 0.6633443832397461
Train F1-mic 0.8304, Train F1-mac 0.5202
 F1-mic 0.8287,  F1-mac 0.5129
oral,dgl,1,570,41.8687,0.8287

 F1-mic 0.8294,  F1-mac 0.5159
oral,dgl,1,571,41.9407,0.8294

 F1-mic 0.8293,  F1-mac 0.5157
oral,dgl,1,572,42.0137,0.8293

 F1-mic 0.8289,  F1-mac 0.5149
oral,dgl,1,573,42.0866,0.8289

 F1-mic 0.8297,  F1-mac 0.5168
oral,dgl,1,574,42.1593,0.8297

 F1-mic 0.8290,  F1-mac 0.5141
oral,dgl,1,575,42.2322,0.8290

 F1-mic 0.8297,  F1-mac 0.5166
oral,dgl,1,576,42.3051,0.8297

 F1-mic 0.8291,  F1-mac 0.5142
oral,dgl,1,577,42.3778,0.8291

 F1-mic 0.8298,  F1-mac 0.5170
oral,dgl,1,578,42.4507,0.8298

 F1-mic 0.8289,  F1-mac 0.5145
oral,dgl,1,579,42.5234,0.8289

epoch:581/50, Iteration 32/32:training loss 0.6609935760498047
Train F1-mic 0.8295, Train F1-mac 0.5173
 F1-mic 0.8302,  F1-mac 0.5176
new best val f1: 0.8302153395693208
oral,dgl,1,580,42.5964,0.8302

 F1-mic 0.8289,  F1-mac 0.5141
oral,dgl,1,581,42.6684,0.8289

 F1-mic 0.8302,  F1-mac 0.5178
new best val f1: 0.830242339515321
oral,dgl,1,582,42.7412,0.8302

 F1-mic 0.8289,  F1-mac 0.5140
oral,dgl,1,583,42.8139,0.8289

 F1-mic 0.8306,  F1-mac 0.5189
new best val f1: 0.8305993388013224
oral,dgl,1,584,42.8866,0.8306

 F1-mic 0.8287,  F1-mac 0.5133
oral,dgl,1,585,42.9593,0.8287

 F1-mic 0.8309,  F1-mac 0.5190
new best val f1: 0.8308603382793235
oral,dgl,1,586,43.0322,0.8309

 F1-mic 0.8287,  F1-mac 0.5140
oral,dgl,1,587,43.1049,0.8287

 F1-mic 0.8306,  F1-mac 0.5183
oral,dgl,1,588,43.1777,0.8306

 F1-mic 0.8293,  F1-mac 0.5143
oral,dgl,1,589,43.2503,0.8293

epoch:591/50, Iteration 32/32:training loss 0.6589381098747253
Train F1-mic 0.8298, Train F1-mac 0.5168
 F1-mic 0.8304,  F1-mac 0.5181
oral,dgl,1,590,43.3230,0.8304

 F1-mic 0.8298,  F1-mac 0.5141
oral,dgl,1,591,43.3951,0.8298

 F1-mic 0.8302,  F1-mac 0.5180
oral,dgl,1,592,43.4679,0.8302

 F1-mic 0.8299,  F1-mac 0.5151
oral,dgl,1,593,43.5409,0.8299

 F1-mic 0.8305,  F1-mac 0.5169
oral,dgl,1,594,43.6138,0.8305

 F1-mic 0.8296,  F1-mac 0.5159
oral,dgl,1,595,43.6865,0.8296

 F1-mic 0.8307,  F1-mac 0.5167
oral,dgl,1,596,43.7594,0.8307

 F1-mic 0.8299,  F1-mac 0.5161
oral,dgl,1,597,43.8321,0.8299

 F1-mic 0.8305,  F1-mac 0.5186
oral,dgl,1,598,43.9049,0.8305

 F1-mic 0.8300,  F1-mac 0.5144
oral,dgl,1,599,43.9777,0.8300

epoch:601/50, Iteration 32/32:training loss 0.6568586826324463
Train F1-mic 0.8305, Train F1-mac 0.5173
 F1-mic 0.8307,  F1-mac 0.5191
oral,dgl,1,600,44.0505,0.8307

 F1-mic 0.8294,  F1-mac 0.5133
oral,dgl,1,601,44.1226,0.8294

 F1-mic 0.8315,  F1-mac 0.5205
new best val f1: 0.831514336971326
oral,dgl,1,602,44.1953,0.8315

 F1-mic 0.8290,  F1-mac 0.5134
oral,dgl,1,603,44.2683,0.8290

 F1-mic 0.8318,  F1-mac 0.5210
new best val f1: 0.8318143363713274
oral,dgl,1,604,44.3411,0.8318

 F1-mic 0.8290,  F1-mac 0.5129
oral,dgl,1,605,44.4138,0.8290

 F1-mic 0.8317,  F1-mac 0.5204
oral,dgl,1,606,44.4867,0.8317

 F1-mic 0.8295,  F1-mac 0.5135
oral,dgl,1,607,44.5596,0.8295

 F1-mic 0.8311,  F1-mac 0.5197
oral,dgl,1,608,44.6323,0.8311

 F1-mic 0.8305,  F1-mac 0.5152
oral,dgl,1,609,44.7051,0.8305

epoch:611/50, Iteration 32/32:training loss 0.6548659801483154
Train F1-mic 0.8311, Train F1-mac 0.5181
 F1-mic 0.8305,  F1-mac 0.5182
oral,dgl,1,610,44.7781,0.8305

 F1-mic 0.8311,  F1-mac 0.5188
oral,dgl,1,611,44.8501,0.8311

 F1-mic 0.8301,  F1-mac 0.5148
oral,dgl,1,612,44.9228,0.8301

 F1-mic 0.8316,  F1-mac 0.5199
oral,dgl,1,613,44.9960,0.8316

 F1-mic 0.8296,  F1-mac 0.5128
oral,dgl,1,614,45.0687,0.8296

 F1-mic 0.8320,  F1-mac 0.5217
new best val f1: 0.831991336017328
oral,dgl,1,615,45.1417,0.8320

 F1-mic 0.8292,  F1-mac 0.5124
oral,dgl,1,616,45.2145,0.8292

 F1-mic 0.8325,  F1-mac 0.5224
new best val f1: 0.8325373349253301
oral,dgl,1,617,45.2874,0.8325

 F1-mic 0.8290,  F1-mac 0.5108
oral,dgl,1,618,45.3601,0.8290

 F1-mic 0.8327,  F1-mac 0.5223
new best val f1: 0.8327233345533309
oral,dgl,1,619,45.4333,0.8327

epoch:621/50, Iteration 32/32:training loss 0.6543963551521301
Train F1-mic 0.8331, Train F1-mac 0.5245
 F1-mic 0.8293,  F1-mac 0.5116
oral,dgl,1,620,45.5063,0.8293

 F1-mic 0.8321,  F1-mac 0.5230
oral,dgl,1,621,45.5783,0.8321

 F1-mic 0.8303,  F1-mac 0.5132
oral,dgl,1,622,45.6511,0.8303

 F1-mic 0.8316,  F1-mac 0.5190
oral,dgl,1,623,45.7243,0.8316

 F1-mic 0.8309,  F1-mac 0.5173
oral,dgl,1,624,45.7972,0.8309

 F1-mic 0.8313,  F1-mac 0.5170
oral,dgl,1,625,45.8700,0.8313

 F1-mic 0.8313,  F1-mac 0.5185
oral,dgl,1,626,45.9428,0.8313

 F1-mic 0.8309,  F1-mac 0.5162
oral,dgl,1,627,46.0154,0.8309

 F1-mic 0.8321,  F1-mac 0.5191
oral,dgl,1,628,46.0884,0.8321

 F1-mic 0.8305,  F1-mac 0.5169
oral,dgl,1,629,46.1613,0.8305

epoch:631/50, Iteration 32/32:training loss 0.6512306332588196
Train F1-mic 0.8310, Train F1-mac 0.5194
 F1-mic 0.8320,  F1-mac 0.5181
oral,dgl,1,630,46.2342,0.8320

 F1-mic 0.8311,  F1-mac 0.5175
oral,dgl,1,631,46.3062,0.8311

 F1-mic 0.8315,  F1-mac 0.5181
oral,dgl,1,632,46.3790,0.8315

 F1-mic 0.8315,  F1-mac 0.5181
oral,dgl,1,633,46.4519,0.8315

 F1-mic 0.8313,  F1-mac 0.5173
oral,dgl,1,634,46.5247,0.8313

 F1-mic 0.8321,  F1-mac 0.5188
oral,dgl,1,635,46.5976,0.8321

 F1-mic 0.8308,  F1-mac 0.5156
oral,dgl,1,636,46.6703,0.8308

 F1-mic 0.8324,  F1-mac 0.5204
oral,dgl,1,637,46.7432,0.8324

 F1-mic 0.8306,  F1-mac 0.5156
oral,dgl,1,638,46.8162,0.8306

 F1-mic 0.8328,  F1-mac 0.5207
new best val f1: 0.832750334499331
oral,dgl,1,639,46.8888,0.8328

epoch:641/50, Iteration 32/32:training loss 0.6497098803520203
Train F1-mic 0.8333, Train F1-mac 0.5230
 F1-mic 0.8307,  F1-mac 0.5147
oral,dgl,1,640,46.9616,0.8307

 F1-mic 0.8326,  F1-mac 0.5215
oral,dgl,1,641,47.0337,0.8326

 F1-mic 0.8306,  F1-mac 0.5135
oral,dgl,1,642,47.1067,0.8306

 F1-mic 0.8330,  F1-mac 0.5227
new best val f1: 0.832999334001332
oral,dgl,1,643,47.1794,0.8330

 F1-mic 0.8305,  F1-mac 0.5135
oral,dgl,1,644,47.2522,0.8305

 F1-mic 0.8333,  F1-mac 0.5225
new best val f1: 0.833254333491333
oral,dgl,1,645,47.3249,0.8333

 F1-mic 0.8305,  F1-mac 0.5151
oral,dgl,1,646,47.3976,0.8305

 F1-mic 0.8331,  F1-mac 0.5200
oral,dgl,1,647,47.4702,0.8331

 F1-mic 0.8314,  F1-mac 0.5169
oral,dgl,1,648,47.5432,0.8314

 F1-mic 0.8324,  F1-mac 0.5191
oral,dgl,1,649,47.6159,0.8324

epoch:651/50, Iteration 32/32:training loss 0.6476349234580994
Train F1-mic 0.8328, Train F1-mac 0.5216
 F1-mic 0.8326,  F1-mac 0.5195
oral,dgl,1,650,47.6886,0.8326

 F1-mic 0.8311,  F1-mac 0.5171
oral,dgl,1,651,47.7606,0.8311

 F1-mic 0.8336,  F1-mac 0.5213
new best val f1: 0.8335573328853341
oral,dgl,1,652,47.8337,0.8336

 F1-mic 0.8300,  F1-mac 0.5141
oral,dgl,1,653,47.9064,0.8300

 F1-mic 0.8341,  F1-mac 0.5255
new best val f1: 0.8341063317873364
oral,dgl,1,654,47.9791,0.8341

 F1-mic 0.8303,  F1-mac 0.5126
oral,dgl,1,655,48.0518,0.8303

 F1-mic 0.8338,  F1-mac 0.5257
oral,dgl,1,656,48.1245,0.8338

 F1-mic 0.8314,  F1-mac 0.5139
oral,dgl,1,657,48.1973,0.8314

 F1-mic 0.8328,  F1-mac 0.5224
oral,dgl,1,658,48.2703,0.8328

 F1-mic 0.8323,  F1-mac 0.5189
oral,dgl,1,659,48.3430,0.8323

epoch:661/50, Iteration 32/32:training loss 0.6460267901420593
Train F1-mic 0.8328, Train F1-mac 0.5202
 F1-mic 0.8325,  F1-mac 0.5188
oral,dgl,1,660,48.4162,0.8325

 F1-mic 0.8326,  F1-mac 0.5213
oral,dgl,1,661,48.4883,0.8326

 F1-mic 0.8321,  F1-mac 0.5178
oral,dgl,1,662,48.5611,0.8321

 F1-mic 0.8333,  F1-mac 0.5215
oral,dgl,1,663,48.6341,0.8333

 F1-mic 0.8318,  F1-mac 0.5182
oral,dgl,1,664,48.7069,0.8318

 F1-mic 0.8335,  F1-mac 0.5205
oral,dgl,1,665,48.7799,0.8335

 F1-mic 0.8320,  F1-mac 0.5194
oral,dgl,1,666,48.8528,0.8320

 F1-mic 0.8334,  F1-mac 0.5202
oral,dgl,1,667,48.9256,0.8334

 F1-mic 0.8325,  F1-mac 0.5198
oral,dgl,1,668,48.9984,0.8325

 F1-mic 0.8328,  F1-mac 0.5205
oral,dgl,1,669,49.0712,0.8328

epoch:671/50, Iteration 32/32:training loss 0.6444094777107239
Train F1-mic 0.8331, Train F1-mac 0.5221
 F1-mic 0.8333,  F1-mac 0.5195
oral,dgl,1,670,49.1440,0.8333

 F1-mic 0.8325,  F1-mac 0.5207
oral,dgl,1,671,49.2162,0.8325

 F1-mic 0.8332,  F1-mac 0.5198
oral,dgl,1,672,49.2892,0.8332

 F1-mic 0.8329,  F1-mac 0.5197
oral,dgl,1,673,49.3619,0.8329

 F1-mic 0.8329,  F1-mac 0.5203
oral,dgl,1,674,49.4348,0.8329

 F1-mic 0.8335,  F1-mac 0.5187
oral,dgl,1,675,49.5077,0.8335

 F1-mic 0.8327,  F1-mac 0.5207
oral,dgl,1,676,49.5805,0.8327

 F1-mic 0.8331,  F1-mac 0.5191
oral,dgl,1,677,49.6534,0.8331

 F1-mic 0.8336,  F1-mac 0.5213
oral,dgl,1,678,49.7261,0.8336

 F1-mic 0.8322,  F1-mac 0.5187
oral,dgl,1,679,49.7988,0.8322

epoch:681/50, Iteration 32/32:training loss 0.6430222392082214
Train F1-mic 0.8327, Train F1-mac 0.5206
 F1-mic 0.8340,  F1-mac 0.5209
oral,dgl,1,680,49.8716,0.8340

 F1-mic 0.8328,  F1-mac 0.5191
oral,dgl,1,681,49.9437,0.8328

 F1-mic 0.8334,  F1-mac 0.5207
oral,dgl,1,682,50.0165,0.8334

 F1-mic 0.8337,  F1-mac 0.5208
oral,dgl,1,683,50.0895,0.8337

 F1-mic 0.8325,  F1-mac 0.5188
oral,dgl,1,684,50.1623,0.8325

 F1-mic 0.8342,  F1-mac 0.5221
new best val f1: 0.8341843316313369
oral,dgl,1,685,50.2350,0.8342

 F1-mic 0.8319,  F1-mac 0.5169
oral,dgl,1,686,50.3078,0.8319

 F1-mic 0.8345,  F1-mac 0.5239
new best val f1: 0.8345173309653382
oral,dgl,1,687,50.3805,0.8345

 F1-mic 0.8319,  F1-mac 0.5161
oral,dgl,1,688,50.4535,0.8319

 F1-mic 0.8345,  F1-mac 0.5259
oral,dgl,1,689,50.5264,0.8345

epoch:691/50, Iteration 32/32:training loss 0.6421864032745361
Train F1-mic 0.8349, Train F1-mac 0.5263
 F1-mic 0.8321,  F1-mac 0.5166
oral,dgl,1,690,50.5994,0.8321

 F1-mic 0.8345,  F1-mac 0.5230
oral,dgl,1,691,50.6714,0.8345

 F1-mic 0.8328,  F1-mac 0.5187
oral,dgl,1,692,50.7445,0.8328

 F1-mic 0.8341,  F1-mac 0.5214
oral,dgl,1,693,50.8174,0.8341

 F1-mic 0.8335,  F1-mac 0.5204
oral,dgl,1,694,50.8904,0.8335

 F1-mic 0.8337,  F1-mac 0.5212
oral,dgl,1,695,50.9631,0.8337

 F1-mic 0.8341,  F1-mac 0.5213
oral,dgl,1,696,51.0359,0.8341

 F1-mic 0.8333,  F1-mac 0.5200
oral,dgl,1,697,51.1086,0.8333

 F1-mic 0.8344,  F1-mac 0.5214
oral,dgl,1,698,51.1815,0.8344

 F1-mic 0.8334,  F1-mac 0.5186
oral,dgl,1,699,51.2546,0.8334

epoch:701/50, Iteration 32/32:training loss 0.6399767994880676
Train F1-mic 0.8338, Train F1-mac 0.5204
 F1-mic 0.8342,  F1-mac 0.5226
oral,dgl,1,700,51.3275,0.8342

 F1-mic 0.8335,  F1-mac 0.5190
oral,dgl,1,701,51.3995,0.8335

 F1-mic 0.8345,  F1-mac 0.5225
new best val f1: 0.8345443309113382
oral,dgl,1,702,51.4724,0.8345

 F1-mic 0.8332,  F1-mac 0.5184
oral,dgl,1,703,51.5451,0.8332

 F1-mic 0.8345,  F1-mac 0.5228
new best val f1: 0.8345473309053382
oral,dgl,1,704,51.6178,0.8345

 F1-mic 0.8336,  F1-mac 0.5205
oral,dgl,1,705,51.6904,0.8336

 F1-mic 0.8345,  F1-mac 0.5216
oral,dgl,1,706,51.7631,0.8345

 F1-mic 0.8342,  F1-mac 0.5215
oral,dgl,1,707,51.8358,0.8342

 F1-mic 0.8338,  F1-mac 0.5199
oral,dgl,1,708,51.9086,0.8338

 F1-mic 0.8347,  F1-mac 0.5223
new best val f1: 0.8347243305513389
oral,dgl,1,709,51.9815,0.8347

epoch:711/50, Iteration 32/32:training loss 0.6385411024093628
Train F1-mic 0.8351, Train F1-mac 0.5238
 F1-mic 0.8331,  F1-mac 0.5192
oral,dgl,1,710,52.0542,0.8331

 F1-mic 0.8353,  F1-mac 0.5229
new best val f1: 0.8352883294233412
oral,dgl,1,711,52.1261,0.8353

 F1-mic 0.8329,  F1-mac 0.5194
oral,dgl,1,712,52.1988,0.8329

 F1-mic 0.8353,  F1-mac 0.5235
oral,dgl,1,713,52.2714,0.8353

 F1-mic 0.8335,  F1-mac 0.5191
oral,dgl,1,714,52.3442,0.8335

 F1-mic 0.8349,  F1-mac 0.5230
oral,dgl,1,715,52.4168,0.8349

 F1-mic 0.8338,  F1-mac 0.5193
oral,dgl,1,716,52.4896,0.8338

 F1-mic 0.8350,  F1-mac 0.5239
oral,dgl,1,717,52.5622,0.8350

 F1-mic 0.8336,  F1-mac 0.5186
oral,dgl,1,718,52.6349,0.8336

 F1-mic 0.8354,  F1-mac 0.5246
new best val f1: 0.8354083291833416
oral,dgl,1,719,52.7078,0.8354

epoch:721/50, Iteration 32/32:training loss 0.637437105178833
Train F1-mic 0.8357, Train F1-mac 0.5256
 F1-mic 0.8334,  F1-mac 0.5188
oral,dgl,1,720,52.7805,0.8334

 F1-mic 0.8355,  F1-mac 0.5245
new best val f1: 0.8355283289433421
oral,dgl,1,721,52.8524,0.8355

 F1-mic 0.8335,  F1-mac 0.5195
oral,dgl,1,722,52.9253,0.8335

 F1-mic 0.8353,  F1-mac 0.5229
oral,dgl,1,723,52.9981,0.8353

 F1-mic 0.8344,  F1-mac 0.5203
oral,dgl,1,724,53.0710,0.8344

 F1-mic 0.8346,  F1-mac 0.5223
oral,dgl,1,725,53.1436,0.8346

 F1-mic 0.8352,  F1-mac 0.5225
oral,dgl,1,726,53.2163,0.8352

 F1-mic 0.8339,  F1-mac 0.5206
oral,dgl,1,727,53.2889,0.8339

 F1-mic 0.8357,  F1-mac 0.5238
new best val f1: 0.835744328511343
oral,dgl,1,728,53.3615,0.8357

 F1-mic 0.8333,  F1-mac 0.5189
oral,dgl,1,729,53.4342,0.8333

epoch:731/50, Iteration 32/32:training loss 0.6362417936325073
Train F1-mic 0.8336, Train F1-mac 0.5196
 F1-mic 0.8363,  F1-mac 0.5271
new best val f1: 0.8363083273833453
oral,dgl,1,730,53.5070,0.8363

 F1-mic 0.8331,  F1-mac 0.5160
oral,dgl,1,731,53.5789,0.8331

 F1-mic 0.8363,  F1-mac 0.5282
oral,dgl,1,732,53.6517,0.8363

 F1-mic 0.8331,  F1-mac 0.5141
oral,dgl,1,733,53.7244,0.8331

 F1-mic 0.8363,  F1-mac 0.5285
new best val f1: 0.8363293273413454
oral,dgl,1,734,53.7970,0.8363

 F1-mic 0.8333,  F1-mac 0.5150
oral,dgl,1,735,53.8696,0.8333

 F1-mic 0.8363,  F1-mac 0.5273
oral,dgl,1,736,53.9422,0.8363

 F1-mic 0.8341,  F1-mac 0.5196
oral,dgl,1,737,54.0151,0.8341

 F1-mic 0.8357,  F1-mac 0.5241
oral,dgl,1,738,54.0880,0.8357

 F1-mic 0.8355,  F1-mac 0.5236
oral,dgl,1,739,54.1608,0.8355

epoch:741/50, Iteration 32/32:training loss 0.6343069672584534
Train F1-mic 0.8357, Train F1-mac 0.5244
 F1-mic 0.8346,  F1-mac 0.5198
oral,dgl,1,740,54.2339,0.8346

 F1-mic 0.8362,  F1-mac 0.5266
oral,dgl,1,741,54.3060,0.8362

 F1-mic 0.8338,  F1-mac 0.5177
oral,dgl,1,742,54.3790,0.8338

 F1-mic 0.8367,  F1-mac 0.5269
new best val f1: 0.8366893266213468
oral,dgl,1,743,54.4516,0.8367

 F1-mic 0.8338,  F1-mac 0.5191
oral,dgl,1,744,54.5243,0.8338

 F1-mic 0.8365,  F1-mac 0.5250
oral,dgl,1,745,54.5970,0.8365

 F1-mic 0.8345,  F1-mac 0.5212
oral,dgl,1,746,54.6701,0.8345

 F1-mic 0.8359,  F1-mac 0.5239
oral,dgl,1,747,54.7427,0.8359

 F1-mic 0.8357,  F1-mac 0.5235
oral,dgl,1,748,54.8153,0.8357

 F1-mic 0.8350,  F1-mac 0.5224
oral,dgl,1,749,54.8879,0.8350

epoch:751/50, Iteration 32/32:training loss 0.6330026388168335
Train F1-mic 0.8353, Train F1-mac 0.5233
 F1-mic 0.8362,  F1-mac 0.5246
oral,dgl,1,750,54.9605,0.8362

 F1-mic 0.8343,  F1-mac 0.5204
oral,dgl,1,751,55.0326,0.8343

 F1-mic 0.8367,  F1-mac 0.5257
new best val f1: 0.836746326507347
oral,dgl,1,752,55.1060,0.8367

 F1-mic 0.8342,  F1-mac 0.5201
oral,dgl,1,753,55.1787,0.8342

 F1-mic 0.8365,  F1-mac 0.5259
oral,dgl,1,754,55.2513,0.8365

 F1-mic 0.8352,  F1-mac 0.5199
oral,dgl,1,755,55.3242,0.8352

 F1-mic 0.8360,  F1-mac 0.5259
oral,dgl,1,756,55.3967,0.8360

 F1-mic 0.8357,  F1-mac 0.5205
oral,dgl,1,757,55.4693,0.8357

 F1-mic 0.8355,  F1-mac 0.5246
oral,dgl,1,758,55.5419,0.8355

 F1-mic 0.8363,  F1-mac 0.5234
oral,dgl,1,759,55.6146,0.8363

epoch:761/50, Iteration 32/32:training loss 0.6317681670188904
Train F1-mic 0.8365, Train F1-mac 0.5241
 F1-mic 0.8354,  F1-mac 0.5230
oral,dgl,1,760,55.6875,0.8354

 F1-mic 0.8362,  F1-mac 0.5250
oral,dgl,1,761,55.7594,0.8362

 F1-mic 0.8359,  F1-mac 0.5223
oral,dgl,1,762,55.8319,0.8359

 F1-mic 0.8361,  F1-mac 0.5249
oral,dgl,1,763,55.9047,0.8361

 F1-mic 0.8361,  F1-mac 0.5220
oral,dgl,1,764,55.9773,0.8361

 F1-mic 0.8358,  F1-mac 0.5249
oral,dgl,1,765,56.0500,0.8358

 F1-mic 0.8362,  F1-mac 0.5231
oral,dgl,1,766,56.1226,0.8362

 F1-mic 0.8361,  F1-mac 0.5245
oral,dgl,1,767,56.1953,0.8361

 F1-mic 0.8363,  F1-mac 0.5237
oral,dgl,1,768,56.2680,0.8363

 F1-mic 0.8361,  F1-mac 0.5237
oral,dgl,1,769,56.3407,0.8361

epoch:771/50, Iteration 32/32:training loss 0.6303942203521729
Train F1-mic 0.8363, Train F1-mac 0.5246
 F1-mic 0.8363,  F1-mac 0.5247
oral,dgl,1,770,56.4134,0.8363

 F1-mic 0.8362,  F1-mac 0.5228
oral,dgl,1,771,56.4855,0.8362

 F1-mic 0.8365,  F1-mac 0.5251
oral,dgl,1,772,56.5582,0.8365

 F1-mic 0.8359,  F1-mac 0.5227
oral,dgl,1,773,56.6308,0.8359

 F1-mic 0.8368,  F1-mac 0.5250
new best val f1: 0.8368123263753473
oral,dgl,1,774,56.7035,0.8368

 F1-mic 0.8354,  F1-mac 0.5225
oral,dgl,1,775,56.7763,0.8354

 F1-mic 0.8373,  F1-mac 0.5261
new best val f1: 0.8373163253673492
oral,dgl,1,776,56.8490,0.8373

 F1-mic 0.8348,  F1-mac 0.5219
oral,dgl,1,777,56.9217,0.8348

 F1-mic 0.8375,  F1-mac 0.5261
new best val f1: 0.83747832504335
oral,dgl,1,778,56.9946,0.8375

 F1-mic 0.8351,  F1-mac 0.5217
oral,dgl,1,779,57.0675,0.8351

epoch:781/50, Iteration 32/32:training loss 0.6295584440231323
Train F1-mic 0.8354, Train F1-mac 0.5220
 F1-mic 0.8374,  F1-mac 0.5260
oral,dgl,1,780,57.1403,0.8374

 F1-mic 0.8357,  F1-mac 0.5213
oral,dgl,1,781,57.2122,0.8357

 F1-mic 0.8368,  F1-mac 0.5269
oral,dgl,1,782,57.2850,0.8368

 F1-mic 0.8361,  F1-mac 0.5215
oral,dgl,1,783,57.3580,0.8361

 F1-mic 0.8368,  F1-mac 0.5260
oral,dgl,1,784,57.4307,0.8368

 F1-mic 0.8365,  F1-mac 0.5229
oral,dgl,1,785,57.5035,0.8365

 F1-mic 0.8365,  F1-mac 0.5236
oral,dgl,1,786,57.5764,0.8365

 F1-mic 0.8370,  F1-mac 0.5247
oral,dgl,1,787,57.6493,0.8370

 F1-mic 0.8361,  F1-mac 0.5224
oral,dgl,1,788,57.7221,0.8361

 F1-mic 0.8373,  F1-mac 0.5269
oral,dgl,1,789,57.7949,0.8373

epoch:791/50, Iteration 32/32:training loss 0.6281341314315796
Train F1-mic 0.8373, Train F1-mac 0.5270
 F1-mic 0.8360,  F1-mac 0.5213
oral,dgl,1,790,57.8676,0.8360

 F1-mic 0.8372,  F1-mac 0.5274
oral,dgl,1,791,57.9396,0.8372

 F1-mic 0.8361,  F1-mac 0.5206
oral,dgl,1,792,58.0122,0.8361

 F1-mic 0.8373,  F1-mac 0.5275
oral,dgl,1,793,58.0851,0.8373

 F1-mic 0.8362,  F1-mac 0.5207
oral,dgl,1,794,58.1578,0.8362

 F1-mic 0.8373,  F1-mac 0.5276
oral,dgl,1,795,58.2305,0.8373

 F1-mic 0.8363,  F1-mac 0.5210
oral,dgl,1,796,58.3034,0.8363

 F1-mic 0.8374,  F1-mac 0.5272
oral,dgl,1,797,58.3762,0.8374

 F1-mic 0.8363,  F1-mac 0.5222
oral,dgl,1,798,58.4489,0.8363

 F1-mic 0.8374,  F1-mac 0.5264
oral,dgl,1,799,58.5218,0.8374

epoch:801/50, Iteration 32/32:training loss 0.6268391013145447
Train F1-mic 0.8375, Train F1-mac 0.5266
 F1-mic 0.8366,  F1-mac 0.5231
oral,dgl,1,800,58.5946,0.8366

 F1-mic 0.8372,  F1-mac 0.5239
oral,dgl,1,801,58.6666,0.8372

 F1-mic 0.8371,  F1-mac 0.5265
oral,dgl,1,802,58.7394,0.8371

 F1-mic 0.8368,  F1-mac 0.5220
oral,dgl,1,803,58.8121,0.8368

 F1-mic 0.8374,  F1-mac 0.5273
oral,dgl,1,804,58.8850,0.8374

 F1-mic 0.8364,  F1-mac 0.5207
oral,dgl,1,805,58.9577,0.8364

 F1-mic 0.8383,  F1-mac 0.5285
new best val f1: 0.8382853234293531
oral,dgl,1,806,59.0303,0.8383

 F1-mic 0.8350,  F1-mac 0.5201
oral,dgl,1,807,59.1030,0.8350

 F1-mic 0.8391,  F1-mac 0.5293
new best val f1: 0.8390593218813562
oral,dgl,1,808,59.1758,0.8391

 F1-mic 0.8339,  F1-mac 0.5208
oral,dgl,1,809,59.2486,0.8339

epoch:811/50, Iteration 32/32:training loss 0.6276342272758484
Train F1-mic 0.8343, Train F1-mac 0.5213
 F1-mic 0.8389,  F1-mac 0.5279
oral,dgl,1,810,59.3215,0.8389

 F1-mic 0.8344,  F1-mac 0.5223
oral,dgl,1,811,59.3934,0.8344

 F1-mic 0.8386,  F1-mac 0.5262
oral,dgl,1,812,59.4663,0.8386

 F1-mic 0.8364,  F1-mac 0.5244
oral,dgl,1,813,59.5392,0.8364

 F1-mic 0.8374,  F1-mac 0.5249
oral,dgl,1,814,59.6121,0.8374

 F1-mic 0.8379,  F1-mac 0.5254
oral,dgl,1,815,59.6848,0.8379

 F1-mic 0.8361,  F1-mac 0.5243
oral,dgl,1,816,59.7575,0.8361

 F1-mic 0.8384,  F1-mac 0.5261
oral,dgl,1,817,59.8304,0.8384

 F1-mic 0.8361,  F1-mac 0.5245
oral,dgl,1,818,59.9030,0.8361

 F1-mic 0.8381,  F1-mac 0.5260
oral,dgl,1,819,59.9757,0.8381

epoch:821/50, Iteration 32/32:training loss 0.6245917081832886
Train F1-mic 0.8382, Train F1-mac 0.5263
 F1-mic 0.8373,  F1-mac 0.5254
oral,dgl,1,820,60.0486,0.8373

 F1-mic 0.8373,  F1-mac 0.5252
oral,dgl,1,821,60.1208,0.8373

 F1-mic 0.8380,  F1-mac 0.5258
oral,dgl,1,822,60.1936,0.8380

 F1-mic 0.8366,  F1-mac 0.5248
oral,dgl,1,823,60.2663,0.8366

 F1-mic 0.8382,  F1-mac 0.5258
oral,dgl,1,824,60.3390,0.8382

 F1-mic 0.8369,  F1-mac 0.5256
oral,dgl,1,825,60.4118,0.8369

 F1-mic 0.8379,  F1-mac 0.5244
oral,dgl,1,826,60.4847,0.8379

 F1-mic 0.8375,  F1-mac 0.5263
oral,dgl,1,827,60.5573,0.8375

 F1-mic 0.8373,  F1-mac 0.5239
oral,dgl,1,828,60.6303,0.8373

 F1-mic 0.8383,  F1-mac 0.5266
oral,dgl,1,829,60.7030,0.8383

epoch:831/50, Iteration 32/32:training loss 0.6233941316604614
Train F1-mic 0.8384, Train F1-mac 0.5269
 F1-mic 0.8366,  F1-mac 0.5239
oral,dgl,1,830,60.7762,0.8366

 F1-mic 0.8389,  F1-mac 0.5276
oral,dgl,1,831,60.8484,0.8389

 F1-mic 0.8358,  F1-mac 0.5230
oral,dgl,1,832,60.9211,0.8358

 F1-mic 0.8391,  F1-mac 0.5279
new best val f1: 0.8390683218633562
oral,dgl,1,833,60.9938,0.8391

 F1-mic 0.8361,  F1-mac 0.5228
oral,dgl,1,834,61.0666,0.8361

 F1-mic 0.8389,  F1-mac 0.5291
oral,dgl,1,835,61.1393,0.8389

 F1-mic 0.8372,  F1-mac 0.5217
oral,dgl,1,836,61.2120,0.8372

 F1-mic 0.8381,  F1-mac 0.5292
oral,dgl,1,837,61.2847,0.8381

 F1-mic 0.8380,  F1-mac 0.5231
oral,dgl,1,838,61.3574,0.8380

 F1-mic 0.8372,  F1-mac 0.5271
oral,dgl,1,839,61.4302,0.8372

epoch:841/50, Iteration 32/32:training loss 0.6226724982261658
Train F1-mic 0.8373, Train F1-mac 0.5275
 F1-mic 0.8385,  F1-mac 0.5253
oral,dgl,1,840,61.5031,0.8385

 F1-mic 0.8374,  F1-mac 0.5250
oral,dgl,1,841,61.5751,0.8374

 F1-mic 0.8385,  F1-mac 0.5281
oral,dgl,1,842,61.6479,0.8385

 F1-mic 0.8375,  F1-mac 0.5227
oral,dgl,1,843,61.7208,0.8375

 F1-mic 0.8381,  F1-mac 0.5292
oral,dgl,1,844,61.7936,0.8381

 F1-mic 0.8379,  F1-mac 0.5211
oral,dgl,1,845,61.8663,0.8379

 F1-mic 0.8380,  F1-mac 0.5296
oral,dgl,1,846,61.9390,0.8380

 F1-mic 0.8378,  F1-mac 0.5230
oral,dgl,1,847,62.0116,0.8378

 F1-mic 0.8387,  F1-mac 0.5273
oral,dgl,1,848,62.0844,0.8387

 F1-mic 0.8374,  F1-mac 0.5255
oral,dgl,1,849,62.1571,0.8374

epoch:851/50, Iteration 32/32:training loss 0.6212426424026489
Train F1-mic 0.8374, Train F1-mac 0.5255
 F1-mic 0.8390,  F1-mac 0.5263
oral,dgl,1,850,62.2299,0.8390

 F1-mic 0.8368,  F1-mac 0.5266
oral,dgl,1,851,62.3018,0.8368

 F1-mic 0.8389,  F1-mac 0.5240
oral,dgl,1,852,62.3746,0.8389

 F1-mic 0.8372,  F1-mac 0.5279
oral,dgl,1,853,62.4475,0.8372

 F1-mic 0.8387,  F1-mac 0.5239
oral,dgl,1,854,62.5204,0.8387

 F1-mic 0.8383,  F1-mac 0.5271
oral,dgl,1,855,62.5933,0.8383

 F1-mic 0.8377,  F1-mac 0.5255
oral,dgl,1,856,62.6662,0.8377

 F1-mic 0.8391,  F1-mac 0.5265
new best val f1: 0.8391463217073567
oral,dgl,1,857,62.7389,0.8391

 F1-mic 0.8371,  F1-mac 0.5264
oral,dgl,1,858,62.8116,0.8371

 F1-mic 0.8393,  F1-mac 0.5268
new best val f1: 0.8392813214373571
oral,dgl,1,859,62.8843,0.8393

epoch:861/50, Iteration 32/32:training loss 0.6206177473068237
Train F1-mic 0.8393, Train F1-mac 0.5267
 F1-mic 0.8369,  F1-mac 0.5259
oral,dgl,1,860,62.9570,0.8369

 F1-mic 0.8394,  F1-mac 0.5271
new best val f1: 0.8393713212573574
oral,dgl,1,861,63.0290,0.8394

 F1-mic 0.8377,  F1-mac 0.5245
oral,dgl,1,862,63.1020,0.8377

 F1-mic 0.8387,  F1-mac 0.5288
oral,dgl,1,863,63.1751,0.8387

 F1-mic 0.8384,  F1-mac 0.5234
oral,dgl,1,864,63.2478,0.8384

 F1-mic 0.8383,  F1-mac 0.5295
oral,dgl,1,865,63.3208,0.8383

 F1-mic 0.8386,  F1-mac 0.5237
oral,dgl,1,866,63.3937,0.8386

 F1-mic 0.8383,  F1-mac 0.5288
oral,dgl,1,867,63.4665,0.8383

 F1-mic 0.8387,  F1-mac 0.5250
oral,dgl,1,868,63.5394,0.8387

 F1-mic 0.8388,  F1-mac 0.5269
oral,dgl,1,869,63.6124,0.8388

epoch:871/50, Iteration 32/32:training loss 0.6189417839050293
Train F1-mic 0.8389, Train F1-mac 0.5271
 F1-mic 0.8381,  F1-mac 0.5270
oral,dgl,1,870,63.6850,0.8381

 F1-mic 0.8393,  F1-mac 0.5262
oral,dgl,1,871,63.7571,0.8393

 F1-mic 0.8377,  F1-mac 0.5275
oral,dgl,1,872,63.8298,0.8377

 F1-mic 0.8395,  F1-mac 0.5260
new best val f1: 0.8394703210593579
oral,dgl,1,873,63.9024,0.8395

 F1-mic 0.8379,  F1-mac 0.5268
oral,dgl,1,874,63.9752,0.8379

 F1-mic 0.8393,  F1-mac 0.5271
oral,dgl,1,875,64.0478,0.8393

 F1-mic 0.8382,  F1-mac 0.5258
oral,dgl,1,876,64.1208,0.8382

 F1-mic 0.8390,  F1-mac 0.5278
oral,dgl,1,877,64.1936,0.8390

 F1-mic 0.8390,  F1-mac 0.5260
oral,dgl,1,878,64.2665,0.8390

 F1-mic 0.8383,  F1-mac 0.5276
oral,dgl,1,879,64.3394,0.8383

epoch:881/50, Iteration 32/32:training loss 0.6180388331413269
Train F1-mic 0.8384, Train F1-mac 0.5276
 F1-mic 0.8392,  F1-mac 0.5264
oral,dgl,1,880,64.4122,0.8392

 F1-mic 0.8386,  F1-mac 0.5270
oral,dgl,1,881,64.4843,0.8386

 F1-mic 0.8391,  F1-mac 0.5269
oral,dgl,1,882,64.5572,0.8391

 F1-mic 0.8387,  F1-mac 0.5266
oral,dgl,1,883,64.6298,0.8387

 F1-mic 0.8392,  F1-mac 0.5276
oral,dgl,1,884,64.7025,0.8392

 F1-mic 0.8387,  F1-mac 0.5255
oral,dgl,1,885,64.7751,0.8387

 F1-mic 0.8395,  F1-mac 0.5288
oral,dgl,1,886,64.8481,0.8395

 F1-mic 0.8384,  F1-mac 0.5251
oral,dgl,1,887,64.9208,0.8384

 F1-mic 0.8397,  F1-mac 0.5290
new best val f1: 0.839734320531359
oral,dgl,1,888,64.9935,0.8397

 F1-mic 0.8383,  F1-mac 0.5245
oral,dgl,1,889,65.0664,0.8383

epoch:891/50, Iteration 32/32:training loss 0.6170788407325745
Train F1-mic 0.8385, Train F1-mac 0.5247
 F1-mic 0.8398,  F1-mac 0.5286
new best val f1: 0.839752320495359
oral,dgl,1,890,65.1393,0.8398

 F1-mic 0.8385,  F1-mac 0.5251
oral,dgl,1,891,65.2114,0.8385

 F1-mic 0.8397,  F1-mac 0.5286
oral,dgl,1,892,65.2841,0.8397

 F1-mic 0.8387,  F1-mac 0.5255
oral,dgl,1,893,65.3568,0.8387

 F1-mic 0.8396,  F1-mac 0.5277
oral,dgl,1,894,65.4297,0.8396

 F1-mic 0.8390,  F1-mac 0.5266
oral,dgl,1,895,65.5026,0.8390

 F1-mic 0.8394,  F1-mac 0.5268
oral,dgl,1,896,65.5754,0.8394

 F1-mic 0.8392,  F1-mac 0.5275
oral,dgl,1,897,65.6481,0.8392

 F1-mic 0.8392,  F1-mac 0.5262
oral,dgl,1,898,65.7208,0.8392

 F1-mic 0.8395,  F1-mac 0.5281
oral,dgl,1,899,65.7937,0.8395

epoch:901/50, Iteration 32/32:training loss 0.6157616972923279
Train F1-mic 0.8396, Train F1-mac 0.5282
 F1-mic 0.8390,  F1-mac 0.5253
oral,dgl,1,900,65.8665,0.8390

 F1-mic 0.8395,  F1-mac 0.5277
oral,dgl,1,901,65.9385,0.8395

 F1-mic 0.8393,  F1-mac 0.5259
oral,dgl,1,902,66.0114,0.8393

 F1-mic 0.8394,  F1-mac 0.5282
oral,dgl,1,903,66.0843,0.8394

 F1-mic 0.8392,  F1-mac 0.5257
oral,dgl,1,904,66.1571,0.8392

 F1-mic 0.8397,  F1-mac 0.5281
oral,dgl,1,905,66.2297,0.8397

 F1-mic 0.8392,  F1-mac 0.5256
oral,dgl,1,906,66.3025,0.8392

 F1-mic 0.8394,  F1-mac 0.5277
oral,dgl,1,907,66.3753,0.8394

 F1-mic 0.8395,  F1-mac 0.5261
oral,dgl,1,908,66.4483,0.8395

 F1-mic 0.8396,  F1-mac 0.5270
oral,dgl,1,909,66.5212,0.8396

epoch:911/50, Iteration 32/32:training loss 0.6146307587623596
Train F1-mic 0.8397, Train F1-mac 0.5273
 F1-mic 0.8395,  F1-mac 0.5276
oral,dgl,1,910,66.5941,0.8395

 F1-mic 0.8395,  F1-mac 0.5266
oral,dgl,1,911,66.6661,0.8395

 F1-mic 0.8396,  F1-mac 0.5275
oral,dgl,1,912,66.7389,0.8396

 F1-mic 0.8396,  F1-mac 0.5259
oral,dgl,1,913,66.8116,0.8396

 F1-mic 0.8395,  F1-mac 0.5282
oral,dgl,1,914,66.8845,0.8395

 F1-mic 0.8397,  F1-mac 0.5265
oral,dgl,1,915,66.9574,0.8397

 F1-mic 0.8396,  F1-mac 0.5271
oral,dgl,1,916,67.0303,0.8396

 F1-mic 0.8399,  F1-mac 0.5269
new best val f1: 0.8399083201833596
oral,dgl,1,917,67.1030,0.8399

 F1-mic 0.8394,  F1-mac 0.5253
oral,dgl,1,918,67.1756,0.8394

 F1-mic 0.8404,  F1-mac 0.5283
new best val f1: 0.8404033191933616
oral,dgl,1,919,67.2483,0.8404

epoch:921/50, Iteration 32/32:training loss 0.6137144565582275
Train F1-mic 0.8405, Train F1-mac 0.5289
 F1-mic 0.8390,  F1-mac 0.5246
oral,dgl,1,920,67.3211,0.8390

 F1-mic 0.8410,  F1-mac 0.5300
new best val f1: 0.841015317969364
oral,dgl,1,921,67.3932,0.8410

 F1-mic 0.8384,  F1-mac 0.5235
oral,dgl,1,922,67.4659,0.8384

 F1-mic 0.8414,  F1-mac 0.5302
new best val f1: 0.8413723172553655
oral,dgl,1,923,67.5386,0.8414

 F1-mic 0.8375,  F1-mac 0.5226
oral,dgl,1,924,67.6114,0.8375

 F1-mic 0.8415,  F1-mac 0.5298
new best val f1: 0.8415283169433662
oral,dgl,1,925,67.6844,0.8415

 F1-mic 0.8369,  F1-mac 0.5230
oral,dgl,1,926,67.7571,0.8369

 F1-mic 0.8414,  F1-mac 0.5300
oral,dgl,1,927,67.8297,0.8414

 F1-mic 0.8376,  F1-mac 0.5233
oral,dgl,1,928,67.9026,0.8376

 F1-mic 0.8414,  F1-mac 0.5295
oral,dgl,1,929,67.9753,0.8414

epoch:931/50, Iteration 32/32:training loss 0.6133947968482971
Train F1-mic 0.8413, Train F1-mac 0.5302
 F1-mic 0.8393,  F1-mac 0.5241
oral,dgl,1,930,68.0482,0.8393

 F1-mic 0.8402,  F1-mac 0.5290
oral,dgl,1,931,68.1203,0.8402

 F1-mic 0.8408,  F1-mac 0.5256
oral,dgl,1,932,68.1932,0.8408

 F1-mic 0.8387,  F1-mac 0.5274
oral,dgl,1,933,68.2660,0.8387

 F1-mic 0.8413,  F1-mac 0.5277
oral,dgl,1,934,68.3387,0.8413

 F1-mic 0.8380,  F1-mac 0.5251
oral,dgl,1,935,68.4113,0.8380

 F1-mic 0.8418,  F1-mac 0.5296
new best val f1: 0.8417983164033672
oral,dgl,1,936,68.4840,0.8418

 F1-mic 0.8386,  F1-mac 0.5229
oral,dgl,1,937,68.5570,0.8386

 F1-mic 0.8414,  F1-mac 0.5314
oral,dgl,1,938,68.6296,0.8414

 F1-mic 0.8398,  F1-mac 0.5231
oral,dgl,1,939,68.7026,0.8398

epoch:941/50, Iteration 32/32:training loss 0.612332284450531
Train F1-mic 0.8400, Train F1-mac 0.5239
 F1-mic 0.8403,  F1-mac 0.5314
oral,dgl,1,940,68.7753,0.8403

 F1-mic 0.8404,  F1-mac 0.5225
oral,dgl,1,941,68.8473,0.8404

 F1-mic 0.8398,  F1-mac 0.5317
oral,dgl,1,942,68.9200,0.8398

 F1-mic 0.8406,  F1-mac 0.5245
oral,dgl,1,943,68.9929,0.8406

 F1-mic 0.8404,  F1-mac 0.5293
oral,dgl,1,944,69.0661,0.8404

 F1-mic 0.8405,  F1-mac 0.5271
oral,dgl,1,945,69.1390,0.8405

 F1-mic 0.8409,  F1-mac 0.5276
oral,dgl,1,946,69.2118,0.8409

 F1-mic 0.8399,  F1-mac 0.5292
oral,dgl,1,947,69.2847,0.8399

 F1-mic 0.8410,  F1-mac 0.5252
oral,dgl,1,948,69.3575,0.8410

 F1-mic 0.8404,  F1-mac 0.5300
oral,dgl,1,949,69.4304,0.8404

epoch:951/50, Iteration 32/32:training loss 0.6110283732414246
Train F1-mic 0.8404, Train F1-mac 0.5310
 F1-mic 0.8404,  F1-mac 0.5246
oral,dgl,1,950,69.5030,0.8404

 F1-mic 0.8410,  F1-mac 0.5301
oral,dgl,1,951,69.5750,0.8410

 F1-mic 0.8399,  F1-mac 0.5253
oral,dgl,1,952,69.6477,0.8399

 F1-mic 0.8415,  F1-mac 0.5284
oral,dgl,1,953,69.7205,0.8415

 F1-mic 0.8398,  F1-mac 0.5276
oral,dgl,1,954,69.7931,0.8398

 F1-mic 0.8415,  F1-mac 0.5280
oral,dgl,1,955,69.8661,0.8415

 F1-mic 0.8396,  F1-mac 0.5283
oral,dgl,1,956,69.9388,0.8396

 F1-mic 0.8417,  F1-mac 0.5273
oral,dgl,1,957,70.0117,0.8417

 F1-mic 0.8401,  F1-mac 0.5280
oral,dgl,1,958,70.0846,0.8401

 F1-mic 0.8413,  F1-mac 0.5280
oral,dgl,1,959,70.1575,0.8413

epoch:961/50, Iteration 32/32:training loss 0.6094997525215149
Train F1-mic 0.8414, Train F1-mac 0.5287
 F1-mic 0.8407,  F1-mac 0.5266
oral,dgl,1,960,70.2301,0.8407

 F1-mic 0.8410,  F1-mac 0.5296
oral,dgl,1,961,70.3021,0.8410

 F1-mic 0.8410,  F1-mac 0.5262
oral,dgl,1,962,70.3748,0.8410

 F1-mic 0.8407,  F1-mac 0.5300
oral,dgl,1,963,70.4476,0.8407

 F1-mic 0.8412,  F1-mac 0.5261
oral,dgl,1,964,70.5205,0.8412

 F1-mic 0.8406,  F1-mac 0.5304
oral,dgl,1,965,70.5933,0.8406

 F1-mic 0.8413,  F1-mac 0.5263
oral,dgl,1,966,70.6661,0.8413

 F1-mic 0.8411,  F1-mac 0.5299
oral,dgl,1,967,70.7390,0.8411

 F1-mic 0.8409,  F1-mac 0.5265
oral,dgl,1,968,70.8120,0.8409

 F1-mic 0.8414,  F1-mac 0.5302
oral,dgl,1,969,70.8848,0.8414

epoch:971/50, Iteration 32/32:training loss 0.6085219979286194
Train F1-mic 0.8415, Train F1-mac 0.5308
 F1-mic 0.8407,  F1-mac 0.5262
oral,dgl,1,970,70.9575,0.8407

 F1-mic 0.8420,  F1-mac 0.5303
new best val f1: 0.842011315977368
oral,dgl,1,971,71.0296,0.8420

 F1-mic 0.8400,  F1-mac 0.5249
oral,dgl,1,972,71.1024,0.8400

 F1-mic 0.8425,  F1-mac 0.5320
new best val f1: 0.8424523150953698
oral,dgl,1,973,71.1753,0.8425

 F1-mic 0.8395,  F1-mac 0.5231
oral,dgl,1,974,71.2481,0.8395

 F1-mic 0.8428,  F1-mac 0.5327
new best val f1: 0.8428213143573713
oral,dgl,1,975,71.3207,0.8428

 F1-mic 0.8390,  F1-mac 0.5227
oral,dgl,1,976,71.3937,0.8390

 F1-mic 0.8427,  F1-mac 0.5326
oral,dgl,1,977,71.4664,0.8427

 F1-mic 0.8398,  F1-mac 0.5246
oral,dgl,1,978,71.5391,0.8398

 F1-mic 0.8422,  F1-mac 0.5298
oral,dgl,1,979,71.6121,0.8422

epoch:981/50, Iteration 32/32:training loss 0.6076950430870056
Train F1-mic 0.8422, Train F1-mac 0.5304
 F1-mic 0.8414,  F1-mac 0.5288
oral,dgl,1,980,71.6848,0.8414

 F1-mic 0.8407,  F1-mac 0.5266
oral,dgl,1,981,71.7571,0.8407

 F1-mic 0.8427,  F1-mac 0.5319
oral,dgl,1,982,71.8299,0.8427

 F1-mic 0.8397,  F1-mac 0.5241
oral,dgl,1,983,71.9029,0.8397

 F1-mic 0.8429,  F1-mac 0.5328
new best val f1: 0.8429023141953716
oral,dgl,1,984,71.9758,0.8429

 F1-mic 0.8392,  F1-mac 0.5237
oral,dgl,1,985,72.0489,0.8392

 F1-mic 0.8431,  F1-mac 0.5330
new best val f1: 0.8430763138473724
oral,dgl,1,986,72.1217,0.8431

 F1-mic 0.8399,  F1-mac 0.5249
oral,dgl,1,987,72.1948,0.8399

 F1-mic 0.8427,  F1-mac 0.5312
oral,dgl,1,988,72.2678,0.8427

 F1-mic 0.8412,  F1-mac 0.5279
oral,dgl,1,989,72.3405,0.8412

epoch:991/50, Iteration 32/32:training loss 0.6065242290496826
Train F1-mic 0.8413, Train F1-mac 0.5289
 F1-mic 0.8412,  F1-mac 0.5283
oral,dgl,1,990,72.4133,0.8412

 F1-mic 0.8425,  F1-mac 0.5300
oral,dgl,1,991,72.4854,0.8425

 F1-mic 0.8404,  F1-mac 0.5263
oral,dgl,1,992,72.5582,0.8404

 F1-mic 0.8427,  F1-mac 0.5321
oral,dgl,1,993,72.6315,0.8427

 F1-mic 0.8404,  F1-mac 0.5258
oral,dgl,1,994,72.7044,0.8404

 F1-mic 0.8427,  F1-mac 0.5323
oral,dgl,1,995,72.7773,0.8427

 F1-mic 0.8412,  F1-mac 0.5272
oral,dgl,1,996,72.8500,0.8412

 F1-mic 0.8422,  F1-mac 0.5301
oral,dgl,1,997,72.9227,0.8422

 F1-mic 0.8417,  F1-mac 0.5281
oral,dgl,1,998,72.9955,0.8417

 F1-mic 0.8419,  F1-mac 0.5288
oral,dgl,1,999,73.0685,0.8419

epoch:1001/50, Iteration 32/32:training loss 0.6055076122283936
Train F1-mic 0.8419, Train F1-mac 0.5300
 F1-mic 0.8418,  F1-mac 0.5285
oral,dgl,1,1000,73.1412,0.8418

 F1-mic 0.8421,  F1-mac 0.5291
oral,dgl,1,1001,73.2132,0.8421

 F1-mic 0.8417,  F1-mac 0.5284
oral,dgl,1,1002,73.2862,0.8417

 F1-mic 0.8420,  F1-mac 0.5289
oral,dgl,1,1003,73.3589,0.8420

 F1-mic 0.8419,  F1-mac 0.5284
oral,dgl,1,1004,73.4318,0.8419

 F1-mic 0.8422,  F1-mac 0.5297
oral,dgl,1,1005,73.5045,0.8422

 F1-mic 0.8420,  F1-mac 0.5286
oral,dgl,1,1006,73.5774,0.8420

 F1-mic 0.8419,  F1-mac 0.5293
oral,dgl,1,1007,73.6502,0.8419

 F1-mic 0.8424,  F1-mac 0.5286
oral,dgl,1,1008,73.7229,0.8424

 F1-mic 0.8416,  F1-mac 0.5288
oral,dgl,1,1009,73.7958,0.8416

epoch:1011/50, Iteration 32/32:training loss 0.6046715378761292
Train F1-mic 0.8416, Train F1-mac 0.5301
 F1-mic 0.8425,  F1-mac 0.5284
oral,dgl,1,1010,73.8685,0.8425

 F1-mic 0.8415,  F1-mac 0.5294
oral,dgl,1,1011,73.9406,0.8415

 F1-mic 0.8424,  F1-mac 0.5286
oral,dgl,1,1012,74.0133,0.8424

 F1-mic 0.8416,  F1-mac 0.5289
oral,dgl,1,1013,74.0864,0.8416

 F1-mic 0.8428,  F1-mac 0.5298
oral,dgl,1,1014,74.1592,0.8428

 F1-mic 0.8411,  F1-mac 0.5286
oral,dgl,1,1015,74.2321,0.8411

 F1-mic 0.8431,  F1-mac 0.5308
new best val f1: 0.8431303137393725
oral,dgl,1,1016,74.3049,0.8431

 F1-mic 0.8411,  F1-mac 0.5274
oral,dgl,1,1017,74.3778,0.8411

 F1-mic 0.8430,  F1-mac 0.5311
oral,dgl,1,1018,74.4506,0.8430

 F1-mic 0.8410,  F1-mac 0.5274
oral,dgl,1,1019,74.5234,0.8410

epoch:1021/50, Iteration 32/32:training loss 0.6040011048316956
Train F1-mic 0.8413, Train F1-mac 0.5285
 F1-mic 0.8432,  F1-mac 0.5312
new best val f1: 0.8431693136613727
oral,dgl,1,1020,74.5964,0.8432

 F1-mic 0.8414,  F1-mac 0.5276
oral,dgl,1,1021,74.6684,0.8414

 F1-mic 0.8429,  F1-mac 0.5316
oral,dgl,1,1022,74.7412,0.8429

 F1-mic 0.8420,  F1-mac 0.5274
oral,dgl,1,1023,74.8141,0.8420

 F1-mic 0.8426,  F1-mac 0.5316
oral,dgl,1,1024,74.8869,0.8426

 F1-mic 0.8422,  F1-mac 0.5269
oral,dgl,1,1025,74.9597,0.8422

 F1-mic 0.8425,  F1-mac 0.5320
oral,dgl,1,1026,75.0323,0.8425

 F1-mic 0.8424,  F1-mac 0.5277
oral,dgl,1,1027,75.1052,0.8424

 F1-mic 0.8422,  F1-mac 0.5316
oral,dgl,1,1028,75.1782,0.8422

 F1-mic 0.8427,  F1-mac 0.5274
oral,dgl,1,1029,75.2511,0.8427

epoch:1031/50, Iteration 32/32:training loss 0.6030535101890564
Train F1-mic 0.8428, Train F1-mac 0.5286
 F1-mic 0.8418,  F1-mac 0.5317
oral,dgl,1,1030,75.3239,0.8418

 F1-mic 0.8429,  F1-mac 0.5281
oral,dgl,1,1031,75.3959,0.8429

 F1-mic 0.8420,  F1-mac 0.5319
oral,dgl,1,1032,75.4688,0.8420

 F1-mic 0.8428,  F1-mac 0.5274
oral,dgl,1,1033,75.5416,0.8428

 F1-mic 0.8421,  F1-mac 0.5311
oral,dgl,1,1034,75.6142,0.8421

 F1-mic 0.8428,  F1-mac 0.5285
oral,dgl,1,1035,75.6870,0.8428

 F1-mic 0.8425,  F1-mac 0.5308
oral,dgl,1,1036,75.7600,0.8425

 F1-mic 0.8426,  F1-mac 0.5291
oral,dgl,1,1037,75.8327,0.8426

 F1-mic 0.8426,  F1-mac 0.5301
oral,dgl,1,1038,75.9113,0.8426

 F1-mic 0.8425,  F1-mac 0.5284
oral,dgl,1,1039,75.9843,0.8425

epoch:1041/50, Iteration 32/32:training loss 0.6017634272575378
Train F1-mic 0.8427, Train F1-mac 0.5299
 F1-mic 0.8427,  F1-mac 0.5295
oral,dgl,1,1040,76.0570,0.8427

 F1-mic 0.8425,  F1-mac 0.5293
oral,dgl,1,1041,76.1290,0.8425

 F1-mic 0.8427,  F1-mac 0.5305
oral,dgl,1,1042,76.2019,0.8427

 F1-mic 0.8427,  F1-mac 0.5289
oral,dgl,1,1043,76.2748,0.8427

 F1-mic 0.8427,  F1-mac 0.5300
oral,dgl,1,1044,76.3475,0.8427

 F1-mic 0.8426,  F1-mac 0.5290
oral,dgl,1,1045,76.4202,0.8426

 F1-mic 0.8428,  F1-mac 0.5305
oral,dgl,1,1046,76.4929,0.8428

 F1-mic 0.8429,  F1-mac 0.5291
oral,dgl,1,1047,76.5659,0.8429

 F1-mic 0.8425,  F1-mac 0.5309
oral,dgl,1,1048,76.6388,0.8425

 F1-mic 0.8434,  F1-mac 0.5295
new best val f1: 0.8433613132773734
oral,dgl,1,1049,76.7115,0.8434

epoch:1051/50, Iteration 32/32:training loss 0.6010441184043884
Train F1-mic 0.8434, Train F1-mac 0.5309
 F1-mic 0.8415,  F1-mac 0.5299
oral,dgl,1,1050,76.7845,0.8415

 F1-mic 0.8438,  F1-mac 0.5308
new best val f1: 0.8438053123893752
oral,dgl,1,1051,76.8567,0.8438

 F1-mic 0.8401,  F1-mac 0.5294
oral,dgl,1,1052,76.9297,0.8401

 F1-mic 0.8437,  F1-mac 0.5314
oral,dgl,1,1053,77.0025,0.8437

 F1-mic 0.8381,  F1-mac 0.5285
oral,dgl,1,1054,77.0752,0.8381

 F1-mic 0.8435,  F1-mac 0.5316
oral,dgl,1,1055,77.1480,0.8435

 F1-mic 0.8397,  F1-mac 0.5287
oral,dgl,1,1056,77.2210,0.8397

 F1-mic 0.8439,  F1-mac 0.5315
new best val f1: 0.8439133121733755
oral,dgl,1,1057,77.2938,0.8439

 F1-mic 0.8434,  F1-mac 0.5306
oral,dgl,1,1058,77.3666,0.8434

 F1-mic 0.8411,  F1-mac 0.5303
oral,dgl,1,1059,77.4393,0.8411

epoch:1061/50, Iteration 32/32:training loss 0.6011978983879089
Train F1-mic 0.8412, Train F1-mac 0.5313
 F1-mic 0.8439,  F1-mac 0.5318
oral,dgl,1,1060,77.5122,0.8439

 F1-mic 0.8389,  F1-mac 0.5281
oral,dgl,1,1061,77.5843,0.8389

 F1-mic 0.8441,  F1-mac 0.5324
new best val f1: 0.8440783118433763
oral,dgl,1,1062,77.6573,0.8441

 F1-mic 0.8413,  F1-mac 0.5277
oral,dgl,1,1063,77.7305,0.8413

 F1-mic 0.8433,  F1-mac 0.5340
oral,dgl,1,1064,77.8036,0.8433

 F1-mic 0.8436,  F1-mac 0.5285
oral,dgl,1,1065,77.8763,0.8436

 F1-mic 0.8412,  F1-mac 0.5318
oral,dgl,1,1066,77.9491,0.8412

 F1-mic 0.8439,  F1-mac 0.5300
oral,dgl,1,1067,78.0217,0.8439

 F1-mic 0.8422,  F1-mac 0.5307
oral,dgl,1,1068,78.0944,0.8422

 F1-mic 0.8433,  F1-mac 0.5318
oral,dgl,1,1069,78.1673,0.8433

epoch:1071/50, Iteration 32/32:training loss 0.5990574955940247
Train F1-mic 0.8433, Train F1-mac 0.5330
 F1-mic 0.8434,  F1-mac 0.5275
oral,dgl,1,1070,78.2403,0.8434

 F1-mic 0.8422,  F1-mac 0.5344
oral,dgl,1,1071,78.3123,0.8422

 F1-mic 0.8433,  F1-mac 0.5265
oral,dgl,1,1072,78.3849,0.8433

 F1-mic 0.8430,  F1-mac 0.5347
oral,dgl,1,1073,78.4579,0.8430

 F1-mic 0.8430,  F1-mac 0.5282
oral,dgl,1,1074,78.5308,0.8430

 F1-mic 0.8439,  F1-mac 0.5311
oral,dgl,1,1075,78.6038,0.8439

 F1-mic 0.8425,  F1-mac 0.5312
oral,dgl,1,1076,78.6767,0.8425

 F1-mic 0.8437,  F1-mac 0.5298
oral,dgl,1,1077,78.7496,0.8437

 F1-mic 0.8428,  F1-mac 0.5331
oral,dgl,1,1078,78.8225,0.8428

 F1-mic 0.8433,  F1-mac 0.5286
oral,dgl,1,1079,78.8953,0.8433

epoch:1081/50, Iteration 32/32:training loss 0.5982980728149414
Train F1-mic 0.8435, Train F1-mac 0.5302
 F1-mic 0.8435,  F1-mac 0.5330
oral,dgl,1,1080,78.9682,0.8435

 F1-mic 0.8425,  F1-mac 0.5292
oral,dgl,1,1081,79.0402,0.8425

 F1-mic 0.8441,  F1-mac 0.5318
oral,dgl,1,1082,79.1130,0.8441

 F1-mic 0.8426,  F1-mac 0.5306
oral,dgl,1,1083,79.1859,0.8426

 F1-mic 0.8437,  F1-mac 0.5302
oral,dgl,1,1084,79.2586,0.8437

 F1-mic 0.8434,  F1-mac 0.5327
oral,dgl,1,1085,79.3312,0.8434

 F1-mic 0.8431,  F1-mac 0.5283
oral,dgl,1,1086,79.4041,0.8431

 F1-mic 0.8441,  F1-mac 0.5349
new best val f1: 0.8441023117953764
oral,dgl,1,1087,79.4770,0.8441

 F1-mic 0.8425,  F1-mac 0.5266
oral,dgl,1,1088,79.5499,0.8425

 F1-mic 0.8443,  F1-mac 0.5367
new best val f1: 0.844291311417377
oral,dgl,1,1089,79.6226,0.8443

epoch:1091/50, Iteration 32/32:training loss 0.598188042640686
Train F1-mic 0.8443, Train F1-mac 0.5366
 F1-mic 0.8424,  F1-mac 0.5242
oral,dgl,1,1090,79.6953,0.8424

 F1-mic 0.8443,  F1-mac 0.5369
oral,dgl,1,1091,79.7673,0.8443

 F1-mic 0.8428,  F1-mac 0.5249
oral,dgl,1,1092,79.8402,0.8428

 F1-mic 0.8441,  F1-mac 0.5363
oral,dgl,1,1093,79.9131,0.8441

 F1-mic 0.8435,  F1-mac 0.5282
oral,dgl,1,1094,79.9858,0.8435

 F1-mic 0.8438,  F1-mac 0.5326
oral,dgl,1,1095,80.0585,0.8438

 F1-mic 0.8435,  F1-mac 0.5319
oral,dgl,1,1096,80.1314,0.8435

 F1-mic 0.8437,  F1-mac 0.5299
oral,dgl,1,1097,80.2041,0.8437

 F1-mic 0.8437,  F1-mac 0.5336
oral,dgl,1,1098,80.2770,0.8437

 F1-mic 0.8434,  F1-mac 0.5293
oral,dgl,1,1099,80.3573,0.8434

epoch:1101/50, Iteration 32/32:training loss 0.5964908599853516
Train F1-mic 0.8435, Train F1-mac 0.5300
 F1-mic 0.8442,  F1-mac 0.5345
oral,dgl,1,1100,80.4302,0.8442

 F1-mic 0.8433,  F1-mac 0.5295
oral,dgl,1,1101,80.5023,0.8433

 F1-mic 0.8442,  F1-mac 0.5329
oral,dgl,1,1102,80.5751,0.8442

 F1-mic 0.8435,  F1-mac 0.5319
oral,dgl,1,1103,80.6479,0.8435

 F1-mic 0.8441,  F1-mac 0.5309
oral,dgl,1,1104,80.7206,0.8441

 F1-mic 0.8438,  F1-mac 0.5332
oral,dgl,1,1105,80.7935,0.8438

 F1-mic 0.8438,  F1-mac 0.5294
oral,dgl,1,1106,80.8661,0.8438

 F1-mic 0.8443,  F1-mac 0.5350
oral,dgl,1,1107,80.9390,0.8443

 F1-mic 0.8433,  F1-mac 0.5296
oral,dgl,1,1108,81.0120,0.8433

 F1-mic 0.8446,  F1-mac 0.5338
new best val f1: 0.8445553108893783
oral,dgl,1,1109,81.0849,0.8446

epoch:1111/50, Iteration 32/32:training loss 0.595664918422699
Train F1-mic 0.8446, Train F1-mac 0.5343
 F1-mic 0.8433,  F1-mac 0.5310
oral,dgl,1,1110,81.1576,0.8433

 F1-mic 0.8442,  F1-mac 0.5320
oral,dgl,1,1111,81.2297,0.8442

 F1-mic 0.8438,  F1-mac 0.5333
oral,dgl,1,1112,81.3025,0.8438

 F1-mic 0.8441,  F1-mac 0.5298
oral,dgl,1,1113,81.3751,0.8441

 F1-mic 0.8441,  F1-mac 0.5349
oral,dgl,1,1114,81.4480,0.8441

 F1-mic 0.8435,  F1-mac 0.5293
oral,dgl,1,1115,81.5210,0.8435

 F1-mic 0.8447,  F1-mac 0.5351
new best val f1: 0.8447293105413789
oral,dgl,1,1116,81.5937,0.8447

 F1-mic 0.8429,  F1-mac 0.5297
oral,dgl,1,1117,81.6665,0.8429

 F1-mic 0.8449,  F1-mac 0.5342
new best val f1: 0.8448763102473795
oral,dgl,1,1118,81.7393,0.8449

 F1-mic 0.8429,  F1-mac 0.5309
oral,dgl,1,1119,81.8123,0.8429

epoch:1121/50, Iteration 32/32:training loss 0.595068097114563
Train F1-mic 0.8430, Train F1-mac 0.5314
 F1-mic 0.8447,  F1-mac 0.5333
oral,dgl,1,1120,81.8852,0.8447

 F1-mic 0.8435,  F1-mac 0.5315
oral,dgl,1,1121,81.9572,0.8435

 F1-mic 0.8444,  F1-mac 0.5324
oral,dgl,1,1122,82.0300,0.8444

 F1-mic 0.8442,  F1-mac 0.5332
oral,dgl,1,1123,82.1029,0.8442

 F1-mic 0.8441,  F1-mac 0.5319
oral,dgl,1,1124,82.1756,0.8441

 F1-mic 0.8446,  F1-mac 0.5332
oral,dgl,1,1125,82.2483,0.8446

 F1-mic 0.8434,  F1-mac 0.5306
oral,dgl,1,1126,82.3213,0.8434

 F1-mic 0.8448,  F1-mac 0.5347
oral,dgl,1,1127,82.3940,0.8448

 F1-mic 0.8436,  F1-mac 0.5310
oral,dgl,1,1128,82.4668,0.8436

 F1-mic 0.8446,  F1-mac 0.5338
oral,dgl,1,1129,82.5394,0.8446

epoch:1131/50, Iteration 32/32:training loss 0.5938222408294678
Train F1-mic 0.8447, Train F1-mac 0.5341
 F1-mic 0.8439,  F1-mac 0.5313
oral,dgl,1,1130,82.6123,0.8439

 F1-mic 0.8445,  F1-mac 0.5333
oral,dgl,1,1131,82.6843,0.8445

 F1-mic 0.8443,  F1-mac 0.5327
oral,dgl,1,1132,82.7571,0.8443

 F1-mic 0.8442,  F1-mac 0.5318
oral,dgl,1,1133,82.8299,0.8442

 F1-mic 0.8446,  F1-mac 0.5342
oral,dgl,1,1134,82.9028,0.8446

 F1-mic 0.8441,  F1-mac 0.5302
oral,dgl,1,1135,82.9759,0.8441

 F1-mic 0.8448,  F1-mac 0.5357
oral,dgl,1,1136,83.0487,0.8448

 F1-mic 0.8436,  F1-mac 0.5287
oral,dgl,1,1137,83.1215,0.8436

 F1-mic 0.8451,  F1-mac 0.5379
new best val f1: 0.8450563098873802
oral,dgl,1,1138,83.1944,0.8451

 F1-mic 0.8429,  F1-mac 0.5261
oral,dgl,1,1139,83.2674,0.8429

epoch:1141/50, Iteration 32/32:training loss 0.5940593481063843
Train F1-mic 0.8431, Train F1-mac 0.5274
 F1-mic 0.8455,  F1-mac 0.5386
new best val f1: 0.845491309017382
oral,dgl,1,1140,83.3401,0.8455

 F1-mic 0.8424,  F1-mac 0.5251
oral,dgl,1,1141,83.4122,0.8424

 F1-mic 0.8454,  F1-mac 0.5388
oral,dgl,1,1142,83.4849,0.8454

 F1-mic 0.8430,  F1-mac 0.5262
oral,dgl,1,1143,83.5579,0.8430

 F1-mic 0.8452,  F1-mac 0.5376
oral,dgl,1,1144,83.6309,0.8452

 F1-mic 0.8440,  F1-mac 0.5290
oral,dgl,1,1145,83.7037,0.8440

 F1-mic 0.8448,  F1-mac 0.5359
oral,dgl,1,1146,83.7766,0.8448

 F1-mic 0.8446,  F1-mac 0.5315
oral,dgl,1,1147,83.8495,0.8446

 F1-mic 0.8441,  F1-mac 0.5341
oral,dgl,1,1148,83.9222,0.8441

 F1-mic 0.8450,  F1-mac 0.5323
oral,dgl,1,1149,83.9949,0.8450

epoch:1151/50, Iteration 32/32:training loss 0.5921729207038879
Train F1-mic 0.8451, Train F1-mac 0.5330
 F1-mic 0.8438,  F1-mac 0.5326
oral,dgl,1,1150,84.0681,0.8438

 F1-mic 0.8452,  F1-mac 0.5340
oral,dgl,1,1151,84.1402,0.8452

 F1-mic 0.8442,  F1-mac 0.5314
oral,dgl,1,1152,84.2129,0.8442

 F1-mic 0.8449,  F1-mac 0.5348
oral,dgl,1,1153,84.2856,0.8449

 F1-mic 0.8444,  F1-mac 0.5307
oral,dgl,1,1154,84.3583,0.8444

 F1-mic 0.8448,  F1-mac 0.5364
oral,dgl,1,1155,84.4310,0.8448

 F1-mic 0.8447,  F1-mac 0.5304
oral,dgl,1,1156,84.5039,0.8447

 F1-mic 0.8444,  F1-mac 0.5357
oral,dgl,1,1157,84.5768,0.8444

 F1-mic 0.8450,  F1-mac 0.5307
oral,dgl,1,1158,84.6495,0.8450

 F1-mic 0.8440,  F1-mac 0.5348
oral,dgl,1,1159,84.7222,0.8440

epoch:1161/50, Iteration 32/32:training loss 0.5914049744606018
Train F1-mic 0.8440, Train F1-mac 0.5342
 F1-mic 0.8452,  F1-mac 0.5330
oral,dgl,1,1160,84.7949,0.8452

 F1-mic 0.8441,  F1-mac 0.5331
oral,dgl,1,1161,84.8670,0.8441

 F1-mic 0.8452,  F1-mac 0.5344
oral,dgl,1,1162,84.9397,0.8452

 F1-mic 0.8443,  F1-mac 0.5310
oral,dgl,1,1163,85.0126,0.8443

 F1-mic 0.8452,  F1-mac 0.5370
oral,dgl,1,1164,85.0853,0.8452

 F1-mic 0.8444,  F1-mac 0.5287
oral,dgl,1,1165,85.1581,0.8444

 F1-mic 0.8451,  F1-mac 0.5383
oral,dgl,1,1166,85.2310,0.8451

 F1-mic 0.8444,  F1-mac 0.5262
oral,dgl,1,1167,85.3037,0.8444

 F1-mic 0.8447,  F1-mac 0.5386
oral,dgl,1,1168,85.3764,0.8447

 F1-mic 0.8447,  F1-mac 0.5282
oral,dgl,1,1169,85.4491,0.8447

epoch:1171/50, Iteration 32/32:training loss 0.5911771059036255
Train F1-mic 0.8449, Train F1-mac 0.5287
 F1-mic 0.8443,  F1-mac 0.5374
oral,dgl,1,1170,85.5218,0.8443

 F1-mic 0.8451,  F1-mac 0.5308
oral,dgl,1,1171,85.5939,0.8451

 F1-mic 0.8445,  F1-mac 0.5351
oral,dgl,1,1172,85.6668,0.8445

 F1-mic 0.8450,  F1-mac 0.5341
oral,dgl,1,1173,85.7398,0.8450

 F1-mic 0.8450,  F1-mac 0.5320
oral,dgl,1,1174,85.8127,0.8450

 F1-mic 0.8449,  F1-mac 0.5363
oral,dgl,1,1175,85.8857,0.8449

 F1-mic 0.8451,  F1-mac 0.5314
oral,dgl,1,1176,85.9585,0.8451

 F1-mic 0.8444,  F1-mac 0.5360
oral,dgl,1,1177,86.0313,0.8444

 F1-mic 0.8455,  F1-mac 0.5323
oral,dgl,1,1178,86.1040,0.8455

 F1-mic 0.8435,  F1-mac 0.5350
oral,dgl,1,1179,86.1768,0.8435

epoch:1181/50, Iteration 32/32:training loss 0.5903143286705017
Train F1-mic 0.8435, Train F1-mac 0.5341
 F1-mic 0.8457,  F1-mac 0.5334
new best val f1: 0.8457163085673829
oral,dgl,1,1180,86.2495,0.8457

 F1-mic 0.8436,  F1-mac 0.5336
oral,dgl,1,1181,86.3216,0.8436

 F1-mic 0.8458,  F1-mac 0.5349
new best val f1: 0.8457643084713831
oral,dgl,1,1182,86.3943,0.8458

 F1-mic 0.8441,  F1-mac 0.5317
oral,dgl,1,1183,86.4669,0.8441

 F1-mic 0.8459,  F1-mac 0.5375
new best val f1: 0.8458813082373835
oral,dgl,1,1184,86.5398,0.8459

 F1-mic 0.8439,  F1-mac 0.5281
oral,dgl,1,1185,86.6124,0.8439

 F1-mic 0.8460,  F1-mac 0.5384
new best val f1: 0.8460253079493841
oral,dgl,1,1186,86.6851,0.8460

 F1-mic 0.8442,  F1-mac 0.5285
oral,dgl,1,1187,86.7579,0.8442

 F1-mic 0.8458,  F1-mac 0.5383
oral,dgl,1,1188,86.8307,0.8458

 F1-mic 0.8443,  F1-mac 0.5294
oral,dgl,1,1189,86.9037,0.8443

epoch:1191/50, Iteration 32/32:training loss 0.5891086459159851
Train F1-mic 0.8444, Train F1-mac 0.5297
 F1-mic 0.8459,  F1-mac 0.5375
oral,dgl,1,1190,86.9766,0.8459

 F1-mic 0.8442,  F1-mac 0.5303
oral,dgl,1,1191,87.0487,0.8442

 F1-mic 0.8461,  F1-mac 0.5373
new best val f1: 0.8461393077213847
oral,dgl,1,1192,87.1282,0.8461

 F1-mic 0.8441,  F1-mac 0.5310
oral,dgl,1,1193,87.2009,0.8441

 F1-mic 0.8461,  F1-mac 0.5368
oral,dgl,1,1194,87.2738,0.8461

 F1-mic 0.8441,  F1-mac 0.5313
oral,dgl,1,1195,87.3465,0.8441

 F1-mic 0.8462,  F1-mac 0.5366
new best val f1: 0.8461783076433848
oral,dgl,1,1196,87.4194,0.8462

 F1-mic 0.8446,  F1-mac 0.5329
oral,dgl,1,1197,87.4924,0.8446

 F1-mic 0.8459,  F1-mac 0.5362
oral,dgl,1,1198,87.5654,0.8459

 F1-mic 0.8452,  F1-mac 0.5339
oral,dgl,1,1199,87.6382,0.8452

epoch:1201/50, Iteration 32/32:training loss 0.5876948237419128
Train F1-mic 0.8452, Train F1-mac 0.5334
 F1-mic 0.8454,  F1-mac 0.5352
oral,dgl,1,1200,87.7112,0.8454

 F1-mic 0.8457,  F1-mac 0.5355
oral,dgl,1,1201,87.7833,0.8457

 F1-mic 0.8450,  F1-mac 0.5334
oral,dgl,1,1202,87.8563,0.8450

 F1-mic 0.8460,  F1-mac 0.5361
oral,dgl,1,1203,87.9293,0.8460

 F1-mic 0.8447,  F1-mac 0.5323
oral,dgl,1,1204,88.0020,0.8447

 F1-mic 0.8462,  F1-mac 0.5363
new best val f1: 0.8462323075353849
oral,dgl,1,1205,88.0752,0.8462

 F1-mic 0.8446,  F1-mac 0.5335
oral,dgl,1,1206,88.1479,0.8446

 F1-mic 0.8461,  F1-mac 0.5356
oral,dgl,1,1207,88.2207,0.8461

 F1-mic 0.8446,  F1-mac 0.5343
oral,dgl,1,1208,88.2934,0.8446

 F1-mic 0.8461,  F1-mac 0.5339
oral,dgl,1,1209,88.3663,0.8461

epoch:1211/50, Iteration 32/32:training loss 0.5876205563545227
Train F1-mic 0.8461, Train F1-mac 0.5332
 F1-mic 0.8439,  F1-mac 0.5355
oral,dgl,1,1210,88.4392,0.8439

 F1-mic 0.8460,  F1-mac 0.5325
oral,dgl,1,1211,88.5113,0.8460

 F1-mic 0.8441,  F1-mac 0.5357
oral,dgl,1,1212,88.5843,0.8441

 F1-mic 0.8459,  F1-mac 0.5319
oral,dgl,1,1213,88.6570,0.8459

 F1-mic 0.8447,  F1-mac 0.5374
oral,dgl,1,1214,88.7300,0.8447

 F1-mic 0.8455,  F1-mac 0.5298
oral,dgl,1,1215,88.8027,0.8455

 F1-mic 0.8455,  F1-mac 0.5379
oral,dgl,1,1216,88.8755,0.8455

 F1-mic 0.8451,  F1-mac 0.5298
oral,dgl,1,1217,88.9482,0.8451

 F1-mic 0.8460,  F1-mac 0.5384
oral,dgl,1,1218,89.0210,0.8460

 F1-mic 0.8452,  F1-mac 0.5316
oral,dgl,1,1219,89.0939,0.8452

epoch:1221/50, Iteration 32/32:training loss 0.586178183555603
Train F1-mic 0.8454, Train F1-mac 0.5321
 F1-mic 0.8461,  F1-mac 0.5362
oral,dgl,1,1220,89.1666,0.8461

 F1-mic 0.8455,  F1-mac 0.5350
oral,dgl,1,1221,89.2387,0.8455

 F1-mic 0.8457,  F1-mac 0.5336
oral,dgl,1,1222,89.3114,0.8457

 F1-mic 0.8457,  F1-mac 0.5370
oral,dgl,1,1223,89.3841,0.8457

 F1-mic 0.8455,  F1-mac 0.5309
oral,dgl,1,1224,89.4568,0.8455

 F1-mic 0.8457,  F1-mac 0.5377
oral,dgl,1,1225,89.5295,0.8457

 F1-mic 0.8456,  F1-mac 0.5310
oral,dgl,1,1226,89.6022,0.8456

 F1-mic 0.8457,  F1-mac 0.5370
oral,dgl,1,1227,89.6750,0.8457

 F1-mic 0.8458,  F1-mac 0.5324
oral,dgl,1,1228,89.7477,0.8458

 F1-mic 0.8457,  F1-mac 0.5366
oral,dgl,1,1229,89.8203,0.8457

epoch:1231/50, Iteration 32/32:training loss 0.5852567553520203
Train F1-mic 0.8458, Train F1-mac 0.5356
 F1-mic 0.8459,  F1-mac 0.5344
oral,dgl,1,1230,89.8930,0.8459

 F1-mic 0.8458,  F1-mac 0.5342
oral,dgl,1,1231,89.9651,0.8458

 F1-mic 0.8458,  F1-mac 0.5365
oral,dgl,1,1232,90.0379,0.8458

 F1-mic 0.8459,  F1-mac 0.5331
oral,dgl,1,1233,90.1106,0.8459

 F1-mic 0.8456,  F1-mac 0.5366
oral,dgl,1,1234,90.1833,0.8456

 F1-mic 0.8460,  F1-mac 0.5320
oral,dgl,1,1235,90.2561,0.8460

 F1-mic 0.8454,  F1-mac 0.5370
oral,dgl,1,1236,90.3287,0.8454

 F1-mic 0.8461,  F1-mac 0.5328
oral,dgl,1,1237,90.4017,0.8461

 F1-mic 0.8452,  F1-mac 0.5357
oral,dgl,1,1238,90.4746,0.8452

 F1-mic 0.8466,  F1-mac 0.5357
new best val f1: 0.8466373067253865
oral,dgl,1,1239,90.5476,0.8466

epoch:1241/50, Iteration 32/32:training loss 0.584888756275177
Train F1-mic 0.8466, Train F1-mac 0.5348
 F1-mic 0.8443,  F1-mac 0.5313
oral,dgl,1,1240,90.6204,0.8443

 F1-mic 0.8470,  F1-mac 0.5383
new best val f1: 0.846994306011388
oral,dgl,1,1241,90.6927,0.8470

 F1-mic 0.8432,  F1-mac 0.5280
oral,dgl,1,1242,90.7654,0.8432

 F1-mic 0.8469,  F1-mac 0.5404
oral,dgl,1,1243,90.8383,0.8469

 F1-mic 0.8425,  F1-mac 0.5260
oral,dgl,1,1244,90.9113,0.8425

 F1-mic 0.8469,  F1-mac 0.5414
oral,dgl,1,1245,90.9842,0.8469

 F1-mic 0.8437,  F1-mac 0.5267
oral,dgl,1,1246,91.0572,0.8437

 F1-mic 0.8471,  F1-mac 0.5397
new best val f1: 0.8470843058313884
oral,dgl,1,1247,91.1301,0.8471

 F1-mic 0.8458,  F1-mac 0.5308
oral,dgl,1,1248,91.2028,0.8458

 F1-mic 0.8455,  F1-mac 0.5373
oral,dgl,1,1249,91.2755,0.8455

epoch:1251/50, Iteration 32/32:training loss 0.5840052962303162
Train F1-mic 0.8456, Train F1-mac 0.5360
 F1-mic 0.8469,  F1-mac 0.5351
oral,dgl,1,1250,91.3482,0.8469

 F1-mic 0.8436,  F1-mac 0.5321
oral,dgl,1,1251,91.4203,0.8436

 F1-mic 0.8470,  F1-mac 0.5384
oral,dgl,1,1252,91.4932,0.8470

 F1-mic 0.8435,  F1-mac 0.5291
oral,dgl,1,1253,91.5661,0.8435

 F1-mic 0.8471,  F1-mac 0.5394
new best val f1: 0.8471173057653885
oral,dgl,1,1254,91.6390,0.8471

 F1-mic 0.8455,  F1-mac 0.5308
oral,dgl,1,1255,91.7119,0.8455

 F1-mic 0.8458,  F1-mac 0.5374
oral,dgl,1,1256,91.7847,0.8458

 F1-mic 0.8468,  F1-mac 0.5337
oral,dgl,1,1257,91.8573,0.8468

 F1-mic 0.8435,  F1-mac 0.5338
oral,dgl,1,1258,91.9304,0.8435

 F1-mic 0.8468,  F1-mac 0.5372
oral,dgl,1,1259,92.0033,0.8468

epoch:1261/50, Iteration 32/32:training loss 0.5854806900024414
Train F1-mic 0.8468, Train F1-mac 0.5360
 F1-mic 0.8435,  F1-mac 0.5301
oral,dgl,1,1260,92.0761,0.8435

 F1-mic 0.8473,  F1-mac 0.5393
new best val f1: 0.8473123053753893
oral,dgl,1,1261,92.1482,0.8473

 F1-mic 0.8454,  F1-mac 0.5303
oral,dgl,1,1262,92.2210,0.8454

 F1-mic 0.8462,  F1-mac 0.5382
oral,dgl,1,1263,92.2939,0.8462

 F1-mic 0.8469,  F1-mac 0.5342
oral,dgl,1,1264,92.3667,0.8469

 F1-mic 0.8448,  F1-mac 0.5348
oral,dgl,1,1265,92.4395,0.8448

 F1-mic 0.8471,  F1-mac 0.5367
oral,dgl,1,1266,92.5123,0.8471

 F1-mic 0.8450,  F1-mac 0.5318
oral,dgl,1,1267,92.5854,0.8450

 F1-mic 0.8470,  F1-mac 0.5378
oral,dgl,1,1268,92.6582,0.8470

 F1-mic 0.8459,  F1-mac 0.5320
oral,dgl,1,1269,92.7310,0.8459

epoch:1271/50, Iteration 32/32:training loss 0.5822147727012634
Train F1-mic 0.8461, Train F1-mac 0.5323
 F1-mic 0.8464,  F1-mac 0.5363
oral,dgl,1,1270,92.8038,0.8464

 F1-mic 0.8468,  F1-mac 0.5364
oral,dgl,1,1271,92.8759,0.8468

 F1-mic 0.8456,  F1-mac 0.5329
oral,dgl,1,1272,92.9488,0.8456

 F1-mic 0.8471,  F1-mac 0.5379
oral,dgl,1,1273,93.0218,0.8471

 F1-mic 0.8454,  F1-mac 0.5308
oral,dgl,1,1274,93.0947,0.8454

 F1-mic 0.8470,  F1-mac 0.5386
oral,dgl,1,1275,93.1675,0.8470

 F1-mic 0.8460,  F1-mac 0.5320
oral,dgl,1,1276,93.2402,0.8460

 F1-mic 0.8465,  F1-mac 0.5374
oral,dgl,1,1277,93.3130,0.8465

 F1-mic 0.8469,  F1-mac 0.5348
oral,dgl,1,1278,93.3859,0.8469

 F1-mic 0.8457,  F1-mac 0.5339
oral,dgl,1,1279,93.4587,0.8457

epoch:1281/50, Iteration 32/32:training loss 0.5815140604972839
Train F1-mic 0.8459, Train F1-mac 0.5337
 F1-mic 0.8472,  F1-mac 0.5379
oral,dgl,1,1280,93.5314,0.8472

 F1-mic 0.8457,  F1-mac 0.5323
oral,dgl,1,1281,93.6036,0.8457

 F1-mic 0.8471,  F1-mac 0.5379
oral,dgl,1,1282,93.6763,0.8471

 F1-mic 0.8460,  F1-mac 0.5323
oral,dgl,1,1283,93.7491,0.8460

 F1-mic 0.8468,  F1-mac 0.5377
oral,dgl,1,1284,93.8221,0.8468

 F1-mic 0.8467,  F1-mac 0.5344
oral,dgl,1,1285,93.8949,0.8467

 F1-mic 0.8461,  F1-mac 0.5349
oral,dgl,1,1286,93.9675,0.8461

 F1-mic 0.8472,  F1-mac 0.5370
oral,dgl,1,1287,94.0403,0.8472

 F1-mic 0.8459,  F1-mac 0.5333
oral,dgl,1,1288,94.1130,0.8459

 F1-mic 0.8472,  F1-mac 0.5373
oral,dgl,1,1289,94.1858,0.8472

epoch:1291/50, Iteration 32/32:training loss 0.5806887745857239
Train F1-mic 0.8471, Train F1-mac 0.5366
 F1-mic 0.8463,  F1-mac 0.5333
oral,dgl,1,1290,94.2587,0.8463

 F1-mic 0.8467,  F1-mac 0.5373
oral,dgl,1,1291,94.3307,0.8467

 F1-mic 0.8469,  F1-mac 0.5345
oral,dgl,1,1292,94.4037,0.8469

 F1-mic 0.8463,  F1-mac 0.5369
oral,dgl,1,1293,94.4763,0.8463

 F1-mic 0.8471,  F1-mac 0.5355
oral,dgl,1,1294,94.5491,0.8471

 F1-mic 0.8461,  F1-mac 0.5352
oral,dgl,1,1295,94.6220,0.8461

 F1-mic 0.8472,  F1-mac 0.5354
oral,dgl,1,1296,94.6947,0.8472

 F1-mic 0.8464,  F1-mac 0.5358
oral,dgl,1,1297,94.7675,0.8464

 F1-mic 0.8469,  F1-mac 0.5350
oral,dgl,1,1298,94.8403,0.8469

 F1-mic 0.8469,  F1-mac 0.5360
oral,dgl,1,1299,94.9133,0.8469

epoch:1301/50, Iteration 32/32:training loss 0.5797601938247681
Train F1-mic 0.8470, Train F1-mac 0.5359
 F1-mic 0.8463,  F1-mac 0.5342
oral,dgl,1,1300,94.9863,0.8463

 F1-mic 0.8474,  F1-mac 0.5373
new best val f1: 0.8473903052193895
oral,dgl,1,1301,95.0583,0.8474

 F1-mic 0.8459,  F1-mac 0.5329
oral,dgl,1,1302,95.1312,0.8459

 F1-mic 0.8474,  F1-mac 0.5383
new best val f1: 0.8474413051173898
oral,dgl,1,1303,95.2041,0.8474

 F1-mic 0.8453,  F1-mac 0.5332
oral,dgl,1,1304,95.2770,0.8453

 F1-mic 0.8477,  F1-mac 0.5369
new best val f1: 0.8476813046373908
oral,dgl,1,1305,95.3498,0.8477

 F1-mic 0.8451,  F1-mac 0.5349
oral,dgl,1,1306,95.4225,0.8451

 F1-mic 0.8475,  F1-mac 0.5355
oral,dgl,1,1307,95.4952,0.8475

 F1-mic 0.8458,  F1-mac 0.5366
oral,dgl,1,1308,95.5679,0.8458

 F1-mic 0.8472,  F1-mac 0.5347
oral,dgl,1,1309,95.6408,0.8472

epoch:1311/50, Iteration 32/32:training loss 0.5792730450630188
Train F1-mic 0.8473, Train F1-mac 0.5342
 F1-mic 0.8469,  F1-mac 0.5366
oral,dgl,1,1310,95.7136,0.8469

 F1-mic 0.8466,  F1-mac 0.5346
oral,dgl,1,1311,95.7857,0.8466

 F1-mic 0.8474,  F1-mac 0.5376
oral,dgl,1,1312,95.8585,0.8474

 F1-mic 0.8460,  F1-mac 0.5337
oral,dgl,1,1313,95.9314,0.8460

 F1-mic 0.8477,  F1-mac 0.5375
new best val f1: 0.847729304541391
oral,dgl,1,1314,96.0041,0.8477

 F1-mic 0.8457,  F1-mac 0.5335
oral,dgl,1,1315,96.0768,0.8457

 F1-mic 0.8477,  F1-mac 0.5375
oral,dgl,1,1316,96.1495,0.8477

 F1-mic 0.8462,  F1-mac 0.5343
oral,dgl,1,1317,96.2223,0.8462

 F1-mic 0.8475,  F1-mac 0.5379
oral,dgl,1,1318,96.2952,0.8475

 F1-mic 0.8466,  F1-mac 0.5343
oral,dgl,1,1319,96.3681,0.8466

epoch:1321/50, Iteration 32/32:training loss 0.5784178376197815
Train F1-mic 0.8467, Train F1-mac 0.5340
 F1-mic 0.8473,  F1-mac 0.5363
oral,dgl,1,1320,96.4408,0.8473

 F1-mic 0.8467,  F1-mac 0.5355
oral,dgl,1,1321,96.5129,0.8467

 F1-mic 0.8472,  F1-mac 0.5360
oral,dgl,1,1322,96.5860,0.8472

 F1-mic 0.8473,  F1-mac 0.5360
oral,dgl,1,1323,96.6590,0.8473

 F1-mic 0.8467,  F1-mac 0.5361
oral,dgl,1,1324,96.7318,0.8467

 F1-mic 0.8475,  F1-mac 0.5369
oral,dgl,1,1325,96.8045,0.8475

 F1-mic 0.8465,  F1-mac 0.5347
oral,dgl,1,1326,96.8773,0.8465

 F1-mic 0.8475,  F1-mac 0.5371
oral,dgl,1,1327,96.9500,0.8475

 F1-mic 0.8463,  F1-mac 0.5347
oral,dgl,1,1328,97.0228,0.8463

 F1-mic 0.8478,  F1-mac 0.5374
new best val f1: 0.8478013043973912
oral,dgl,1,1329,97.0957,0.8478

epoch:1331/50, Iteration 32/32:training loss 0.5781005024909973
Train F1-mic 0.8478, Train F1-mac 0.5367
 F1-mic 0.8458,  F1-mac 0.5344
oral,dgl,1,1330,97.1684,0.8458

 F1-mic 0.8478,  F1-mac 0.5373
oral,dgl,1,1331,97.2404,0.8478

 F1-mic 0.8456,  F1-mac 0.5344
oral,dgl,1,1332,97.3133,0.8456

 F1-mic 0.8478,  F1-mac 0.5373
oral,dgl,1,1333,97.3860,0.8478

 F1-mic 0.8463,  F1-mac 0.5346
oral,dgl,1,1334,97.4586,0.8463

 F1-mic 0.8477,  F1-mac 0.5375
oral,dgl,1,1335,97.5313,0.8477

 F1-mic 0.8467,  F1-mac 0.5346
oral,dgl,1,1336,97.6044,0.8467

 F1-mic 0.8476,  F1-mac 0.5386
oral,dgl,1,1337,97.6770,0.8476

 F1-mic 0.8471,  F1-mac 0.5339
oral,dgl,1,1338,97.7500,0.8471

 F1-mic 0.8476,  F1-mac 0.5393
oral,dgl,1,1339,97.8227,0.8476

epoch:1341/50, Iteration 32/32:training loss 0.577022910118103
Train F1-mic 0.8476, Train F1-mac 0.5380
 F1-mic 0.8471,  F1-mac 0.5335
oral,dgl,1,1340,97.8955,0.8471

 F1-mic 0.8475,  F1-mac 0.5393
oral,dgl,1,1341,97.9676,0.8475

 F1-mic 0.8474,  F1-mac 0.5340
oral,dgl,1,1342,98.0402,0.8474

 F1-mic 0.8469,  F1-mac 0.5382
oral,dgl,1,1343,98.1130,0.8469

 F1-mic 0.8479,  F1-mac 0.5357
new best val f1: 0.8478553042893914
oral,dgl,1,1344,98.1857,0.8479

 F1-mic 0.8466,  F1-mac 0.5361
oral,dgl,1,1345,98.2584,0.8466

 F1-mic 0.8479,  F1-mac 0.5379
new best val f1: 0.8478823042353916
oral,dgl,1,1346,98.3311,0.8479

 F1-mic 0.8464,  F1-mac 0.5341
oral,dgl,1,1347,98.4040,0.8464

 F1-mic 0.8479,  F1-mac 0.5392
new best val f1: 0.8479243041513918
oral,dgl,1,1348,98.4768,0.8479

 F1-mic 0.8466,  F1-mac 0.5331
oral,dgl,1,1349,98.5497,0.8466

epoch:1351/50, Iteration 32/32:training loss 0.5766574144363403
Train F1-mic 0.8467, Train F1-mac 0.5325
 F1-mic 0.8479,  F1-mac 0.5403
new best val f1: 0.8479423041153917
oral,dgl,1,1350,98.6224,0.8479

 F1-mic 0.8471,  F1-mac 0.5323
oral,dgl,1,1351,98.6945,0.8471

 F1-mic 0.8475,  F1-mac 0.5409
oral,dgl,1,1352,98.7675,0.8475

 F1-mic 0.8474,  F1-mac 0.5326
oral,dgl,1,1353,98.8406,0.8474

 F1-mic 0.8473,  F1-mac 0.5402
oral,dgl,1,1354,98.9136,0.8473

 F1-mic 0.8477,  F1-mac 0.5343
oral,dgl,1,1355,98.9873,0.8477

 F1-mic 0.8467,  F1-mac 0.5381
oral,dgl,1,1356,99.0602,0.8467

 F1-mic 0.8480,  F1-mac 0.5356
new best val f1: 0.8479543040913918
oral,dgl,1,1357,99.1330,0.8480

 F1-mic 0.8461,  F1-mac 0.5381
oral,dgl,1,1358,99.2058,0.8461

 F1-mic 0.8481,  F1-mac 0.5360
new best val f1: 0.8480953038093924
oral,dgl,1,1359,99.2787,0.8481

epoch:1361/50, Iteration 32/32:training loss 0.5763890147209167
Train F1-mic 0.8480, Train F1-mac 0.5353
 F1-mic 0.8459,  F1-mac 0.5369
oral,dgl,1,1360,99.3517,0.8459

 F1-mic 0.8480,  F1-mac 0.5362
oral,dgl,1,1361,99.4239,0.8480

 F1-mic 0.8465,  F1-mac 0.5355
oral,dgl,1,1362,99.4970,0.8465

 F1-mic 0.8480,  F1-mac 0.5378
oral,dgl,1,1363,99.5699,0.8480

 F1-mic 0.8471,  F1-mac 0.5348
oral,dgl,1,1364,99.6427,0.8471

 F1-mic 0.8476,  F1-mac 0.5393
oral,dgl,1,1365,99.7154,0.8476

 F1-mic 0.8478,  F1-mac 0.5341
oral,dgl,1,1366,99.7883,0.8478

 F1-mic 0.8470,  F1-mac 0.5399
oral,dgl,1,1367,99.8609,0.8470

 F1-mic 0.8478,  F1-mac 0.5340
oral,dgl,1,1368,99.9337,0.8478

 F1-mic 0.8471,  F1-mac 0.5392
oral,dgl,1,1369,100.0064,0.8471

epoch:1371/50, Iteration 32/32:training loss 0.575051486492157
Train F1-mic 0.8472, Train F1-mac 0.5382
 F1-mic 0.8479,  F1-mac 0.5359
oral,dgl,1,1370,100.0791,0.8479

 F1-mic 0.8473,  F1-mac 0.5373
oral,dgl,1,1371,100.1512,0.8473

 F1-mic 0.8478,  F1-mac 0.5371
oral,dgl,1,1372,100.2242,0.8478

 F1-mic 0.8475,  F1-mac 0.5356
oral,dgl,1,1373,100.2970,0.8475

 F1-mic 0.8477,  F1-mac 0.5381
oral,dgl,1,1374,100.3697,0.8477

 F1-mic 0.8476,  F1-mac 0.5357
oral,dgl,1,1375,100.4427,0.8476

 F1-mic 0.8476,  F1-mac 0.5391
oral,dgl,1,1376,100.5153,0.8476

 F1-mic 0.8475,  F1-mac 0.5353
oral,dgl,1,1377,100.5880,0.8475

 F1-mic 0.8478,  F1-mac 0.5378
oral,dgl,1,1378,100.6608,0.8478

 F1-mic 0.8475,  F1-mac 0.5353
oral,dgl,1,1379,100.7335,0.8475

epoch:1381/50, Iteration 32/32:training loss 0.5739452242851257
Train F1-mic 0.8476, Train F1-mac 0.5353
 F1-mic 0.8478,  F1-mac 0.5384
oral,dgl,1,1380,100.8064,0.8478

 F1-mic 0.8477,  F1-mac 0.5357
oral,dgl,1,1381,100.8785,0.8477

 F1-mic 0.8477,  F1-mac 0.5396
oral,dgl,1,1382,100.9513,0.8477

 F1-mic 0.8478,  F1-mac 0.5339
oral,dgl,1,1383,101.0240,0.8478

 F1-mic 0.8477,  F1-mac 0.5407
oral,dgl,1,1384,101.0967,0.8477

 F1-mic 0.8477,  F1-mac 0.5332
oral,dgl,1,1385,101.1694,0.8477

 F1-mic 0.8477,  F1-mac 0.5413
oral,dgl,1,1386,101.2423,0.8477

 F1-mic 0.8477,  F1-mac 0.5329
oral,dgl,1,1387,101.3152,0.8477

 F1-mic 0.8478,  F1-mac 0.5424
oral,dgl,1,1388,101.3880,0.8478

 F1-mic 0.8477,  F1-mac 0.5329
oral,dgl,1,1389,101.4609,0.8477

epoch:1391/50, Iteration 32/32:training loss 0.573889434337616
Train F1-mic 0.8476, Train F1-mac 0.5323
 F1-mic 0.8478,  F1-mac 0.5411
oral,dgl,1,1390,101.5338,0.8478

 F1-mic 0.8478,  F1-mac 0.5342
oral,dgl,1,1391,101.6059,0.8478

 F1-mic 0.8478,  F1-mac 0.5399
oral,dgl,1,1392,101.6788,0.8478

 F1-mic 0.8482,  F1-mac 0.5363
new best val f1: 0.8481613036773926
oral,dgl,1,1393,101.7517,0.8482

 F1-mic 0.8473,  F1-mac 0.5364
oral,dgl,1,1394,101.8247,0.8473

 F1-mic 0.8485,  F1-mac 0.5399
new best val f1: 0.848521302957394
oral,dgl,1,1395,101.8975,0.8485

 F1-mic 0.8466,  F1-mac 0.5327
oral,dgl,1,1396,101.9707,0.8466

 F1-mic 0.8487,  F1-mac 0.5435
new best val f1: 0.8486683026633947
oral,dgl,1,1397,102.0436,0.8487

 F1-mic 0.8449,  F1-mac 0.5278
oral,dgl,1,1398,102.1164,0.8449

 F1-mic 0.8484,  F1-mac 0.5447
oral,dgl,1,1399,102.1891,0.8484

epoch:1401/50, Iteration 32/32:training loss 0.5780255198478699
Train F1-mic 0.8483, Train F1-mac 0.5430
 F1-mic 0.8437,  F1-mac 0.5258
oral,dgl,1,1400,102.2620,0.8437

 F1-mic 0.8482,  F1-mac 0.5453
oral,dgl,1,1401,102.3341,0.8482

 F1-mic 0.8452,  F1-mac 0.5308
oral,dgl,1,1402,102.4070,0.8452

 F1-mic 0.8488,  F1-mac 0.5417
new best val f1: 0.8487973024053952
oral,dgl,1,1403,102.4799,0.8488

 F1-mic 0.8480,  F1-mac 0.5370
oral,dgl,1,1404,102.5526,0.8480

 F1-mic 0.8472,  F1-mac 0.5366
oral,dgl,1,1405,102.6254,0.8472

 F1-mic 0.8488,  F1-mac 0.5410
oral,dgl,1,1406,102.6982,0.8488

 F1-mic 0.8450,  F1-mac 0.5325
oral,dgl,1,1407,102.7711,0.8450

 F1-mic 0.8482,  F1-mac 0.5410
oral,dgl,1,1408,102.8440,0.8482

 F1-mic 0.8450,  F1-mac 0.5342
oral,dgl,1,1409,102.9167,0.8450

epoch:1411/50, Iteration 32/32:training loss 0.5754667520523071
Train F1-mic 0.8452, Train F1-mac 0.5335
 F1-mic 0.8486,  F1-mac 0.5399
oral,dgl,1,1410,102.9895,0.8486

 F1-mic 0.8480,  F1-mac 0.5376
oral,dgl,1,1411,103.0616,0.8480

 F1-mic 0.8468,  F1-mac 0.5370
oral,dgl,1,1412,103.1343,0.8468

 F1-mic 0.8486,  F1-mac 0.5403
oral,dgl,1,1413,103.2072,0.8486

 F1-mic 0.8457,  F1-mac 0.5341
oral,dgl,1,1414,103.2799,0.8457

 F1-mic 0.8488,  F1-mac 0.5402
oral,dgl,1,1415,103.3529,0.8488

 F1-mic 0.8473,  F1-mac 0.5364
oral,dgl,1,1416,103.4257,0.8473

 F1-mic 0.8482,  F1-mac 0.5375
oral,dgl,1,1417,103.4985,0.8482

 F1-mic 0.8486,  F1-mac 0.5392
oral,dgl,1,1418,103.5713,0.8486

 F1-mic 0.8470,  F1-mac 0.5356
oral,dgl,1,1419,103.6442,0.8470

epoch:1421/50, Iteration 32/32:training loss 0.5719094276428223
Train F1-mic 0.8471, Train F1-mac 0.5350
 F1-mic 0.8487,  F1-mac 0.5398
oral,dgl,1,1420,103.7171,0.8487

 F1-mic 0.8465,  F1-mac 0.5366
oral,dgl,1,1421,103.7893,0.8465

 F1-mic 0.8486,  F1-mac 0.5372
oral,dgl,1,1422,103.8623,0.8486

 F1-mic 0.8475,  F1-mac 0.5401
oral,dgl,1,1423,103.9351,0.8475

 F1-mic 0.8483,  F1-mac 0.5363
oral,dgl,1,1424,104.0080,0.8483

 F1-mic 0.8486,  F1-mac 0.5412
oral,dgl,1,1425,104.0809,0.8486

 F1-mic 0.8473,  F1-mac 0.5342
oral,dgl,1,1426,104.1538,0.8473

 F1-mic 0.8490,  F1-mac 0.5418
new best val f1: 0.848995302009396
oral,dgl,1,1427,104.2266,0.8490

 F1-mic 0.8472,  F1-mac 0.5349
oral,dgl,1,1428,104.2993,0.8472

 F1-mic 0.8487,  F1-mac 0.5405
oral,dgl,1,1429,104.3722,0.8487

epoch:1431/50, Iteration 32/32:training loss 0.5708330273628235
Train F1-mic 0.8486, Train F1-mac 0.5397
 F1-mic 0.8481,  F1-mac 0.5367
oral,dgl,1,1430,104.4492,0.8481

 F1-mic 0.8482,  F1-mac 0.5374
oral,dgl,1,1431,104.5212,0.8482

 F1-mic 0.8486,  F1-mac 0.5402
oral,dgl,1,1432,104.5940,0.8486

 F1-mic 0.8478,  F1-mac 0.5343
oral,dgl,1,1433,104.6671,0.8478

 F1-mic 0.8488,  F1-mac 0.5419
oral,dgl,1,1434,104.7400,0.8488

 F1-mic 0.8480,  F1-mac 0.5345
oral,dgl,1,1435,104.8131,0.8480

 F1-mic 0.8486,  F1-mac 0.5409
oral,dgl,1,1436,104.8858,0.8486

 F1-mic 0.8483,  F1-mac 0.5363
oral,dgl,1,1437,104.9585,0.8483

 F1-mic 0.8483,  F1-mac 0.5396
oral,dgl,1,1438,105.0311,0.8483

 F1-mic 0.8487,  F1-mac 0.5382
oral,dgl,1,1439,105.1040,0.8487

epoch:1441/50, Iteration 32/32:training loss 0.5699175000190735
Train F1-mic 0.8486, Train F1-mac 0.5372
 F1-mic 0.8481,  F1-mac 0.5380
oral,dgl,1,1440,105.1767,0.8481

 F1-mic 0.8487,  F1-mac 0.5397
oral,dgl,1,1441,105.2489,0.8487

 F1-mic 0.8483,  F1-mac 0.5367
oral,dgl,1,1442,105.3217,0.8483

 F1-mic 0.8485,  F1-mac 0.5414
oral,dgl,1,1443,105.3943,0.8485

 F1-mic 0.8484,  F1-mac 0.5361
oral,dgl,1,1444,105.4670,0.8484

 F1-mic 0.8485,  F1-mac 0.5398
oral,dgl,1,1445,105.5399,0.8485

 F1-mic 0.8487,  F1-mac 0.5374
oral,dgl,1,1446,105.6128,0.8487

 F1-mic 0.8480,  F1-mac 0.5402
oral,dgl,1,1447,105.6855,0.8480

 F1-mic 0.8489,  F1-mac 0.5379
oral,dgl,1,1448,105.7584,0.8489

 F1-mic 0.8478,  F1-mac 0.5376
oral,dgl,1,1449,105.8311,0.8478

epoch:1451/50, Iteration 32/32:training loss 0.5694552063941956
Train F1-mic 0.8478, Train F1-mac 0.5369
 F1-mic 0.8489,  F1-mac 0.5399
oral,dgl,1,1450,105.9038,0.8489

 F1-mic 0.8482,  F1-mac 0.5377
oral,dgl,1,1451,105.9760,0.8482

 F1-mic 0.8487,  F1-mac 0.5409
oral,dgl,1,1452,106.0488,0.8487

 F1-mic 0.8485,  F1-mac 0.5355
oral,dgl,1,1453,106.1214,0.8485

 F1-mic 0.8486,  F1-mac 0.5418
oral,dgl,1,1454,106.1941,0.8486

 F1-mic 0.8486,  F1-mac 0.5351
oral,dgl,1,1455,106.2669,0.8486

 F1-mic 0.8482,  F1-mac 0.5429
oral,dgl,1,1456,106.3397,0.8482

 F1-mic 0.8487,  F1-mac 0.5343
oral,dgl,1,1457,106.4126,0.8487

 F1-mic 0.8480,  F1-mac 0.5419
oral,dgl,1,1458,106.4855,0.8480

 F1-mic 0.8489,  F1-mac 0.5359
oral,dgl,1,1459,106.5582,0.8489

epoch:1461/50, Iteration 32/32:training loss 0.5691859722137451
Train F1-mic 0.8487, Train F1-mac 0.5353
 F1-mic 0.8481,  F1-mac 0.5416
oral,dgl,1,1460,106.6312,0.8481

 F1-mic 0.8487,  F1-mac 0.5372
oral,dgl,1,1461,106.7032,0.8487

 F1-mic 0.8484,  F1-mac 0.5398
oral,dgl,1,1462,106.7761,0.8484

 F1-mic 0.8489,  F1-mac 0.5383
oral,dgl,1,1463,106.8490,0.8489

 F1-mic 0.8484,  F1-mac 0.5382
oral,dgl,1,1464,106.9217,0.8484

 F1-mic 0.8490,  F1-mac 0.5399
oral,dgl,1,1465,106.9945,0.8490

 F1-mic 0.8487,  F1-mac 0.5372
oral,dgl,1,1466,107.0672,0.8487

 F1-mic 0.8487,  F1-mac 0.5411
oral,dgl,1,1467,107.1399,0.8487

 F1-mic 0.8488,  F1-mac 0.5368
oral,dgl,1,1468,107.2126,0.8488

 F1-mic 0.8488,  F1-mac 0.5412
oral,dgl,1,1469,107.2852,0.8488

epoch:1471/50, Iteration 32/32:training loss 0.5681238770484924
Train F1-mic 0.8486, Train F1-mac 0.5399
 F1-mic 0.8487,  F1-mac 0.5361
oral,dgl,1,1470,107.3579,0.8487

 F1-mic 0.8484,  F1-mac 0.5408
oral,dgl,1,1471,107.4298,0.8484

 F1-mic 0.8491,  F1-mac 0.5371
new best val f1: 0.8490973018053964
oral,dgl,1,1472,107.5029,0.8491

 F1-mic 0.8482,  F1-mac 0.5413
oral,dgl,1,1473,107.5758,0.8482

 F1-mic 0.8490,  F1-mac 0.5377
oral,dgl,1,1474,107.6486,0.8490

 F1-mic 0.8487,  F1-mac 0.5389
oral,dgl,1,1475,107.7213,0.8487

 F1-mic 0.8489,  F1-mac 0.5401
oral,dgl,1,1476,107.7939,0.8489

 F1-mic 0.8489,  F1-mac 0.5376
oral,dgl,1,1477,107.8665,0.8489

 F1-mic 0.8487,  F1-mac 0.5404
oral,dgl,1,1478,107.9393,0.8487

 F1-mic 0.8490,  F1-mac 0.5372
oral,dgl,1,1479,108.0120,0.8490

epoch:1481/50, Iteration 32/32:training loss 0.5675929188728333
Train F1-mic 0.8488, Train F1-mac 0.5363
 F1-mic 0.8483,  F1-mac 0.5403
oral,dgl,1,1480,108.0850,0.8483

 F1-mic 0.8493,  F1-mac 0.5389
new best val f1: 0.8493013013973972
oral,dgl,1,1481,108.1570,0.8493

 F1-mic 0.8483,  F1-mac 0.5379
oral,dgl,1,1482,108.2300,0.8483

 F1-mic 0.8492,  F1-mac 0.5407
oral,dgl,1,1483,108.3030,0.8492

 F1-mic 0.8486,  F1-mac 0.5376
oral,dgl,1,1484,108.3757,0.8486

 F1-mic 0.8491,  F1-mac 0.5417
oral,dgl,1,1485,108.4486,0.8491

 F1-mic 0.8484,  F1-mac 0.5360
oral,dgl,1,1486,108.5213,0.8484

 F1-mic 0.8494,  F1-mac 0.5419
new best val f1: 0.8494213011573977
oral,dgl,1,1487,108.5940,0.8494

 F1-mic 0.8481,  F1-mac 0.5348
oral,dgl,1,1488,108.6670,0.8481

 F1-mic 0.8495,  F1-mac 0.5434
new best val f1: 0.8494843010313979
oral,dgl,1,1489,108.7397,0.8495

epoch:1491/50, Iteration 32/32:training loss 0.5673379898071289
Train F1-mic 0.8492, Train F1-mac 0.5421
 F1-mic 0.8484,  F1-mac 0.5346
oral,dgl,1,1490,108.8127,0.8484

 F1-mic 0.8494,  F1-mac 0.5439
oral,dgl,1,1491,108.8849,0.8494

 F1-mic 0.8486,  F1-mac 0.5340
oral,dgl,1,1492,108.9578,0.8486

 F1-mic 0.8489,  F1-mac 0.5439
oral,dgl,1,1493,109.0306,0.8489

 F1-mic 0.8490,  F1-mac 0.5344
oral,dgl,1,1494,109.1033,0.8490

 F1-mic 0.8487,  F1-mac 0.5414
oral,dgl,1,1495,109.1762,0.8487

 F1-mic 0.8493,  F1-mac 0.5379
oral,dgl,1,1496,109.2491,0.8493

 F1-mic 0.8485,  F1-mac 0.5398
oral,dgl,1,1497,109.3219,0.8485

 F1-mic 0.8494,  F1-mac 0.5396
oral,dgl,1,1498,109.3946,0.8494

 F1-mic 0.8486,  F1-mac 0.5371
oral,dgl,1,1499,109.4674,0.8486

epoch:1501/50, Iteration 32/32:training loss 0.5661863088607788
Train F1-mic 0.8485, Train F1-mac 0.5365
 F1-mic 0.8494,  F1-mac 0.5407
oral,dgl,1,1500,109.5407,0.8494

 F1-mic 0.8486,  F1-mac 0.5366
oral,dgl,1,1501,109.6128,0.8486

 F1-mic 0.8495,  F1-mac 0.5413
oral,dgl,1,1502,109.6855,0.8495

 F1-mic 0.8486,  F1-mac 0.5367
oral,dgl,1,1503,109.7584,0.8486

 F1-mic 0.8495,  F1-mac 0.5408
new best val f1: 0.8495473009053982
oral,dgl,1,1504,109.8311,0.8495

 F1-mic 0.8483,  F1-mac 0.5366
oral,dgl,1,1505,109.9039,0.8483

 F1-mic 0.8496,  F1-mac 0.5411
new best val f1: 0.8495623008753983
oral,dgl,1,1506,109.9767,0.8496

 F1-mic 0.8480,  F1-mac 0.5366
oral,dgl,1,1507,110.0493,0.8480

 F1-mic 0.8495,  F1-mac 0.5392
oral,dgl,1,1508,110.1222,0.8495

 F1-mic 0.8478,  F1-mac 0.5375
oral,dgl,1,1509,110.1949,0.8478

epoch:1511/50, Iteration 32/32:training loss 0.5663669109344482
Train F1-mic 0.8478, Train F1-mac 0.5376
 F1-mic 0.8494,  F1-mac 0.5395
oral,dgl,1,1510,110.2679,0.8494

 F1-mic 0.8475,  F1-mac 0.5368
oral,dgl,1,1511,110.3400,0.8475

 F1-mic 0.8494,  F1-mac 0.5407
oral,dgl,1,1512,110.4129,0.8494

 F1-mic 0.8478,  F1-mac 0.5362
oral,dgl,1,1513,110.4857,0.8478

 F1-mic 0.8497,  F1-mac 0.5419
new best val f1: 0.8497243005513989
oral,dgl,1,1514,110.5586,0.8497

 F1-mic 0.8486,  F1-mac 0.5358
oral,dgl,1,1515,110.6313,0.8486

 F1-mic 0.8496,  F1-mac 0.5416
oral,dgl,1,1516,110.7040,0.8496

 F1-mic 0.8490,  F1-mac 0.5362
oral,dgl,1,1517,110.7767,0.8490

 F1-mic 0.8495,  F1-mac 0.5419
oral,dgl,1,1518,110.8495,0.8495

 F1-mic 0.8494,  F1-mac 0.5369
oral,dgl,1,1519,110.9222,0.8494

epoch:1521/50, Iteration 32/32:training loss 0.5648196339607239
Train F1-mic 0.8491, Train F1-mac 0.5367
 F1-mic 0.8491,  F1-mac 0.5402
oral,dgl,1,1520,110.9949,0.8491

 F1-mic 0.8497,  F1-mac 0.5392
oral,dgl,1,1521,111.0669,0.8497

 F1-mic 0.8488,  F1-mac 0.5376
oral,dgl,1,1522,111.1398,0.8488

 F1-mic 0.8496,  F1-mac 0.5411
oral,dgl,1,1523,111.2125,0.8496

 F1-mic 0.8488,  F1-mac 0.5362
oral,dgl,1,1524,111.2855,0.8488

 F1-mic 0.8497,  F1-mac 0.5424
oral,dgl,1,1525,111.3582,0.8497

 F1-mic 0.8488,  F1-mac 0.5346
oral,dgl,1,1526,111.4308,0.8488

 F1-mic 0.8498,  F1-mac 0.5449
new best val f1: 0.8497693004613991
oral,dgl,1,1527,111.5034,0.8498

 F1-mic 0.8490,  F1-mac 0.5337
oral,dgl,1,1528,111.5761,0.8490

 F1-mic 0.8495,  F1-mac 0.5448
oral,dgl,1,1529,111.6487,0.8495

epoch:1531/50, Iteration 32/32:training loss 0.5650811791419983
Train F1-mic 0.8493, Train F1-mac 0.5434
 F1-mic 0.8490,  F1-mac 0.5337
oral,dgl,1,1530,111.7216,0.8490

 F1-mic 0.8496,  F1-mac 0.5453
oral,dgl,1,1531,111.7938,0.8496

 F1-mic 0.8491,  F1-mac 0.5343
oral,dgl,1,1532,111.8667,0.8491

 F1-mic 0.8493,  F1-mac 0.5433
oral,dgl,1,1533,111.9394,0.8493

 F1-mic 0.8495,  F1-mac 0.5365
oral,dgl,1,1534,112.0122,0.8495

 F1-mic 0.8490,  F1-mac 0.5405
oral,dgl,1,1535,112.0849,0.8490

 F1-mic 0.8498,  F1-mac 0.5404
new best val f1: 0.8498353003293994
oral,dgl,1,1536,112.1575,0.8498

 F1-mic 0.8487,  F1-mac 0.5350
oral,dgl,1,1537,112.2302,0.8487

 F1-mic 0.8499,  F1-mac 0.5450
new best val f1: 0.8499343001313997
oral,dgl,1,1538,112.3029,0.8499

 F1-mic 0.8482,  F1-mac 0.5322
oral,dgl,1,1539,112.3758,0.8482

epoch:1541/50, Iteration 32/32:training loss 0.565249502658844
Train F1-mic 0.8480, Train F1-mac 0.5316
 F1-mic 0.8501,  F1-mac 0.5463
new best val f1: 0.8501082997834004
oral,dgl,1,1540,112.4486,0.8501

 F1-mic 0.8479,  F1-mac 0.5314
oral,dgl,1,1541,112.5205,0.8479

 F1-mic 0.8501,  F1-mac 0.5450
oral,dgl,1,1542,112.5935,0.8501

 F1-mic 0.8483,  F1-mac 0.5350
oral,dgl,1,1543,112.6662,0.8483

 F1-mic 0.8499,  F1-mac 0.5410
oral,dgl,1,1544,112.7391,0.8499

 F1-mic 0.8485,  F1-mac 0.5403
oral,dgl,1,1545,112.8117,0.8485

 F1-mic 0.8497,  F1-mac 0.5366
oral,dgl,1,1546,112.8845,0.8497

 F1-mic 0.8489,  F1-mac 0.5434
oral,dgl,1,1547,112.9573,0.8489

 F1-mic 0.8494,  F1-mac 0.5345
oral,dgl,1,1548,113.0299,0.8494

 F1-mic 0.8492,  F1-mac 0.5440
oral,dgl,1,1549,113.1028,0.8492

epoch:1551/50, Iteration 32/32:training loss 0.5638105869293213
Train F1-mic 0.8490, Train F1-mac 0.5429
 F1-mic 0.8495,  F1-mac 0.5352
oral,dgl,1,1550,113.1755,0.8495

 F1-mic 0.8491,  F1-mac 0.5415
oral,dgl,1,1551,113.2475,0.8491

 F1-mic 0.8499,  F1-mac 0.5391
oral,dgl,1,1552,113.3203,0.8499

 F1-mic 0.8486,  F1-mac 0.5362
oral,dgl,1,1553,113.3932,0.8486

 F1-mic 0.8501,  F1-mac 0.5444
oral,dgl,1,1554,113.4659,0.8501

 F1-mic 0.8477,  F1-mac 0.5328
oral,dgl,1,1555,113.5388,0.8477

 F1-mic 0.8498,  F1-mac 0.5453
oral,dgl,1,1556,113.6115,0.8498

 F1-mic 0.8461,  F1-mac 0.5314
oral,dgl,1,1557,113.6844,0.8461

 F1-mic 0.8492,  F1-mac 0.5427
oral,dgl,1,1558,113.7571,0.8492

 F1-mic 0.8454,  F1-mac 0.5354
oral,dgl,1,1559,113.8298,0.8454

epoch:1561/50, Iteration 32/32:training loss 0.5682856440544128
Train F1-mic 0.8453, Train F1-mac 0.5351
 F1-mic 0.8488,  F1-mac 0.5405
oral,dgl,1,1560,113.9025,0.8488

 F1-mic 0.8475,  F1-mac 0.5392
oral,dgl,1,1561,113.9750,0.8475

 F1-mic 0.8498,  F1-mac 0.5377
oral,dgl,1,1562,114.0479,0.8498

 F1-mic 0.8499,  F1-mac 0.5415
oral,dgl,1,1563,114.1207,0.8499

 F1-mic 0.8480,  F1-mac 0.5368
oral,dgl,1,1564,114.1935,0.8480

 F1-mic 0.8495,  F1-mac 0.5402
oral,dgl,1,1565,114.2661,0.8495

 F1-mic 0.8465,  F1-mac 0.5371
oral,dgl,1,1566,114.3387,0.8465

 F1-mic 0.8495,  F1-mac 0.5400
oral,dgl,1,1567,114.4116,0.8495

 F1-mic 0.8479,  F1-mac 0.5385
oral,dgl,1,1568,114.4844,0.8479

 F1-mic 0.8498,  F1-mac 0.5395
oral,dgl,1,1569,114.5573,0.8498

epoch:1571/50, Iteration 32/32:training loss 0.5619485378265381
Train F1-mic 0.8496, Train F1-mac 0.5398
 F1-mic 0.8500,  F1-mac 0.5390
oral,dgl,1,1570,114.6302,0.8500

 F1-mic 0.8479,  F1-mac 0.5384
oral,dgl,1,1571,114.7023,0.8479

 F1-mic 0.8493,  F1-mac 0.5399
oral,dgl,1,1572,114.7748,0.8493

 F1-mic 0.8471,  F1-mac 0.5376
oral,dgl,1,1573,114.8476,0.8471

 F1-mic 0.8500,  F1-mac 0.5421
oral,dgl,1,1574,114.9206,0.8500

 F1-mic 0.8491,  F1-mac 0.5354
oral,dgl,1,1575,114.9932,0.8491

 F1-mic 0.8495,  F1-mac 0.5432
oral,dgl,1,1576,115.0659,0.8495

 F1-mic 0.8496,  F1-mac 0.5361
oral,dgl,1,1577,115.1389,0.8496

 F1-mic 0.8478,  F1-mac 0.5414
oral,dgl,1,1578,115.2120,0.8478

 F1-mic 0.8498,  F1-mac 0.5389
oral,dgl,1,1579,115.2847,0.8498

epoch:1581/50, Iteration 32/32:training loss 0.562988817691803
Train F1-mic 0.8497, Train F1-mac 0.5388
 F1-mic 0.8485,  F1-mac 0.5367
oral,dgl,1,1580,115.3575,0.8485

 F1-mic 0.8499,  F1-mac 0.5431
oral,dgl,1,1581,115.4295,0.8499

 F1-mic 0.8497,  F1-mac 0.5351
oral,dgl,1,1582,115.5022,0.8497

 F1-mic 0.8489,  F1-mac 0.5435
oral,dgl,1,1583,115.5749,0.8489

 F1-mic 0.8497,  F1-mac 0.5365
oral,dgl,1,1584,115.6476,0.8497

 F1-mic 0.8486,  F1-mac 0.5398
oral,dgl,1,1585,115.7208,0.8486

 F1-mic 0.8502,  F1-mac 0.5405
new best val f1: 0.8502192995614009
oral,dgl,1,1586,115.7937,0.8502

 F1-mic 0.8494,  F1-mac 0.5355
oral,dgl,1,1587,115.8664,0.8494

 F1-mic 0.8498,  F1-mac 0.5439
oral,dgl,1,1588,115.9392,0.8498

 F1-mic 0.8497,  F1-mac 0.5353
oral,dgl,1,1589,116.0119,0.8497

epoch:1591/50, Iteration 32/32:training loss 0.5613937973976135
Train F1-mic 0.8495, Train F1-mac 0.5349
 F1-mic 0.8494,  F1-mac 0.5437
oral,dgl,1,1590,116.0847,0.8494

 F1-mic 0.8499,  F1-mac 0.5380
oral,dgl,1,1591,116.1568,0.8499

 F1-mic 0.8499,  F1-mac 0.5386
oral,dgl,1,1592,116.2298,0.8499

 F1-mic 0.8500,  F1-mac 0.5427
oral,dgl,1,1593,116.3025,0.8500

 F1-mic 0.8496,  F1-mac 0.5351
oral,dgl,1,1594,116.3754,0.8496

 F1-mic 0.8495,  F1-mac 0.5444
oral,dgl,1,1595,116.4481,0.8495

 F1-mic 0.8498,  F1-mac 0.5358
oral,dgl,1,1596,116.5211,0.8498

 F1-mic 0.8496,  F1-mac 0.5421
oral,dgl,1,1597,116.5938,0.8496

 F1-mic 0.8501,  F1-mac 0.5388
oral,dgl,1,1598,116.6667,0.8501

 F1-mic 0.8497,  F1-mac 0.5369
oral,dgl,1,1599,116.7397,0.8497

epoch:1601/50, Iteration 32/32:training loss 0.5600379109382629
Train F1-mic 0.8495, Train F1-mac 0.5374
 F1-mic 0.8500,  F1-mac 0.5442
oral,dgl,1,1600,116.8125,0.8500

 F1-mic 0.8498,  F1-mac 0.5356
oral,dgl,1,1601,116.8845,0.8498

 F1-mic 0.8497,  F1-mac 0.5428
oral,dgl,1,1602,116.9574,0.8497

 F1-mic 0.8499,  F1-mac 0.5373
oral,dgl,1,1603,117.0304,0.8499

 F1-mic 0.8500,  F1-mac 0.5392
oral,dgl,1,1604,117.1031,0.8500

 F1-mic 0.8500,  F1-mac 0.5414
oral,dgl,1,1605,117.1758,0.8500

 F1-mic 0.8498,  F1-mac 0.5372
oral,dgl,1,1606,117.2487,0.8498

 F1-mic 0.8499,  F1-mac 0.5430
oral,dgl,1,1607,117.3214,0.8499

 F1-mic 0.8499,  F1-mac 0.5368
oral,dgl,1,1608,117.3944,0.8499

 F1-mic 0.8501,  F1-mac 0.5413
oral,dgl,1,1609,117.4673,0.8501

epoch:1611/50, Iteration 32/32:training loss 0.5594276785850525
Train F1-mic 0.8497, Train F1-mac 0.5414
 F1-mic 0.8499,  F1-mac 0.5392
oral,dgl,1,1610,117.5400,0.8499

 F1-mic 0.8500,  F1-mac 0.5386
oral,dgl,1,1611,117.6120,0.8500

 F1-mic 0.8497,  F1-mac 0.5424
oral,dgl,1,1612,117.6847,0.8497

 F1-mic 0.8500,  F1-mac 0.5369
oral,dgl,1,1613,117.7575,0.8500

 F1-mic 0.8500,  F1-mac 0.5423
oral,dgl,1,1614,117.8305,0.8500

 F1-mic 0.8498,  F1-mac 0.5374
oral,dgl,1,1615,117.9031,0.8498

 F1-mic 0.8502,  F1-mac 0.5406
oral,dgl,1,1616,117.9760,0.8502

 F1-mic 0.8499,  F1-mac 0.5396
oral,dgl,1,1617,118.0487,0.8499

 F1-mic 0.8500,  F1-mac 0.5384
oral,dgl,1,1618,118.1214,0.8500

 F1-mic 0.8490,  F1-mac 0.5416
oral,dgl,1,1619,118.1943,0.8490

epoch:1621/50, Iteration 32/32:training loss 0.5596398711204529
Train F1-mic 0.8490, Train F1-mac 0.5415
 F1-mic 0.8501,  F1-mac 0.5391
oral,dgl,1,1620,118.2670,0.8501

 F1-mic 0.8486,  F1-mac 0.5391
oral,dgl,1,1621,118.3392,0.8486

 F1-mic 0.8503,  F1-mac 0.5408
new best val f1: 0.850252299495401
oral,dgl,1,1622,118.4124,0.8503

 F1-mic 0.8494,  F1-mac 0.5364
oral,dgl,1,1623,118.4852,0.8494

 F1-mic 0.8502,  F1-mac 0.5434
oral,dgl,1,1624,118.5582,0.8502

 F1-mic 0.8499,  F1-mac 0.5358
oral,dgl,1,1625,118.6309,0.8499

 F1-mic 0.8498,  F1-mac 0.5432
oral,dgl,1,1626,118.7035,0.8498

 F1-mic 0.8502,  F1-mac 0.5382
oral,dgl,1,1627,118.7764,0.8502

 F1-mic 0.8497,  F1-mac 0.5395
oral,dgl,1,1628,118.8491,0.8497

 F1-mic 0.8504,  F1-mac 0.5424
new best val f1: 0.8504112991774017
oral,dgl,1,1629,118.9218,0.8504

epoch:1631/50, Iteration 32/32:training loss 0.5582744479179382
Train F1-mic 0.8501, Train F1-mac 0.5421
 F1-mic 0.8500,  F1-mac 0.5363
oral,dgl,1,1630,118.9945,0.8500

 F1-mic 0.8499,  F1-mac 0.5427
oral,dgl,1,1631,119.0665,0.8499

 F1-mic 0.8501,  F1-mac 0.5370
oral,dgl,1,1632,119.1394,0.8501

 F1-mic 0.8498,  F1-mac 0.5418
oral,dgl,1,1633,119.2123,0.8498

 F1-mic 0.8503,  F1-mac 0.5406
oral,dgl,1,1634,119.2852,0.8503

 F1-mic 0.8498,  F1-mac 0.5371
oral,dgl,1,1635,119.3580,0.8498

 F1-mic 0.8503,  F1-mac 0.5437
oral,dgl,1,1636,119.4306,0.8503

 F1-mic 0.8496,  F1-mac 0.5343
oral,dgl,1,1637,119.5033,0.8496

 F1-mic 0.8503,  F1-mac 0.5448
oral,dgl,1,1638,119.5761,0.8503

 F1-mic 0.8496,  F1-mac 0.5353
oral,dgl,1,1639,119.6488,0.8496

epoch:1641/50, Iteration 32/32:training loss 0.5582171082496643
Train F1-mic 0.8494, Train F1-mac 0.5351
 F1-mic 0.8505,  F1-mac 0.5430
new best val f1: 0.8505402989194023
oral,dgl,1,1640,119.7219,0.8505

 F1-mic 0.8494,  F1-mac 0.5377
oral,dgl,1,1641,119.7941,0.8494

 F1-mic 0.8503,  F1-mac 0.5405
oral,dgl,1,1642,119.8674,0.8503

 F1-mic 0.8492,  F1-mac 0.5397
oral,dgl,1,1643,119.9403,0.8492

 F1-mic 0.8503,  F1-mac 0.5404
oral,dgl,1,1644,120.0130,0.8503

 F1-mic 0.8494,  F1-mac 0.5380
oral,dgl,1,1645,120.0858,0.8494

 F1-mic 0.8506,  F1-mac 0.5416
new best val f1: 0.8505582988834023
oral,dgl,1,1646,120.1586,0.8506

 F1-mic 0.8499,  F1-mac 0.5375
oral,dgl,1,1647,120.2314,0.8499

 F1-mic 0.8503,  F1-mac 0.5423
oral,dgl,1,1648,120.3044,0.8503

 F1-mic 0.8503,  F1-mac 0.5386
oral,dgl,1,1649,120.3771,0.8503

epoch:1651/50, Iteration 32/32:training loss 0.5570500493049622
Train F1-mic 0.8501, Train F1-mac 0.5388
 F1-mic 0.8496,  F1-mac 0.5400
oral,dgl,1,1650,120.4499,0.8496

 F1-mic 0.8503,  F1-mac 0.5408
oral,dgl,1,1651,120.5221,0.8503

 F1-mic 0.8492,  F1-mac 0.5363
oral,dgl,1,1652,120.5951,0.8492

 F1-mic 0.8505,  F1-mac 0.5439
oral,dgl,1,1653,120.6678,0.8505

 F1-mic 0.8494,  F1-mac 0.5348
oral,dgl,1,1654,120.7406,0.8494

 F1-mic 0.8505,  F1-mac 0.5463
oral,dgl,1,1655,120.8136,0.8505

 F1-mic 0.8497,  F1-mac 0.5345
oral,dgl,1,1656,120.8865,0.8497

 F1-mic 0.8502,  F1-mac 0.5440
oral,dgl,1,1657,120.9594,0.8502

 F1-mic 0.8499,  F1-mac 0.5367
oral,dgl,1,1658,121.0322,0.8499

 F1-mic 0.8502,  F1-mac 0.5397
oral,dgl,1,1659,121.1052,0.8502

epoch:1661/50, Iteration 32/32:training loss 0.5558936595916748
Train F1-mic 0.8500, Train F1-mac 0.5405
 F1-mic 0.8501,  F1-mac 0.5422
oral,dgl,1,1660,121.1780,0.8501

 F1-mic 0.8497,  F1-mac 0.5363
oral,dgl,1,1661,121.2501,0.8497

 F1-mic 0.8500,  F1-mac 0.5435
oral,dgl,1,1662,121.3229,0.8500

 F1-mic 0.8496,  F1-mac 0.5364
oral,dgl,1,1663,121.3958,0.8496

 F1-mic 0.8499,  F1-mac 0.5419
oral,dgl,1,1664,121.4687,0.8499

 F1-mic 0.8496,  F1-mac 0.5379
oral,dgl,1,1665,121.5417,0.8496

 F1-mic 0.8497,  F1-mac 0.5390
oral,dgl,1,1666,121.6147,0.8497

 F1-mic 0.8496,  F1-mac 0.5423
oral,dgl,1,1667,121.6875,0.8496

 F1-mic 0.8494,  F1-mac 0.5380
oral,dgl,1,1668,121.7604,0.8494

 F1-mic 0.8497,  F1-mac 0.5416
oral,dgl,1,1669,121.8331,0.8497

epoch:1671/50, Iteration 32/32:training loss 0.5548364520072937
Train F1-mic 0.8495, Train F1-mac 0.5413
 F1-mic 0.8490,  F1-mac 0.5376
oral,dgl,1,1670,121.9059,0.8490

 F1-mic 0.8497,  F1-mac 0.5408
oral,dgl,1,1671,121.9780,0.8497

 F1-mic 0.8485,  F1-mac 0.5392
oral,dgl,1,1672,122.0509,0.8485

 F1-mic 0.8494,  F1-mac 0.5399
oral,dgl,1,1673,122.1237,0.8494

 F1-mic 0.8477,  F1-mac 0.5369
oral,dgl,1,1674,122.1966,0.8477

 F1-mic 0.8493,  F1-mac 0.5414
oral,dgl,1,1675,122.2693,0.8493

 F1-mic 0.8466,  F1-mac 0.5338
oral,dgl,1,1676,122.3420,0.8466

 F1-mic 0.8495,  F1-mac 0.5444
oral,dgl,1,1677,122.4148,0.8495

 F1-mic 0.8467,  F1-mac 0.5303
oral,dgl,1,1678,122.4876,0.8467

 F1-mic 0.8494,  F1-mac 0.5469
oral,dgl,1,1679,122.5604,0.8494

epoch:1681/50, Iteration 32/32:training loss 0.5562798976898193
Train F1-mic 0.8493, Train F1-mac 0.5457
 F1-mic 0.8480,  F1-mac 0.5299
oral,dgl,1,1680,122.6334,0.8480

 F1-mic 0.8494,  F1-mac 0.5452
oral,dgl,1,1681,122.7055,0.8494

 F1-mic 0.8488,  F1-mac 0.5352
oral,dgl,1,1682,122.7782,0.8488

 F1-mic 0.8488,  F1-mac 0.5399
oral,dgl,1,1683,122.8511,0.8488

 F1-mic 0.8493,  F1-mac 0.5425
oral,dgl,1,1684,122.9239,0.8493

 F1-mic 0.8475,  F1-mac 0.5335
oral,dgl,1,1685,122.9966,0.8475

 F1-mic 0.8494,  F1-mac 0.5447
oral,dgl,1,1686,123.0696,0.8494

 F1-mic 0.8469,  F1-mac 0.5320
oral,dgl,1,1687,123.1425,0.8469

 F1-mic 0.8490,  F1-mac 0.5437
oral,dgl,1,1688,123.2153,0.8490

 F1-mic 0.8472,  F1-mac 0.5340
oral,dgl,1,1689,123.2881,0.8472

epoch:1691/50, Iteration 32/32:training loss 0.5540796518325806
Train F1-mic 0.8472, Train F1-mac 0.5351
 F1-mic 0.8491,  F1-mac 0.5422
oral,dgl,1,1690,123.3609,0.8491

 F1-mic 0.8482,  F1-mac 0.5388
oral,dgl,1,1691,123.4332,0.8482

 F1-mic 0.8492,  F1-mac 0.5401
oral,dgl,1,1692,123.5062,0.8492

 F1-mic 0.8490,  F1-mac 0.5403
oral,dgl,1,1693,123.5790,0.8490

 F1-mic 0.8484,  F1-mac 0.5371
oral,dgl,1,1694,123.6520,0.8484

 F1-mic 0.8492,  F1-mac 0.5410
oral,dgl,1,1695,123.7248,0.8492

 F1-mic 0.8477,  F1-mac 0.5363
oral,dgl,1,1696,123.7976,0.8477

 F1-mic 0.8489,  F1-mac 0.5418
oral,dgl,1,1697,123.8706,0.8489

 F1-mic 0.8467,  F1-mac 0.5327
oral,dgl,1,1698,123.9434,0.8467

 F1-mic 0.8489,  F1-mac 0.5429
oral,dgl,1,1699,124.0163,0.8489

epoch:1701/50, Iteration 32/32:training loss 0.5532791614532471
Train F1-mic 0.8489, Train F1-mac 0.5429
 F1-mic 0.8471,  F1-mac 0.5329
oral,dgl,1,1700,124.0890,0.8471

 F1-mic 0.8491,  F1-mac 0.5425
oral,dgl,1,1701,124.1611,0.8491

 F1-mic 0.8484,  F1-mac 0.5362
oral,dgl,1,1702,124.2341,0.8484

 F1-mic 0.8486,  F1-mac 0.5400
oral,dgl,1,1703,124.3070,0.8486

 F1-mic 0.8490,  F1-mac 0.5402
oral,dgl,1,1704,124.3799,0.8490

 F1-mic 0.8477,  F1-mac 0.5350
oral,dgl,1,1705,124.4527,0.8477

 F1-mic 0.8492,  F1-mac 0.5428
oral,dgl,1,1706,124.5255,0.8492

 F1-mic 0.8472,  F1-mac 0.5324
oral,dgl,1,1707,124.5985,0.8472

 F1-mic 0.8492,  F1-mac 0.5436
oral,dgl,1,1708,124.6712,0.8492

 F1-mic 0.8476,  F1-mac 0.5338
oral,dgl,1,1709,124.7440,0.8476

epoch:1711/50, Iteration 32/32:training loss 0.5513449907302856
Train F1-mic 0.8475, Train F1-mac 0.5350
 F1-mic 0.8489,  F1-mac 0.5415
oral,dgl,1,1710,124.8169,0.8489

 F1-mic 0.8486,  F1-mac 0.5398
oral,dgl,1,1711,124.8893,0.8486

 F1-mic 0.8486,  F1-mac 0.5370
oral,dgl,1,1712,124.9623,0.8486

 F1-mic 0.8489,  F1-mac 0.5424
oral,dgl,1,1713,125.0352,0.8489

 F1-mic 0.8479,  F1-mac 0.5351
oral,dgl,1,1714,125.1080,0.8479

 F1-mic 0.8491,  F1-mac 0.5425
oral,dgl,1,1715,125.1808,0.8491

 F1-mic 0.8469,  F1-mac 0.5354
oral,dgl,1,1716,125.2536,0.8469

 F1-mic 0.8487,  F1-mac 0.5395
oral,dgl,1,1717,125.3266,0.8487

 F1-mic 0.8471,  F1-mac 0.5380
oral,dgl,1,1718,125.3993,0.8471

 F1-mic 0.8487,  F1-mac 0.5393
oral,dgl,1,1719,125.4721,0.8487

epoch:1721/50, Iteration 32/32:training loss 0.5500491261482239
Train F1-mic 0.8486, Train F1-mac 0.5401
 F1-mic 0.8482,  F1-mac 0.5398
oral,dgl,1,1720,125.5449,0.8482

 F1-mic 0.8489,  F1-mac 0.5401
oral,dgl,1,1721,125.6173,0.8489

 F1-mic 0.8486,  F1-mac 0.5381
oral,dgl,1,1722,125.6900,0.8486

 F1-mic 0.8483,  F1-mac 0.5408
oral,dgl,1,1723,125.7629,0.8483

 F1-mic 0.8487,  F1-mac 0.5376
oral,dgl,1,1724,125.8356,0.8487

 F1-mic 0.8476,  F1-mac 0.5409
oral,dgl,1,1725,125.9085,0.8476

 F1-mic 0.8488,  F1-mac 0.5402
oral,dgl,1,1726,125.9815,0.8488

 F1-mic 0.8471,  F1-mac 0.5365
oral,dgl,1,1727,126.0543,0.8471

 F1-mic 0.8489,  F1-mac 0.5419
oral,dgl,1,1728,126.1273,0.8489

 F1-mic 0.8478,  F1-mac 0.5359
oral,dgl,1,1729,126.2002,0.8478

epoch:1731/50, Iteration 32/32:training loss 0.5490085482597351
Train F1-mic 0.8477, Train F1-mac 0.5367
 F1-mic 0.8489,  F1-mac 0.5423
oral,dgl,1,1730,126.2730,0.8489

 F1-mic 0.8485,  F1-mac 0.5365
oral,dgl,1,1731,126.3451,0.8485

 F1-mic 0.8489,  F1-mac 0.5423
oral,dgl,1,1732,126.4180,0.8489

 F1-mic 0.8488,  F1-mac 0.5390
oral,dgl,1,1733,126.4908,0.8488

 F1-mic 0.8488,  F1-mac 0.5401
oral,dgl,1,1734,126.5635,0.8488

 F1-mic 0.8490,  F1-mac 0.5407
oral,dgl,1,1735,126.6364,0.8490

 F1-mic 0.8485,  F1-mac 0.5378
oral,dgl,1,1736,126.7092,0.8485

 F1-mic 0.8490,  F1-mac 0.5421
oral,dgl,1,1737,126.7820,0.8490

 F1-mic 0.8487,  F1-mac 0.5380
oral,dgl,1,1738,126.8549,0.8487

 F1-mic 0.8489,  F1-mac 0.5416
oral,dgl,1,1739,126.9276,0.8489

epoch:1741/50, Iteration 32/32:training loss 0.5472649335861206
Train F1-mic 0.8486, Train F1-mac 0.5415
 F1-mic 0.8487,  F1-mac 0.5379
oral,dgl,1,1740,127.0003,0.8487

 F1-mic 0.8490,  F1-mac 0.5417
oral,dgl,1,1741,127.0723,0.8490

 F1-mic 0.8486,  F1-mac 0.5390
oral,dgl,1,1742,127.1451,0.8486

 F1-mic 0.8490,  F1-mac 0.5414
oral,dgl,1,1743,127.2180,0.8490

 F1-mic 0.8488,  F1-mac 0.5407
oral,dgl,1,1744,127.2908,0.8488

 F1-mic 0.8488,  F1-mac 0.5397
oral,dgl,1,1745,127.3635,0.8488

 F1-mic 0.8489,  F1-mac 0.5409
oral,dgl,1,1746,127.4364,0.8489

 F1-mic 0.8489,  F1-mac 0.5398
oral,dgl,1,1747,127.5091,0.8489

 F1-mic 0.8489,  F1-mac 0.5408
oral,dgl,1,1748,127.5818,0.8489

 F1-mic 0.8489,  F1-mac 0.5399
oral,dgl,1,1749,127.6545,0.8489

epoch:1751/50, Iteration 32/32:training loss 0.546236515045166
Train F1-mic 0.8487, Train F1-mac 0.5399
 F1-mic 0.8491,  F1-mac 0.5410
oral,dgl,1,1750,127.7272,0.8491

 F1-mic 0.8487,  F1-mac 0.5408
oral,dgl,1,1751,127.7993,0.8487

 F1-mic 0.8492,  F1-mac 0.5410
oral,dgl,1,1752,127.8720,0.8492

 F1-mic 0.8485,  F1-mac 0.5401
oral,dgl,1,1753,127.9447,0.8485

 F1-mic 0.8492,  F1-mac 0.5418
oral,dgl,1,1754,128.0177,0.8492

 F1-mic 0.8483,  F1-mac 0.5388
oral,dgl,1,1755,128.0906,0.8483

 F1-mic 0.8489,  F1-mac 0.5415
oral,dgl,1,1756,128.1636,0.8489

 F1-mic 0.8481,  F1-mac 0.5390
oral,dgl,1,1757,128.2365,0.8481

 F1-mic 0.8493,  F1-mac 0.5421
oral,dgl,1,1758,128.3092,0.8493

 F1-mic 0.8478,  F1-mac 0.5374
oral,dgl,1,1759,128.3820,0.8478

epoch:1761/50, Iteration 32/32:training loss 0.546542227268219
Train F1-mic 0.8478, Train F1-mac 0.5376
 F1-mic 0.8492,  F1-mac 0.5425
oral,dgl,1,1760,128.4547,0.8492

 F1-mic 0.8476,  F1-mac 0.5361
oral,dgl,1,1761,128.5267,0.8476

 F1-mic 0.8492,  F1-mac 0.5438
oral,dgl,1,1762,128.5994,0.8492

 F1-mic 0.8474,  F1-mac 0.5347
oral,dgl,1,1763,128.6721,0.8474

 F1-mic 0.8493,  F1-mac 0.5439
oral,dgl,1,1764,128.7451,0.8493

 F1-mic 0.8477,  F1-mac 0.5355
oral,dgl,1,1765,128.8179,0.8477

 F1-mic 0.8493,  F1-mac 0.5444
oral,dgl,1,1766,128.8906,0.8493

 F1-mic 0.8483,  F1-mac 0.5370
oral,dgl,1,1767,128.9634,0.8483

 F1-mic 0.8494,  F1-mac 0.5434
oral,dgl,1,1768,129.0362,0.8494

 F1-mic 0.8487,  F1-mac 0.5397
oral,dgl,1,1769,129.1088,0.8487

epoch:1771/50, Iteration 32/32:training loss 0.5448207259178162
Train F1-mic 0.8486, Train F1-mac 0.5395
 F1-mic 0.8494,  F1-mac 0.5418
oral,dgl,1,1770,129.1819,0.8494

 F1-mic 0.8488,  F1-mac 0.5413
oral,dgl,1,1771,129.2540,0.8488

 F1-mic 0.8492,  F1-mac 0.5410
oral,dgl,1,1772,129.3268,0.8492

 F1-mic 0.8492,  F1-mac 0.5425
oral,dgl,1,1773,129.3995,0.8492

 F1-mic 0.8490,  F1-mac 0.5386
oral,dgl,1,1774,129.4722,0.8490

 F1-mic 0.8492,  F1-mac 0.5431
oral,dgl,1,1775,129.5450,0.8492

 F1-mic 0.8492,  F1-mac 0.5399
oral,dgl,1,1776,129.6178,0.8492

 F1-mic 0.8493,  F1-mac 0.5419
oral,dgl,1,1777,129.6908,0.8493

 F1-mic 0.8491,  F1-mac 0.5413
oral,dgl,1,1778,129.7640,0.8491

 F1-mic 0.8493,  F1-mac 0.5402
oral,dgl,1,1779,129.8369,0.8493

epoch:1781/50, Iteration 32/32:training loss 0.5439412593841553
Train F1-mic 0.8491, Train F1-mac 0.5398
 F1-mic 0.8490,  F1-mac 0.5432
oral,dgl,1,1780,129.9097,0.8490

 F1-mic 0.8493,  F1-mac 0.5398
oral,dgl,1,1781,129.9819,0.8493

 F1-mic 0.8489,  F1-mac 0.5422
oral,dgl,1,1782,130.0553,0.8489

 F1-mic 0.8492,  F1-mac 0.5394
oral,dgl,1,1783,130.1282,0.8492

 F1-mic 0.8488,  F1-mac 0.5419
oral,dgl,1,1784,130.2012,0.8488

 F1-mic 0.8494,  F1-mac 0.5422
oral,dgl,1,1785,130.2740,0.8494

 F1-mic 0.8482,  F1-mac 0.5395
oral,dgl,1,1786,130.3468,0.8482

 F1-mic 0.8492,  F1-mac 0.5424
oral,dgl,1,1787,130.4195,0.8492

 F1-mic 0.8473,  F1-mac 0.5356
oral,dgl,1,1788,130.4922,0.8473

 F1-mic 0.8492,  F1-mac 0.5451
oral,dgl,1,1789,130.5652,0.8492

epoch:1791/50, Iteration 32/32:training loss 0.5470161437988281
Train F1-mic 0.8489, Train F1-mac 0.5445
 F1-mic 0.8466,  F1-mac 0.5323
oral,dgl,1,1790,130.6378,0.8466

 F1-mic 0.8494,  F1-mac 0.5460
oral,dgl,1,1791,130.7099,0.8494

 F1-mic 0.8478,  F1-mac 0.5338
oral,dgl,1,1792,130.7828,0.8478

 F1-mic 0.8495,  F1-mac 0.5446
oral,dgl,1,1793,130.8555,0.8495

 F1-mic 0.8492,  F1-mac 0.5396
oral,dgl,1,1794,130.9283,0.8492

 F1-mic 0.8489,  F1-mac 0.5409
oral,dgl,1,1795,131.0012,0.8489

 F1-mic 0.8496,  F1-mac 0.5437
oral,dgl,1,1796,131.0739,0.8496

 F1-mic 0.8474,  F1-mac 0.5344
oral,dgl,1,1797,131.1467,0.8474

 F1-mic 0.8494,  F1-mac 0.5461
oral,dgl,1,1798,131.2194,0.8494

 F1-mic 0.8471,  F1-mac 0.5345
oral,dgl,1,1799,131.2924,0.8471

epoch:1801/50, Iteration 32/32:training loss 0.5458048582077026
Train F1-mic 0.8471, Train F1-mac 0.5345
 F1-mic 0.8494,  F1-mac 0.5439
oral,dgl,1,1800,131.3654,0.8494

 F1-mic 0.8488,  F1-mac 0.5396
oral,dgl,1,1801,131.4375,0.8488

 F1-mic 0.8492,  F1-mac 0.5411
oral,dgl,1,1802,131.5105,0.8492

 F1-mic 0.8496,  F1-mac 0.5442
oral,dgl,1,1803,131.5835,0.8496

 F1-mic 0.8477,  F1-mac 0.5358
oral,dgl,1,1804,131.6564,0.8477

 F1-mic 0.8494,  F1-mac 0.5447
oral,dgl,1,1805,131.7292,0.8494

 F1-mic 0.8473,  F1-mac 0.5354
oral,dgl,1,1806,131.8021,0.8473

 F1-mic 0.8494,  F1-mac 0.5438
oral,dgl,1,1807,131.8749,0.8494

 F1-mic 0.8487,  F1-mac 0.5395
oral,dgl,1,1808,131.9477,0.8487

 F1-mic 0.8496,  F1-mac 0.5423
oral,dgl,1,1809,132.0206,0.8496

epoch:1811/50, Iteration 32/32:training loss 0.541749894618988
Train F1-mic 0.8493, Train F1-mac 0.5414
 F1-mic 0.8496,  F1-mac 0.5435
oral,dgl,1,1810,132.0935,0.8496

 F1-mic 0.8483,  F1-mac 0.5380
oral,dgl,1,1811,132.1656,0.8483

 F1-mic 0.8495,  F1-mac 0.5436
oral,dgl,1,1812,132.2383,0.8495

 F1-mic 0.8480,  F1-mac 0.5374
oral,dgl,1,1813,132.3110,0.8480

 F1-mic 0.8495,  F1-mac 0.5436
oral,dgl,1,1814,132.3837,0.8495

 F1-mic 0.8487,  F1-mac 0.5404
oral,dgl,1,1815,132.4565,0.8487

 F1-mic 0.8495,  F1-mac 0.5414
oral,dgl,1,1816,132.5293,0.8495

 F1-mic 0.8498,  F1-mac 0.5437
oral,dgl,1,1817,132.6021,0.8498

 F1-mic 0.8490,  F1-mac 0.5389
oral,dgl,1,1818,132.6750,0.8490

 F1-mic 0.8497,  F1-mac 0.5445
oral,dgl,1,1819,132.7477,0.8497

epoch:1821/50, Iteration 32/32:training loss 0.5416979193687439
Train F1-mic 0.8495, Train F1-mac 0.5440
 F1-mic 0.8486,  F1-mac 0.5378
oral,dgl,1,1820,132.8207,0.8486

 F1-mic 0.8499,  F1-mac 0.5446
oral,dgl,1,1821,132.8928,0.8499

 F1-mic 0.8491,  F1-mac 0.5403
oral,dgl,1,1822,132.9655,0.8491

 F1-mic 0.8497,  F1-mac 0.5427
oral,dgl,1,1823,133.0384,0.8497

 F1-mic 0.8497,  F1-mac 0.5433
oral,dgl,1,1824,133.1112,0.8497

 F1-mic 0.8490,  F1-mac 0.5403
oral,dgl,1,1825,133.1842,0.8490

 F1-mic 0.8499,  F1-mac 0.5440
oral,dgl,1,1826,133.2569,0.8499

 F1-mic 0.8492,  F1-mac 0.5395
oral,dgl,1,1827,133.3298,0.8492

 F1-mic 0.8498,  F1-mac 0.5435
oral,dgl,1,1828,133.4027,0.8498

 F1-mic 0.8495,  F1-mac 0.5413
oral,dgl,1,1829,133.4756,0.8495

epoch:1831/50, Iteration 32/32:training loss 0.540428102016449
Train F1-mic 0.8493, Train F1-mac 0.5404
 F1-mic 0.8496,  F1-mac 0.5434
oral,dgl,1,1830,133.5483,0.8496

 F1-mic 0.8498,  F1-mac 0.5425
oral,dgl,1,1831,133.6204,0.8498

 F1-mic 0.8493,  F1-mac 0.5425
oral,dgl,1,1832,133.6932,0.8493

 F1-mic 0.8497,  F1-mac 0.5423
oral,dgl,1,1833,133.7659,0.8497

 F1-mic 0.8491,  F1-mac 0.5421
oral,dgl,1,1834,133.8388,0.8491

 F1-mic 0.8496,  F1-mac 0.5418
oral,dgl,1,1835,133.9115,0.8496

 F1-mic 0.8492,  F1-mac 0.5430
oral,dgl,1,1836,133.9845,0.8492

 F1-mic 0.8496,  F1-mac 0.5405
oral,dgl,1,1837,134.0575,0.8496

 F1-mic 0.8494,  F1-mac 0.5435
oral,dgl,1,1838,134.1305,0.8494

 F1-mic 0.8497,  F1-mac 0.5413
oral,dgl,1,1839,134.2033,0.8497

epoch:1841/50, Iteration 32/32:training loss 0.5398276448249817
Train F1-mic 0.8494, Train F1-mac 0.5406
 F1-mic 0.8498,  F1-mac 0.5429
oral,dgl,1,1840,134.2761,0.8498

 F1-mic 0.8494,  F1-mac 0.5423
oral,dgl,1,1841,134.3481,0.8494

 F1-mic 0.8500,  F1-mac 0.5431
oral,dgl,1,1842,134.4208,0.8500

 F1-mic 0.8493,  F1-mac 0.5407
oral,dgl,1,1843,134.4937,0.8493

 F1-mic 0.8498,  F1-mac 0.5433
oral,dgl,1,1844,134.5664,0.8498

 F1-mic 0.8488,  F1-mac 0.5393
oral,dgl,1,1845,134.6393,0.8488

 F1-mic 0.8499,  F1-mac 0.5447
oral,dgl,1,1846,134.7121,0.8499

 F1-mic 0.8485,  F1-mac 0.5387
oral,dgl,1,1847,134.7849,0.8485

 F1-mic 0.8500,  F1-mac 0.5444
oral,dgl,1,1848,134.8578,0.8500

 F1-mic 0.8490,  F1-mac 0.5405
oral,dgl,1,1849,134.9308,0.8490

epoch:1851/50, Iteration 32/32:training loss 0.5396546125411987
Train F1-mic 0.8490, Train F1-mac 0.5398
 F1-mic 0.8498,  F1-mac 0.5427
oral,dgl,1,1850,135.0036,0.8498

 F1-mic 0.8497,  F1-mac 0.5431
oral,dgl,1,1851,135.0757,0.8497

 F1-mic 0.8496,  F1-mac 0.5415
oral,dgl,1,1852,135.1486,0.8496

 F1-mic 0.8499,  F1-mac 0.5437
oral,dgl,1,1853,135.2213,0.8499

 F1-mic 0.8492,  F1-mac 0.5399
oral,dgl,1,1854,135.2941,0.8492

 F1-mic 0.8501,  F1-mac 0.5445
oral,dgl,1,1855,135.3668,0.8501

 F1-mic 0.8492,  F1-mac 0.5396
oral,dgl,1,1856,135.4395,0.8492

 F1-mic 0.8501,  F1-mac 0.5447
oral,dgl,1,1857,135.5124,0.8501

 F1-mic 0.8493,  F1-mac 0.5394
oral,dgl,1,1858,135.5854,0.8493

 F1-mic 0.8499,  F1-mac 0.5445
oral,dgl,1,1859,135.6582,0.8499

epoch:1861/50, Iteration 32/32:training loss 0.5386776924133301
Train F1-mic 0.8496, Train F1-mac 0.5440
 F1-mic 0.8496,  F1-mac 0.5406
oral,dgl,1,1860,135.7312,0.8496

 F1-mic 0.8499,  F1-mac 0.5439
oral,dgl,1,1861,135.8034,0.8499

 F1-mic 0.8497,  F1-mac 0.5407
oral,dgl,1,1862,135.8762,0.8497

 F1-mic 0.8498,  F1-mac 0.5432
oral,dgl,1,1863,135.9493,0.8498

 F1-mic 0.8500,  F1-mac 0.5434
oral,dgl,1,1864,136.0224,0.8500

 F1-mic 0.8496,  F1-mac 0.5408
oral,dgl,1,1865,136.0972,0.8496

 F1-mic 0.8500,  F1-mac 0.5445
oral,dgl,1,1866,136.1701,0.8500

 F1-mic 0.8494,  F1-mac 0.5394
oral,dgl,1,1867,136.2428,0.8494

 F1-mic 0.8499,  F1-mac 0.5458
oral,dgl,1,1868,136.3159,0.8499

 F1-mic 0.8493,  F1-mac 0.5373
oral,dgl,1,1869,136.3886,0.8493

epoch:1871/50, Iteration 32/32:training loss 0.5384652018547058
Train F1-mic 0.8494, Train F1-mac 0.5375
 F1-mic 0.8502,  F1-mac 0.5466
oral,dgl,1,1870,136.4613,0.8502

 F1-mic 0.8490,  F1-mac 0.5361
oral,dgl,1,1871,136.5334,0.8490

 F1-mic 0.8503,  F1-mac 0.5469
oral,dgl,1,1872,136.6062,0.8503

 F1-mic 0.8490,  F1-mac 0.5367
oral,dgl,1,1873,136.6791,0.8490

 F1-mic 0.8503,  F1-mac 0.5469
oral,dgl,1,1874,136.7520,0.8503

 F1-mic 0.8492,  F1-mac 0.5371
oral,dgl,1,1875,136.8247,0.8492

 F1-mic 0.8501,  F1-mac 0.5455
oral,dgl,1,1876,136.8977,0.8501

 F1-mic 0.8494,  F1-mac 0.5400
oral,dgl,1,1877,136.9749,0.8494

 F1-mic 0.8501,  F1-mac 0.5437
oral,dgl,1,1878,137.0477,0.8501

 F1-mic 0.8499,  F1-mac 0.5440
oral,dgl,1,1879,137.1204,0.8499

epoch:1881/50, Iteration 32/32:training loss 0.5373842120170593
Train F1-mic 0.8497, Train F1-mac 0.5430
 F1-mic 0.8496,  F1-mac 0.5413
oral,dgl,1,1880,137.1931,0.8496

 F1-mic 0.8503,  F1-mac 0.5446
oral,dgl,1,1881,137.2651,0.8503

 F1-mic 0.8494,  F1-mac 0.5400
oral,dgl,1,1882,137.3378,0.8494

 F1-mic 0.8502,  F1-mac 0.5448
oral,dgl,1,1883,137.4108,0.8502

 F1-mic 0.8495,  F1-mac 0.5392
oral,dgl,1,1884,137.4837,0.8495

 F1-mic 0.8500,  F1-mac 0.5448
oral,dgl,1,1885,137.5566,0.8500

 F1-mic 0.8496,  F1-mac 0.5393
oral,dgl,1,1886,137.6293,0.8496

 F1-mic 0.8499,  F1-mac 0.5449
oral,dgl,1,1887,137.7021,0.8499

 F1-mic 0.8499,  F1-mac 0.5407
oral,dgl,1,1888,137.7750,0.8499

 F1-mic 0.8499,  F1-mac 0.5438
oral,dgl,1,1889,137.8476,0.8499

epoch:1891/50, Iteration 32/32:training loss 0.5369012951850891
Train F1-mic 0.8497, Train F1-mac 0.5431
 F1-mic 0.8501,  F1-mac 0.5423
oral,dgl,1,1890,137.9204,0.8501

 F1-mic 0.8497,  F1-mac 0.5424
oral,dgl,1,1891,137.9925,0.8497

 F1-mic 0.8501,  F1-mac 0.5430
oral,dgl,1,1892,138.0655,0.8501

 F1-mic 0.8498,  F1-mac 0.5416
oral,dgl,1,1893,138.1382,0.8498

 F1-mic 0.8500,  F1-mac 0.5440
oral,dgl,1,1894,138.2109,0.8500

 F1-mic 0.8500,  F1-mac 0.5407
oral,dgl,1,1895,138.2839,0.8500

 F1-mic 0.8498,  F1-mac 0.5444
oral,dgl,1,1896,138.3565,0.8498

 F1-mic 0.8501,  F1-mac 0.5405
oral,dgl,1,1897,138.4292,0.8501

 F1-mic 0.8497,  F1-mac 0.5435
oral,dgl,1,1898,138.5019,0.8497

 F1-mic 0.8501,  F1-mac 0.5416
oral,dgl,1,1899,138.5747,0.8501

epoch:1901/50, Iteration 32/32:training loss 0.5363019108772278
Train F1-mic 0.8499, Train F1-mac 0.5416
 F1-mic 0.8499,  F1-mac 0.5429
oral,dgl,1,1900,138.6477,0.8499

 F1-mic 0.8501,  F1-mac 0.5434
oral,dgl,1,1901,138.7198,0.8501

 F1-mic 0.8501,  F1-mac 0.5419
oral,dgl,1,1902,138.7925,0.8501

 F1-mic 0.8500,  F1-mac 0.5440
oral,dgl,1,1903,138.8654,0.8500

 F1-mic 0.8500,  F1-mac 0.5403
oral,dgl,1,1904,138.9384,0.8500

 F1-mic 0.8500,  F1-mac 0.5446
oral,dgl,1,1905,139.0112,0.8500

 F1-mic 0.8499,  F1-mac 0.5392
oral,dgl,1,1906,139.0839,0.8499

 F1-mic 0.8499,  F1-mac 0.5456
oral,dgl,1,1907,139.1566,0.8499

 F1-mic 0.8498,  F1-mac 0.5379
oral,dgl,1,1908,139.2294,0.8498

 F1-mic 0.8499,  F1-mac 0.5464
oral,dgl,1,1909,139.3021,0.8499

epoch:1911/50, Iteration 32/32:training loss 0.5362988710403442
Train F1-mic 0.8498, Train F1-mac 0.5453
 F1-mic 0.8497,  F1-mac 0.5374
oral,dgl,1,1910,139.3748,0.8497

 F1-mic 0.8500,  F1-mac 0.5460
oral,dgl,1,1911,139.4470,0.8500

 F1-mic 0.8498,  F1-mac 0.5380
oral,dgl,1,1912,139.5200,0.8498

 F1-mic 0.8500,  F1-mac 0.5464
oral,dgl,1,1913,139.5929,0.8500

 F1-mic 0.8498,  F1-mac 0.5375
oral,dgl,1,1914,139.6656,0.8498

 F1-mic 0.8502,  F1-mac 0.5467
oral,dgl,1,1915,139.7383,0.8502

 F1-mic 0.8496,  F1-mac 0.5369
oral,dgl,1,1916,139.8110,0.8496

 F1-mic 0.8505,  F1-mac 0.5461
oral,dgl,1,1917,139.8837,0.8505

 F1-mic 0.8494,  F1-mac 0.5381
oral,dgl,1,1918,139.9564,0.8494

 F1-mic 0.8506,  F1-mac 0.5458
oral,dgl,1,1919,140.0292,0.8506

epoch:1921/50, Iteration 32/32:training loss 0.5360335111618042
Train F1-mic 0.8502, Train F1-mac 0.5451
 F1-mic 0.8490,  F1-mac 0.5387
oral,dgl,1,1920,140.1020,0.8490

 F1-mic 0.8501,  F1-mac 0.5446
oral,dgl,1,1921,140.1741,0.8501

 F1-mic 0.8486,  F1-mac 0.5403
oral,dgl,1,1922,140.2470,0.8486

 F1-mic 0.8499,  F1-mac 0.5433
oral,dgl,1,1923,140.3198,0.8499

 F1-mic 0.8481,  F1-mac 0.5405
oral,dgl,1,1924,140.3928,0.8481

 F1-mic 0.8500,  F1-mac 0.5441
oral,dgl,1,1925,140.4657,0.8500

 F1-mic 0.8487,  F1-mac 0.5386
oral,dgl,1,1926,140.5387,0.8487

 F1-mic 0.8505,  F1-mac 0.5461
oral,dgl,1,1927,140.6115,0.8505

 F1-mic 0.8497,  F1-mac 0.5379
oral,dgl,1,1928,140.6844,0.8497

 F1-mic 0.8503,  F1-mac 0.5458
oral,dgl,1,1929,140.7571,0.8503

epoch:1931/50, Iteration 32/32:training loss 0.5349016189575195
Train F1-mic 0.8501, Train F1-mac 0.5452
 F1-mic 0.8501,  F1-mac 0.5390
oral,dgl,1,1930,140.8297,0.8501

 F1-mic 0.8495,  F1-mac 0.5436
oral,dgl,1,1931,140.9019,0.8495

 F1-mic 0.8502,  F1-mac 0.5420
oral,dgl,1,1932,140.9747,0.8502

 F1-mic 0.8489,  F1-mac 0.5410
oral,dgl,1,1933,141.0473,0.8489

 F1-mic 0.8502,  F1-mac 0.5447
oral,dgl,1,1934,141.1201,0.8502

 F1-mic 0.8487,  F1-mac 0.5375
oral,dgl,1,1935,141.1929,0.8487

 F1-mic 0.8506,  F1-mac 0.5464
new best val f1: 0.8506002987994022
oral,dgl,1,1936,141.2658,0.8506

 F1-mic 0.8492,  F1-mac 0.5347
oral,dgl,1,1937,141.3387,0.8492

 F1-mic 0.8504,  F1-mac 0.5478
oral,dgl,1,1938,141.4114,0.8504

 F1-mic 0.8498,  F1-mac 0.5352
oral,dgl,1,1939,141.4840,0.8498

epoch:1941/50, Iteration 32/32:training loss 0.5356976985931396
Train F1-mic 0.8496, Train F1-mac 0.5352
 F1-mic 0.8498,  F1-mac 0.5459
oral,dgl,1,1940,141.5569,0.8498

 F1-mic 0.8502,  F1-mac 0.5397
oral,dgl,1,1941,141.6292,0.8502

 F1-mic 0.8494,  F1-mac 0.5415
oral,dgl,1,1942,141.7020,0.8494

 F1-mic 0.8505,  F1-mac 0.5454
oral,dgl,1,1943,141.7749,0.8505

 F1-mic 0.8493,  F1-mac 0.5373
oral,dgl,1,1944,141.8476,0.8493

 F1-mic 0.8506,  F1-mac 0.5466
new best val f1: 0.8506272987454025
oral,dgl,1,1945,141.9205,0.8506

 F1-mic 0.8496,  F1-mac 0.5364
oral,dgl,1,1946,141.9934,0.8496

 F1-mic 0.8506,  F1-mac 0.5467
oral,dgl,1,1947,142.0663,0.8506

 F1-mic 0.8499,  F1-mac 0.5381
oral,dgl,1,1948,142.1392,0.8499

 F1-mic 0.8505,  F1-mac 0.5442
oral,dgl,1,1949,142.2118,0.8505

epoch:1951/50, Iteration 32/32:training loss 0.5335506796836853
Train F1-mic 0.8503, Train F1-mac 0.5442
 F1-mic 0.8503,  F1-mac 0.5432
oral,dgl,1,1950,142.2845,0.8503

 F1-mic 0.8501,  F1-mac 0.5407
oral,dgl,1,1951,142.3566,0.8501

 F1-mic 0.8505,  F1-mac 0.5457
oral,dgl,1,1952,142.4296,0.8505

 F1-mic 0.8498,  F1-mac 0.5380
oral,dgl,1,1953,142.5023,0.8498

 F1-mic 0.8505,  F1-mac 0.5452
oral,dgl,1,1954,142.5753,0.8505

 F1-mic 0.8498,  F1-mac 0.5392
oral,dgl,1,1955,142.6483,0.8498

 F1-mic 0.8506,  F1-mac 0.5440
oral,dgl,1,1956,142.7210,0.8506

 F1-mic 0.8496,  F1-mac 0.5417
oral,dgl,1,1957,142.7937,0.8496

 F1-mic 0.8503,  F1-mac 0.5422
oral,dgl,1,1958,142.8667,0.8503

 F1-mic 0.8499,  F1-mac 0.5436
oral,dgl,1,1959,142.9398,0.8499

epoch:1961/50, Iteration 32/32:training loss 0.5335196256637573
Train F1-mic 0.8499, Train F1-mac 0.5434
 F1-mic 0.8504,  F1-mac 0.5410
oral,dgl,1,1960,143.0125,0.8504

 F1-mic 0.8502,  F1-mac 0.5421
oral,dgl,1,1961,143.0845,0.8502

 F1-mic 0.8504,  F1-mac 0.5428
oral,dgl,1,1962,143.1575,0.8504

 F1-mic 0.8502,  F1-mac 0.5415
oral,dgl,1,1963,143.2302,0.8502

 F1-mic 0.8504,  F1-mac 0.5440
oral,dgl,1,1964,143.3032,0.8504

 F1-mic 0.8503,  F1-mac 0.5392
oral,dgl,1,1965,143.3761,0.8503

 F1-mic 0.8503,  F1-mac 0.5446
oral,dgl,1,1966,143.4488,0.8503

 F1-mic 0.8503,  F1-mac 0.5402
oral,dgl,1,1967,143.5215,0.8503

 F1-mic 0.8504,  F1-mac 0.5434
oral,dgl,1,1968,143.5942,0.8504

 F1-mic 0.8503,  F1-mac 0.5417
oral,dgl,1,1969,143.6669,0.8503

epoch:1971/50, Iteration 32/32:training loss 0.5323569774627686
Train F1-mic 0.8502, Train F1-mac 0.5420
 F1-mic 0.8505,  F1-mac 0.5421
oral,dgl,1,1970,143.7397,0.8505

 F1-mic 0.8503,  F1-mac 0.5426
oral,dgl,1,1971,143.8117,0.8503

 F1-mic 0.8504,  F1-mac 0.5412
oral,dgl,1,1972,143.8846,0.8504

 F1-mic 0.8505,  F1-mac 0.5435
oral,dgl,1,1973,143.9573,0.8505

 F1-mic 0.8503,  F1-mac 0.5407
oral,dgl,1,1974,144.0301,0.8503

 F1-mic 0.8505,  F1-mac 0.5444
oral,dgl,1,1975,144.1030,0.8505

 F1-mic 0.8503,  F1-mac 0.5395
oral,dgl,1,1976,144.1757,0.8503

 F1-mic 0.8505,  F1-mac 0.5441
oral,dgl,1,1977,144.2483,0.8505

 F1-mic 0.8503,  F1-mac 0.5398
oral,dgl,1,1978,144.3212,0.8503

 F1-mic 0.8507,  F1-mac 0.5442
new best val f1: 0.8506602986794026
oral,dgl,1,1979,144.3940,0.8507

epoch:1981/50, Iteration 32/32:training loss 0.5320295691490173
Train F1-mic 0.8505, Train F1-mac 0.5441
 F1-mic 0.8498,  F1-mac 0.5400
oral,dgl,1,1980,144.4668,0.8498

 F1-mic 0.8507,  F1-mac 0.5450
new best val f1: 0.8507352985294031
oral,dgl,1,1981,144.5389,0.8507

 F1-mic 0.8490,  F1-mac 0.5391
oral,dgl,1,1982,144.6118,0.8490

 F1-mic 0.8504,  F1-mac 0.5446
oral,dgl,1,1983,144.6847,0.8504

 F1-mic 0.8482,  F1-mac 0.5384
oral,dgl,1,1984,144.7576,0.8482

 F1-mic 0.8503,  F1-mac 0.5451
oral,dgl,1,1985,144.8305,0.8503

 F1-mic 0.8484,  F1-mac 0.5362
oral,dgl,1,1986,144.9034,0.8484

 F1-mic 0.8507,  F1-mac 0.5462
oral,dgl,1,1987,144.9762,0.8507

 F1-mic 0.8494,  F1-mac 0.5362
oral,dgl,1,1988,145.0491,0.8494

 F1-mic 0.8510,  F1-mac 0.5470
new best val f1: 0.8509722980554039
oral,dgl,1,1989,145.1219,0.8510

epoch:1991/50, Iteration 32/32:training loss 0.5323712229728699
Train F1-mic 0.8507, Train F1-mac 0.5468
 F1-mic 0.8502,  F1-mac 0.5381
oral,dgl,1,1990,145.1948,0.8502

 F1-mic 0.8504,  F1-mac 0.5451
oral,dgl,1,1991,145.2669,0.8504

 F1-mic 0.8505,  F1-mac 0.5404
oral,dgl,1,1992,145.3396,0.8505

 F1-mic 0.8499,  F1-mac 0.5423
oral,dgl,1,1993,145.4124,0.8499

 F1-mic 0.8509,  F1-mac 0.5451
oral,dgl,1,1994,145.4854,0.8509

 F1-mic 0.8496,  F1-mac 0.5370
oral,dgl,1,1995,145.5583,0.8496

 F1-mic 0.8510,  F1-mac 0.5474
new best val f1: 0.8509812980374039
oral,dgl,1,1996,145.6311,0.8510

 F1-mic 0.8499,  F1-mac 0.5354
oral,dgl,1,1997,145.7038,0.8499

 F1-mic 0.8508,  F1-mac 0.5474
oral,dgl,1,1998,145.7767,0.8508

 F1-mic 0.8504,  F1-mac 0.5378
oral,dgl,1,1999,145.8494,0.8504

training using time 1212.9219725131989
Test F1-mic 0.8504, Test F1-mac 0.5378
